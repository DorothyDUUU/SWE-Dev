{
  "dir_path": "/app/elasticsearch_curator",
  "package_name": "elasticsearch_curator",
  "sample_name": "elasticsearch_curator-test_helpers_getters",
  "src_dir": "curator/",
  "test_dir": "tests/",
  "test_file": "tests/unit/test_helpers_getters.py",
  "test_code": "\"\"\"Unit testing for helpers.creators functions\"\"\"\n\nfrom unittest import TestCase\nfrom unittest.mock import Mock\nimport pytest\nfrom elastic_transport import ApiResponseMeta\nfrom elasticsearch8 import NotFoundError, TransportError\nfrom curator.exceptions import CuratorException, FailedExecution, MissingArgument\nfrom curator.helpers import getters\n\nFAKE_FAIL = Exception('Simulated Failure')\nNAMED_INDICES = [\"index-2015.01.01\", \"index-2015.02.01\"]\nREPO_NAME = 'repo_name'\nTEST_REPO = {REPO_NAME: {}}\nSNAP_NAME = 'snap_name'\nSINGLE = {'snapshot': SNAP_NAME, 'indices': NAMED_INDICES}\nSNAPSHOT = {'snapshots': [SINGLE]}\nSNAPSHOTS = {\n    'snapshots': [SINGLE, {'snapshot': 'snapshot-2015.03.01', 'indices': NAMED_INDICES}]\n}\n\n\nclass TestByteSize(TestCase):\n    \"\"\"TestByteSize\n\n    Test helpers.getters.byte_size functionality.\n    \"\"\"\n\n    def test_byte_size(self):\n        \"\"\"test_byte_size\n\n        Output should match expected\n        \"\"\"\n        size = 3 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024\n        unit = ['Z', 'E', 'P', 'T', 'G', 'M', 'K', '']\n        for i in range(0, 7):\n            assert f'3.0{unit[i]}B' == getters.byte_size(size)\n            size /= 1024\n\n    def test_byte_size_yotta(self):\n        \"\"\"test_byte_size_yotta\n\n        Output should match expected\n        \"\"\"\n        size = 3 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024\n        assert '3.0YB' == getters.byte_size(size)\n\n    def test_raise_invalid(self):\n        \"\"\"test_raise_invalid\n\n        Should raise a TypeError exception if an invalid value is passed\n        \"\"\"\n        with pytest.raises(TypeError):\n            getters.byte_size('invalid')\n\n\nclass TestGetIndices(TestCase):\n    \"\"\"TestGetIndices\n\n    Test helpers.getters.get_indices functionality.\n    \"\"\"\n\n    IDX1 = 'index-2016.03.03'\n    IDX2 = 'index-2016.03.04'\n    RESPONSE = [{'index': IDX1, 'state': 'open'}, {'index': IDX2, 'state': 'open'}]\n\n    def test_client_exception(self):\n        \"\"\"test_client_exception\n\n        Should raise a FailedExecution exception when an upstream exception occurs\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = self.RESPONSE\n        client.cat.indices.side_effect = FAKE_FAIL\n        with pytest.raises(FailedExecution):\n            getters.get_indices(client)\n\n    def test_positive(self):\n        \"\"\"test_positive\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = self.RESPONSE\n        self.assertEqual([self.IDX1, self.IDX2], sorted(getters.get_indices(client)))\n\n    def test_empty(self):\n        \"\"\"test_empty\n\n        Output should be an empty list\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = {}\n        self.assertEqual([], getters.get_indices(client))\n\n\nclass TestGetRepository(TestCase):\n    \"\"\"TestGetRepository\n\n    Test helpers.getters.get_repository functionality.\n    \"\"\"\n\n    MULTI = {'other': {}, REPO_NAME: {}}\n\n    def test_get_repository_missing_arg(self):\n        \"\"\"test_get_repository_missing_arg\n\n        Should return an empty response if no repository name provided\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = {}\n        assert not getters.get_repository(client)\n\n    def test_get_repository_positive(self):\n        \"\"\"test_get_repository_positive\n\n        Return value should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        assert TEST_REPO == getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_transporterror_negative(self):\n        \"\"\"test_get_repository_transporterror_negative\n\n        Should raise a CuratorException if a TransportError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.side_effect = TransportError(\n            503, ('exception', 'reason')\n        )\n        with pytest.raises(CuratorException, match=r'503 Check Elasticsearch logs'):\n            getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_notfounderror_negative(self):\n        \"\"\"test_get_repository_notfounderror_negative\n\n        Should raise a CuratorException if a NotFoundError is raised first\n        \"\"\"\n        client = Mock()\n        # 5 positional args for meta: status, http_version, headers, duration, node\n        meta = ApiResponseMeta(404, '1.1', {}, 0.01, None)\n        body = 'simulated error'\n        msg = 'simulated error'\n        # 3 positional args for NotFoundError: message, meta, body\n        effect = NotFoundError(msg, meta, body)\n        client.snapshot.get_repository.side_effect = effect\n        with pytest.raises(CuratorException, match=r'Error: NotFoundError'):\n            getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_all_positive(self):\n        \"\"\"test_get_repository_all_positive\n\n        Return value should match expected with multiple repositories\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = self.MULTI\n        assert self.MULTI == getters.get_repository(client)\n\n\nclass TestGetSnapshot(TestCase):\n    \"\"\"TestGetSnapshot\n\n    Test helpers.getters.get_snapshot functionality.\n    \"\"\"\n\n    def test_get_snapshot_missing_repository_arg(self):\n        \"\"\"test_get_snapshot_missing_repository_arg\n\n        Should raise a MissingArgument exception when repository not passed\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'No value for \"repository\" provided'\n        ):\n            getters.get_snapshot(client, snapshot=SNAP_NAME)\n\n    def test_get_snapshot_positive(self):\n        \"\"\"test_get_snapshot_positive\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOT\n        assert SNAPSHOT == getters.get_snapshot(\n            client, repository=REPO_NAME, snapshot=SNAP_NAME\n        )\n\n    def test_get_snapshot_transporterror_negative(self):\n        \"\"\"test_get_snapshot_transporterror_negative\n\n        Should raise a FailedExecution exception if a TransportError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        client.snapshot.get.side_effect = TransportError(401, \"simulated error\")\n        with pytest.raises(FailedExecution, match=r'Error: 401'):\n            getters.get_snapshot(client, repository=REPO_NAME, snapshot=SNAP_NAME)\n\n    def test_get_snapshot_notfounderror_negative(self):\n        \"\"\"test_get_snapshot_notfounderror_negative\n\n        Should raise a FailedExecution exception if a NotFoundError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        # 5 positional args for meta: status, http_version, headers, duration, node\n        meta = ApiResponseMeta(404, '1.1', {}, 1.0, None)\n        client.snapshot.get.side_effect = NotFoundError(\n            'simulated error', meta, 'simulated error'\n        )\n        with pytest.raises(FailedExecution, match=r'Error: NotFoundError'):\n            getters.get_snapshot(client, repository=REPO_NAME, snapshot=SNAP_NAME)\n\n\nclass TestGetSnapshotData(TestCase):\n    \"\"\"TestGetSnapshotData\n\n    Test helpers.getters.get_snapshot_data functionality.\n    \"\"\"\n\n    def test_missing_repo_arg(self):\n        \"\"\"test_missing_repo_arg\n\n        Should raise a MissingArgument exception if the repository arg is missing\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'No value for \"repository\" provided'\n        ):\n            getters.get_snapshot_data(client)\n\n    def test_return_data(self):\n        \"\"\"test_return_data\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOTS\n        client.snapshot.get_repository.return_value = TEST_REPO\n        assert SNAPSHOTS['snapshots'] == getters.get_snapshot_data(\n            client, repository=REPO_NAME\n        )\n\n    def test_raises_exception_onfail(self):\n        \"\"\"test_raises_exception_onfail\n\n        Should raise a FailedExecution exception if a TransportError is raised upstream\n        first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOTS\n        client.snapshot.get.side_effect = TransportError(401, \"simulated error\")\n        client.snapshot.get_repository.return_value = TEST_REPO\n        with pytest.raises(FailedExecution, match=r'Error: 401'):\n            getters.get_snapshot_data(client, repository=REPO_NAME)\n\n\nclass TestNodeRoles(TestCase):\n    \"\"\"TestNodeRoles\n\n    Test helpers.getters.node_roles functionality.\n    \"\"\"\n\n    def test_node_roles(self):\n        \"\"\"test_node_roles\n\n        Output should match expected\n        \"\"\"\n        node_id = 'my_node'\n        expected = ['data']\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'roles': expected}}}\n        assert expected == getters.node_roles(client, node_id)\n\n\nclass TestSingleDataPath(TestCase):\n    \"\"\"TestSingleDataPath\n\n    Test helpers.getters.single_data_path functionality.\n    \"\"\"\n\n    def test_single_data_path(self):\n        \"\"\"test_single_data_path\n\n        Return value should be True with only one data path\n        \"\"\"\n        node_id = 'my_node'\n        client = Mock()\n        client.nodes.stats.return_value = {\n            'nodes': {node_id: {'fs': {'data': ['one']}}}\n        }\n        assert getters.single_data_path(client, node_id)\n\n    def test_two_data_paths(self):\n        \"\"\"test_two_data_paths\n\n        Return value should be False with two data paths\n        \"\"\"\n        node_id = 'my_node'\n        client = Mock()\n        client.nodes.stats.return_value = {\n            'nodes': {node_id: {'fs': {'data': ['one', 'two']}}}\n        }\n        assert not getters.single_data_path(client, node_id)\n\n\nclass TestNameToNodeId(TestCase):\n    \"\"\"TestNameToNodeId\n\n    Test helpers.getters.name_to_node_id functionality.\n    \"\"\"\n\n    def test_positive(self):\n        \"\"\"test_positive\n\n        Output should match expected\n        \"\"\"\n        node_id = 'node_id'\n        node_name = 'node_name'\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'name': node_name}}}\n        assert node_id == getters.name_to_node_id(client, node_name)\n\n    def test_negative(self):\n        \"\"\"test_negative\n\n        Output should be None due to mismatch\n        \"\"\"\n        node_id = 'node_id'\n        node_name = 'node_name'\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'name': node_name}}}\n        assert None is getters.name_to_node_id(client, 'wrong_name')\n\n\nclass TestNodeIdToName(TestCase):\n    \"\"\"TestNodeIdToName\n\n    Test helpers.getters.node_id_to_name functionality.\n    \"\"\"\n\n    def test_negative(self):\n        \"\"\"test_negative\n\n        Output should be None due to mismatch\n        \"\"\"\n        client = Mock()\n        client.nodes.info.return_value = {\n            'nodes': {'my_node_id': {'name': 'my_node_name'}}\n        }\n        assert None is getters.node_id_to_name(client, 'not_my_node_id')\n\n\nclass TestGetAliasActions(TestCase):\n    \"\"\"TestGetAliasActions\n\n    Test helpers.getters.get_alias_actions functionality.\n    \"\"\"\n\n    def test_get_alias_actions(self):\n        \"\"\"test_get_alias_actions\"\"\"\n        name = 'alias1'\n        aliases = {name: {}}\n        oldidx = 'old'\n        newidx = 'new'\n        expected = [\n            {'remove': {'index': oldidx, 'alias': name}},\n            {'add': {'index': newidx, 'alias': name}},\n        ]\n        assert getters.get_alias_actions(oldidx, newidx, aliases) == expected\n\n\nclass TestGetTierPreference(TestCase):\n    \"\"\"TestGetTierPreference\n\n    Test helpers.getters.get_tier_preference functionality.\n    \"\"\"\n\n    def test_get_tier_preference1(self):\n        \"\"\"test_get_tier_preference1\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_frozen', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_frozen'\n\n    def test_get_tier_preference2(self):\n        \"\"\"test_get_tier_preference2\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_cold,data_warm,data_hot'\n\n    def test_get_tier_preference3(self):\n        \"\"\"test_get_tier_preference3\"\"\"\n        client = Mock()\n        roles = ['data_content']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_content'\n\n    def test_get_tier_preference4(self):\n        \"\"\"test_get_tier_preference4\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_frozen', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert (\n            getters.get_tier_preference(client, target_tier='data_cold')\n            == 'data_cold,data_warm,data_hot'\n        )\n\n    def test_get_tier_preference5(self):\n        \"\"\"test_get_tier_preference5\"\"\"\n        client = Mock()\n        roles = ['data_content']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert (\n            getters.get_tier_preference(client, target_tier='data_hot')\n            == 'data_content'\n        )\n",
  "GT_file_code": {
    "curator/helpers/getters.py": "\"\"\"Utility functions that get things\"\"\"\n\nimport logging\nfrom elasticsearch8 import exceptions as es8exc\nfrom curator.exceptions import (\n    ConfigurationError,\n    CuratorException,\n    FailedExecution,\n    MissingArgument,\n)\n\n\ndef byte_size(num, suffix='B'):\n    \"\"\"\n    :param num: The number of byte\n    :param suffix: An arbitrary suffix, like ``Bytes``\n\n    :type num: int\n    :type suffix: str\n\n    :returns: A formatted string indicating the size in bytes, with the proper unit,\n        e.g. KB, MB, GB, TB, etc.\n    :rtype: float\n    \"\"\"\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return f'{num:3.1f}{unit}{suffix}'\n        num /= 1024.0\n    return f'{num:.1f}Y{suffix}'\n\n\ndef escape_dots(stringval):\n    \"\"\"\n    Escape any dots (periods) in ``stringval``.\n\n    Primarily used for ``filter_path`` where dots are indicators of path nesting\n\n    :param stringval: A string, ostensibly an index name\n\n    :type stringval: str\n\n    :returns: ``stringval``, but with any periods escaped with a backslash\n    :retval: str\n    \"\"\"\n    return stringval.replace('.', r'\\.')\n\n\ndef get_alias_actions(oldidx, newidx, aliases):\n    \"\"\"\n    :param oldidx: The old index name\n    :param newidx: The new index name\n    :param aliases: The aliases\n\n    :type oldidx: str\n    :type newidx: str\n    :type aliases: dict\n\n    :returns: A list of actions suitable for\n        :py:meth:`~.elasticsearch.client.IndicesClient.update_aliases` ``actions``\n        kwarg.\n    :rtype: list\n    \"\"\"\n    actions = []\n    for alias in aliases.keys():\n        actions.append({'remove': {'index': oldidx, 'alias': alias}})\n        actions.append({'add': {'index': newidx, 'alias': alias}})\n    return actions\n\n\ndef get_data_tiers(client):\n    \"\"\"\n    Get all valid data tiers from the node roles of each node in the cluster by\n    polling each node\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The available data tiers in ``tier: bool`` form.\n    :rtype: dict\n    \"\"\"\n\n    def role_check(role, node_info):\n        if role in node_info['roles']:\n            return True\n        return False\n\n    info = client.nodes.info()['nodes']\n    retval = {\n        'data_hot': False,\n        'data_warm': False,\n        'data_cold': False,\n        'data_frozen': False,\n    }\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            # This guarantees we don't overwrite a True with a False.\n            # We only add True values\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval\n\n\ndef get_indices(client, search_pattern='_all'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.CatClient.indices`\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The current list of indices from the cluster\n    :rtype: list\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    indices = []\n    try:\n        # Doing this in two stages because IndexList also calls for these args,\n        # and the unit tests need to Mock this call the same exact way.\n        resp = client.cat.indices(\n            index=search_pattern,\n            expand_wildcards='open,closed',\n            h='index,status',\n            format='json',\n        )\n    except Exception as err:\n        raise FailedExecution(f'Failed to get indices. Error: {err}') from err\n    if not resp:\n        return indices\n    for entry in resp:\n        indices.append(entry['index'])\n    logger.debug('All indices: %s', indices)\n    return indices\n\n\ndef get_repository(client, repository=''):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get_repository`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n\n    :returns: Configuration information for ``repository``.\n    :rtype: dict\n    \"\"\"\n    try:\n        return client.snapshot.get_repository(name=repository)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get repository {repository}.  Error: {err} Check Elasticsearch '\n            f'logs for more information.'\n        )\n        raise CuratorException(msg) from err\n\n\ndef get_snapshot(client, repository=None, snapshot=''):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n    :param snapshot: The snapshot name, or a comma-separated list of snapshots\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n    :type snapshot: str\n\n    :returns: Information about the provided ``snapshot``, a snapshot (or a\n        comma-separated list of snapshots). If no snapshot specified, it will\n        collect info for all snapshots.  If none exist, an empty :py:class:`dict`\n        will be returned.\n    :rtype: dict\n    \"\"\"\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    snapname = '*' if snapshot == '' else snapshot\n    try:\n        return client.snapshot.get(repository=repository, snapshot=snapshot)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get information about snapshot {snapname} from repository: '\n            f'{repository}.  Error: {err}'\n        )\n        raise FailedExecution(msg) from err\n\n\ndef get_snapshot_data(client, repository=None):\n    \"\"\"\n    Get all snapshots from repository and return a list.\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n\n    :returns: The list of all snapshots from ``repository``\n    :rtype: list\n    \"\"\"\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    try:\n        return client.snapshot.get(repository=repository, snapshot=\"*\")['snapshots']\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get snapshot information from repository: '\n            f'{repository}. Error: {err}'\n        )\n        raise FailedExecution(msg) from err\n\n\ndef get_tier_preference(client, target_tier='data_frozen'):\n    \"\"\"Do the tier preference thing in reverse order from coldest to hottest\n    Based on the value of ``target_tier``, build out the list to use.\n\n    :param client: A client connection object\n    :param target_tier: The target data tier, e.g. data_warm.\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type target_tier: str\n\n    :returns: A suitable tier preference string in csv format\n    :rtype: str\n    \"\"\"\n    tiermap = {\n        'data_content': 0,\n        'data_hot': 1,\n        'data_warm': 2,\n        'data_cold': 3,\n        'data_frozen': 4,\n    }\n    tiers = get_data_tiers(client)\n    test_list = []\n    for tier in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n        if tier in tiers and tiermap[tier] <= tiermap[target_tier]:\n            test_list.insert(0, tier)\n    if target_tier == 'data_frozen':\n        # We're migrating to frozen here. If a frozen tier exists, frozen searchable\n        # snapshot mounts should only ever go to the frozen tier.\n        if 'data_frozen' in tiers and tiers['data_frozen']:\n            return 'data_frozen'\n    # If there are no  nodes with the 'data_frozen' role...\n    preflist = []\n    for key in test_list:\n        # This ordering ensures that colder tiers are prioritized\n        if key in tiers and tiers[key]:\n            preflist.append(key)\n    # If all of these are false, then we have no data tiers and must use 'data_content'\n    if not preflist:\n        return 'data_content'\n    # This will join from coldest to hottest as csv string,\n    # e.g. 'data_cold,data_warm,data_hot'\n    return ','.join(preflist)\n\n\ndef get_write_index(client, alias):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param alias: An alias name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type alias: str\n\n    :returns: The the index name associated with the alias that is designated\n        ``is_write_index``\n    :rtype: str\n    \"\"\"\n    try:\n        response = client.indices.get_alias(index=alias)\n    except Exception as exc:\n        raise CuratorException(f'Alias {alias} not found') from exc\n    # If there are more than one in the list, one needs to be the write index\n    # otherwise the alias is a one to many, and can't do rollover.\n    retval = None\n    if len(list(response.keys())) > 1:\n        for index in list(response.keys()):\n            try:\n                if response[index]['aliases'][alias]['is_write_index']:\n                    retval = index\n            except KeyError as exc:\n                raise FailedExecution(\n                    'Invalid alias: is_write_index not found in 1 to many alias'\n                ) from exc\n    else:\n        # There's only one, so this is it\n        retval = list(response.keys())[0]\n    return retval\n\n\ndef index_size(client, idx, value='total'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.stats`\n\n    :param client: A client connection object\n    :param idx: An index name\n    :param value: One of either ``primaries`` or ``total``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type value: str\n\n    :returns: The sum of either ``primaries`` or ``total`` shards for index ``idx``\n    :rtype: integer\n    \"\"\"\n    fpath = f'indices.{escape_dots(idx)}.{value}.store.size_in_bytes'\n    return client.indices.stats(index=idx, filter_path=fpath)['indices'][idx][value][\n        'store'\n    ]['size_in_bytes']\n\n\ndef meta_getter(client, idx, get=None):\n    \"\"\"Meta Getter\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_settings` or\n    :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param idx: An Elasticsearch index\n    :param get: The kind of get to perform, e.g. settings or alias\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type get: str\n\n    :returns: The settings from the get call to the named index\n    :rtype: dict\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    acceptable = ['settings', 'alias']\n    if not get:\n        raise ConfigurationError('\"get\" can not be a NoneType')\n    if get not in acceptable:\n        raise ConfigurationError(f'\"get\" must be one of {acceptable}')\n    retval = {}\n    try:\n        if get == 'settings':\n            retval = client.indices.get_settings(index=idx)[idx]['settings']['index']\n        elif get == 'alias':\n            retval = client.indices.get_alias(index=idx)[idx]['aliases']\n    except es8exc.NotFoundError as missing:\n        logger.error('Index %s was not found!', idx)\n        raise es8exc.NotFoundError from missing\n    except KeyError as err:\n        logger.error('Key not found: %s', err)\n        raise KeyError from err\n    # pylint: disable=broad-except\n    except Exception as exc:\n        logger.error('Exception encountered: %s', exc)\n    return retval\n\n\ndef name_to_node_id(client, name):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param name: The node ``name``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type name: str\n\n    :returns: The node_id of the node identified by ``name``\n    :rtype: str\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    fpath = 'nodes'\n    info = client.nodes.info(filter_path=fpath)\n    for node in info['nodes']:\n        if info['nodes'][node]['name'] == name:\n            logger.debug('Found node_id \"%s\" for name \"%s\".', node, name)\n            return node\n    logger.error('No node_id found matching name: \"%s\"', name)\n    return None\n\n\ndef node_id_to_name(client, node_id):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: The name of the node identified by ``node_id``\n    :rtype: str\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    fpath = f'nodes.{node_id}.name'\n    info = client.nodes.info(filter_path=fpath)\n    name = None\n    if node_id in info['nodes']:\n        name = info['nodes'][node_id]['name']\n    else:\n        logger.error('No node_id found matching: \"%s\"', node_id)\n    logger.debug('Name associated with node_id \"%s\": %s', node_id, name)\n    return name\n\n\ndef node_roles(client, node_id):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: The list of roles assigned to the node identified by ``node_id``\n    :rtype: list\n    \"\"\"\n    fpath = f'nodes.{node_id}.roles'\n    return client.nodes.info(filter_path=fpath)['nodes'][node_id]['roles']\n\n\ndef single_data_path(client, node_id):\n    \"\"\"\n    In order for a shrink to work, it should be on a single filesystem, as shards\n    cannot span filesystems. Calls :py:meth:`~.elasticsearch.client.NodesClient.stats`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: ``True`` if the node has a single filesystem, else ``False``\n    :rtype: bool\n    \"\"\"\n    fpath = f'nodes.{node_id}.fs.data'\n    response = client.nodes.stats(filter_path=fpath)\n    return len(response['nodes'][node_id]['fs']['data']) == 1\n",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\"\n"
  },
  "GT_src_dict": {
    "curator/helpers/getters.py": {
      "byte_size": {
        "code": "def byte_size(num, suffix='B'):\n    \"\"\"Convert a byte size to a human-readable format.\n\nThis function takes a number representing a size in bytes and converts it to a formatted string that includes the appropriate unit, such as KB, MB, GB, etc. The conversion is based on powers of 1024, as is standard in computing.\n\nParameters:\n- num (int): The number of bytes to be converted.\n- suffix (str): An optional suffix to append to the size (default is 'B').\n\nReturns:\n- str: A formatted string representing the size, such as '1.5MB', '512.0KB'.\n\nThe function does not modify any external state and relies only on its parameters for calculations. It iterates through a list of unit prefixes corresponding to byte size (from bytes to zettabytes) to determine the correct output format.\"\"\"\n    '\\n    :param num: The number of byte\\n    :param suffix: An arbitrary suffix, like ``Bytes``\\n\\n    :type num: int\\n    :type suffix: str\\n\\n    :returns: A formatted string indicating the size in bytes, with the proper unit,\\n        e.g. KB, MB, GB, TB, etc.\\n    :rtype: float\\n    '\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return f'{num:3.1f}{unit}{suffix}'\n        num /= 1024.0\n    return f'{num:.1f}Y{suffix}'",
        "docstring": "Convert a byte size to a human-readable format.\n\nThis function takes a number representing a size in bytes and converts it to a formatted string that includes the appropriate unit, such as KB, MB, GB, etc. The conversion is based on powers of 1024, as is standard in computing.\n\nParameters:\n- num (int): The number of bytes to be converted.\n- suffix (str): An optional suffix to append to the size (default is 'B').\n\nReturns:\n- str: A formatted string representing the size, such as '1.5MB', '512.0KB'.\n\nThe function does not modify any external state and relies only on its parameters for calculations. It iterates through a list of unit prefixes corresponding to byte size (from bytes to zettabytes) to determine the correct output format.",
        "signature": "def byte_size(num, suffix='B'):",
        "type": "Function",
        "class_signature": null
      },
      "get_alias_actions": {
        "code": "def get_alias_actions(oldidx, newidx, aliases):\n    \"\"\"Generates a list of alias actions to update Elasticsearch index aliases.\n\n:param oldidx: The name of the old index from which aliases are being removed.\n:type oldidx: str\n:param newidx: The name of the new index to which aliases are being added.\n:type newidx: str\n:param aliases: A dictionary containing the aliases that need to be updated.\n:type aliases: dict\n\n:returns: A list of actions formatted for use with `elasticsearch.client.IndicesClient.update_aliases`,\n          including 'remove' actions for the old index and 'add' actions for the new index.\n:rtype: list\n\nThis function is a utility for managing alias updates when an index is replaced, \nensuring that aliases are properly redirected to the new index. It does not modify any \nstate directly but prepares the necessary data for subsequent API calls to Elasticsearch.\"\"\"\n    '\\n    :param oldidx: The old index name\\n    :param newidx: The new index name\\n    :param aliases: The aliases\\n\\n    :type oldidx: str\\n    :type newidx: str\\n    :type aliases: dict\\n\\n    :returns: A list of actions suitable for\\n        :py:meth:`~.elasticsearch.client.IndicesClient.update_aliases` ``actions``\\n        kwarg.\\n    :rtype: list\\n    '\n    actions = []\n    for alias in aliases.keys():\n        actions.append({'remove': {'index': oldidx, 'alias': alias}})\n        actions.append({'add': {'index': newidx, 'alias': alias}})\n    return actions",
        "docstring": "Generates a list of alias actions to update Elasticsearch index aliases.\n\n:param oldidx: The name of the old index from which aliases are being removed.\n:type oldidx: str\n:param newidx: The name of the new index to which aliases are being added.\n:type newidx: str\n:param aliases: A dictionary containing the aliases that need to be updated.\n:type aliases: dict\n\n:returns: A list of actions formatted for use with `elasticsearch.client.IndicesClient.update_aliases`,\n          including 'remove' actions for the old index and 'add' actions for the new index.\n:rtype: list\n\nThis function is a utility for managing alias updates when an index is replaced, \nensuring that aliases are properly redirected to the new index. It does not modify any \nstate directly but prepares the necessary data for subsequent API calls to Elasticsearch.",
        "signature": "def get_alias_actions(oldidx, newidx, aliases):",
        "type": "Function",
        "class_signature": null
      },
      "get_data_tiers": {
        "code": "def get_data_tiers(client):\n    \"\"\"Get the availability of data tiers (hot, warm, cold, frozen) in an Elasticsearch cluster by inspecting the roles of each node. \n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: A dictionary indicating the availability of each data tier, structured as ``{'data_hot': bool, 'data_warm': bool, 'data_cold': bool, 'data_frozen': bool}``. Each key corresponds to a data tier and the boolean value indicates whether that tier is present in the cluster.\n:rtype: dict\n\nThe function utilizes the roles defined in the node information obtained from the `client.nodes.info()` method to determine the tiers' availability. It initializes a return dictionary with all data tier keys set to `False` and updates the values to `True` if any node is found to have that role. The `role_check` inner function is used to verify if a role exists in a node's roles, preventing overwriting of `True` values with `False`.\"\"\"\n    '\\n    Get all valid data tiers from the node roles of each node in the cluster by\\n    polling each node\\n\\n    :param client: A client connection object\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n\\n    :returns: The available data tiers in ``tier: bool`` form.\\n    :rtype: dict\\n    '\n\n    def role_check(role, node_info):\n        if role in node_info['roles']:\n            return True\n        return False\n    info = client.nodes.info()['nodes']\n    retval = {'data_hot': False, 'data_warm': False, 'data_cold': False, 'data_frozen': False}\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval",
        "docstring": "Get the availability of data tiers (hot, warm, cold, frozen) in an Elasticsearch cluster by inspecting the roles of each node. \n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: A dictionary indicating the availability of each data tier, structured as ``{'data_hot': bool, 'data_warm': bool, 'data_cold': bool, 'data_frozen': bool}``. Each key corresponds to a data tier and the boolean value indicates whether that tier is present in the cluster.\n:rtype: dict\n\nThe function utilizes the roles defined in the node information obtained from the `client.nodes.info()` method to determine the tiers' availability. It initializes a return dictionary with all data tier keys set to `False` and updates the values to `True` if any node is found to have that role. The `role_check` inner function is used to verify if a role exists in a node's roles, preventing overwriting of `True` values with `False`.",
        "signature": "def get_data_tiers(client):",
        "type": "Function",
        "class_signature": null
      },
      "get_indices": {
        "code": "def get_indices(client, search_pattern='_all'):\n    \"\"\"Retrieve a list of indices from an Elasticsearch cluster.\n\n:param client: A client connection object to interact with Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param search_pattern: A search pattern to filter indices (default is '_all' to retrieve all indices).\n:type search_pattern: str\n\n:returns: A list containing the names of indices present in the cluster.\n:rtype: list\n\n:raises FailedExecution: If there is an error while fetching the indices, an exception is raised.\n\nThe function utilizes the client's `cat.indices` method to get a JSON-formatted list of indices and their statuses. It expands wildcards to include both open and closed indices, ensuring comprehensive retrieval. The function logs the complete list of indices and handles exceptions gracefully, converting them into a `FailedExecution` error to indicate the failure to retrieve indices. This functionality is essential in managing and analyzing data states within the Elasticsearch ecosystem.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.CatClient.indices`\\n\\n    :param client: A client connection object\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n\\n    :returns: The current list of indices from the cluster\\n    :rtype: list\\n    '\n    logger = logging.getLogger(__name__)\n    indices = []\n    try:\n        resp = client.cat.indices(index=search_pattern, expand_wildcards='open,closed', h='index,status', format='json')\n    except Exception as err:\n        raise FailedExecution(f'Failed to get indices. Error: {err}') from err\n    if not resp:\n        return indices\n    for entry in resp:\n        indices.append(entry['index'])\n    logger.debug('All indices: %s', indices)\n    return indices",
        "docstring": "Retrieve a list of indices from an Elasticsearch cluster.\n\n:param client: A client connection object to interact with Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param search_pattern: A search pattern to filter indices (default is '_all' to retrieve all indices).\n:type search_pattern: str\n\n:returns: A list containing the names of indices present in the cluster.\n:rtype: list\n\n:raises FailedExecution: If there is an error while fetching the indices, an exception is raised.\n\nThe function utilizes the client's `cat.indices` method to get a JSON-formatted list of indices and their statuses. It expands wildcards to include both open and closed indices, ensuring comprehensive retrieval. The function logs the complete list of indices and handles exceptions gracefully, converting them into a `FailedExecution` error to indicate the failure to retrieve indices. This functionality is essential in managing and analyzing data states within the Elasticsearch ecosystem.",
        "signature": "def get_indices(client, search_pattern='_all'):",
        "type": "Function",
        "class_signature": null
      },
      "get_repository": {
        "code": "def get_repository(client, repository=''):\n    \"\"\"Retrieve configuration information for a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the snapshot repository to retrieve (default is an empty string, which indicates no repository).\n\n:raises CuratorException: If the repository cannot be found or if there is a transport error during the request, an exception is raised with a detailed message that includes the error encountered.\n\n:returns: A dictionary containing the configuration details of the specified snapshot repository.\n\nThis function interacts with the Elasticsearch snapshot client's `get_repository` method, leveraging the `name` parameter to specify the desired repository. It handles exceptions related to transport errors and not-found errors by raising a `CuratorException`, ensuring appropriate error messaging for users.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get_repository`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n\\n    :returns: Configuration information for ``repository``.\\n    :rtype: dict\\n    '\n    try:\n        return client.snapshot.get_repository(name=repository)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get repository {repository}.  Error: {err} Check Elasticsearch logs for more information.'\n        raise CuratorException(msg) from err",
        "docstring": "Retrieve configuration information for a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the snapshot repository to retrieve (default is an empty string, which indicates no repository).\n\n:raises CuratorException: If the repository cannot be found or if there is a transport error during the request, an exception is raised with a detailed message that includes the error encountered.\n\n:returns: A dictionary containing the configuration details of the specified snapshot repository.\n\nThis function interacts with the Elasticsearch snapshot client's `get_repository` method, leveraging the `name` parameter to specify the desired repository. It handles exceptions related to transport errors and not-found errors by raising a `CuratorException`, ensuring appropriate error messaging for users.",
        "signature": "def get_repository(client, repository=''):",
        "type": "Function",
        "class_signature": null
      },
      "get_snapshot": {
        "code": "def get_snapshot(client, repository=None, snapshot=''):\n    \"\"\"Retrieve information about a specified snapshot from a given Elasticsearch snapshot repository. If no specific snapshot is provided, it retrieves information for all snapshots within the repository.\n\nParameters:\n- client (Elasticsearch): A connection object for interacting with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository from which to retrieve snapshots. This parameter is required and should not be None.\n- snapshot (str): The name of the snapshot to retrieve, or a comma-separated list of snapshots. If left empty, it defaults to '*', indicating all snapshots.\n\nReturns:\n- dict: A dictionary containing details about the specified snapshot(s). If no snapshots exist, an empty dictionary is returned.\n\nRaises:\n- MissingArgument: If the 'repository' parameter is not provided.\n- FailedExecution: If there is an error retrieving snapshot information, with details included in the error message.\n\nDependencies:\n- This function interacts with the `elasticsearch.client.SnapshotClient.get` method to perform the retrieval. \n- It also handles specific exceptions from the elasticsearch8 package, specifically `TransportError` and `NotFoundError`, signaling issues with the API request.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n    :param snapshot: The snapshot name, or a comma-separated list of snapshots\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n    :type snapshot: str\\n\\n    :returns: Information about the provided ``snapshot``, a snapshot (or a\\n        comma-separated list of snapshots). If no snapshot specified, it will\\n        collect info for all snapshots.  If none exist, an empty :py:class:`dict`\\n        will be returned.\\n    :rtype: dict\\n    '\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    snapname = '*' if snapshot == '' else snapshot\n    try:\n        return client.snapshot.get(repository=repository, snapshot=snapshot)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get information about snapshot {snapname} from repository: {repository}.  Error: {err}'\n        raise FailedExecution(msg) from err",
        "docstring": "Retrieve information about a specified snapshot from a given Elasticsearch snapshot repository. If no specific snapshot is provided, it retrieves information for all snapshots within the repository.\n\nParameters:\n- client (Elasticsearch): A connection object for interacting with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository from which to retrieve snapshots. This parameter is required and should not be None.\n- snapshot (str): The name of the snapshot to retrieve, or a comma-separated list of snapshots. If left empty, it defaults to '*', indicating all snapshots.\n\nReturns:\n- dict: A dictionary containing details about the specified snapshot(s). If no snapshots exist, an empty dictionary is returned.\n\nRaises:\n- MissingArgument: If the 'repository' parameter is not provided.\n- FailedExecution: If there is an error retrieving snapshot information, with details included in the error message.\n\nDependencies:\n- This function interacts with the `elasticsearch.client.SnapshotClient.get` method to perform the retrieval. \n- It also handles specific exceptions from the elasticsearch8 package, specifically `TransportError` and `NotFoundError`, signaling issues with the API request.",
        "signature": "def get_snapshot(client, repository=None, snapshot=''):",
        "type": "Function",
        "class_signature": null
      },
      "get_snapshot_data": {
        "code": "def get_snapshot_data(client, repository=None):\n    \"\"\"Retrieve all snapshots from a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object representing the connection to an Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository to query.\n:type repository: str\n\n:raises MissingArgument: If no value for `repository` is provided.\n:raises FailedExecution: If there is an issue retrieving snapshots from the repository due to transport errors or if the repository is not found.\n\n:return: A list of all snapshots in the specified repository.\n:rtype: list\n\nThis function interacts with the Elasticsearch SnapshotClient to retrieve snapshot information. It expects a valid repository name, and it returns a list of snapshots present in that repository. If the repository is not provided, it raises a `MissingArgument` exception. Errors during execution trigger a `FailedExecution` exception with a detailed error message.\"\"\"\n    '\\n    Get all snapshots from repository and return a list.\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n\\n    :returns: The list of all snapshots from ``repository``\\n    :rtype: list\\n    '\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    try:\n        return client.snapshot.get(repository=repository, snapshot='*')['snapshots']\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get snapshot information from repository: {repository}. Error: {err}'\n        raise FailedExecution(msg) from err",
        "docstring": "Retrieve all snapshots from a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object representing the connection to an Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository to query.\n:type repository: str\n\n:raises MissingArgument: If no value for `repository` is provided.\n:raises FailedExecution: If there is an issue retrieving snapshots from the repository due to transport errors or if the repository is not found.\n\n:return: A list of all snapshots in the specified repository.\n:rtype: list\n\nThis function interacts with the Elasticsearch SnapshotClient to retrieve snapshot information. It expects a valid repository name, and it returns a list of snapshots present in that repository. If the repository is not provided, it raises a `MissingArgument` exception. Errors during execution trigger a `FailedExecution` exception with a detailed error message.",
        "signature": "def get_snapshot_data(client, repository=None):",
        "type": "Function",
        "class_signature": null
      },
      "get_tier_preference": {
        "code": "def get_tier_preference(client, target_tier='data_frozen'):\n    \"\"\"Determine the preferred data tier for Elasticsearch operations based on a specified target tier.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param target_tier: The desired data tier to use, which can be one of 'data_hot', 'data_warm', 'data_cold', 'data_frozen'. Default is 'data_frozen'.\n:type target_tier: str\n\n:returns: A comma-separated string representing the preferred data tiers in order from coldest to hottest, or 'data_content' if no valid tiers are found.\n:rtype: str\n\nThis function utilizes the `get_data_tiers` function to fetch the available data tiers in the cluster and builds a preference list based on a pre-defined `tiermap`. The tiermap defines the hierarchy of data tiers, with 'data_content' being the least preferred and 'data_frozen' the most preferred. If the target tier is 'data_frozen' and such a tier is available, it is returned directly. If no valid tiers are identified, 'data_content' is returned as a fallback.\"\"\"\n    'Do the tier preference thing in reverse order from coldest to hottest\\n    Based on the value of ``target_tier``, build out the list to use.\\n\\n    :param client: A client connection object\\n    :param target_tier: The target data tier, e.g. data_warm.\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type target_tier: str\\n\\n    :returns: A suitable tier preference string in csv format\\n    :rtype: str\\n    '\n    tiermap = {'data_content': 0, 'data_hot': 1, 'data_warm': 2, 'data_cold': 3, 'data_frozen': 4}\n    tiers = get_data_tiers(client)\n    test_list = []\n    for tier in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n        if tier in tiers and tiermap[tier] <= tiermap[target_tier]:\n            test_list.insert(0, tier)\n    if target_tier == 'data_frozen':\n        if 'data_frozen' in tiers and tiers['data_frozen']:\n            return 'data_frozen'\n    preflist = []\n    for key in test_list:\n        if key in tiers and tiers[key]:\n            preflist.append(key)\n    if not preflist:\n        return 'data_content'\n    return ','.join(preflist)",
        "docstring": "Determine the preferred data tier for Elasticsearch operations based on a specified target tier.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param target_tier: The desired data tier to use, which can be one of 'data_hot', 'data_warm', 'data_cold', 'data_frozen'. Default is 'data_frozen'.\n:type target_tier: str\n\n:returns: A comma-separated string representing the preferred data tiers in order from coldest to hottest, or 'data_content' if no valid tiers are found.\n:rtype: str\n\nThis function utilizes the `get_data_tiers` function to fetch the available data tiers in the cluster and builds a preference list based on a pre-defined `tiermap`. The tiermap defines the hierarchy of data tiers, with 'data_content' being the least preferred and 'data_frozen' the most preferred. If the target tier is 'data_frozen' and such a tier is available, it is returned directly. If no valid tiers are identified, 'data_content' is returned as a fallback.",
        "signature": "def get_tier_preference(client, target_tier='data_frozen'):",
        "type": "Function",
        "class_signature": null
      },
      "name_to_node_id": {
        "code": "def name_to_node_id(client, name):\n    \"\"\"Retrieve the node_id corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node whose id is to be retrieved.\n:type name: str\n\n:returns: The node_id of the specified node name, or `None` if no matching node is found.\n:rtype: str\n\nThis function utilizes the `client.nodes.info()` method to gather information about nodes in the cluster. It logs debug information for successful retrievals and error messages for scenarios where no matching node_id is found. The `fpath` variable is defined within the function to specify the filter path for node information retrieval.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param name: The node ``name``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type name: str\\n\\n    :returns: The node_id of the node identified by ``name``\\n    :rtype: str\\n    '\n    logger = logging.getLogger(__name__)\n    fpath = 'nodes'\n    info = client.nodes.info(filter_path=fpath)\n    for node in info['nodes']:\n        if info['nodes'][node]['name'] == name:\n            logger.debug('Found node_id \"%s\" for name \"%s\".', node, name)\n            return node\n    logger.error('No node_id found matching name: \"%s\"', name)\n    return None",
        "docstring": "Retrieve the node_id corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node whose id is to be retrieved.\n:type name: str\n\n:returns: The node_id of the specified node name, or `None` if no matching node is found.\n:rtype: str\n\nThis function utilizes the `client.nodes.info()` method to gather information about nodes in the cluster. It logs debug information for successful retrievals and error messages for scenarios where no matching node_id is found. The `fpath` variable is defined within the function to specify the filter path for node information retrieval.",
        "signature": "def name_to_node_id(client, name):",
        "type": "Function",
        "class_signature": null
      },
      "node_id_to_name": {
        "code": "def node_id_to_name(client, node_id):\n    \"\"\"Retrieve the name of an Elasticsearch node identified by its unique `node_id`.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node whose name is to be retrieved.\n:type node_id: str\n\n:returns: The name of the node corresponding to the provided `node_id`, or `None` if not found.\n:rtype: str\n\nThis function leverages the `client.nodes.info` method to fetch node details, filtering the result to include only the name of the specified node. A logger is used to record any errors when a matching `node_id` is not found. The function constructs a filter path `fpath` as `nodes.{node_id}.name` to target relevant information in the Elasticsearch response.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: The name of the node identified by ``node_id``\\n    :rtype: str\\n    '\n    logger = logging.getLogger(__name__)\n    fpath = f'nodes.{node_id}.name'\n    info = client.nodes.info(filter_path=fpath)\n    name = None\n    if node_id in info['nodes']:\n        name = info['nodes'][node_id]['name']\n    else:\n        logger.error('No node_id found matching: \"%s\"', node_id)\n    logger.debug('Name associated with node_id \"%s\": %s', node_id, name)\n    return name",
        "docstring": "Retrieve the name of an Elasticsearch node identified by its unique `node_id`.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node whose name is to be retrieved.\n:type node_id: str\n\n:returns: The name of the node corresponding to the provided `node_id`, or `None` if not found.\n:rtype: str\n\nThis function leverages the `client.nodes.info` method to fetch node details, filtering the result to include only the name of the specified node. A logger is used to record any errors when a matching `node_id` is not found. The function constructs a filter path `fpath` as `nodes.{node_id}.name` to target relevant information in the Elasticsearch response.",
        "signature": "def node_id_to_name(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "node_roles": {
        "code": "def node_roles(client, node_id):\n    \"\"\"Retrieve the list of roles assigned to a specified node in an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node whose roles are being queried.\n:type node_id: str\n\n:returns: A list of roles assigned to the node identified by ``node_id``.\n:rtype: list\n\nThis function interacts with Elasticsearch's NodesClient to retrieve node information. It constructs a filter path based on the provided ``node_id`` to extract the roles from the node's information. The resulting roles provide insight into the node's responsibilities within the cluster, such as whether it handles data or serves as a master node.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: The list of roles assigned to the node identified by ``node_id``\\n    :rtype: list\\n    '\n    fpath = f'nodes.{node_id}.roles'\n    return client.nodes.info(filter_path=fpath)['nodes'][node_id]['roles']",
        "docstring": "Retrieve the list of roles assigned to a specified node in an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node whose roles are being queried.\n:type node_id: str\n\n:returns: A list of roles assigned to the node identified by ``node_id``.\n:rtype: list\n\nThis function interacts with Elasticsearch's NodesClient to retrieve node information. It constructs a filter path based on the provided ``node_id`` to extract the roles from the node's information. The resulting roles provide insight into the node's responsibilities within the cluster, such as whether it handles data or serves as a master node.",
        "signature": "def node_roles(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "single_data_path": {
        "code": "def single_data_path(client, node_id):\n    \"\"\"Check if a specified Elasticsearch node uses a single filesystem for data storage.\n\nThis function checks the filesystem data paths of a given node identified by its `node_id` to determine if there is only one filesystem. A single filesystem is necessary to perform shard shrinking, as shards cannot be spread across multiple filesystems.\n\n:param client: An Elasticsearch client connection object.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The identifier for the Elasticsearch node to check.\n:type node_id: str\n\n:returns: `True` if the node has a single filesystem; otherwise, returns `False`.\n:rtype: bool\n\nThis function interacts with the Elasticsearch cluster by calling the `nodes.stats` method, specifying a filter path to obtain the filesystem data for the node. The variable `fpath` defines the specific filter path used to access the node's filesystem data metrics, enabling the function to evaluate the length of the `data` field in the node\u2019s filesystem information.\"\"\"\n    '\\n    In order for a shrink to work, it should be on a single filesystem, as shards\\n    cannot span filesystems. Calls :py:meth:`~.elasticsearch.client.NodesClient.stats`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: ``True`` if the node has a single filesystem, else ``False``\\n    :rtype: bool\\n    '\n    fpath = f'nodes.{node_id}.fs.data'\n    response = client.nodes.stats(filter_path=fpath)\n    return len(response['nodes'][node_id]['fs']['data']) == 1",
        "docstring": "Check if a specified Elasticsearch node uses a single filesystem for data storage.\n\nThis function checks the filesystem data paths of a given node identified by its `node_id` to determine if there is only one filesystem. A single filesystem is necessary to perform shard shrinking, as shards cannot be spread across multiple filesystems.\n\n:param client: An Elasticsearch client connection object.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The identifier for the Elasticsearch node to check.\n:type node_id: str\n\n:returns: `True` if the node has a single filesystem; otherwise, returns `False`.\n:rtype: bool\n\nThis function interacts with the Elasticsearch cluster by calling the `nodes.stats` method, specifying a filter path to obtain the filesystem data for the node. The variable `fpath` defines the specific filter path used to access the node's filesystem data metrics, enabling the function to evaluate the length of the `data` field in the node\u2019s filesystem information.",
        "signature": "def single_data_path(client, node_id):",
        "type": "Function",
        "class_signature": null
      }
    },
    "curator/exceptions.py": {}
  },
  "dependency_dict": {
    "curator/helpers/getters.py:get_tier_preference": {},
    "curator/helpers/getters.py:get_data_tiers": {}
  },
  "call_tree": {
    "tests/unit/test_helpers_getters.py:TestByteSize:test_byte_size": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestByteSize:test_byte_size_yotta": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestByteSize:test_raise_invalid": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_client_exception": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_empty": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_positive": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_all_positive": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_missing_arg": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_notfounderror_negative": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_positive": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_transporterror_negative": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_missing_repository_arg": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_notfounderror_negative": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_positive": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_transporterror_negative": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_missing_repo_arg": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_raises_exception_onfail": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_return_data": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestNodeRoles:test_node_roles": {
      "curator/helpers/getters.py:node_roles": {}
    },
    "tests/unit/test_helpers_getters.py:TestSingleDataPath:test_single_data_path": {
      "curator/helpers/getters.py:single_data_path": {}
    },
    "tests/unit/test_helpers_getters.py:TestSingleDataPath:test_two_data_paths": {
      "curator/helpers/getters.py:single_data_path": {}
    },
    "tests/unit/test_helpers_getters.py:TestNameToNodeId:test_negative": {
      "curator/helpers/getters.py:name_to_node_id": {}
    },
    "tests/unit/test_helpers_getters.py:TestNameToNodeId:test_positive": {
      "curator/helpers/getters.py:name_to_node_id": {}
    },
    "tests/unit/test_helpers_getters.py:TestNodeIdToName:test_negative": {
      "curator/helpers/getters.py:node_id_to_name": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetAliasActions:test_get_alias_actions": {
      "curator/helpers/getters.py:get_alias_actions": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference1": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference2": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference3": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference4": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference5": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_cli.py:TestCLIMethods:test_action_is_none": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_cli.py:TestCLIMethods:test_no_action": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_integrations.py:TestFilters:test_filter_by_alias_bad_aliases": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    }
  },
  "PRD": "# PROJECT NAME: elasticsearch_curator-test_helpers_getters\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 curator/\n    \u251c\u2500\u2500 exceptions.py\n    \u2502   \u2514\u2500\u2500 ConfigurationError.ConfigurationError\n    \u2514\u2500\u2500 helpers/\n        \u2514\u2500\u2500 getters.py\n            \u251c\u2500\u2500 byte_size\n            \u251c\u2500\u2500 get_alias_actions\n            \u251c\u2500\u2500 get_data_tiers\n            \u251c\u2500\u2500 get_indices\n            \u251c\u2500\u2500 get_repository\n            \u251c\u2500\u2500 get_snapshot\n            \u251c\u2500\u2500 get_snapshot_data\n            \u251c\u2500\u2500 get_tier_preference\n            \u251c\u2500\u2500 name_to_node_id\n            \u251c\u2500\u2500 node_id_to_name\n            \u251c\u2500\u2500 node_roles\n            \u2514\u2500\u2500 single_data_path\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module validates and tests the functionality of helper methods related to Elasticsearch operations, ensuring robust and reliable interactions with Elasticsearch clusters. It provides capabilities to retrieve and manipulate data at various levels, including indices, snapshots, repositories, and node-specific details such as roles and configurations. By offering functionality such as byte size parsing, tier preference determination, and alias management, the module addresses common challenges developers face when working with Elasticsearch's APIs, such as error handling, data consistency, and intuitive access to core cluster information. This ensures developers can build and maintain Elasticsearch integrations with confidence in the reliability of foundational helper methods.\n\n## FILE 1: curator/helpers/getters.py\n\n- FUNCTION NAME: get_alias_actions\n  - SIGNATURE: def get_alias_actions(oldidx, newidx, aliases):\n  - DOCSTRING: \n```python\n\"\"\"\nGenerates a list of alias actions to update Elasticsearch index aliases.\n\n:param oldidx: The name of the old index from which aliases are being removed.\n:type oldidx: str\n:param newidx: The name of the new index to which aliases are being added.\n:type newidx: str\n:param aliases: A dictionary containing the aliases that need to be updated.\n:type aliases: dict\n\n:returns: A list of actions formatted for use with `elasticsearch.client.IndicesClient.update_aliases`,\n          including 'remove' actions for the old index and 'add' actions for the new index.\n:rtype: list\n\nThis function is a utility for managing alias updates when an index is replaced, \nensuring that aliases are properly redirected to the new index. It does not modify any \nstate directly but prepares the necessary data for subsequent API calls to Elasticsearch.\n\"\"\"\n```\n\n- FUNCTION NAME: name_to_node_id\n  - SIGNATURE: def name_to_node_id(client, name):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the node_id corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node whose id is to be retrieved.\n:type name: str\n\n:returns: The node_id of the specified node name, or `None` if no matching node is found.\n:rtype: str\n\nThis function utilizes the `client.nodes.info()` method to gather information about nodes in the cluster. It logs debug information for successful retrievals and error messages for scenarios where no matching node_id is found. The `fpath` variable is defined within the function to specify the filter path for node information retrieval.\n\"\"\"\n```\n\n- FUNCTION NAME: get_data_tiers\n  - SIGNATURE: def get_data_tiers(client):\n  - DOCSTRING: \n```python\n\"\"\"\nGet the availability of data tiers (hot, warm, cold, frozen) in an Elasticsearch cluster by inspecting the roles of each node. \n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: A dictionary indicating the availability of each data tier, structured as ``{'data_hot': bool, 'data_warm': bool, 'data_cold': bool, 'data_frozen': bool}``. Each key corresponds to a data tier and the boolean value indicates whether that tier is present in the cluster.\n:rtype: dict\n\nThe function utilizes the roles defined in the node information obtained from the `client.nodes.info()` method to determine the tiers' availability. It initializes a return dictionary with all data tier keys set to `False` and updates the values to `True` if any node is found to have that role. The `role_check` inner function is used to verify if a role exists in a node's roles, preventing overwriting of `True` values with `False`.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/getters.py:get_tier_preference\n    - curator/helpers/getters.py:role_check\n\n- FUNCTION NAME: node_id_to_name\n  - SIGNATURE: def node_id_to_name(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the name of an Elasticsearch node identified by its unique `node_id`.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node whose name is to be retrieved.\n:type node_id: str\n\n:returns: The name of the node corresponding to the provided `node_id`, or `None` if not found.\n:rtype: str\n\nThis function leverages the `client.nodes.info` method to fetch node details, filtering the result to include only the name of the specified node. A logger is used to record any errors when a matching `node_id` is not found. The function constructs a filter path `fpath` as `nodes.{node_id}.name` to target relevant information in the Elasticsearch response.\n\"\"\"\n```\n\n- FUNCTION NAME: get_tier_preference\n  - SIGNATURE: def get_tier_preference(client, target_tier='data_frozen'):\n  - DOCSTRING: \n```python\n\"\"\"\nDetermine the preferred data tier for Elasticsearch operations based on a specified target tier.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param target_tier: The desired data tier to use, which can be one of 'data_hot', 'data_warm', 'data_cold', 'data_frozen'. Default is 'data_frozen'.\n:type target_tier: str\n\n:returns: A comma-separated string representing the preferred data tiers in order from coldest to hottest, or 'data_content' if no valid tiers are found.\n:rtype: str\n\nThis function utilizes the `get_data_tiers` function to fetch the available data tiers in the cluster and builds a preference list based on a pre-defined `tiermap`. The tiermap defines the hierarchy of data tiers, with 'data_content' being the least preferred and 'data_frozen' the most preferred. If the target tier is 'data_frozen' and such a tier is available, it is returned directly. If no valid tiers are identified, 'data_content' is returned as a fallback.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/getters.py:get_data_tiers\n\n- FUNCTION NAME: get_snapshot_data\n  - SIGNATURE: def get_snapshot_data(client, repository=None):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve all snapshots from a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object representing the connection to an Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository to query.\n:type repository: str\n\n:raises MissingArgument: If no value for `repository` is provided.\n:raises FailedExecution: If there is an issue retrieving snapshots from the repository due to transport errors or if the repository is not found.\n\n:return: A list of all snapshots in the specified repository.\n:rtype: list\n\nThis function interacts with the Elasticsearch SnapshotClient to retrieve snapshot information. It expects a valid repository name, and it returns a list of snapshots present in that repository. If the repository is not provided, it raises a `MissingArgument` exception. Errors during execution trigger a `FailedExecution` exception with a detailed error message.\n\"\"\"\n```\n\n- FUNCTION NAME: get_indices\n  - SIGNATURE: def get_indices(client, search_pattern='_all'):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve a list of indices from an Elasticsearch cluster.\n\n:param client: A client connection object to interact with Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param search_pattern: A search pattern to filter indices (default is '_all' to retrieve all indices).\n:type search_pattern: str\n\n:returns: A list containing the names of indices present in the cluster.\n:rtype: list\n\n:raises FailedExecution: If there is an error while fetching the indices, an exception is raised.\n\nThe function utilizes the client's `cat.indices` method to get a JSON-formatted list of indices and their statuses. It expands wildcards to include both open and closed indices, ensuring comprehensive retrieval. The function logs the complete list of indices and handles exceptions gracefully, converting them into a `FailedExecution` error to indicate the failure to retrieve indices. This functionality is essential in managing and analyzing data states within the Elasticsearch ecosystem.\n\"\"\"\n```\n\n- FUNCTION NAME: get_repository\n  - SIGNATURE: def get_repository(client, repository=''):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve configuration information for a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the snapshot repository to retrieve (default is an empty string, which indicates no repository).\n\n:raises CuratorException: If the repository cannot be found or if there is a transport error during the request, an exception is raised with a detailed message that includes the error encountered.\n\n:returns: A dictionary containing the configuration details of the specified snapshot repository.\n\nThis function interacts with the Elasticsearch snapshot client's `get_repository` method, leveraging the `name` parameter to specify the desired repository. It handles exceptions related to transport errors and not-found errors by raising a `CuratorException`, ensuring appropriate error messaging for users.\n\"\"\"\n```\n\n- FUNCTION NAME: get_snapshot\n  - SIGNATURE: def get_snapshot(client, repository=None, snapshot=''):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve information about a specified snapshot from a given Elasticsearch snapshot repository. If no specific snapshot is provided, it retrieves information for all snapshots within the repository.\n\nParameters:\n- client (Elasticsearch): A connection object for interacting with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository from which to retrieve snapshots. This parameter is required and should not be None.\n- snapshot (str): The name of the snapshot to retrieve, or a comma-separated list of snapshots. If left empty, it defaults to '*', indicating all snapshots.\n\nReturns:\n- dict: A dictionary containing details about the specified snapshot(s). If no snapshots exist, an empty dictionary is returned.\n\nRaises:\n- MissingArgument: If the 'repository' parameter is not provided.\n- FailedExecution: If there is an error retrieving snapshot information, with details included in the error message.\n\nDependencies:\n- This function interacts with the `elasticsearch.client.SnapshotClient.get` method to perform the retrieval. \n- It also handles specific exceptions from the elasticsearch8 package, specifically `TransportError` and `NotFoundError`, signaling issues with the API request.\n\"\"\"\n```\n\n- FUNCTION NAME: single_data_path\n  - SIGNATURE: def single_data_path(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nCheck if a specified Elasticsearch node uses a single filesystem for data storage.\n\nThis function checks the filesystem data paths of a given node identified by its `node_id` to determine if there is only one filesystem. A single filesystem is necessary to perform shard shrinking, as shards cannot be spread across multiple filesystems.\n\n:param client: An Elasticsearch client connection object.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The identifier for the Elasticsearch node to check.\n:type node_id: str\n\n:returns: `True` if the node has a single filesystem; otherwise, returns `False`.\n:rtype: bool\n\nThis function interacts with the Elasticsearch cluster by calling the `nodes.stats` method, specifying a filter path to obtain the filesystem data for the node. The variable `fpath` defines the specific filter path used to access the node's filesystem data metrics, enabling the function to evaluate the length of the `data` field in the node\u2019s filesystem information.\n\"\"\"\n```\n\n- FUNCTION NAME: byte_size\n  - SIGNATURE: def byte_size(num, suffix='B'):\n  - DOCSTRING: \n```python\n\"\"\"\nConvert a byte size to a human-readable format.\n\nThis function takes a number representing a size in bytes and converts it to a formatted string that includes the appropriate unit, such as KB, MB, GB, etc. The conversion is based on powers of 1024, as is standard in computing.\n\nParameters:\n- num (int): The number of bytes to be converted.\n- suffix (str): An optional suffix to append to the size (default is 'B').\n\nReturns:\n- str: A formatted string representing the size, such as '1.5MB', '512.0KB'.\n\nThe function does not modify any external state and relies only on its parameters for calculations. It iterates through a list of unit prefixes corresponding to byte size (from bytes to zettabytes) to determine the correct output format.\n\"\"\"\n```\n\n- FUNCTION NAME: node_roles\n  - SIGNATURE: def node_roles(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the list of roles assigned to a specified node in an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node whose roles are being queried.\n:type node_id: str\n\n:returns: A list of roles assigned to the node identified by ``node_id``.\n:rtype: list\n\nThis function interacts with Elasticsearch's NodesClient to retrieve node information. It constructs a filter path based on the provided ``node_id`` to extract the roles from the node's information. The resulting roles provide insight into the node's responsibilities within the cluster, such as whether it handles data or serves as a master node.\n\"\"\"\n```\n\n## FILE 2: curator/exceptions.py\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "curator/helpers/getters.py": "\"\"\"Utility functions that get things\"\"\"\nimport logging\nfrom elasticsearch8 import exceptions as es8exc\nfrom curator.exceptions import ConfigurationError, CuratorException, FailedExecution, MissingArgument\n\ndef escape_dots(stringval):\n    \"\"\"\n    Escape any dots (periods) in ``stringval``.\n\n    Primarily used for ``filter_path`` where dots are indicators of path nesting\n\n    :param stringval: A string, ostensibly an index name\n\n    :type stringval: str\n\n    :returns: ``stringval``, but with any periods escaped with a backslash\n    :retval: str\n    \"\"\"\n    return stringval.replace('.', '\\\\.')\n\ndef get_write_index(client, alias):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param alias: An alias name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type alias: str\n\n    :returns: The the index name associated with the alias that is designated\n        ``is_write_index``\n    :rtype: str\n    \"\"\"\n    try:\n        response = client.indices.get_alias(index=alias)\n    except Exception as exc:\n        raise CuratorException(f'Alias {alias} not found') from exc\n    retval = None\n    if len(list(response.keys())) > 1:\n        for index in list(response.keys()):\n            try:\n                if response[index]['aliases'][alias]['is_write_index']:\n                    retval = index\n            except KeyError as exc:\n                raise FailedExecution('Invalid alias: is_write_index not found in 1 to many alias') from exc\n    else:\n        retval = list(response.keys())[0]\n    return retval\n\ndef index_size(client, idx, value='total'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.stats`\n\n    :param client: A client connection object\n    :param idx: An index name\n    :param value: One of either ``primaries`` or ``total``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type value: str\n\n    :returns: The sum of either ``primaries`` or ``total`` shards for index ``idx``\n    :rtype: integer\n    \"\"\"\n    fpath = f'indices.{escape_dots(idx)}.{value}.store.size_in_bytes'\n    return client.indices.stats(index=idx, filter_path=fpath)['indices'][idx][value]['store']['size_in_bytes']\n\ndef meta_getter(client, idx, get=None):\n    \"\"\"Meta Getter\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_settings` or\n    :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param idx: An Elasticsearch index\n    :param get: The kind of get to perform, e.g. settings or alias\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type get: str\n\n    :returns: The settings from the get call to the named index\n    :rtype: dict\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    acceptable = ['settings', 'alias']\n    if not get:\n        raise ConfigurationError('\"get\" can not be a NoneType')\n    if get not in acceptable:\n        raise ConfigurationError(f'\"get\" must be one of {acceptable}')\n    retval = {}\n    try:\n        if get == 'settings':\n            retval = client.indices.get_settings(index=idx)[idx]['settings']['index']\n        elif get == 'alias':\n            retval = client.indices.get_alias(index=idx)[idx]['aliases']\n    except es8exc.NotFoundError as missing:\n        logger.error('Index %s was not found!', idx)\n        raise es8exc.NotFoundError from missing\n    except KeyError as err:\n        logger.error('Key not found: %s', err)\n        raise KeyError from err\n    except Exception as exc:\n        logger.error('Exception encountered: %s', exc)\n    return retval",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\n\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\""
  }
}