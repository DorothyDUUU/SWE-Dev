{
  "dir_path": "/app/questionary",
  "package_name": "questionary",
  "sample_name": "questionary-test_question",
  "src_dir": "examples/",
  "test_dir": "tests/",
  "test_file": "tests/test_question.py",
  "test_code": "import asyncio\nimport platform\n\nimport pytest\nfrom prompt_toolkit.output import DummyOutput\nfrom pytest import fail\n\nfrom questionary import text\nfrom questionary.utils import is_prompt_toolkit_3\nfrom tests.utils import KeyInputs\nfrom tests.utils import execute_with_input_pipe\n\n\ndef test_ask_should_catch_keyboard_exception():\n    def run(inp):\n        inp.send_text(KeyInputs.CONTROLC)\n        question = text(\"Hello?\", input=inp, output=DummyOutput())\n        try:\n            result = question.ask()\n            assert result is None\n        except KeyboardInterrupt:\n            fail(\"Keyboard Interrupt should be caught by `ask()`\")\n\n    execute_with_input_pipe(run)\n\n\ndef test_skipping_of_questions():\n    def run(inp):\n        question = text(\"Hello?\", input=inp, output=DummyOutput()).skip_if(\n            condition=True, default=42\n        )\n        response = question.ask()\n        assert response == 42\n\n    execute_with_input_pipe(run)\n\n\ndef test_skipping_of_questions_unsafe():\n    def run(inp):\n        question = text(\"Hello?\", input=inp, output=DummyOutput()).skip_if(\n            condition=True, default=42\n        )\n        response = question.unsafe_ask()\n        assert response == 42\n\n    execute_with_input_pipe(run)\n\n\ndef test_skipping_of_skipping_of_questions():\n    def run(inp):\n        inp.send_text(\"World\" + KeyInputs.ENTER + \"\\r\")\n        question = text(\"Hello?\", input=inp, output=DummyOutput()).skip_if(\n            condition=False, default=42\n        )\n        response = question.ask()\n        assert response == \"World\" and not response == 42\n\n    execute_with_input_pipe(run)\n\n\ndef test_skipping_of_skipping_of_questions_unsafe():\n    def run(inp):\n        inp.send_text(\"World\" + KeyInputs.ENTER + \"\\r\")\n        question = text(\"Hello?\", input=inp, output=DummyOutput()).skip_if(\n            condition=False, default=42\n        )\n        response = question.unsafe_ask()\n        assert response == \"World\" and not response == 42\n\n    execute_with_input_pipe(run)\n\n\n@pytest.mark.skipif(\n    not is_prompt_toolkit_3() and platform.system() == \"Windows\",\n    reason=\"requires prompt_toolkit >= 3\",\n)\ndef test_async_ask_question():\n    loop = asyncio.new_event_loop()\n\n    def run(inp):\n        inp.send_text(\"World\" + KeyInputs.ENTER + \"\\r\")\n        question = text(\"Hello?\", input=inp, output=DummyOutput())\n        response = loop.run_until_complete(question.ask_async())\n        assert response == \"World\"\n\n    execute_with_input_pipe(run)\n\n\ndef test_multiline_text():\n    def run(inp):\n        inp.send_text(f\"Hello{KeyInputs.ENTER}world{KeyInputs.ESCAPE}{KeyInputs.ENTER}\")\n        question = text(\"Hello?\", input=inp, output=DummyOutput(), multiline=True)\n        response = question.ask()\n        assert response == \"Hello\\nworld\"\n\n    execute_with_input_pipe(run)\n",
  "GT_file_code": {
    "questionary/question.py": "import sys\nfrom typing import Any\n\nimport prompt_toolkit.patch_stdout\nfrom prompt_toolkit import Application\n\nfrom questionary import utils\nfrom questionary.constants import DEFAULT_KBI_MESSAGE\n\n\nclass Question:\n    \"\"\"A question to be prompted.\n\n    This is an internal class. Questions should be created using the\n    predefined questions (e.g. text or password).\"\"\"\n\n    application: \"Application[Any]\"\n    should_skip_question: bool\n    default: Any\n\n    def __init__(self, application: \"Application[Any]\") -> None:\n        self.application = application\n        self.should_skip_question = False\n        self.default = None\n\n    async def ask_async(\n        self, patch_stdout: bool = False, kbi_msg: str = DEFAULT_KBI_MESSAGE\n    ) -> Any:\n        \"\"\"Ask the question using asyncio and return user response.\n\n        Args:\n            patch_stdout: Ensure that the prompt renders correctly if other threads\n                          are printing to stdout.\n\n            kbi_msg: The message to be printed on a keyboard interrupt.\n\n        Returns:\n            `Any`: The answer from the question.\n        \"\"\"\n\n        try:\n            sys.stdout.flush()\n            return await self.unsafe_ask_async(patch_stdout)\n        except KeyboardInterrupt:\n            print(\"{}\".format(kbi_msg))\n            return None\n\n    def ask(\n        self, patch_stdout: bool = False, kbi_msg: str = DEFAULT_KBI_MESSAGE\n    ) -> Any:\n        \"\"\"Ask the question synchronously and return user response.\n\n        Args:\n            patch_stdout: Ensure that the prompt renders correctly if other threads\n                          are printing to stdout.\n\n            kbi_msg: The message to be printed on a keyboard interrupt.\n\n        Returns:\n            `Any`: The answer from the question.\n        \"\"\"\n\n        try:\n            return self.unsafe_ask(patch_stdout)\n        except KeyboardInterrupt:\n            print(\"{}\".format(kbi_msg))\n            return None\n\n    def unsafe_ask(self, patch_stdout: bool = False) -> Any:\n        \"\"\"Ask the question synchronously and return user response.\n\n        Does not catch keyboard interrupts.\n\n        Args:\n            patch_stdout: Ensure that the prompt renders correctly if other threads\n                          are printing to stdout.\n\n        Returns:\n            `Any`: The answer from the question.\n        \"\"\"\n\n        if self.should_skip_question:\n            return self.default\n\n        if patch_stdout:\n            with prompt_toolkit.patch_stdout.patch_stdout():\n                return self.application.run()\n        else:\n            return self.application.run()\n\n    def skip_if(self, condition: bool, default: Any = None) -> \"Question\":\n        \"\"\"Skip the question if flag is set and return the default instead.\n\n        Args:\n            condition: A conditional boolean value.\n            default: The default value to return.\n\n        Returns:\n            :class:`Question`: `self`.\n        \"\"\"\n\n        self.should_skip_question = condition\n        self.default = default\n        return self\n\n    async def unsafe_ask_async(self, patch_stdout: bool = False) -> Any:\n        \"\"\"Ask the question using asyncio and return user response.\n\n        Does not catch keyboard interrupts.\n\n        Args:\n            patch_stdout: Ensure that the prompt renders correctly if other threads\n                          are printing to stdout.\n\n        Returns:\n            `Any`: The answer from the question.\n        \"\"\"\n\n        if self.should_skip_question:\n            return self.default\n\n        if not utils.ACTIVATED_ASYNC_MODE:\n            await utils.activate_prompt_toolkit_async_mode()\n\n        if patch_stdout:\n            with prompt_toolkit.patch_stdout.patch_stdout():\n                r = self.application.run_async()\n        else:\n            r = self.application.run_async()\n\n        if utils.is_prompt_toolkit_3():\n            return await r\n        else:\n            return await r.to_asyncio_future()  # type: ignore[attr-defined]\n",
    "questionary/prompts/text.py": "from typing import Any\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\n\nfrom prompt_toolkit.document import Document\nfrom prompt_toolkit.lexers import Lexer\nfrom prompt_toolkit.lexers import SimpleLexer\nfrom prompt_toolkit.shortcuts.prompt import PromptSession\nfrom prompt_toolkit.styles import Style\n\nfrom questionary.constants import DEFAULT_QUESTION_PREFIX\nfrom questionary.constants import INSTRUCTION_MULTILINE\nfrom questionary.prompts.common import build_validator\nfrom questionary.question import Question\nfrom questionary.styles import merge_styles_default\n\n\ndef text(\n    message: str,\n    default: str = \"\",\n    validate: Any = None,\n    qmark: str = DEFAULT_QUESTION_PREFIX,\n    style: Optional[Style] = None,\n    multiline: bool = False,\n    instruction: Optional[str] = None,\n    lexer: Optional[Lexer] = None,\n    **kwargs: Any,\n) -> Question:\n    \"\"\"Prompt the user to enter a free text message.\n\n    This question type can be used to prompt the user for some text input.\n\n    Example:\n        >>> import questionary\n        >>> questionary.text(\"What's your first name?\").ask()\n        ? What's your first name? Tom\n        'Tom'\n\n    .. image:: ../images/text.gif\n\n    This is just a really basic example, the prompt can be customised using the\n    parameters.\n\n    Args:\n        message: Question text.\n\n        default: Default value will be returned if the user just hits\n                 enter.\n\n        validate: Require the entered value to pass a validation. The\n                  value can not be submitted until the validator accepts\n                  it (e.g. to check minimum password length).\n\n                  This can either be a function accepting the input and\n                  returning a boolean, or an class reference to a\n                  subclass of the prompt toolkit Validator class.\n\n        qmark: Question prefix displayed in front of the question.\n               By default this is a ``?``.\n\n        style: A custom color and style for the question parts. You can\n               configure colors as well as font types for different elements.\n\n        multiline: If ``True``, multiline input will be enabled.\n\n        instruction: Write instructions for the user if needed. If ``None``\n                     and ``multiline=True``, some instructions will appear.\n\n        lexer: Supply a valid lexer to style the answer. Leave empty to\n               use a simple one by default.\n\n        kwargs: Additional arguments, they will be passed to prompt toolkit.\n\n    Returns:\n        :class:`Question`: Question instance, ready to be prompted (using ``.ask()``).\n    \"\"\"\n    merged_style = merge_styles_default([style])\n    lexer = lexer or SimpleLexer(\"class:answer\")\n    validator = build_validator(validate)\n\n    if instruction is None and multiline:\n        instruction = INSTRUCTION_MULTILINE\n\n    def get_prompt_tokens() -> List[Tuple[str, str]]:\n        result = [(\"class:qmark\", qmark), (\"class:question\", \" {} \".format(message))]\n        if instruction:\n            result.append((\"class:instruction\", \" {} \".format(instruction)))\n        return result\n\n    p: PromptSession = PromptSession(\n        get_prompt_tokens,\n        style=merged_style,\n        validator=validator,\n        lexer=lexer,\n        multiline=multiline,\n        **kwargs,\n    )\n    p.default_buffer.reset(Document(default))\n\n    return Question(p.app)\n"
  },
  "GT_src_dict": {
    "questionary/question.py": {
      "Question.ask": {
        "code": "    def ask(self, patch_stdout: bool=False, kbi_msg: str=DEFAULT_KBI_MESSAGE) -> Any:\n        \"\"\"Ask a question synchronously and return the user's response.\n\nThis method prompts the user for input and handles keyboard interrupts gracefully. If a `KeyboardInterrupt` occurs, a specified message (`kbi_msg`, defaulting to `DEFAULT_KBI_MESSAGE`) is printed, and `None` is returned. The method utilizes the `unsafe_ask` method to perform the questioning logic and options for patching standard output to ensure proper rendering.\n\nArgs:\n    patch_stdout (bool, optional): If True, ensures the prompt renders correctly in the presence of concurrent stdout operations. Defaults to False.\n    kbi_msg (str, optional): Message to print upon a keyboard interrupt, allowing customization of the interrupt response. Defaults to `DEFAULT_KBI_MESSAGE`, which is defined in `questionary.constants`.\n\nReturns:\n    Any: The user's response to the question, or None if interrupted.\n\nThis method interacts with the `unsafe_ask` method to perform the actual prompting and is part of the `Question` class, which is designed to create various types of questions for user interaction.\"\"\"\n        'Ask the question synchronously and return user response.\\n\\n        Args:\\n            patch_stdout: Ensure that the prompt renders correctly if other threads\\n                          are printing to stdout.\\n\\n            kbi_msg: The message to be printed on a keyboard interrupt.\\n\\n        Returns:\\n            `Any`: The answer from the question.\\n        '\n        try:\n            return self.unsafe_ask(patch_stdout)\n        except KeyboardInterrupt:\n            print('{}'.format(kbi_msg))\n            return None",
        "docstring": "Ask a question synchronously and return the user's response.\n\nThis method prompts the user for input and handles keyboard interrupts gracefully. If a `KeyboardInterrupt` occurs, a specified message (`kbi_msg`, defaulting to `DEFAULT_KBI_MESSAGE`) is printed, and `None` is returned. The method utilizes the `unsafe_ask` method to perform the questioning logic and options for patching standard output to ensure proper rendering.\n\nArgs:\n    patch_stdout (bool, optional): If True, ensures the prompt renders correctly in the presence of concurrent stdout operations. Defaults to False.\n    kbi_msg (str, optional): Message to print upon a keyboard interrupt, allowing customization of the interrupt response. Defaults to `DEFAULT_KBI_MESSAGE`, which is defined in `questionary.constants`.\n\nReturns:\n    Any: The user's response to the question, or None if interrupted.\n\nThis method interacts with the `unsafe_ask` method to perform the actual prompting and is part of the `Question` class, which is designed to create various types of questions for user interaction.",
        "signature": "def ask(self, patch_stdout: bool=False, kbi_msg: str=DEFAULT_KBI_MESSAGE) -> Any:",
        "type": "Method",
        "class_signature": "class Question:"
      },
      "Question.unsafe_ask": {
        "code": "    def unsafe_ask(self, patch_stdout: bool=False) -> Any:\n        \"\"\"Ask the question synchronously and return the user's response.\n\nThis method checks if the question should be skipped; if so, it returns the specified default value. If `patch_stdout` is set to True, it ensures proper rendering of the prompt while other threads print to stdout by using `prompt_toolkit.patch_stdout`. It relies on the `application` attribute, which is an instance of `prompt_toolkit.Application`, to execute the prompt.\n\nParameters:\n- patch_stdout (bool): If True, adjusts stdout for rendering issues during concurrent output. Default is False.\n\nReturns:\n- Any: The user's response to the question, or the default value if the question is skipped.\n\nImportant dependencies:\n- `prompt_toolkit`: Provides the application and methods to handle prompt rendering.\"\"\"\n        'Ask the question synchronously and return user response.\\n\\n        Does not catch keyboard interrupts.\\n\\n        Args:\\n            patch_stdout: Ensure that the prompt renders correctly if other threads\\n                          are printing to stdout.\\n\\n        Returns:\\n            `Any`: The answer from the question.\\n        '\n        if self.should_skip_question:\n            return self.default\n        if patch_stdout:\n            with prompt_toolkit.patch_stdout.patch_stdout():\n                return self.application.run()\n        else:\n            return self.application.run()",
        "docstring": "Ask the question synchronously and return the user's response.\n\nThis method checks if the question should be skipped; if so, it returns the specified default value. If `patch_stdout` is set to True, it ensures proper rendering of the prompt while other threads print to stdout by using `prompt_toolkit.patch_stdout`. It relies on the `application` attribute, which is an instance of `prompt_toolkit.Application`, to execute the prompt.\n\nParameters:\n- patch_stdout (bool): If True, adjusts stdout for rendering issues during concurrent output. Default is False.\n\nReturns:\n- Any: The user's response to the question, or the default value if the question is skipped.\n\nImportant dependencies:\n- `prompt_toolkit`: Provides the application and methods to handle prompt rendering.",
        "signature": "def unsafe_ask(self, patch_stdout: bool=False) -> Any:",
        "type": "Method",
        "class_signature": "class Question:"
      },
      "Question.skip_if": {
        "code": "    def skip_if(self, condition: bool, default: Any=None) -> 'Question':\n        \"\"\"Sets a flag to determine whether the question should be skipped based on a given condition. If the condition is `True`, the question will be bypassed, returning a specified default value instead.\n\nArgs:\n    condition (bool): A boolean value indicating whether to skip the question.\n    default (Any, optional): The value to return if the question is skipped.\n\nReturns:\n    Question: The current instance of the Question class, allowing for method chaining.\n\nThis method interacts with the `should_skip_question` and `default` attributes of the Question class, enabling conditional logic around prompting the user. The `default` value can be utilized in other methods, such as `ask` or `ask_async`, when signaling that the question should not be asked.\"\"\"\n        'Skip the question if flag is set and return the default instead.\\n\\n        Args:\\n            condition: A conditional boolean value.\\n            default: The default value to return.\\n\\n        Returns:\\n            :class:`Question`: `self`.\\n        '\n        self.should_skip_question = condition\n        self.default = default\n        return self",
        "docstring": "Sets a flag to determine whether the question should be skipped based on a given condition. If the condition is `True`, the question will be bypassed, returning a specified default value instead.\n\nArgs:\n    condition (bool): A boolean value indicating whether to skip the question.\n    default (Any, optional): The value to return if the question is skipped.\n\nReturns:\n    Question: The current instance of the Question class, allowing for method chaining.\n\nThis method interacts with the `should_skip_question` and `default` attributes of the Question class, enabling conditional logic around prompting the user. The `default` value can be utilized in other methods, such as `ask` or `ask_async`, when signaling that the question should not be asked.",
        "signature": "def skip_if(self, condition: bool, default: Any=None) -> 'Question':",
        "type": "Method",
        "class_signature": "class Question:"
      }
    },
    "questionary/prompts/text.py": {
      "text": {
        "code": "def text(message: str, default: str='', validate: Any=None, qmark: str=DEFAULT_QUESTION_PREFIX, style: Optional[Style]=None, multiline: bool=False, instruction: Optional[str]=None, lexer: Optional[Lexer]=None, **kwargs: Any) -> Question:\n    \"\"\"Prompts the user to enter a free text message, allowing for customization of the prompt appearance and behavior.\n\nParameters:\n- message (str): The question text displayed to the user.\n- default (str, optional): Default value returned if the user simply hits enter. Defaults to an empty string.\n- validate (Any, optional): Validation for the user input. This can be a function returning a boolean or a Validator class reference from the prompt toolkit.\n- qmark (str, optional): The prefix displayed in front of the question, defaulting to a question mark (`?`), defined in the questionary.constants.\n- style (Optional[Style], optional): A custom style definition for colors and fonts.\n- multiline (bool, optional): If True, enables multiline input.\n- instruction (Optional[str], optional): Additional instructions for the user. If None and multiline is True, default instructions will appear.\n- lexer (Optional[Lexer], optional): A lexer for styling the response, defaults to SimpleLexer if None.\n- **kwargs (Any): Additional arguments passed to the prompt toolkit\u2019s PromptSession.\n\nReturns:\n- Question: An instance of Question, ready for prompting using the `.ask()` method.\n\nNotes:\n- This function relies on constants like DEFAULT_QUESTION_PREFIX for the question prefix and INSTRUCTION_MULTILINE for default instructions.\n- The function creates a PromptSession using the specified or default styles, validators, and lexer, handling input through an internal function get_prompt_tokens to format the prompt display.\"\"\"\n    'Prompt the user to enter a free text message.\\n\\n    This question type can be used to prompt the user for some text input.\\n\\n    Example:\\n        >>> import questionary\\n        >>> questionary.text(\"What\\'s your first name?\").ask()\\n        ? What\\'s your first name? Tom\\n        \\'Tom\\'\\n\\n    .. image:: ../images/text.gif\\n\\n    This is just a really basic example, the prompt can be customised using the\\n    parameters.\\n\\n    Args:\\n        message: Question text.\\n\\n        default: Default value will be returned if the user just hits\\n                 enter.\\n\\n        validate: Require the entered value to pass a validation. The\\n                  value can not be submitted until the validator accepts\\n                  it (e.g. to check minimum password length).\\n\\n                  This can either be a function accepting the input and\\n                  returning a boolean, or an class reference to a\\n                  subclass of the prompt toolkit Validator class.\\n\\n        qmark: Question prefix displayed in front of the question.\\n               By default this is a ``?``.\\n\\n        style: A custom color and style for the question parts. You can\\n               configure colors as well as font types for different elements.\\n\\n        multiline: If ``True``, multiline input will be enabled.\\n\\n        instruction: Write instructions for the user if needed. If ``None``\\n                     and ``multiline=True``, some instructions will appear.\\n\\n        lexer: Supply a valid lexer to style the answer. Leave empty to\\n               use a simple one by default.\\n\\n        kwargs: Additional arguments, they will be passed to prompt toolkit.\\n\\n    Returns:\\n        :class:`Question`: Question instance, ready to be prompted (using ``.ask()``).\\n    '\n    merged_style = merge_styles_default([style])\n    lexer = lexer or SimpleLexer('class:answer')\n    validator = build_validator(validate)\n    if instruction is None and multiline:\n        instruction = INSTRUCTION_MULTILINE\n\n    def get_prompt_tokens() -> List[Tuple[str, str]]:\n        \"\"\"Generate prompt tokens for displaying a formatted question in the prompt. The tokens consist of the question prefix (`qmark`), the main question message, and any additional instructions if provided.\n\nArgs:\n    None\n\nReturns:\n    List[Tuple[str, str]]: A list of tuples where each tuple contains a styling class and the corresponding text to be displayed in the prompt.\n\nDependencies:\n    - `qmark`: A string representing the question prefix, defined earlier in the `text` function with a default value of `DEFAULT_QUESTION_PREFIX`.\n    - `message`: A string containing the main question, passed in from the `text` function.\n    - `instruction`: If provided, it will append instruction text styled appropriately; otherwise, it is omitted.\n\nThis function is integral to the construction of the prompt UI by creating the visible tokens that make up the user interface's question display.\"\"\"\n        result = [('class:qmark', qmark), ('class:question', ' {} '.format(message))]\n        if instruction:\n            result.append(('class:instruction', ' {} '.format(instruction)))\n        return result\n    p: PromptSession = PromptSession(get_prompt_tokens, style=merged_style, validator=validator, lexer=lexer, multiline=multiline, **kwargs)\n    p.default_buffer.reset(Document(default))\n    return Question(p.app)",
        "docstring": "Prompts the user to enter a free text message, allowing for customization of the prompt appearance and behavior.\n\nParameters:\n- message (str): The question text displayed to the user.\n- default (str, optional): Default value returned if the user simply hits enter. Defaults to an empty string.\n- validate (Any, optional): Validation for the user input. This can be a function returning a boolean or a Validator class reference from the prompt toolkit.\n- qmark (str, optional): The prefix displayed in front of the question, defaulting to a question mark (`?`), defined in the questionary.constants.\n- style (Optional[Style], optional): A custom style definition for colors and fonts.\n- multiline (bool, optional): If True, enables multiline input.\n- instruction (Optional[str], optional): Additional instructions for the user. If None and multiline is True, default instructions will appear.\n- lexer (Optional[Lexer], optional): A lexer for styling the response, defaults to SimpleLexer if None.\n- **kwargs (Any): Additional arguments passed to the prompt toolkit\u2019s PromptSession.\n\nReturns:\n- Question: An instance of Question, ready for prompting using the `.ask()` method.\n\nNotes:\n- This function relies on constants like DEFAULT_QUESTION_PREFIX for the question prefix and INSTRUCTION_MULTILINE for default instructions.\n- The function creates a PromptSession using the specified or default styles, validators, and lexer, handling input through an internal function get_prompt_tokens to format the prompt display.",
        "signature": "def text(message: str, default: str='', validate: Any=None, qmark: str=DEFAULT_QUESTION_PREFIX, style: Optional[Style]=None, multiline: bool=False, instruction: Optional[str]=None, lexer: Optional[Lexer]=None, **kwargs: Any) -> Question:",
        "type": "Function",
        "class_signature": null
      },
      "get_prompt_tokens": {
        "code": "    def get_prompt_tokens() -> List[Tuple[str, str]]:\n        \"\"\"Generate prompt tokens for displaying a formatted question in the prompt. The tokens consist of the question prefix (`qmark`), the main question message, and any additional instructions if provided.\n\nArgs:\n    None\n\nReturns:\n    List[Tuple[str, str]]: A list of tuples where each tuple contains a styling class and the corresponding text to be displayed in the prompt.\n\nDependencies:\n    - `qmark`: A string representing the question prefix, defined earlier in the `text` function with a default value of `DEFAULT_QUESTION_PREFIX`.\n    - `message`: A string containing the main question, passed in from the `text` function.\n    - `instruction`: If provided, it will append instruction text styled appropriately; otherwise, it is omitted.\n\nThis function is integral to the construction of the prompt UI by creating the visible tokens that make up the user interface's question display.\"\"\"\n        result = [('class:qmark', qmark), ('class:question', ' {} '.format(message))]\n        if instruction:\n            result.append(('class:instruction', ' {} '.format(instruction)))\n        return result",
        "docstring": "Generate prompt tokens for displaying a formatted question in the prompt. The tokens consist of the question prefix (`qmark`), the main question message, and any additional instructions if provided.\n\nArgs:\n    None\n\nReturns:\n    List[Tuple[str, str]]: A list of tuples where each tuple contains a styling class and the corresponding text to be displayed in the prompt.\n\nDependencies:\n    - `qmark`: A string representing the question prefix, defined earlier in the `text` function with a default value of `DEFAULT_QUESTION_PREFIX`.\n    - `message`: A string containing the main question, passed in from the `text` function.\n    - `instruction`: If provided, it will append instruction text styled appropriately; otherwise, it is omitted.\n\nThis function is integral to the construction of the prompt UI by creating the visible tokens that make up the user interface's question display.",
        "signature": "def get_prompt_tokens() -> List[Tuple[str, str]]:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {},
  "PRD": "# PROJECT NAME: questionary-test_question\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 questionary/\n    \u251c\u2500\u2500 prompts/\n    \u2502   \u2514\u2500\u2500 text.py\n    \u2502       \u251c\u2500\u2500 get_prompt_tokens\n    \u2502       \u2514\u2500\u2500 text\n    \u2514\u2500\u2500 question.py\n        \u251c\u2500\u2500 Question.ask\n        \u251c\u2500\u2500 Question.ask_async\n        \u251c\u2500\u2500 Question.skip_if\n        \u2514\u2500\u2500 Question.unsafe_ask\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module facilitates the automated testing of interactive CLI prompts built using the `questionary` library, ensuring their behavior aligns with expected outcomes under various conditions. It provides capabilities to test standard and asynchronous user input handling, keyboard interrupt exceptions, multi-line text input, and conditional skipping of questions based on predefined logic. By enabling thorough validation of the prompt behavior, including edge cases like interrupts or skipping logic, the module helps developers ensure robust and user-friendly command-line interfaces that handle complex input scenarios seamlessly.\n\n## FILE 1: questionary/question.py\n\n- CLASS METHOD: Question.ask\n  - CLASS SIGNATURE: class Question:\n  - SIGNATURE: def ask(self, patch_stdout: bool=False, kbi_msg: str=DEFAULT_KBI_MESSAGE) -> Any:\n  - DOCSTRING: \n```python\n\"\"\"\nAsk a question synchronously and return the user's response.\n\nThis method prompts the user for input and handles keyboard interrupts gracefully. If a `KeyboardInterrupt` occurs, a specified message (`kbi_msg`, defaulting to `DEFAULT_KBI_MESSAGE`) is printed, and `None` is returned. The method utilizes the `unsafe_ask` method to perform the questioning logic and options for patching standard output to ensure proper rendering.\n\nArgs:\n    patch_stdout (bool, optional): If True, ensures the prompt renders correctly in the presence of concurrent stdout operations. Defaults to False.\n    kbi_msg (str, optional): Message to print upon a keyboard interrupt, allowing customization of the interrupt response. Defaults to `DEFAULT_KBI_MESSAGE`, which is defined in `questionary.constants`.\n\nReturns:\n    Any: The user's response to the question, or None if interrupted.\n\nThis method interacts with the `unsafe_ask` method to perform the actual prompting and is part of the `Question` class, which is designed to create various types of questions for user interaction.\n\"\"\"\n```\n\n- CLASS METHOD: Question.skip_if\n  - CLASS SIGNATURE: class Question:\n  - SIGNATURE: def skip_if(self, condition: bool, default: Any=None) -> 'Question':\n  - DOCSTRING: \n```python\n\"\"\"\nSets a flag to determine whether the question should be skipped based on a given condition. If the condition is `True`, the question will be bypassed, returning a specified default value instead.\n\nArgs:\n    condition (bool): A boolean value indicating whether to skip the question.\n    default (Any, optional): The value to return if the question is skipped.\n\nReturns:\n    Question: The current instance of the Question class, allowing for method chaining.\n\nThis method interacts with the `should_skip_question` and `default` attributes of the Question class, enabling conditional logic around prompting the user. The `default` value can be utilized in other methods, such as `ask` or `ask_async`, when signaling that the question should not be asked.\n\"\"\"\n```\n\n- CLASS METHOD: Question.unsafe_ask\n  - CLASS SIGNATURE: class Question:\n  - SIGNATURE: def unsafe_ask(self, patch_stdout: bool=False) -> Any:\n  - DOCSTRING: \n```python\n\"\"\"\nAsk the question synchronously and return the user's response.\n\nThis method checks if the question should be skipped; if so, it returns the specified default value. If `patch_stdout` is set to True, it ensures proper rendering of the prompt while other threads print to stdout by using `prompt_toolkit.patch_stdout`. It relies on the `application` attribute, which is an instance of `prompt_toolkit.Application`, to execute the prompt.\n\nParameters:\n- patch_stdout (bool): If True, adjusts stdout for rendering issues during concurrent output. Default is False.\n\nReturns:\n- Any: The user's response to the question, or the default value if the question is skipped.\n\nImportant dependencies:\n- `prompt_toolkit`: Provides the application and methods to handle prompt rendering.\n\"\"\"\n```\n\n## FILE 2: questionary/prompts/text.py\n\n- FUNCTION NAME: get_prompt_tokens\n  - SIGNATURE: def get_prompt_tokens() -> List[Tuple[str, str]]:\n  - DOCSTRING: \n```python\n\"\"\"\nGenerate prompt tokens for displaying a formatted question in the prompt. The tokens consist of the question prefix (`qmark`), the main question message, and any additional instructions if provided.\n\nArgs:\n    None\n\nReturns:\n    List[Tuple[str, str]]: A list of tuples where each tuple contains a styling class and the corresponding text to be displayed in the prompt.\n\nDependencies:\n    - `qmark`: A string representing the question prefix, defined earlier in the `text` function with a default value of `DEFAULT_QUESTION_PREFIX`.\n    - `message`: A string containing the main question, passed in from the `text` function.\n    - `instruction`: If provided, it will append instruction text styled appropriately; otherwise, it is omitted.\n\nThis function is integral to the construction of the prompt UI by creating the visible tokens that make up the user interface's question display.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - tests/test_question.py:run\n\n- FUNCTION NAME: text\n  - SIGNATURE: def text(message: str, default: str='', validate: Any=None, qmark: str=DEFAULT_QUESTION_PREFIX, style: Optional[Style]=None, multiline: bool=False, instruction: Optional[str]=None, lexer: Optional[Lexer]=None, **kwargs: Any) -> Question:\n  - DOCSTRING: \n```python\n\"\"\"\nPrompts the user to enter a free text message, allowing for customization of the prompt appearance and behavior.\n\nParameters:\n- message (str): The question text displayed to the user.\n- default (str, optional): Default value returned if the user simply hits enter. Defaults to an empty string.\n- validate (Any, optional): Validation for the user input. This can be a function returning a boolean or a Validator class reference from the prompt toolkit.\n- qmark (str, optional): The prefix displayed in front of the question, defaulting to a question mark (`?`), defined in the questionary.constants.\n- style (Optional[Style], optional): A custom style definition for colors and fonts.\n- multiline (bool, optional): If True, enables multiline input.\n- instruction (Optional[str], optional): Additional instructions for the user. If None and multiline is True, default instructions will appear.\n- lexer (Optional[Lexer], optional): A lexer for styling the response, defaults to SimpleLexer if None.\n- **kwargs (Any): Additional arguments passed to the prompt toolkit\u2019s PromptSession.\n\nReturns:\n- Question: An instance of Question, ready for prompting using the `.ask()` method.\n\nNotes:\n- This function relies on constants like DEFAULT_QUESTION_PREFIX for the question prefix and INSTRUCTION_MULTILINE for default instructions.\n- The function creates a PromptSession using the specified or default styles, validators, and lexer, handling input through an internal function get_prompt_tokens to format the prompt display.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - tests/test_question.py:run\n    - questionary/styles.py:merge_styles_default\n    - questionary/prompts/common.py:build_validator\n    - questionary/question.py:Question:__init__\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "questionary/question.py": "import sys\nfrom typing import Any\nimport prompt_toolkit.patch_stdout\nfrom prompt_toolkit import Application\nfrom questionary import utils\nfrom questionary.constants import DEFAULT_KBI_MESSAGE\n\nclass Question:\n    \"\"\"A question to be prompted.\n\n    This is an internal class. Questions should be created using the\n    predefined questions (e.g. text or password).\"\"\"\n    application: 'Application[Any]'\n    should_skip_question: bool\n    default: Any\n\n    def __init__(self, application: 'Application[Any]') -> None:\n        self.application = application\n        self.should_skip_question = False\n        self.default = None\n\n    async def unsafe_ask_async(self, patch_stdout: bool=False) -> Any:\n        \"\"\"Ask the question using asyncio and return user response.\n\n        Does not catch keyboard interrupts.\n\n        Args:\n            patch_stdout: Ensure that the prompt renders correctly if other threads\n                          are printing to stdout.\n\n        Returns:\n            `Any`: The answer from the question.\n        \"\"\"\n        if self.should_skip_question:\n            return self.default\n        if not utils.ACTIVATED_ASYNC_MODE:\n            await utils.activate_prompt_toolkit_async_mode()\n        if patch_stdout:\n            with prompt_toolkit.patch_stdout.patch_stdout():\n                r = self.application.run_async()\n        else:\n            r = self.application.run_async()\n        if utils.is_prompt_toolkit_3():\n            return await r\n        else:\n            return await r.to_asyncio_future()",
    "questionary/prompts/text.py": "from typing import Any\nfrom typing import List\nfrom typing import Optional\nfrom typing import Tuple\nfrom prompt_toolkit.document import Document\nfrom prompt_toolkit.lexers import Lexer\nfrom prompt_toolkit.lexers import SimpleLexer\nfrom prompt_toolkit.shortcuts.prompt import PromptSession\nfrom prompt_toolkit.styles import Style\nfrom questionary.constants import DEFAULT_QUESTION_PREFIX\nfrom questionary.constants import INSTRUCTION_MULTILINE\nfrom questionary.prompts.common import build_validator\nfrom questionary.question import Question\nfrom questionary.styles import merge_styles_default"
  },
  "call_tree": {
    "tests/test_question.py:test_ask_should_catch_keyboard_exception": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:ask": {
            "questionary/question.py:Question:unsafe_ask": {
              "questionary/prompts/text.py:get_prompt_tokens": {}
            }
          }
        }
      }
    },
    "tests/test_question.py:test_skipping_of_questions": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:skip_if": {},
          "questionary/question.py:Question:ask": {
            "questionary/question.py:Question:unsafe_ask": {}
          }
        }
      }
    },
    "tests/test_question.py:test_skipping_of_questions_unsafe": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:skip_if": {},
          "questionary/question.py:Question:unsafe_ask": {}
        }
      }
    },
    "tests/test_question.py:test_skipping_of_skipping_of_questions": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:skip_if": {},
          "questionary/question.py:Question:ask": {
            "questionary/question.py:Question:unsafe_ask": {
              "questionary/prompts/text.py:get_prompt_tokens": {}
            }
          }
        }
      }
    },
    "tests/test_question.py:test_skipping_of_skipping_of_questions_unsafe": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:skip_if": {},
          "questionary/question.py:Question:unsafe_ask": {
            "questionary/prompts/text.py:get_prompt_tokens": {}
          }
        }
      }
    },
    "tests/test_question.py:test_async_ask_question": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:ask_async": {
            "questionary/question.py:Question:unsafe_ask_async": {
              "questionary/utils.py:activate_prompt_toolkit_async_mode": {
                "questionary/utils.py:is_prompt_toolkit_3": {}
              },
              "questionary/utils.py:is_prompt_toolkit_3": {},
              "questionary/prompts/text.py:get_prompt_tokens": {}
            }
          },
          "questionary/prompts/text.py:get_prompt_tokens": {}
        }
      }
    },
    "tests/test_question.py:test_multiline_text": {
      "tests/utils.py:execute_with_input_pipe": {
        "tests/test_question.py:run": {
          "questionary/prompts/text.py:text": {
            "questionary/styles.py:merge_styles_default": {},
            "questionary/prompts/common.py:build_validator": {},
            "questionary/question.py:Question:__init__": {}
          },
          "questionary/question.py:Question:ask": {
            "questionary/question.py:Question:unsafe_ask": {
              "questionary/prompts/text.py:get_prompt_tokens": {}
            }
          }
        }
      }
    }
  }
}