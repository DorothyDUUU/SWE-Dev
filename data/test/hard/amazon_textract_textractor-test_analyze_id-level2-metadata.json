{
  "dir_path": "/app/amazon_textract_textractor",
  "package_name": "amazon_textract_textractor",
  "sample_name": "amazon_textract_textractor-test_analyze_id",
  "src_dir": "textractor/",
  "test_dir": "tests/",
  "test_file": "tests/test_analyze_id.py",
  "test_code": "import json\nimport os\nimport PIL\nimport unittest\nfrom tests.utils import get_fixture_path\nfrom textractor import Textractor\nfrom textractor.entities.document import Document\nfrom textractor.data.constants import TextractFeatures, AnalyzeIDFields\nfrom textractor.exceptions import InvalidProfileNameError, NoImageException, S3FilePathMissing\n\nfrom .utils import save_document_to_fixture_path\n\nclass TestTextractorAnalyzeID(unittest.TestCase):\n    def setUp(self):\n        # insert credentials and filepaths here to run test\n        self.profile_name = \"default\"\n        self.current_directory = os.path.abspath(os.path.dirname(__file__))\n        self.image_path = os.path.join(self.current_directory, \"fixtures/fake_id.png\")\n        self.image = PIL.Image.open(os.path.join(self.current_directory, \"fixtures/fake_id.png\"))\n\n        if self.profile_name is None:\n            raise InvalidProfileNameError(\n                \"Textractor could not be initialized. Populate profile_name with a valid input in tests/test_textractor.py.\"\n            )\n        if os.environ.get(\"CALL_TEXTRACT\"):\n            self.extractor = Textractor(\n                profile_name=self.profile_name, kms_key_id=\"\"\n            )\n\n    def test_analyze_id_from_path(self):\n        # Testing local single image input\n        if os.environ.get(\"CALL_TEXTRACT\"):\n            document = self.extractor.analyze_id(\n                file_source=self.image_path,\n            )\n            with open(get_fixture_path(), \"w\") as f:\n                json.dump(document.response, f)\n        else:\n            document = Document.open(get_fixture_path())\n\n        self.assertIsInstance(document, Document)\n        self.assertEqual(len(document.identity_documents), 1)\n        self.assertEqual(len(document.identity_documents[0].fields), 21)\n        self.assertEqual(document.identity_documents[0].get(AnalyzeIDFields.FIRST_NAME), \"GARCIA\")\n        self.assertEqual(document.identity_documents[0][AnalyzeIDFields.FIRST_NAME], \"GARCIA\")\n    \n    def test_analyze_id_from_image(self):\n        # Testing local single image input\n        if os.environ.get(\"CALL_TEXTRACT\"):\n            document = self.extractor.analyze_id(\n                file_source=self.image,\n            )\n            with open(get_fixture_path(), \"w\") as f:\n                json.dump(document.response, f)\n        else:\n            document = Document.open(get_fixture_path())\n\n        self.assertIsInstance(document, Document)\n        self.assertEqual(len(document.identity_documents), 1)\n        self.assertEqual(len(document.identity_documents[0].fields), 21)\n        self.assertEqual(document.identity_documents[0].get(\"FIRST_NAME\"), \"GARCIA\")\n        self.assertEqual(document.identity_documents[0][\"FIRST_NAME\"], \"GARCIA\")\n\nif __name__ == \"__main__\":\n    test = TestTextractorAnalyzeID()\n    test.setUp()\n    test.test_analyze_id_from_path()",
  "GT_file_code": {
    "textractor/entities/document.py": "\"\"\"The Document class is defined to host all the various DocumentEntity objects within it. :class:`DocumentEntity` objects can be \naccessed, searched and exported the functions given below.\"\"\"\n\nimport boto3\nimport json\nimport os\nimport string\nimport logging\nimport xlsxwriter\nimport io\nfrom pathlib import Path\nfrom typing import List, IO, Union, AnyStr, Tuple\nfrom copy import deepcopy\nfrom collections import defaultdict\nfrom PIL import Image\n\nfrom textractor.entities.expense_document import ExpenseDocument\nfrom textractor.entities.identity_document import IdentityDocument\nfrom textractor.entities.word import Word\nfrom textractor.entities.line import Line\nfrom textractor.entities.page import Page\nfrom textractor.entities.table import Table\nfrom textractor.entities.query import Query\nfrom textractor.entities.signature import Signature\nfrom textractor.entities.layout import Layout\nfrom textractor.exceptions import InputError\nfrom textractor.entities.key_value import KeyValue\nfrom textractor.entities.bbox import SpatialObject\nfrom textractor.utils.s3_utils import download_from_s3\nfrom textractor.visualizers.entitylist import EntityList\nfrom textractor.data.constants import (\n    TextTypes,\n    SimilarityMetric,\n    Direction,\n    DirectionalFinderType,\n)\nfrom textractor.utils.search_utils import SearchUtils\nfrom textractor.data.text_linearization_config import TextLinearizationConfig\nfrom textractor.data.html_linearization_config import HTMLLinearizationConfig\nfrom textractor.entities.linearizable import Linearizable\n\n\nclass Document(SpatialObject, Linearizable):\n    \"\"\"\n    Represents the description of a single document, as it would appear in the input to the Textract API.\n    Document serves as the root node of the object model hierarchy,\n    which should be used as an intermediate form for most analytic purposes.\n    The Document node also contains the metadata of the document.\n    \"\"\"\n\n    @classmethod\n    def open(cls, fp: Union[dict, str, Path, IO[AnyStr]]):\n        \"\"\"Create a Document object from a JSON file path, file handle or response dictionary\n\n        :param fp: _description_\n        :type fp: Union[dict, str, Path, IO[AnyStr]]\n        :raises InputError: Raised on input not being of type Union[dict, str, Path, IO[AnyStr]]\n        :return: Document object\n        :rtype: Document\n        \"\"\"\n        from textractor.parsers import response_parser\n\n        if isinstance(fp, dict):\n            return response_parser.parse(fp)\n        elif isinstance(fp, str):\n            if fp.startswith(\"s3://\"):\n                # FIXME: Opening s3 clients for everything should be avoided\n                client = boto3.client(\"s3\")\n                return response_parser.parse(json.load(download_from_s3(client, fp)))\n            with open(fp, \"r\") as f:\n                return response_parser.parse(json.load(f))\n        elif isinstance(fp, Path):\n            with open(fp, \"r\") as f:\n                return response_parser.parse(json.load(f))\n        elif isinstance(fp, io.IOBase):\n            return response_parser.parse(json.load(fp))\n        else:\n            raise InputError(\n                f\"Document.open() input must be of type dict, str, Path or a file handle, not {type(fp)}\"\n            )\n\n    def __init__(self, num_pages: int = 1):\n        \"\"\"\n        Creates a new document, ideally containing entity objects pertaining to each page.\n\n        :param num_pages: Number of pages in the input Document.\n        \"\"\"\n        super().__init__(width=0, height=0)\n        self.num_pages: int = num_pages\n        self._pages: List[Page] = []\n        self._identity_documents: List[IdentityDocument] = []\n        self._trp2_document = None\n        self.response = None\n\n    @property\n    def words(self) -> EntityList[Word]:\n        \"\"\"\n        Returns all the :class:`Word` objects present in the Document.\n\n        :return: List of Word objects, each representing a word within the Document.\n        :rtype: EntityList[Word]\n        \"\"\"\n        return EntityList(sum([page.words for page in self.pages], []))\n\n    @property\n    def text(self) -> str:\n        \"\"\"Returns the document text as one string\n\n        :return: Page text seperated by line return\n        :rtype: str\n        \"\"\"\n        return os.linesep.join([page.text for page in self.pages])\n\n    @property\n    def identity_documents(self) -> EntityList[IdentityDocument]:\n        \"\"\"\n        Returns all the :class:`IdentityDocument` objects present in the Document.\n\n        :return: List of IdentityDocument objects, each representing an identity document within the Document.\n        :rtype: EntityList[IdentityDocument]\n        \"\"\"\n        return EntityList(self._identity_documents)\n\n    @identity_documents.setter\n    def identity_documents(self, identity_documents: List[IdentityDocument]):\n        \"\"\"\n        Set all the identity documents detected inside the Document\n        \"\"\"\n        self._identity_documents = identity_documents\n\n    @property\n    def expense_documents(self) -> EntityList[ExpenseDocument]:\n        \"\"\"\n        Returns all the :class:`ExpenseDocument` objects present in the Document.\n\n        :return: List of ExpenseDocument objects, each representing an expense document within the Document.\n        :rtype: EntityList[ExpenseDocument]\n        \"\"\"\n        return EntityList(sum([page.expense_documents for page in self.pages], []))\n\n    @property\n    def lines(self) -> EntityList[Line]:\n        \"\"\"\n        Returns all the :class:`Line` objects present in the Document.\n\n        :return: List of Line objects, each representing a line within the Document.\n        :rtype: EntityList[Line]\n        \"\"\"\n        return EntityList(sum([page.lines for page in self.pages], []))\n\n    @property\n    def key_values(self) -> EntityList[KeyValue]:\n        \"\"\"\n        Returns all the :class:`KeyValue` objects present in the Document.\n\n        :return: List of KeyValue objects, each representing a key-value pair within the Document.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        return EntityList(sum([page.key_values for page in self.pages], []))\n\n    @property\n    def checkboxes(self) -> EntityList[KeyValue]:\n        \"\"\"\n        Returns all the :class:`KeyValue` objects with SelectionElements present in the Document.\n\n        :return: List of KeyValue objects, each representing a checkbox within the Document.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        return EntityList(sum([page.checkboxes for page in self.pages], []))\n\n    @property\n    def tables(self) -> EntityList[Table]:\n        \"\"\"\n        Returns all the :class:`Table` objects present in the Document.\n\n        :return: List of Table objects, each representing a table within the Document.\n        :rtype: EntityList[Table]\n        \"\"\"\n        return EntityList(sum([page.tables for page in self.pages], []))\n\n    @property\n    def queries(self) -> EntityList[Query]:\n        \"\"\"\n        Returns all the :class:`Query` objects present in the Document.\n\n        :return: List of Query objects.\n        :rtype: EntityList[Query]\n        \"\"\"\n        return EntityList(sum([page.queries for page in self.pages], []))\n\n    @property\n    def signatures(self) -> EntityList[Signature]:\n        \"\"\"\n        Returns all the :class:`Signature` objects present in the Document.\n\n        :return: List of Signature objects.\n        :rtype: EntityList[Signature]\n        \"\"\"\n        return EntityList(sum([page.signatures for page in self.pages], []))\n\n    @property\n    def layouts(self) -> EntityList[Layout]:\n        \"\"\"\n        Returns all the :class:`Layout` objects present in the Document\n\n        :return: List of Layout objects\n        :rtype: EntityList[Layout]\n        \"\"\"\n        return EntityList(sum([page.layouts for page in self.pages], []))\n\n    @property\n    def identity_document(self) -> EntityList[IdentityDocument]:\n        \"\"\"\n        Returns all the :class:`IdentityDocument` objects present in the Page.\n\n        :return: List of IdentityDocument objects.\n        :rtype: EntityList\n        \"\"\"\n        return EntityList(self._identity_documents)\n\n    @identity_document.setter\n    def identity_document(self, identity_documents: List[IdentityDocument]):\n        \"\"\"\n        Add IdentityDocument objects to the Page.\n\n        :param tables: List of IdentityDocument objects.\n        :type identity_documents: list\n        \"\"\"\n        self._identity_document = identity_documents\n\n    @property\n    def images(self) -> List[Image.Image]:\n        \"\"\"\n        Returns all the page images in the Document.\n\n        :return: List of PIL Image objects.\n        :rtype: PIL.Image\n        \"\"\"\n        return [page.image for page in self._pages]\n\n    @property\n    def pages(self) -> List[Page]:\n        \"\"\"\n        Returns all the :class:`Page` objects present in the Document.\n\n        :return: List of Page objects, each representing a Page within the Document.\n        :rtype: List\n        \"\"\"\n        return self._pages\n\n    @pages.setter\n    def pages(self, pages: List[Page]):\n        \"\"\"\n        Add Page objects to the Document.\n\n        :param pages: List of Page objects, each representing a page within the document.\n        No specific ordering is assumed with input.\n        :type pages: List[Page]\n        \"\"\"\n        self._pages = sorted(pages, key=lambda x: x.page_num)\n\n    def get_text_and_words(\n        self, config: TextLinearizationConfig = TextLinearizationConfig()\n    ) -> Tuple[str, List]:\n        text, words_lists = zip(*[p.get_text_and_words(config) for p in self.pages])\n        flattened_words = []\n        for words in words_lists:\n            flattened_words.extend(words)\n        return config.layout_element_separator.join(text), flattened_words\n\n    def page(self, page_no: int = 0):\n        \"\"\"\n        Returns :class:`Page` object/s depending on the input page_no. Follows zero-indexing.\n\n        :param page_no: if int, returns single Page Object, else if list, it returns a list of\n                        Page objects.\n        :type page_no: int if single page, list of int if multiple pages\n\n        :return: Filters and returns Page objects depending on the input page_no\n        :rtype: Page or List[Page]\n        \"\"\"\n        if isinstance(page_no, int):\n            return self.pages[page_no]\n        elif isinstance(page_no, list):\n            return [self.pages[num] for num in page_no]\n        else:\n            raise InputError(\"page_no parameter doesn't match required data type.\")\n\n    def to_html(self, config: HTMLLinearizationConfig = HTMLLinearizationConfig()):\n        \"\"\"\n        Returns the HTML representation of the document, effectively calls Linearizable.to_html()\n        but add <html><body></body></html> around the result and put each page in a <div>. \n\n        :return: HTML text of the entity\n        :rtype: str\n        \"\"\"\n        \n        html = \"<html><body>\"\n        for page in self.pages:\n            html += f\"<div>{page.to_html(config=config)}</div>\"\n        html += \"</body></html>\"\n        \n        return html\n\n    def __repr__(self):\n        return os.linesep.join(\n            [\n                \"This document holds the following data:\",\n                f\"Pages - {len(self.pages)}\",\n                f\"Words - {len(self.words)}\",\n                f\"Lines - {len(self.lines)}\",\n                f\"Key-values - {len(self.key_values)}\",\n                f\"Checkboxes - {len(self.checkboxes)}\",\n                f\"Tables - {len(self.tables)}\",\n                f\"Queries - {len(self.queries)}\",\n                f\"Signatures - {len(self.signatures)}\",\n                f\"Identity Documents - {len(self.identity_documents)}\",\n                f\"Expense Documents - {len(self.expense_documents)}\",\n            ]\n        )\n\n    def to_trp2(self):\n        \"\"\"\n        Parses the response to the trp2 format for backward compatibility\n\n        :return: TDocument object that can be used with the older Textractor libraries\n        :rtype: TDocument\n        \"\"\"\n        from trp.trp2 import TDocument, TDocumentSchema\n        \n        if not self._trp2_document:\n            self._trp2_document = TDocumentSchema().load(self.response)\n        return self._trp2_document\n\n    def visualize(self, *args, **kwargs):\n        \"\"\"\n        Returns the object's children in a visualization EntityList object\n\n        :return: Returns an EntityList object\n        :rtype: EntityList\n        \"\"\"\n        return EntityList(self.pages).visualize(*args, **kwargs)\n\n    def keys(self, include_checkboxes: bool = True) -> List[str]:\n        \"\"\"\n        Prints all keys for key-value pairs and checkboxes if the document contains them.\n\n        :param include_checkboxes: True/False. Set False if checkboxes need to be excluded.\n        :type include_checkboxes: bool\n\n        :return: List of strings containing key names in the Document\n        :rtype: List[str]\n        \"\"\"\n        keys = []\n        keys = [keyvalue.key for keyvalue in self.key_values]\n        if include_checkboxes:\n            keys += [keyvalue.key for keyvalue in self.checkboxes]\n        return keys\n\n    def filter_checkboxes(\n        self, selected: bool = True, not_selected: bool = True\n    ) -> List[KeyValue]:\n        \"\"\"\n        Return a list of :class:`KeyValue` objects containing checkboxes if the document contains them.\n\n        :param selected: True/False Return SELECTED checkboxes\n        :type selected: bool\n        :param not_selected: True/False Return NOT_SELECTED checkboxes\n        :type not_selected: bool\n\n        :return: Returns checkboxes that match the conditions set by the flags.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n\n        checkboxes = EntityList([])\n        for page in self.pages:\n            checkboxes.extend(\n                page.filter_checkboxes(selected=selected, not_selected=not_selected)\n            )\n        return checkboxes\n\n    def get_words_by_type(self, text_type: TextTypes = TextTypes.PRINTED) -> List[Word]:\n        \"\"\"\n        Returns list of :class:`Word` entities that match the input text type.\n\n        :param text_type: TextTypes.PRINTED or TextTypes.HANDWRITING\n        :type text_type: TextTypes\n        :return: Returns list of Word entities that match the input text type.\n        :rtype: EntityList[Word]\n        \"\"\"\n        if not self.words:\n            logging.warn(\"Document contains no word entities.\")\n            return []\n\n        filtered_words = EntityList()\n        for page in self.pages:\n            filtered_words.extend(page.get_words_by_type(text_type=text_type))\n        return filtered_words\n\n    def search_words(\n        self,\n        keyword: str,\n        top_k: int = 1,\n        similarity_metric: SimilarityMetric = SimilarityMetric.LEVENSHTEIN,\n        similarity_threshold: float = 0.6,\n    ) -> List[Word]:\n        \"\"\"\n        Return a list of top_k words that match the keyword.\n\n        :param keyword: Keyword that is used to query the document.\n        :type keyword: str\n        :param top_k: Number of closest word objects to be returned\n        :type top_k: int\n        :param similarity_metric: SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN or SimilarityMetric.LEVENSHTEIN. SimilarityMetric.COSINE is chosen as default.\n        :type similarity_metric: SimilarityMetric\n        :param similarity_threshold: Measure of how similar document key is to queried key. default=0.6\n        :type similarity_threshold: float\n\n        :return: Returns a list of words that match the queried key sorted from highest\n                 to lowest similarity.\n        :rtype: EntityList[Word]\n        \"\"\"\n\n        top_n_words = []\n        for page in self.pages:\n            top_n_words.extend(\n                page._search_words_with_similarity(\n                    keyword=keyword,\n                    top_k=top_k,\n                    similarity_metric=similarity_metric,\n                    similarity_threshold=similarity_threshold,\n                )\n            )\n\n        top_n_words = sorted(top_n_words, key=lambda x: x[0], reverse=True)[:top_k]\n        top_n_words = EntityList([ent[1] for ent in top_n_words])\n\n        return top_n_words\n\n    def search_lines(\n        self,\n        keyword: str,\n        top_k: int = 1,\n        similarity_metric: SimilarityMetric = SimilarityMetric.LEVENSHTEIN,\n        similarity_threshold: float = 0.6,\n    ) -> List[Line]:\n        \"\"\"\n        Return a list of top_k lines that contain the queried keyword.\n\n        :param keyword: Keyword that is used to query the document.\n        :type keyword: str\n        :param top_k: Number of closest line objects to be returned\n        :type top_k: int\n        :param similarity_metric: SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN or SimilarityMetric.LEVENSHTEIN. SimilarityMetric.COSINE is chosen as default.\n        :type similarity_metric: SimilarityMetric\n        :param similarity_threshold: Measure of how similar document key is to queried key. default=0.6\n        :type similarity_threshold: float\n\n        :return: Returns a list of lines that contain the queried key sorted from highest\n                 to lowest similarity.\n        :rtype: EntityList[Line]\n        \"\"\"\n        if not isinstance(similarity_metric, SimilarityMetric):\n            raise InputError(\n                \"similarity_metric parameter should be of SimilarityMetric type. Find input choices from textractor.data.constants\"\n            )\n\n        top_n_lines = []\n        for page in self.pages:\n            top_n_lines.extend(\n                page._search_lines_with_similarity(\n                    keyword=keyword,\n                    top_k=top_k,\n                    similarity_metric=similarity_metric,\n                    similarity_threshold=similarity_threshold,\n                )\n            )\n\n        top_n_lines = EntityList([ent[1] for ent in top_n_lines][:top_k])\n\n        return top_n_lines\n\n    # KeyValue entity related functions\n    def get(\n        self,\n        key: str,\n        top_k_matches: int = 1,\n        similarity_metric: SimilarityMetric = SimilarityMetric.LEVENSHTEIN,\n        similarity_threshold: float = 0.6,\n    ):\n        \"\"\"\n        Return upto top_k_matches of key-value pairs for the key that is queried from the document.\n\n        :param key: Query key to match\n        :type key: str\n        :param top_k_matches: Maximum number of matches to return\n        :type top_k_matches: int\n        :param similarity_metric: SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN or SimilarityMetric.LEVENSHTEIN. SimilarityMetric.COSINE is chosen as default.\n        :type similarity_metric: SimilarityMetric\n        :param similarity_threshold: Measure of how similar document key is to queried key. default=0.6\n        :type similarity_threshold: float\n\n        :return: Returns a list of key-value pairs that match the queried key sorted from highest to lowest similarity.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        if not isinstance(similarity_metric, SimilarityMetric):\n            raise InputError(\n                \"similarity_metric parameter should be of SimilarityMetric type. Find input choices from textractor.data.constants\"\n            )\n\n        top_n = []\n        similarity_threshold = (\n            -similarity_threshold\n            if similarity_metric == SimilarityMetric.EUCLIDEAN\n            else similarity_threshold\n        )\n        lowest_similarity = similarity_threshold\n\n        for kv in self.key_values + self.checkboxes:\n            try:\n                edited_document_key = \"\".join(\n                    [\n                        char\n                        for char in kv.key.__repr__()\n                        if char not in string.punctuation\n                    ]\n                )\n            except:\n                pass\n            key = \"\".join([char for char in key if char not in string.punctuation])\n\n            similarity = [\n                SearchUtils.get_word_similarity(key, word, similarity_metric)\n                for word in edited_document_key.split(\" \")\n            ]\n            similarity.append(\n                SearchUtils.get_word_similarity(\n                    key, edited_document_key, similarity_metric\n                )\n            )\n\n            similarity = (\n                min(similarity)\n                if similarity_metric == SimilarityMetric.EUCLIDEAN\n                else max(similarity)\n            )\n\n            if similarity > similarity_threshold:\n                if len(top_n) < top_k_matches:\n                    top_n.append((kv, similarity))\n                elif similarity > lowest_similarity:\n                    top_n[-1] = (kv, similarity)\n                top_n = sorted(top_n, key=lambda x: x[1], reverse=True)\n                lowest_similarity = top_n[-1][1]\n\n        if not top_n:\n            logging.warning(\n                f\"Query key does not match any existing keys in the document.{os.linesep}{self.keys()}\"\n            )\n            return EntityList([])\n\n        logging.info(f\"Query key matched {len(top_n)} key-values in the document.\")\n\n        return EntityList([value[0] for value in top_n])\n\n    # Export document entities into supported formats\n    def export_kv_to_csv(\n        self,\n        include_kv: bool = True,\n        include_checkboxes: bool = True,\n        filepath: str = \"Key-Values.csv\",\n        sep: str = \";\",\n    ):\n        \"\"\"\n        Export key-value entities and checkboxes in csv format.\n\n        :param include_kv: True if KVs are to be exported. Else False.\n        :type include_kv: bool\n        :param include_checkboxes: True if checkboxes are to be exported. Else False.\n        :type include_checkboxes: bool\n        :param filepath: Path to where file is to be stored.\n        :type filepath: str\n        :param sep: Separator to be used in the csv file.\n        :type sep: str\n        \"\"\"\n        keys = []\n        values = []\n        if include_kv and not self.key_values:\n            logging.warning(\"Document does not contain key-values.\")\n        elif include_kv:\n            for kv in self.key_values:\n                keys.append(\" \".join([w.text for w in kv.key]))\n                values.append(kv.value.get_text())\n\n        if include_checkboxes and not self.checkboxes:\n            logging.warning(\"Document does not contain checkbox elements.\")\n        elif include_checkboxes:\n            for kv in self.checkboxes:\n                keys.append(\" \".join([w.text for w in kv.key]))\n                values.append(kv.value.children[0].status.name)\n\n        with open(filepath, \"w\") as f:\n            f.write(f\"Key{sep}Value{os.linesep}\")\n            for k, v in zip(keys, values):\n                f.write(f\"{k}{sep}{v}{os.linesep}\")\n\n        logging.info(\n            f\"csv file stored at location {os.path.join(os.getcwd(),filepath)}\"\n        )\n\n    def export_kv_to_txt(\n        self,\n        include_kv: bool = True,\n        include_checkboxes: bool = True,\n        filepath: str = \"Key-Values.txt\",\n    ):\n        \"\"\"\n        Export key-value entities and checkboxes in txt format.\n\n        :param include_kv: True if KVs are to be exported. Else False.\n        :type include_kv: bool\n        :param include_checkboxes: True if checkboxes are to be exported. Else False.\n        :type include_checkboxes: bool\n        :param filepath: Path to where file is to be stored.\n        :type filepath: str\n        \"\"\"\n        export_str = \"\"\n        index = 1\n        if include_kv and not self.key_values:\n            logging.warning(\"Document does not contain key-values.\")\n        elif include_kv:\n            for kv in self.key_values:\n                export_str += (\n                    f\"{index}. {kv.key.__repr__()} : {kv.value.__repr__()}{os.linesep}\"\n                )\n                index += 1\n\n        if include_checkboxes and not self.checkboxes:\n            logging.warning(\"Document does not contain checkbox elements.\")\n        elif include_checkboxes:\n            for kv in self.checkboxes:\n                export_str += f\"{index}. {kv.key.__repr__()} : {kv.value.children[0].status.name}{os.linesep}\"\n                index += 1\n\n        with open(filepath, \"w\") as text_file:\n            text_file.write(export_str)\n        logging.info(\n            f\"txt file stored at location {os.path.join(os.getcwd(),filepath)}\"\n        )\n\n    def export_tables_to_excel(self, filepath):\n        \"\"\"\n        Creates an excel file and writes each table on a separate worksheet within the workbook.\n        This is stored on the filepath passed by the user.\n\n        :param filepath: Path to store the exported Excel file.\n        :type filepath: str, required\n        \"\"\"\n        if not filepath:\n            logging.error(\"Filepath required to store excel file.\")\n        workbook = xlsxwriter.Workbook(filepath)\n        for table in self.tables:\n            workbook = table.to_excel(\n                filepath=None, workbook=workbook, save_workbook=False\n            )\n        workbook.close()\n\n    def independent_words(self):\n        \"\"\"\n        :return: Return all words in the document, outside of tables, checkboxes, key-values.\n        :rtype: EntityList[Word]\n        \"\"\"\n        if not self.words:\n            logging.warning(\"Words have not been assigned to this Document object.\")\n            return []\n\n        else:\n            table_words = sum([table.words for table in self.tables], [])\n            kv_words = sum([kv.words for kv in self.key_values], [])\n            checkbox_words = sum([kv.words for kv in self.checkboxes], [])\n            dependent_words = table_words + checkbox_words + kv_words\n            dependent_word_ids = set([word.id for word in dependent_words])\n            independent_words = [\n                word for word in self.words if word.id not in dependent_word_ids\n            ]\n            return EntityList(independent_words)\n\n    def return_duplicates(self):\n        \"\"\"\n        Returns a dictionary containing page numbers as keys and list of :class:`EntityList` objects as values.\n        Each :class:`EntityList` instance contains the key-values and the last item is the table which contains duplicate information.\n        This function is intended to let the Textract user know of duplicate objects extracted by the various Textract models.\n\n        :return: Dictionary containing page numbers as keys and list of EntityList objects as values.\n        :rtype: Dict[page_num, List[EntityList[DocumentEntity]]]\n        \"\"\"\n        document_duplicates = defaultdict(list)\n\n        for page in self.pages:\n            document_duplicates[page.page_num].extend(page.return_duplicates())\n\n        return document_duplicates\n\n    def directional_finder(\n        self,\n        word_1: str = \"\",\n        word_2: str = \"\",\n        page: int = -1,\n        prefix: str = \"\",\n        direction=Direction.BELOW,\n        entities=[],\n    ):\n        \"\"\"\n        The function returns entity types present in entities by prepending the prefix provided by te user. This helps in cases of repeating\n        key-values and checkboxes. The user can manipulate original data or produce a copy. The main advantage of this function is to be able to define direction.\n\n        :param word_1: The reference word from where x1, y1 coordinates are derived\n        :type word_1: str, required\n        :param word_2: The second word preferably in the direction indicated by the parameter direction. When it isn't given the end of page coordinates are used in the given direction.\n        :type word_2: str, optional\n        :param page: page number of the page in the document to search the entities in.\n        :type page: int, required\n        :param prefix: User provided prefix to prepend to the key . Without prefix, the method acts as a search by geometry function\n        :type prefix: str, optional\n        :param entities: List of DirectionalFinderType inputs.\n        :type entities: List[DirectionalFinderType]\n\n        :return: Returns the EntityList of modified key-value and/or checkboxes\n        :rtype: EntityList\n        \"\"\"\n\n        if not word_1 or page == -1:\n            return EntityList([])\n\n        x1, x2, y1, y2 = self._get_coords(word_1, word_2, direction, page)\n\n        if x1 == -1:\n            return EntityList([])\n\n        page_obj = self.pages[page - 1]\n        entity_dict = {\n            DirectionalFinderType.KEY_VALUE_SET: self.key_values,\n            DirectionalFinderType.SELECTION_ELEMENT: self.checkboxes,\n        }\n\n        entitylist = []\n        for entity_type in entities:\n            entitylist.extend(list(entity_dict[entity_type]))\n\n        new_key_values = self._get_kv_with_direction(\n            direction, entitylist, (x1, x2, y1, y2)\n        )\n\n        final_kv = []\n        for kv in new_key_values:\n            if kv.key:\n                key_words = [deepcopy(word) for word in kv.key]\n                key_words[0].text = prefix + key_words[0].text\n                new_kv = deepcopy(kv)\n                new_kv.key = key_words\n                final_kv.append(new_kv)\n            else:\n                final_kv.append(kv)\n\n        return EntityList(final_kv)\n\n    def _get_kv_with_direction(self, direction, entitylist, coords):\n        \"\"\"Return key-values and checkboxes in entitylist present in the direction given with respect to the coordinates.\"\"\"\n        if direction == Direction.ABOVE:\n            new_key_values = [\n                kv\n                for kv in entitylist\n                if kv.bbox.y <= coords[2] and kv.bbox.y >= coords[-1]\n            ]\n\n        elif direction == Direction.BELOW:\n            new_key_values = [\n                kv\n                for kv in entitylist\n                if kv.bbox.y >= coords[2] and kv.bbox.y <= coords[-1]\n            ]\n\n        elif direction == Direction.RIGHT:\n            new_key_values = [\n                kv\n                for kv in entitylist\n                if kv.bbox.x >= coords[0] and kv.bbox.x <= coords[1]\n            ]\n            new_key_values = [\n                kv\n                for kv in new_key_values\n                if kv.bbox.y >= coords[2] - kv.bbox.height\n                and kv.bbox.y <= coords[-1] + 3 * kv.bbox.height\n            ]\n\n        elif direction == Direction.LEFT:\n            new_key_values = [\n                kv\n                for kv in entitylist\n                if kv.bbox.x <= coords[0] and kv.bbox.x >= coords[1]\n            ]\n            new_key_values = [\n                kv\n                for kv in new_key_values\n                if kv.bbox.y >= coords[2] - kv.bbox.height\n                and kv.bbox.y <= coords[-1] + 3 * kv.bbox.height\n            ]\n\n        return new_key_values\n\n    def _get_coords(self, word_1, word_2, direction, page):\n        \"\"\"\n        Returns coordinates for the area within which to search for key-values with the directional_finder by retrieving coordinates of word_1 \\\n        and word_2 if it exists else end of page.\n        \"\"\"\n        word_1_objects = self.search_lines(\n            keyword=word_1,\n            top_k=5,\n            similarity_metric=SimilarityMetric.COSINE,\n            similarity_threshold=0.5,\n        )\n        word_1_objects = (\n            [word for word in word_1_objects if word.page == page] if page != -1 else []\n        )\n\n        if not word_1_objects:\n            logging.warning(f\"{word_1} not found in page {page}\")\n            return -1, -1, -1, -1\n        else:\n            word_1_obj = word_1_objects[0]\n            x1, y1 = word_1_obj.bbox.x, word_1_obj.bbox.y\n\n        if word_2:\n            word_2_objects = self.search_lines(\n                keyword=word_2,\n                top_k=5,\n                similarity_metric=SimilarityMetric.COSINE,\n                similarity_threshold=0.5,\n            )\n            word_2_objects = [word for word in word_2_objects if word.page == page]\n            if not word_2_objects:\n                logging.warning(f\"{word_2} not found in page {page}\")\n                return -1, -1, -1, -1\n            else:\n                word_2_obj = word_2_objects[0]\n                x2, y2 = word_2_obj.bbox.x, word_2_obj.bbox.y\n        else:\n            x2, y2 = x1, y1\n\n        if direction == Direction.ABOVE:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if y2 < y1 else (x1, 0, y1, 0)\n\n        elif direction == Direction.BELOW:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if y2 > y1 else (x1, 1, y1, 1)\n\n        elif direction == Direction.RIGHT:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if x2 > x1 else (x1, 1, y1, y1)\n\n        elif direction == Direction.LEFT:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if x2 < x1 else (x1, 0, y1, y1)\n\n        else:\n            return -1, -1, -1, -1\n\n        return x1, x2, y1, y2\n",
    "textractor/visualizers/entitylist.py": "\"\"\"\nThe :class:`EntityList` is an extension of list type with custom functions to print document entities \\\nin a well formatted manner and visualize on top of the document page with their BoundingBox information. \n\nThe two main functions within this class are :code:`pretty_print()` and :code:`visualize()`.\nUse :code:`pretty_print()` to get a string formatted output of your custom list of entities.\nUse :code:`visualize()` to get the bounding box visualization of the entities on the document page images.\n\"\"\"\n\nimport os\nimport csv\nimport logging\nfrom enum import Enum\nfrom io import StringIO\nfrom tabulate import tabulate\nfrom typing import List, Optional, TypeVar, Generic, Any\nfrom collections import defaultdict\nfrom textractor.utils.geometry_util import get_indices\nfrom PIL import Image, ImageDraw, ImageColor, ImageFont\n\nfrom textractor.data.constants import (\n    TextractType,\n    TableFormat,\n    AnalyzeExpenseLineItemFields,\n    AnalyzeExpenseFields,\n)\nfrom textractor.exceptions import EntityListCreationError, NoImageException\nfrom textractor.entities.linearizable import Linearizable\nfrom textractor.data.text_linearization_config import TextLinearizationConfig\n\nlogger = logging.getLogger(__name__)\n\npresent_path = os.path.abspath(os.path.dirname(__file__))\n\nT = TypeVar(\"T\")\n\n\nclass EntityList(list, Generic[T], Linearizable):\n    \"\"\"\n    Creates a list type object, initially empty but extended with the list passed in objs.\n\n    :param objs: Custom list of objects that can be visualized with this class.\n    :type objs: list\n    \"\"\"\n\n    def __init__(self, objs=None):\n        super().__init__()\n\n        if objs is None:\n            objs = []\n        elif not isinstance(objs, list):\n            objs = [objs]\n\n        self.extend(objs)\n\n    def visualize(\n        self,\n        with_text: bool = True,\n        with_words: bool = True,\n        with_confidence: bool = False,\n        font_size_ratio: float = 0.5,\n    ) -> List:\n        \"\"\"\n        Returns list of PIL Images with bounding boxes drawn around the entities in the list.\n\n        :param with_text: Flag to print the OCR output of Textract on top of the text bounding box.\n        :type with_text: bool\n        :param with_confidence: Flag to print the confidence of prediction on top of the entity bounding box.\n        :type with_confidence: bool\n\n        :return: Returns list of PIL Images with bounding boxes drawn around the entities in the list.\n        :rtype: list\n        \"\"\"\n        # FIXME: This is inelegant\n        if len(self) > 0 and any(\n            [ent.__class__.__name__ == \"Document\" for ent in self]\n        ):\n            return EntityList(self[0].pages).visualize(\n                with_text=with_text,\n                with_words=with_words,\n                with_confidence=with_confidence,\n                font_size_ratio=font_size_ratio,\n            )\n        elif len(self) > 0 and any([ent.__class__.__name__ == \"Page\" for ent in self]):\n            new_entity_list = []\n            for entity in self:\n                if not with_words and (\n                    entity.__class__.__name__ == \"Word\"\n                    or entity.__class__.__name__ == \"Line\"\n                ):\n                    continue\n                if entity.__class__.__name__ == \"Page\":\n                    if with_words:\n                        new_entity_list.extend(entity.words)\n                        new_entity_list.extend(entity.lines)\n                    new_entity_list.extend(entity.tables)\n                    new_entity_list.extend(entity.key_values)\n                    new_entity_list.extend(entity.checkboxes)\n                    new_entity_list.extend(entity.layouts)\n                    for expense_document in entity.expense_documents:\n                        new_entity_list = self._add_expense_document_to_list(\n                            new_entity_list, expense_document\n                        )\n                elif entity.__class__.__name__ == \"ExpenseDocument\":\n                    self._add_expense_document_to_list(new_entity_list, entity)\n                else:\n                    new_entity_list.append(entity)\n            return EntityList(list(dict.fromkeys(new_entity_list).keys())).visualize(\n                with_text=with_text,\n                with_words=with_words,\n                with_confidence=with_confidence,\n                font_size_ratio=font_size_ratio,\n            )\n        elif len(self) > 0 and self[0].bbox.spatial_object.image is None:\n            raise NoImageException(\n                \"Image was not saved during the Textract API call. Set save_image=True when calling the Textractor methods to use the visualize() method.\"\n            )\n\n        visualized_images = {}\n        entities_pagewise = defaultdict(list)\n        for obj in self:\n            entities_pagewise[obj.page].append(obj)\n            if obj.page is None:\n                print(obj.__class__.__name__)\n            try:\n                if with_words:\n                    entities_pagewise[obj.page].extend(obj.words)\n            # FIXME: There should be a way to recurse through all entities\n            except AttributeError:\n                pass\n\n        for page in list(entities_pagewise.keys()):\n            # Deduplication\n            entities_pagewise[page] = list(dict.fromkeys(entities_pagewise[page]).keys())\n\n        for page in entities_pagewise.keys():\n            visualized_images[page] = _draw_bbox(\n                entities_pagewise[page],\n                with_text,\n                with_confidence,\n                font_size_ratio,\n            )\n\n        images = [image.convert(\"RGB\") for image in visualized_images.values()]\n        images = images if len(images) != 1 else images[0]\n        return images\n\n    def _add_expense_document_to_list(self, entity_list, expense_document):\n        entity_list.append(expense_document)\n        for field in expense_document.summary_fields_list:\n            entity_list.append(field)\n        for line_item_group in expense_document.line_items_groups:\n            entity_list.append(line_item_group)\n            for row in line_item_group.rows:\n                entity_list.append(row)\n                for expense in row.expenses:\n                    if (\n                        expense.type.text\n                        != AnalyzeExpenseLineItemFields.EXPENSE_ROW.name\n                    ):\n                        entity_list.append(expense)\n        return entity_list\n\n    def pretty_print(\n        self,\n        table_format: TableFormat = TableFormat.GITHUB,\n        with_confidence: bool = False,\n        with_geo: bool = False,\n        with_page_number: bool = False,\n        trim: bool = False,\n    ) -> str:\n        \"\"\"\n        Returns a formatted string output for each of the entities in the list according to its entity type.\n\n        :param table_format: Choose one of the defined TableFormat types to decorate the table output string. This is a predefined set of choices by the PyPI tabulate package. It is used only if there are KeyValues or Tables in the list of textractor.entities.\n        :type table_format: TableFormat\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n        :type with_geo: bool\n        :param with_page_number: Flag to add the page number to the entity string. default= False.\n        :type with_page_number: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n\n        :return: Returns a formatted string output for each of the entities in the list according to its entity type.\n        :rtype: str\n        \"\"\"\n\n        result_value = \"\"\n        result_value += self._get_text_string(\n            with_page_number=with_page_number,\n            with_confidence=with_confidence,\n            trim=trim,\n            textract_type=TextractType.WORDS,\n        )\n        result_value += self._get_text_string(\n            with_page_number=with_page_number,\n            with_confidence=with_confidence,\n            trim=trim,\n            textract_type=TextractType.LINES,\n        )\n        result_value += self._get_forms_string(\n            table_format=table_format,\n            with_confidence=with_confidence,\n            with_geo=with_geo,\n            trim=trim,\n            textract_type=TextractType.KEY_VALUE_SET,\n        )\n        result_value += self._get_forms_string(\n            table_format=table_format,\n            with_confidence=with_confidence,\n            with_geo=with_geo,\n            trim=trim,\n            textract_type=TextractType.SELECTION_ELEMENT,\n        )\n        result_value += self._get_tables_string(\n            table_format=table_format,\n            with_confidence=with_confidence,\n            with_geo=with_geo,\n            trim=trim,\n        )\n        result_value += self._get_queries_string()\n        result_value += self._get_expense_documents_string()\n        result_value += self._get_id_documents_string()\n        return result_value\n\n    def _get_text_string(\n        self,\n        with_page_number=False,\n        with_confidence=False,\n        trim=False,\n        textract_type=TextractType.WORDS,\n    ):\n        \"\"\"\n        Returns a formatted string output for the entity type stated in the textract_type param. This function is\n        specific to TextractType.WORDS and TextractType.LINES.\n\n        :param with_page_number: Flag to add the page number to the entity string. default= False.\n        :type with_page_number: bool\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n        :param textract_type: TextractType.WORDS / TextractType.LINES\n        :type textract_type: TextractType\n\n        :return: Returns a formatted string output for the entity type stated in the textract_type param.\n        :rtype: str\n        \"\"\"\n\n        result_value = \"\"\n\n        if textract_type == TextractType.WORDS:\n            objects = sorted(\n                [obj for obj in self if obj.__class__.__name__ == \"Word\"],\n                key=lambda x: x.page,\n            )\n        else:\n            objects = sorted(\n                [obj for obj in self if obj.__class__.__name__ == \"Line\"],\n                key=lambda x: x.page,\n            )\n\n        current_page = -1\n\n        for word in objects:\n            if with_page_number and word.page != current_page:\n                result_value += f\"--------- page number: {word.page} - page ID: {word.page_id} --------------{os.linesep}\"\n                current_page = word.page\n            if trim:\n                result_value += f\"{word.text.strip()}\"\n            else:\n                result_value += f\"{word.text}\"\n\n            if with_confidence:\n                result_value += f\", {word.confidence}\"\n            result_value += os.linesep\n\n        return result_value\n\n    def _get_forms_string(\n        self,\n        table_format: TableFormat = TableFormat.GITHUB,\n        with_confidence: bool = False,\n        with_geo: bool = False,\n        trim: bool = False,\n        textract_type=TextractType.KEY_VALUE_SET,\n    ) -> str:\n        \"\"\"\n        Returns a formatted string output for the entity type stated in the textract_type param. This function is\n        specific to TextractType.KEY_VALUE_SET and TextractType.SELECTION_ELEMENT.\n\n        :param table_format: Choose one of the defined TableFormat types to decorate the table output string.\n                             This is a predefined set of choices by the PyPI tabulate package.\n        :type table_format: TableFormat\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n        :type with_geo: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n        :param textract_type: TextractType.KEY_VALUE_SET / TextractType.SELECTION_ELEMENT\n        :type textract_type: TextractType\n\n        :return: Returns a formatted string output for the entity type stated in the textract_type param.\n        :rtype: str\n        \"\"\"\n\n        logger.debug(f\"table_format: {table_format}\")\n        result_value = \"\"\n\n        if textract_type == TextractType.KEY_VALUE_SET:\n            key_value_objects = [\n                obj\n                for obj in self\n                if obj.__class__.__name__ == \"KeyValue\" and not obj.contains_checkbox\n            ]\n        else:\n            key_value_objects = [\n                obj\n                for obj in self\n                if obj.__class__.__name__ == \"KeyValue\" and obj.contains_checkbox\n            ]\n\n        kv_dict = {obj.page: [] for obj in key_value_objects}\n\n        for obj in key_value_objects:\n            kv_dict[obj.page].append(obj)\n\n        if not table_format == TableFormat.CSV:\n            for page in kv_dict.keys():\n                forms_list = _convert_form_to_list(\n                    kv_dict[page],\n                    with_confidence=with_confidence,\n                    with_geo=with_geo,\n                    trim=trim,\n                    textract_type=textract_type,\n                )\n                result_value += (\n                    tabulate(forms_list, tablefmt=table_format.name.lower())\n                    + os.linesep\n                    + os.linesep\n                )\n\n        if table_format == TableFormat.CSV:\n            logger.debug(f\"pretty print - csv\")\n            csv_output = StringIO()\n            csv_writer = csv.writer(\n                csv_output, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n            )\n            for page in kv_dict.keys():\n                forms_list = _convert_form_to_list(\n                    kv_dict[page],\n                    with_confidence=with_confidence,\n                    with_geo=with_geo,\n                    trim=trim,\n                    textract_type=textract_type,\n                )\n                csv_writer.writerows(forms_list)\n            csv_writer.writerow([])\n            result_value = csv_output.getvalue()\n        return result_value\n\n    def _get_tables_string(\n        self,\n        table_format: TableFormat = TableFormat.GITHUB,\n        with_confidence: bool = False,\n        with_geo: bool = False,\n        trim: bool = False,\n    ) -> str:\n        \"\"\"\n        Returns a formatted string output for the Table entity type.\n\n        :param table_format: Choose one of the defined TableFormat types to decorate the table output string.\n                             This is a predefined set of choices by the PyPI tabulate package.\n        :type table_format: TableFormat\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n        :type with_geo: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n\n        :return: Returns a formatted string output for the Table entity type.\n        :rtype: str\n        \"\"\"\n\n        logger.debug(f\"table_format: {table_format}\")\n\n        tables = {}\n        for obj in self:\n            if obj.__class__.__name__ == \"Table\":\n                tables[obj.id] = obj\n            elif obj.__class__.__name__ == \"TableCell\":\n                if obj.table_id in tables.keys():\n                    tables[obj.table_id].append(obj)\n                else:\n                    tables[obj.table_id] = [obj]\n\n        result_value = \"\"\n        if not table_format == TableFormat.CSV:\n            for table_id in tables.keys():\n                table_type = (\n                    TextractType.TABLES\n                    if tables[table_id].__class__.__name__ == \"Table\"\n                    else TextractType.TABLE_CELL\n                )\n\n                table_list = _convert_table_to_list(\n                    tables[table_id],\n                    with_confidence=with_confidence,\n                    with_geo=with_geo,\n                    trim=trim,\n                    textract_type=table_type,\n                )\n                result_value += (\n                    tabulate(table_list, tablefmt=table_format.name.lower())\n                    + os.linesep\n                    + os.linesep\n                )\n\n        if table_format == TableFormat.CSV:\n            logger.debug(f\"pretty print - csv\")\n            for table_id in tables.keys():\n                table_type = (\n                    TextractType.TABLES\n                    if tables[table_id].__class__.__name__ == \"Table\"\n                    else TextractType.TABLE_CELL\n                )\n                csv_output = StringIO()\n                csv_writer = csv.writer(\n                    csv_output, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n                )\n\n                table_list = _convert_table_to_list(\n                    tables[table_id],\n                    with_confidence=with_confidence,\n                    with_geo=with_geo,\n                    trim=trim,\n                    textract_type=table_type,\n                )\n                csv_writer.writerows(table_list)\n                csv_writer.writerow([])\n                result_value += csv_output.getvalue()\n        return result_value\n\n    def _get_queries_string(self):\n        result_value = \"\"\n        queries = [obj for obj in self if obj.__class__.__name__ == \"Query\"]\n\n        for query in queries:\n            if query.result is not None:\n                result_value += f\"{query.query} => {query.result.answer}{os.linesep}\"\n            else:\n                result_value += f\"{query.query} => {os.linesep}\"\n\n        return result_value\n\n    def _get_expense_documents_string(self):\n        result_value = \"\"\n        expense_documents = [\n            obj for obj in self if obj.__class__.__name__ == \"ExpenseDocument\"\n        ]\n\n        for i, expense_document in enumerate(expense_documents):\n            result_value += f\"Expense Document {i+1}:{os.linesep}\"\n            result_value += f\"### Summary Fields:{os.linesep}\"\n            result_value += f\"{expense_document.summary_fields}{os.linesep}\"\n            result_value += f\"### Line Item Groups: {os.linesep}\"\n            for line_item_group in expense_document.line_items_groups:\n                result_value += f\"{line_item_group}{os.linesep}\"\n\n        return result_value\n\n    def _get_id_documents_string(self):\n        result_value = \"\"\n        id_documents = [\n            obj for obj in self if obj.__class__.__name__ == \"IdentityDocument\"\n        ]\n\n        for id_document in id_documents:\n            result_value += f\"{id_document}{os.linesep}\"\n\n        return result_value\n\n    def __add__(self, list2):\n        return EntityList([*self, *list2])\n\n    def get_text_and_words(self, config: TextLinearizationConfig = TextLinearizationConfig()):\n        texts, words = [], []\n        separator = (\n            config.same_paragraph_separator\n            if all([entity.__class__.__name__ == \"Word\" for entity in self]) else\n            config.layout_element_separator\n        )\n        for entity in self:\n            entity_text, entity_words = entity.get_text_and_words(config)\n            texts.append(entity_text)\n            words.extend(entity_words)\n        return separator.join(texts), words\n\ndef _convert_form_to_list(\n    form_objects,\n    with_confidence: bool = False,\n    with_geo: bool = False,\n    trim: bool = False,\n    textract_type=TextractType.KEY_VALUE_SET,\n) -> List:\n    \"\"\"\n    Converts KeyValue objects (KEY_VALUE_SET in JSON) to row-wise list format to pretty_print using the\n    PyPI tabulate package.\n\n    :param form_objects: KeyValue instances to be formatted into strings\n    :type form_objects: KeyValue\n    :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n    :type with_confidence: bool\n    :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n    :type with_geo: bool\n    :param trim: Flag to trim text in the entity string. default= False.\n    :type trim: bool\n    :param textract_type: TextractType.KEY_VALUE_SET / TextractType.SELECTION_ELEMENT\n    :type textract_type: TextractType\n\n    :return: Returns a list of lists, each inner list containing a key-value pair.\n    :rtype: List[List[str]]\n    \"\"\"\n\n    rows_list = list()\n    rows_list.append([\"Key\", \"Value\"])\n    for field in form_objects:\n        t_key = \"\"\n        t_value = \"\"\n        if field.key:\n            text = \" \".join([word.text for word in field.key])\n            if trim:\n                t_key = text.strip()\n            else:\n                t_key = text\n            if with_geo:\n                t_key += \" {\" + field.bbox.__repr__() + \"} \"\n            if with_confidence:\n                t_key += f\" ({field.key.confidence:.1f})\"\n        if field.value:\n            text = (\n                field.value.words\n                if textract_type == TextractType.SELECTION_ELEMENT\n                else \" \".join([word.text for word in field.value.words])\n            )\n            if trim:\n                t_value = text.strip()\n            else:\n                t_value = text\n            if with_geo:\n                t_value += \" {\" + field.value.bbox.__repr__() + \"} \"\n            if with_confidence:\n                t_value += f\" ({field.value.confidence:.1f})\"\n        rows_list.append([t_key, t_value])\n    return rows_list\n\n\ndef _convert_table_to_list(\n    table_object,\n    with_confidence: bool = False,\n    with_geo: bool = False,\n    trim: bool = False,\n    textract_type=TextractType.TABLES,\n) -> List:\n    \"\"\"\n    Converts Table objects (TABLE in JSON) to row-wise list format to pretty_print using the\n    PyPI tabulate package.\n\n    :param table_object: Table instance to be formatted into strings\n    :type table_object: Table\n    :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n    :type with_confidence: bool\n    :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n    :type with_geo: bool\n    :param trim: Flag to trim text in the entity string. default= False.\n    :type trim: bool\n    :param textract_type: TextractType.TABLES / TextractType.TABLE_CELL\n    :type textract_type: TextractType\n\n    :return: Returns a list of lists, each inner list containing a row of table data.\n    :rtype: List[List]\n    \"\"\"\n    if textract_type == TextractType.TABLES:\n        rowwise_table = table_object._get_table_cells()\n    else:\n        rowwise_table = {cell.row_index: [] for cell in table_object}\n        for cell in table_object:\n            rowwise_table[cell.row_index].append(cell)\n    table_rows = []\n    for row in rowwise_table.keys():\n        row_data = []\n        for cell in rowwise_table[row]:\n            text = cell.__repr__().split(\">\")[-1][1:]\n            if trim:\n                t_key = text.strip()\n            else:\n                t_key = text\n            if with_geo:\n                t_key += \" {\" + cell.bbox.__repr__() + \"} \"\n            if with_confidence:\n                t_key += f\" ({cell.confidence:.1f})\"\n            row_data.append(t_key)\n        table_rows.append(row_data)\n    return table_rows\n\n\ndef _draw_bbox(\n    entities: List[Any],\n    with_text: bool = False,\n    with_confidence: bool = False,\n    font_size_ratio: float = 0.5,\n):\n    \"\"\"\n    Function to draw bounding boxes on all objects in entities present in a particular page.\n\n    :param entities: List of entities to be visualized on top of the document page\n    :type entities: list, required\n    :param with_text: Flag to indicate if text is to be printed on top of the bounding box\n    :type with_text: bool, optional\n    :param with_word_text_only: Flag to print only the word-level OCR output of Textract on top of the text bounding box.\n    :type with_word_text_only: bool\n    :param with_confidence: Flag to print the confidence of prediction on top of the entity bounding box.\n    :type with_confidence: bool\n    :param with_word_confidence_only: Flag to print only the word-level confidence of Textract OCR.\n    :type with_word_confidence_only: bool\n\n    :return: Returns PIL.Image with bounding boxes drawn for the entities passed to the function\n    :rtype: PIL.Image\n    \"\"\"\n    image = entities[0].bbox.spatial_object.image\n    if image is None:\n        for e in entities:\n            if e.bbox.spatial_object.image is not None:\n                image = e.bbox.spatial_object.image\n                break\n        else:\n            raise Exception(\"Could not find an entity with an associated image!\")\n    image = image.convert(\"RGBA\")\n    overlay = Image.new(\"RGBA\", image.size, (255, 255, 255, 0))\n    drw = ImageDraw.Draw(overlay, \"RGBA\")\n\n    text_locations = {}\n\n    # First drawing tables\n    for entity in entities:\n        if entity.bbox is None:\n            continue\n        width, height = image.size\n        if entity.__class__.__name__ == \"Table\":\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=2\n            )\n            if entity.title:\n                drw.rectangle(\n                    (\n                        int(entity.title.bbox.x * width),\n                        int(entity.title.bbox.y * height),\n                        int((entity.title.bbox.x + entity.title.bbox.width) * width),\n                        int((entity.title.bbox.y + entity.title.bbox.height) * height),\n                    ),\n                    outline=overlayer_data[\"color\"],\n                    fill=ImageColor.getrgb(\"red\") + (120,),\n                    width=2,\n                )\n\n            for footer in entity.footers:\n                drw.rectangle(\n                    (\n                        int(footer.bbox.x * width),\n                        int(footer.bbox.y * height),\n                        int((footer.bbox.x + footer.bbox.width) * width),\n                        int((footer.bbox.y + footer.bbox.height) * height),\n                    ),\n                    outline=overlayer_data[\"color\"],\n                    fill=ImageColor.getrgb(\"cyan\") + (120,),\n                    width=2,\n                )\n\n            processed_cells = set()\n            for cell in entity.table_cells:\n                if cell.id in processed_cells:\n                    continue\n                if cell.siblings:\n                    for c in cell.siblings:\n                        processed_cells.add(c.id)\n                    min_x, min_y, max_x, max_y = list(\n                        zip(\n                            *[\n                                (\n                                    c.bbox.x,\n                                    c.bbox.y,\n                                    c.bbox.x + c.bbox.width,\n                                    c.bbox.y + c.bbox.height,\n                                )\n                                for c in cell.siblings + [cell]\n                            ]\n                        )\n                    )\n                    min_x, min_y, max_x, max_y = (\n                        min(min_x),\n                        min(min_y),\n                        max(max_x),\n                        max(max_y),\n                    )\n                else:\n                    processed_cells.add(cell.id)\n                    min_x, min_y, max_x, max_y = (\n                        cell.bbox.x,\n                        cell.bbox.y,\n                        cell.bbox.x + cell.bbox.width,\n                        cell.bbox.y + cell.bbox.height,\n                    )\n\n                fill_color = None\n                if cell.is_column_header:\n                    fill_color = ImageColor.getrgb(\"blue\") + (120,)\n                if cell.is_title:\n                    fill_color = ImageColor.getrgb(\"red\") + (120,)\n                if cell.is_footer:\n                    fill_color = ImageColor.getrgb(\"cyan\") + (120,)\n                if cell.is_summary:\n                    fill_color = ImageColor.getrgb(\"yellow\") + (120,)\n                if cell.is_section_title:\n                    fill_color = ImageColor.getrgb(\"green\") + (120,)\n\n                drw.rectangle(\n                    (\n                        int(min_x * width),\n                        int(min_y * height),\n                        int(max_x * width),\n                        int(max_y * height),\n                    ),\n                    outline=overlayer_data[\"color\"],\n                    fill=fill_color,\n                    width=2,\n                )\n                for checkbox in cell.checkboxes:\n                    drw.rectangle(\n                        (\n                            int(checkbox.bbox.x * width),\n                            int(checkbox.bbox.y * height),\n                            int((checkbox.bbox.x + checkbox.bbox.width) * width),\n                            int((checkbox.bbox.y + checkbox.bbox.height) * height),\n                        ),\n                        outline=ImageColor.getrgb(\"lightgreen\")\n                        if checkbox.is_selected()\n                        else ImageColor.getrgb(\"indianred\"),\n                    )\n    # Second drawing bounding boxes\n    for entity in entities:\n        if entity.bbox is None:\n            continue\n        if entity.__class__.__name__ == \"Query\":\n            overlayer_data = _get_overlayer_data(entity.result, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=2\n            )\n        elif entity.__class__.__name__ == \"TableTitle\":\n            overlayer_data = _get_overlayer_data(entity.result, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=2\n            )\n        elif entity.__class__.__name__ == \"TableFooter\":\n            overlayer_data = _get_overlayer_data(entity.result, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=2\n            )\n        elif entity.__class__.__name__ == \"ExpenseField\":\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords_value\"],\n                outline=overlayer_data[\"color_value\"],\n                width=2,\n            )\n            if entity.key is not None:\n                b1 = entity.key.bbox\n                b2 = entity.value.bbox\n                drw.rectangle(\n                    xy=overlayer_data[\"coords_key\"],\n                    outline=overlayer_data[\"color_key\"],\n                    width=2,\n                )\n                drw.line(\n                    [\n                        (\n                            (b1.x + b1.width / 2) * width,\n                            (b1.y + b1.height / 2) * height,\n                        ),\n                        (\n                            (b2.x + b2.width / 2) * width,\n                            (b2.y + b2.height / 2) * height,\n                        ),\n                    ],\n                    fill=overlayer_data[\"color_key\"],\n                    width=2,\n                )\n        elif entity.__class__.__name__ == \"ExpenseDocument\":\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=2\n            )\n            for coord, text in zip(\n                overlayer_data[\"coords_list\"], overlayer_data[\"coords_list\"]\n            ):\n                drw.rectangle(\n                    xy=coord, outline=overlayer_data[\"color_expense_group\"], width=2\n                )\n        elif entity.__class__.__name__.startswith(\"Layout\"):\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=4\n            )\n        else:\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(\n                xy=overlayer_data[\"coords\"], outline=overlayer_data[\"color\"], width=2\n            )\n            if entity.__class__.__name__ == \"KeyValue\":\n                drw.rectangle(\n                    xy=overlayer_data[\"value_bbox\"],\n                    outline=overlayer_data[\"color_value\"],\n                    width=2,\n                )\n                b1 = overlayer_data[\"value_bbox\"]\n                b2 = overlayer_data[\"coords\"]\n                drw.line(\n                    [\n                        ((b1[0] + b1[2]) / 2, (b1[1] + b1[3]) / 2),\n                        ((b2[0] + b2[2]) / 2, (b2[1] + b2[3]) / 2),\n                    ],\n                    fill=overlayer_data[\"color_value\"],\n                    width=1,\n                )\n\n    # Second drawing, text\n    if with_text:\n        for entity in entities:\n            if entity.bbox is None:\n                continue\n            if entity.__class__.__name__ == \"Word\":\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n\n                final_txt = \"\"\n                bbox_height = overlayer_data[\"coords\"][3] - overlayer_data[\"coords\"][1]\n                text_height = int(bbox_height * font_size_ratio)\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n\n                final_txt += overlayer_data[\"text\"]\n\n                if with_confidence:\n                    final_txt += \" (\" + str(overlayer_data[\"confidence\"])[:4] + \")\"\n\n                drw.text(\n                    (\n                        overlayer_data[\"coords\"][0],\n                        overlayer_data[\"coords\"][1] - text_height,\n                    ),\n                    final_txt,\n                    font=fnt,\n                    fill=overlayer_data[\"text_color\"],\n                )\n\n            elif entity.__class__.__name__ == \"KeyValue\":\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n\n                # Key Text\n                final_txt = \"\"\n                bbox_height = overlayer_data[\"coords\"][3] - overlayer_data[\"coords\"][1]\n                text_height = min(\n                    int(0.03 * height), int(bbox_height * font_size_ratio)\n                )\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n\n                final_txt += overlayer_data[\"text\"]\n                if with_confidence:\n                    final_txt += \" (\" + str(overlayer_data[\"confidence\"])[:4] + \")\"\n\n                drw.text(\n                    (\n                        overlayer_data[\"coords\"][0],\n                        overlayer_data[\"coords\"][3] + 1,\n                    ),\n                    final_txt,\n                    font=fnt,\n                    fill=overlayer_data[\"color\"],\n                )\n\n                # Value Text\n                final_txt = overlayer_data[\"value_text\"]\n\n                bbox_height = (\n                    overlayer_data[\"value_bbox\"][3] - overlayer_data[\"value_bbox\"][1]\n                )\n                text_height = min(\n                    int(0.01 * height), int(bbox_height * font_size_ratio)\n                )\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n\n                if with_confidence:\n                    final_txt += \" (\" + str(overlayer_data[\"value_conf\"])[:4] + \")\"\n\n                drw.text(\n                    (\n                        overlayer_data[\"value_bbox\"][0],\n                        overlayer_data[\"value_bbox\"][3] + 1,\n                    ),\n                    final_txt,\n                    font=fnt,\n                    fill=overlayer_data[\"color_value\"],\n                )\n            elif entity.__class__.__name__ == \"ExpenseField\":\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n\n                final_txt = overlayer_data[\"text\"]\n                text_height = int(0.018 * height * font_size_ratio)\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n                if entity.key is not None:\n                    x = overlayer_data[\"coords_key\"][0] + 0.3 * (\n                        overlayer_data[\"coords_key\"][2]\n                        - overlayer_data[\"coords_key\"][0]\n                    )\n                    y = overlayer_data[\"coords_key\"][1] - text_height - 1\n                else:\n                    x = int(\n                        overlayer_data[\"coords\"][0]\n                        + 0.3\n                        * (overlayer_data[\"coords\"][2] - overlayer_data[\"coords\"][0])\n                    )\n                    y = overlayer_data[\"coords\"][1] - text_height - 1\n                while (x, y) in text_locations and text_locations[(x, y)] != final_txt:\n                    y = y - text_height - 1\n                text_locations[(x, y)] = final_txt\n                drw.text(\n                    (x, y),\n                    final_txt,\n                    font=fnt,\n                    fill=overlayer_data[\"text_color\"],\n                )\n            elif entity.__class__.__name__ == \"ExpenseDocument\":\n                width, height = image.size\n                text_height = int(0.018 * height * font_size_ratio)\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n                overlayer_data = _get_overlayer_data(entity, width, height)\n                for coord, text in zip(\n                    overlayer_data[\"coords_list\"], overlayer_data[\"text_list\"]\n                ):\n                    drw.text(\n                        (coord[0], coord[3]),\n                        text,\n                        font=fnt,\n                        fill=overlayer_data[\"color_expense_group\"],\n                    )\n\n            elif entity.__class__.__name__ == \"Query\":\n                if entity.result is None:\n                    continue\n\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity.result, width, height)\n\n                final_txt = entity.query + \" \" + overlayer_data[\"text\"]\n\n                bbox_height = overlayer_data[\"coords\"][3] - overlayer_data[\"coords\"][1]\n                text_height = int(bbox_height * font_size_ratio)\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n\n                if with_confidence:\n                    final_txt += \" (\" + str(entity.result.confidence)[:4] + \")\"\n\n                drw.text(\n                    (\n                        overlayer_data[\"coords\"][0],\n                        overlayer_data[\"coords\"][1] - text_height,\n                    ),\n                    final_txt,\n                    font=fnt,\n                    fill=overlayer_data[\"text_color\"],\n                )\n\n            elif entity.__class__.__name__.startswith(\"Layout\"):\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n\n                final_txt = \"\"\n                bbox_height = overlayer_data[\"coords\"][3] - overlayer_data[\"coords\"][1]\n                text_height = min(20, int(bbox_height * font_size_ratio))\n                fnt = ImageFont.truetype(\n                    os.path.join(present_path, \"arial.ttf\"), text_height\n                )\n\n                final_txt += overlayer_data[\"text\"]\n\n                if with_confidence:\n                    final_txt += \" (\" + str(overlayer_data[\"confidence\"])[:4] + \")\"\n\n                drw.text(\n                    (\n                        overlayer_data[\"coords\"][0],\n                        overlayer_data[\"coords\"][1] - text_height,\n                    ),\n                    final_txt,\n                    font=fnt,\n                    fill=overlayer_data[\"text_color\"],\n                )\n    del drw\n    image = Image.alpha_composite(image, overlay)\n    return image\n\n\ndef _get_overlayer_data(entity: Any, width: float, height: float) -> dict:\n    \"\"\"\n    Returns a dictionary with all the necessary details to draw a bounding box for an entity depending on the information\n    present in it. This includes the bounding box coordinates, color of bounding box, confidence of detection and OCR text.\n\n    :param entity: DocumentEntity object for which the data needs to be created\n    :type entity: DocumentEntity\n    :param width: width of the Page object the entity belongs to\n    :type width: float, required\n    :param height: height of the Page object the entity belongs to\n    :type height: float, required\n\n    :return: Dictionary containing all the information to draw the bounding box for a DocumentEntity.\n    :rtype: dict\n    \"\"\"\n    data = {}\n    bbox = entity.bbox\n    x, y, w, h = (\n        bbox.x * width,\n        bbox.y * height,\n        bbox.width * width,\n        bbox.height * height,\n    )\n    data[\"coords\"] = [x, y, x + w, y + h]\n    data[\"confidence\"] = (\n        entity.confidence\n        if entity.__class__.__name__\n        not in [\n            \"Table\",\n            \"ExpenseField\",\n            \"ExpenseDocument\",\n            \"LineItemRow\",\n            \"LineItemGroup\",\n        ]\n        else \"\"\n    )\n    data[\"color\"] = (0, 0, 0)\n    data[\"text_color\"] = (0, 0, 0)\n\n    if entity.__class__.__name__ == \"Word\":\n        data[\"text\"] = entity.text\n        data[\"color\"] = ImageColor.getrgb(\"blue\")\n\n    elif entity.__class__.__name__ == \"Line\":\n        data[\"text\"] = entity.text\n        data[\"color\"] = ImageColor.getrgb(\"lightgrey\")\n        data[\"coords\"] = [x - 1, y - 1, x + w + 1, y + h + 1]\n    elif entity.__class__.__name__ == \"KeyValue\":\n        data[\"text\"] = entity.key.__repr__()\n        data[\"color\"] = ImageColor.getrgb(\"brown\")\n        data[\"value_text\"] = entity.value.__repr__()\n        data[\"coords\"] = [x - 2, y - 2, x + w + 2, y + h + 2]\n\n        if entity.contains_checkbox and entity.children:\n            value_bbox = entity.children[0].bbox\n            data[\"value_conf\"] = entity.children[0].confidence\n\n        else:\n            value_bbox = entity.value.bbox\n            data[\"value_conf\"] = entity.value.confidence\n\n        data[\"color_value\"] = ImageColor.getrgb(\"orange\")\n        x, y, w, h = (\n            value_bbox.x * width - 2,\n            value_bbox.y * height - 2,\n            value_bbox.width * width + 2,\n            value_bbox.height * height + 2,\n        )\n        data[\"value_bbox\"] = [x, y, x + w, y + h]\n\n    elif entity.__class__.__name__ == \"Table\":\n        data[\"color\"] = ImageColor.getrgb(\"green\")\n        data[\"text\"] = \"\"\n    elif entity.__class__.__name__ == \"TableTitle\":\n        data[\"color\"] = ImageColor.getrgb(\"green\")\n        data[\"text\"] = \"\"\n    elif entity.__class__.__name__ == \"TableFooter\":\n        data[\"color\"] = ImageColor.getrgb(\"green\")\n        data[\"text\"] = \"\"\n\n    elif entity.__class__.__name__ == \"TableCell\":\n        data[\"color\"] = ImageColor.getrgb(\"skyblue\")\n        data[\"text\"] = entity.__repr__().split(\">\")[-1][1:]\n\n    elif entity.__class__.__name__ == \"QueryResult\":\n        data[\"color\"] = ImageColor.getrgb(\"mediumturquoise\")\n        data[\"text\"] = entity.answer\n    elif entity.__class__.__name__ == \"Signature\":\n        data[\"color\"] = ImageColor.getrgb(\"coral\")\n    elif entity.__class__.__name__ == \"ExpenseField\":\n        data[\"text\"] = entity.type.text\n        data[\"text_color\"] = ImageColor.getrgb(\"brown\")\n        data[\"coords\"] = [x - 5, y - 5, x + w + 5, y + h + 5]\n\n        if entity.key:\n            data[\"color_key\"] = ImageColor.getrgb(\"brown\")\n            data[\"coords_key\"] = (\n                entity.key.bbox.x * width - 3,\n                entity.key.bbox.y * height - 3,\n                (entity.key.bbox.x + entity.key.bbox.width) * width + 3,\n                ((entity.key.bbox.y + entity.key.bbox.height)) * height + 3,\n            )\n        data[\"color_value\"] = ImageColor.getrgb(\"orange\")\n        data[\"coords_value\"] = (\n            entity.value.bbox.x * width - 3,\n            entity.value.bbox.y * height - 3,\n            (entity.value.bbox.x + entity.value.bbox.width) * width + 3,\n            ((entity.value.bbox.y + entity.value.bbox.height)) * height + 3,\n        )\n    elif entity.__class__.__name__ == \"Expense\":\n        data[\"text\"] = entity.text\n        data[\"coords\"] = [x - 3, y - 3, x + w + 3, y + h + 3]\n    elif entity.__class__.__name__ == \"ExpenseDocument\":\n        data[\"color\"] = ImageColor.getrgb(\"beige\")\n        data[\"coords_list\"] = []\n        data[\"text_list\"] = []\n        for group in entity.summary_groups:\n            bboxes = entity.summary_groups.get_group_bboxes(group)\n            for bbox in bboxes:\n                data[\"coords_list\"].append(\n                    (\n                        bbox.x * width - 5,\n                        bbox.y * height - 5,\n                        (bbox.x + bbox.width) * width + 3,\n                        (bbox.y + bbox.height) * height + 3,\n                    )\n                )\n                data[\"text_list\"].append(group)\n        data[\"color_expense_group\"] = ImageColor.getrgb(\"coral\")\n\n    elif entity.__class__.__name__ == \"LineItemGroup\":\n        data[\"color\"] = ImageColor.getrgb(\"lightblue\")\n        data[\"coords\"] = [x - 10, y - 10, x + w + 10, y + h + 10]\n\n    elif entity.__class__.__name__ == \"LineItemRow\":\n        data[\"color\"] = ImageColor.getrgb(\"lightyellow\")\n        data[\"coords\"] = [x - 7, y - 7, x + w + 7, y + h + 7]\n    elif entity.__class__.__name__.startswith(\"Layout\"):\n        data[\"color\"] = ImageColor.getrgb(\"teal\")\n        data[\"text\"] = f\"{entity.layout_type} - {entity.reading_order}\"\n    else:\n        pass\n    return data\n",
    "textractor/entities/identity_document.py": "\"\"\"The IdentityDocument class is the object representation of an AnalyzeID response. It is similar to a dictionary. Despite its name it does not inherit from Document as the AnalyzeID response does not contains position information.\"\"\"\n\nimport os\nimport string\nimport logging\nimport xlsxwriter\nfrom typing import List, Dict, Union\nfrom copy import deepcopy\nfrom collections import defaultdict\nfrom textractor.data.constants import AnalyzeIDFields\nfrom textractor.entities.bbox import SpatialObject\nfrom textractor.entities.identity_field import IdentityField\n\nfrom textractor.exceptions import InputError\n\n\nclass IdentityDocument(SpatialObject):\n    \"\"\"\n    Represents the description of a single ID document.\n    \"\"\"\n\n    def __init__(self, fields=None):\n        \"\"\"\n        Creates a new document, ideally containing entity objects pertaining to each page.\n\n        :param num_pages: Number of pages in the input Document.\n        \"\"\"\n        super().__init__(width=0, height=0)\n        self._fields = IdentityDocument._fields_to_dict(fields)\n\n    @classmethod\n    def _fields_to_dict(cls, fields: Union[List[IdentityField], Dict[str, dict]]):\n        if not fields:\n            return {}\n        elif isinstance(fields, list) and isinstance(fields[0], IdentityField):\n            return {id_field.key: id_field for id_field in fields}\n        elif isinstance(fields, dict):\n            field_dict = {}\n            for id_field in fields.values():\n                field_dict[id_field[\"key\"]] = IdentityField(\n                    id_field[\"key\"],\n                    id_field[\"value\"],\n                    id_field[\"confidence\"],\n                )\n            return field_dict\n        else:\n            raise InputError(\n                f\"fields needs to be a list of IdentityFields or a list of dictionaries, not {type(fields)}\"\n            )\n\n    @property\n    def fields(self) -> Dict[str, IdentityField]:\n        return self._fields\n\n    @fields.setter\n    def fields(self, fields):\n        self._fields = fields\n\n    def keys(self) -> List[str]:\n        keys = [key for key in self._fields.keys()]\n        return keys\n\n    def values(self) -> List[str]:\n        values = [field.value for field in self._fields.values()]\n        return values\n\n    def __getitem__(self, key: Union[str, AnalyzeIDFields]) -> str:\n        return self._fields[key if isinstance(key, str) else key.value].value\n\n    def get(self, key: Union[str, AnalyzeIDFields]) -> Union[str, None]:\n        result = self._fields.get(key if isinstance(key, str) else key.value)\n        if result is None:\n            return None\n        return result.value\n\n    def __repr__(self):\n        return os.linesep.join([f\"{str(k)}: {str(v)}\" for k, v in self.fields.items()])\n",
    "textractor/entities/identity_field.py": "class IdentityField:\n    def __init__(self, key, value, confidence):\n        self._key = key\n        self._value = value\n        self._confidence = confidence\n\n    @property\n    def key(self) -> str:\n        return self._key\n\n    @property\n    def value(self) -> str:\n        return self._value\n\n    @property\n    def confidence(self) -> float:\n        return self._confidence\n\n    def __repr__(self) -> str:\n        return self.value\n",
    "textractor/parsers/response_parser.py": "\"\"\"\nConsumes Textract JSON response and converts them to a Document object format.\nThis class contains all the necessary utilities to create entity objects from JSON blocks within the response.\nUse ResponseParser's parse function to handle API response and convert them to Document objects.\n\"\"\"\n\nimport logging\nimport uuid\nfrom copy import deepcopy\nfrom typing import Any, List, Dict, Tuple\nfrom collections import defaultdict\nfrom textractor.entities.identity_document import IdentityDocument\nfrom textractor.entities.expense_document import ExpenseDocument\nfrom textractor.entities.expense_field import (\n    Expense,\n    ExpenseField,\n    ExpenseType,\n    ExpenseGroupProperty,\n    LineItemGroup,\n    LineItemRow,\n)\n\nfrom textractor.entities.page import Page\nfrom textractor.entities.query_result import QueryResult\nfrom textractor.entities.signature import Signature\nfrom textractor.entities.word import Word\nfrom textractor.entities.line import Line\nfrom textractor.entities.value import Value\nfrom textractor.entities.table import Table\nfrom textractor.entities.bbox import BoundingBox\nfrom textractor.entities.document import Document\nfrom textractor.entities.key_value import KeyValue\nfrom textractor.entities.table_cell import TableCell\nfrom textractor.entities.table_title import TableTitle\nfrom textractor.entities.table_footer import TableFooter\nfrom textractor.entities.query import Query\nfrom textractor.entities.selection_element import SelectionElement\nfrom textractor.entities.layout import Layout\nfrom textractor.data.constants import (\n    LAYOUT_ENTITY,\n    LAYOUT_FIGURE,\n    TABLE_FOOTER,\n    TABLE_TITLE,\n    COLUMN_HEADER,\n    TABLE_SUMMARY,\n    TABLE_SECTION_TITLE,\n    TABLE_STRUCTURED,\n    TABLE_SEMI_STRUCTURED,\n    SelectionStatus,\n    TextTypes,\n    TableTypes,\n    HANDWRITING,\n    PRINTED,\n    WORD,\n    LINE,\n    KEY_VALUE_SET,\n    CELL,\n    TABLE,\n    SELECTION_ELEMENT,\n    PAGE,\n    MERGED_CELL,\n    QUERY,\n    SIGNATURE,\n    LAYOUT,\n    LAYOUT_LIST,\n    LAYOUT_TABLE,\n    LAYOUT_KEY_VALUE,\n)\nfrom textractor.utils.legacy_utils import converter\n\nTHRESHOLD = 0.95\n\n\ndef _create_document_object(response: dict) -> Document:\n    \"\"\"\n    Consumes API Response in JSON format and creates a Document object.\n\n    :param response: json response from Textract API\n    :type response: dict\n\n    :return: Returns a Document object populated with metadata on number of pages.\n    :rtype: Document\n    \"\"\"\n    doc = Document(num_pages=response[\"DocumentMetadata\"][\"Pages\"])\n    return doc\n\n\ndef _filter_block_type(response: dict, entity: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    Consumes entire JSON response, filters and returns list of blocks corresponding to the entity\n    parameter from API response JSON.\n\n    :param response: JSON response from Textract API\n    :type response: dict\n    :param entity: Entity to be extracted from the JSON response\n    :type entity: str\n\n    :return: Returns a list of JSON blocks that match entity parameter.\n    :rtype: List\n    \"\"\"\n    return [block for block in response[\"Blocks\"] if block[\"BlockType\"] == entity]\n\n\ndef _filter_by_entity(\n    block_json: List[Dict[str, Any]], entity_type: str\n) -> Dict[str, Any]:\n    \"\"\"\n    Filters and returns dictionary of blocks corresponding to the entity_type from API response JSON.\n\n    :param block_json: list of blocks belonging to a specific entity\n    :type block_json: List[Dict[str, Any]]\n    :param entity_type: EntityType used to select/filter from list of blocks\n    :type entity_type: str\n\n    :return: Dictionary mapping of block ID with JSON block for entity type.\n    :rtype: Dict[str, Any]\n    \"\"\"\n    return {\n        block[\"Id\"]: block\n        for block in block_json\n        if (\n            \"EntityTypes\" in block and\n            len(block[\"EntityTypes\"]) and\n            block[\"EntityTypes\"][0] == entity_type\n        )\n    }\n\n\ndef _get_relationship_ids(block_json: Dict[str, Any], relationship: str) -> List[str]:\n    \"\"\"\n    Takes the JSON block corresponding to an entity and returns the Ids of the chosen Relationship if the Relationship exists.\n\n    :param block_json: JSON block corresponding to an entity\n    :type block_json: List[Dict[str, Any]]\n    :relationship: CHILD or VALUE as input\n    :type relationship: str\n\n    :return: List of IDs with type Relationship to entity\n    :rtype: List\n    \"\"\"\n    ids = []\n    try:\n        ids = [\n            rel[\"Ids\"]\n            for rel in block_json[\"Relationships\"]\n            if rel[\"Type\"] == relationship\n        ][0]\n    except:\n        logging.info(\n            f\"{block_json['BlockType']} - {block_json['Id']} does not have ids with {relationship} relationship.\"\n        )\n    return ids\n\n\ndef _create_page_objects(\n    response: dict,\n) -> Tuple[Dict[str, Page], List[Dict[str, Any]]]:\n    \"\"\"\n    Consumes API Response in JSON format and returns Page objects for the Document.\n\n    :param response: JSON response from Textract API\n    :type response: dict\n\n    :return: Returns dictionary with page ID - Page object mapping,  list of JSON blocks belonging to PAGE blocks.\n    :rtype: Dict[str, Page], List[str]\n    \"\"\"\n    pages = []\n    page_elements = _filter_block_type(response, entity=PAGE)\n\n    for page_json in page_elements:\n        asset_id = page_json[\"Id\"]\n        width = page_json[\"Geometry\"][\"BoundingBox\"][\"Width\"]\n        height = page_json[\"Geometry\"][\"BoundingBox\"][\"Height\"]\n        page_num = page_json[\"Page\"] if len(page_elements) > 1 else 1\n        page_children = _get_relationship_ids(page_json, relationship=\"CHILD\")\n        page = Page(\n            id=asset_id,\n            width=width,\n            height=height,\n            page_num=page_num,\n            child_ids=page_children,\n        )\n        pages.append(page)\n    pages = {page.id: page for page in pages}\n    return pages, page_elements\n\n\ndef _create_word_objects(\n    word_ids: List[str],\n    id_json_map: Dict[str, str],\n    existing_words: Dict[str, Word],\n    page: Page,\n) -> List[Word]:\n    \"\"\"\n    Creates list of Word objects for all word_ids passed to the function.\n\n    :param word_ids: List of ids corresponding to the words present within Page.\n    :type word_ids: list\n    :param id_json_map: Dictionary containing entity_id: JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of Word objects for the IDs passed in word_ids.\n    :rtype: list\n    \"\"\"\n    words = []\n    text_type = {PRINTED: TextTypes.PRINTED, HANDWRITING: TextTypes.HANDWRITING}\n\n    for word_id in word_ids:\n        if word_id in existing_words:\n            words.append(existing_words[word_id])\n        else:\n            # FIXME: This could be gated\n            if not word_id in id_json_map:\n                continue\n            elem = id_json_map[word_id]\n            word = Word(\n                entity_id=elem[\"Id\"],\n                bbox=BoundingBox.from_normalized_dict(\n                    elem[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n                ),\n                text=elem.get(\"Text\"),\n                text_type=text_type[elem.get(\"TextType\")],\n                confidence=elem[\"Confidence\"],\n            )\n            word.raw_object = elem\n            words.append(word)\n            existing_words[word_id] = word\n\n    for word in words:\n        word.page = page.page_num\n        word.page_id = page.id\n\n    return words\n\n\ndef _create_line_objects(\n    line_ids: List[str],\n    id_json_map: Dict[str, str],\n    existing_words: Dict[str, Word],\n    page: Page,\n) -> Tuple[List[Line], List[Word]]:\n    \"\"\"\n    Creates list of Line objects for all lines in the Page derived from the API JSON response.\n\n    :param line_ids: List of IDs corresponding to the lines present within Page.\n    :type line_ids: list\n    :param id_json_map: Dictionary containing entity_id: JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of Line objects for the IDs passed in line_ids and list of Word objects\n             belonging to the corresponding Line objects.\n    :rtype: List[Line], List[Word]\n    \"\"\"\n    page_lines = []\n\n    for line_id in line_ids:\n        if line_id in page.child_ids:\n            page_lines.append(id_json_map[line_id])\n\n    lines = []\n    page_words = []\n    for line in page_lines:\n        if _get_relationship_ids(line, relationship=\"CHILD\"):\n            line_words = _create_word_objects(\n                _get_relationship_ids(line, relationship=\"CHILD\"),\n                id_json_map,\n                existing_words,\n                page,\n            )\n            page_words.extend(line_words)\n            lines.append(\n                Line(\n                    entity_id=line[\"Id\"],\n                    bbox=BoundingBox.from_normalized_dict(\n                        line[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n                    ),\n                    words=line_words,\n                    confidence=line[\"Confidence\"],\n                )\n            )\n            for word in line_words:\n                word.line = lines[-1]\n                word.line_id = lines[-1].id\n                word.line_bbox = lines[-1].bbox\n            lines[-1]._children = line_words\n            lines[-1].raw_object = line\n\n    for line in lines:\n        line.page = page.page_num\n        line.page_id = page.id\n\n    return lines, page_words\n\n\ndef _create_selection_objects(\n    selection_ids: List[str], id_json_map: Dict[str, Any], page: Page\n) -> Dict[str, SelectionElement]:\n    \"\"\"\n    Creates dictionary mapping of SelectionElement ID with SelectionElement objects for all ids passed in selection_ids.\n\n    :param selection_ids: List of ids corresponding to the SelectionElements.\n    :type selection_ids: list\n    :param id_json_map: Dictionary containing entity_id: JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a dictionary mapping of SelectionElement IDs with SelectionElement objects for the IDs present in\n             selection_ids.\n    :rtype: Dict[str, SelectionElement]\n    \"\"\"\n    checkbox_elements = [id_json_map[selection_id] for selection_id in selection_ids]\n\n    status = {\n        \"SELECTED\": SelectionStatus.SELECTED,\n        \"NOT_SELECTED\": SelectionStatus.NOT_SELECTED,\n    }\n\n    checkboxes = {}\n    for block in checkbox_elements:\n        checkboxes[block[\"Id\"]] = SelectionElement(\n            entity_id=block[\"Id\"],\n            bbox=BoundingBox.from_normalized_dict(\n                block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n            status=status[block[\"SelectionStatus\"]],\n            confidence=block[\"Confidence\"],\n        )\n        checkboxes[block[\"Id\"]].raw_object = block\n\n    for c in checkboxes.values():\n        c.page = page.page_num\n        c.page_id = page.id\n\n    return checkboxes\n\n\ndef _create_value_objects(\n    value_ids: List[str],\n    id_json_map: Dict[str, Any],\n    entity_id_map: Dict[str, list],\n    existing_words: Dict[str, Word],\n    page: Page,\n) -> Tuple[Dict[str, Value], Dict[str, SelectionElement]]:\n    \"\"\"\n    Creates dictionary containing Value objects for all value_ids in the Page derived from the API response JSON.\n\n    :param value_ids: List of ids corresponding to the Values in the page.\n    :type value_ids: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param entity_id_map: Dictionary containing entity_type:List[entity_id] mapping.\n    :type entity_id_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Dictionary mapping value_ids to Value objects.\n    :rtype: Dict[str, Value]\n    \"\"\"\n    # FIXME: This could be gated\n    values_info = {value_id: id_json_map.get(value_id, None) for value_id in value_ids}\n\n    values = {}\n    for block_id, block in values_info.items():\n        # FIXME: This should be gated\n        if block is None:\n            continue\n        values[block_id] = Value(\n            entity_id=block_id,\n            bbox=BoundingBox.from_normalized_dict(\n                block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n            confidence=block[\"Confidence\"],\n        )\n        values[block_id].raw_object = block\n\n    checkboxes = _create_selection_objects(\n        entity_id_map[SELECTION_ELEMENT], id_json_map, page\n    )\n\n    # Add children to Value object\n    for val_id in values.keys():\n        val_child_ids = _get_relationship_ids(values_info[val_id], relationship=\"CHILD\")\n        for child_id in val_child_ids:\n            # FIXME: This should be gated\n            if child_id not in id_json_map:\n                continue\n            if id_json_map[child_id][\"BlockType\"] == WORD:\n                words = _create_word_objects(\n                    [child_id], id_json_map, existing_words, page\n                )\n                values[val_id].words += words\n                values[val_id].add_children(words)\n\n            elif id_json_map[child_id][\"BlockType\"] == SIGNATURE:\n                continue\n            else:\n                checkbox = checkboxes[child_id]\n                checkbox.value_id = val_id\n                values[val_id].add_children([checkbox])\n                values[val_id].contains_checkbox = True\n\n            values[val_id].page = page.page_num\n            values[val_id].page_id = page.id\n\n    return values, checkboxes\n\n\ndef _create_query_objects(\n    query_ids: List[str],\n    id_json_map: Dict[str, str],\n    entity_id_map: Dict[str, list],\n    page: Page,\n) -> List[Query]:\n    page_queries = []\n    for query_id in query_ids:\n        if query_id in page.child_ids:\n            page_queries.append(id_json_map[query_id])\n\n    query_result_id_map = {}\n    for block in page_queries:\n        answer = _get_relationship_ids(block, relationship=\"ANSWER\")\n        query_result_id_map[block[\"Id\"]] = answer[0] if answer else None\n\n    query_results = _create_query_result_objects(\n        list(query_result_id_map.values()), id_json_map, entity_id_map, page\n    )\n\n    queries = []\n    for query in page_queries:\n        query_result = query_results.get(query_result_id_map[query[\"Id\"]])\n        query_obj = Query(\n            query[\"Id\"],\n            query[\"Query\"][\"Text\"],\n            query[\"Query\"].get(\"Alias\"),\n            query_result,\n            query_result.bbox if query_result is not None else None,\n        )\n        query_obj.raw_object = query\n        queries.append(query_obj)\n\n    return queries\n\n\ndef _create_query_result_objects(\n    query_result_ids: List[str],\n    id_json_map: Dict[str, str],\n    entity_id_map: Dict[str, list],\n    page: Page,\n) -> Dict[str, QueryResult]:\n    page_query_results = []\n    for query_result_id in query_result_ids:\n        if query_result_id in page.child_ids and query_result_id in id_json_map:\n            page_query_results.append(id_json_map[query_result_id])\n\n    query_results = {}\n    for block in page_query_results:\n        query_results[block[\"Id\"]] = QueryResult(\n            entity_id=block[\"Id\"],\n            confidence=block[\"Confidence\"],\n            result_bbox=BoundingBox.from_normalized_dict(\n                (\n                    block.get(\"Geometry\") or\n                    {\n                        \"BoundingBox\": {\n                            \"Width\": 1.0,\n                            \"Height\": 1.0,\n                            \"Left\": 0.0,\n                            \"Top\": 0.0,\n                        }\n                    }\n                )[\"BoundingBox\"],\n                spatial_object=page,\n            ),\n            answer=block[\"Text\"],\n        )\n        query_results[block[\"Id\"]].raw_object = block\n\n    for query_result_id, query_result in query_results.items():\n        query_result.page = page.page_num\n        query_result.page_id = page.id\n\n    return query_results\n\n\ndef _create_signature_objects(\n    signature_ids: List[str],\n    id_json_map: Dict[str, str],\n    entity_id_map: Dict[str, list],\n    page: Page,\n) -> Dict[str, Signature]:\n    page_signatures = []\n    for signature_id in signature_ids:\n        if signature_id in page.child_ids:\n            page_signatures.append(id_json_map[signature_id])\n\n    signatures = {}\n    for block in page_signatures:\n        signatures[block[\"Id\"]] = Signature(\n            entity_id=block[\"Id\"],\n            confidence=block[\"Confidence\"],\n            bbox=BoundingBox.from_normalized_dict(\n                block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n        )\n        signatures[block[\"Id\"]].raw_object = block\n\n    for signature_id, signature in signatures.items():\n        signature.page = page.page_num\n        signature.page_id = page.id\n\n    signatures_added = set()\n    for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n        if layout.layout_type == LAYOUT_ENTITY:\n            continue\n        for signature in sorted(signatures.values(), key=lambda x: x.bbox.y):\n            if (\n                layout.bbox.get_intersection(signature.bbox).area\n                > THRESHOLD * signature.bbox.area\n                and signature not in signatures_added\n            ):\n                layout.children.append(signature)\n                signatures_added.add(signature)\n                del signatures[signature.id]\n\n    signature_layouts = []\n    for signature in signatures.values():\n        if signature not in signatures_added:\n            signatures_added.add(signature)\n            layout = Layout(\n                entity_id=str(uuid.uuid4()),\n                bbox=signature.bbox,\n                label=LAYOUT_ENTITY,\n                reading_order=-1,\n            )\n            layout.children.append(signature)\n            layout.page = page.page_num\n            layout.page_id = page.id\n            signature_layouts.append(layout)\n\n    layouts_to_remove = []\n    for layout in page.leaf_layouts:\n        layouts_that_intersect = []\n        for signature_layout in signature_layouts:\n            intersection = layout.bbox.get_intersection(signature_layout.bbox).area\n            if intersection:\n                layouts_that_intersect.append(signature_layout)\n        words_in_sub_layouts = set()\n        for i, intersect_layout in enumerate(\n            sorted(layouts_that_intersect, key=lambda l: (l.bbox.y, l.bbox.x))\n        ):\n            intersect_layout.reading_order = (\n                (layout.reading_order + (i + 1) * 0.1)\n                if intersect_layout.reading_order == -1\n                else min(\n                    intersect_layout.reading_order, layout.reading_order + (i + 1) * 0.1\n                )\n            )\n            for w in intersect_layout.children[0].words:\n                words_in_sub_layouts.add(w.id)\n        if words_in_sub_layouts:\n            remaining_words = []\n            for w in layout.words:\n                if w.id not in words_in_sub_layouts:\n                    remaining_words.append(w)\n            if remaining_words:\n                layout.bbox = BoundingBox.enclosing_bbox(\n                    [w.bbox for w in remaining_words]\n                )\n                layout._children = list(set([w.line for w in remaining_words]))\n            else:\n                layouts_to_remove.append(layout)\n\n    for layout in layouts_to_remove:\n        page.leaf_layouts.remove(layout)\n\n    for layout in signature_layouts:\n        page.leaf_layouts.append(layout)\n\n    return list(signatures_added)\n\n\n\ndef _create_keyvalue_objects(\n    key_value_ids: List[str],\n    id_json_map: Dict[str, Any],\n    id_entity_map: Dict[str, str],\n    entity_id_map: Dict[str, list],\n    existing_words: Dict[str, Word],\n    page: Page,\n) -> Tuple[List[KeyValue], List[Word], Dict[str, SelectionElement]]:\n    \"\"\"\n    Creates list of KeyValue objects for all key-value pairs in the Page derived from the API response JSON.\n\n    :param key_value_ids: List of ids corresponding to the KeyValues in the page.\n    :type key_value_ids: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param entity_id_map: Dictionary containing entity_type:List[entity_id] mapping.\n    :type entity_id_map: dict\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of KeyValue objects and list of Word objects with CHILD relationship\n             to the KeyValue objects.\n    :rtype: List[KeyValue], List[Word]\n    \"\"\"\n    page_kv = []\n    for kv_id in key_value_ids:\n        if kv_id in page.child_ids:\n            page_kv.append(id_json_map[kv_id])\n\n    keys_info = _filter_by_entity(page_kv, entity_type=\"KEY\")\n\n    key_value_id_map = {\n        block[\"Id\"]: _get_relationship_ids(block, relationship=\"VALUE\")[0]\n        for block in keys_info.values()\n    }\n\n    values, selection_elements = _create_value_objects(\n        list(key_value_id_map.values()),\n        id_json_map,\n        entity_id_map,\n        existing_words,\n        page,\n    )\n\n    keys = {}\n    for block in keys_info.values():\n        keys[block[\"Id\"]] = KeyValue(\n            entity_id=block[\"Id\"],\n            bbox=BoundingBox.from_normalized_dict(\n                block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n            # FIXME: Should be gated\n            contains_checkbox=(\n                key_value_id_map[block[\"Id\"]] in values and\n                values[key_value_id_map[block[\"Id\"]]].contains_checkbox\n            ),\n            value=values.get(key_value_id_map[block[\"Id\"]]),\n            confidence=block[\"Confidence\"],\n        )\n        keys[block[\"Id\"]].raw_object = block\n\n    # Add words and children (Value Object) to KeyValue object\n    kv_words = []\n    for key_id in keys.keys():\n        if keys[key_id].value is None:\n            continue\n        keys[key_id].value.key_id = key_id\n        if keys[key_id].contains_checkbox:\n            keys[key_id].value.children[0].key_id = key_id\n            keys[key_id].selection_status = [\n                c\n                for c in keys[key_id].value.children\n                if c.__class__.__name__ == \"SelectionElement\"\n            ][0].status\n        else:\n            kv_words.extend(values[key_value_id_map[key_id]].words)\n\n        key_child_ids = _get_relationship_ids(keys_info[key_id], relationship=\"CHILD\")\n        key_word_ids = [\n            child_id\n            for child_id in key_child_ids\n            # FIXME: This should be gated\n            if child_id in id_json_map and id_json_map[child_id][\"BlockType\"] == WORD\n        ]\n        key_words = _create_word_objects(\n            key_word_ids, id_json_map, existing_words, page\n        )\n\n        key_child_ids = [\n            child_id for child_id in key_child_ids if child_id not in key_word_ids\n        ]\n        # find a place to add selection elements for keys\n\n        keys[key_id].key = key_words\n        keys[key_id].add_children(key_words)\n        keys[key_id].add_children([keys[key_id].value])\n        kv_words.extend(key_words)\n\n    key_values = list(keys.values())\n    for kv in key_values:\n        kv.bbox = BoundingBox.enclosing_bbox([kv.bbox] + ([kv.value.bbox] if kv.value is not None else []))\n        kv.page = page.page_num\n        kv.page_id = page.id\n\n    #kv_added = set()\n    #for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n    #    if layout.layout_type == LAYOUT_ENTITY:\n    #        continue\n    #    for kv in sorted(key_values, key=lambda x: x.bbox.y):\n    #        if (\n    #            layout.bbox.get_intersection(kv.bbox).area > THRESHOLD * kv.bbox.area\n    #            and kv not in kv_added\n    #        ):\n    #            layout.children.append(kv)\n    #            kv_added.add(kv)\n    #            key_values.remove(kv)\n\n    return key_values, kv_words, selection_elements\n\n\ndef _create_layout_objects(\n    layout_ids: List[Any],\n    id_json_map: Dict[str, str],\n    id_entity_map: Dict[str, List[str]],\n    line_by_id: Dict[str, Line],\n    page: Page,\n) -> Tuple[List[Layout], List[Layout]]:\n    \"\"\"\n    Creates Layout objects.\n\n    :param page_layouts: Reading-ordered list containing JSON structure of tables within the page.\n    :type page_layouts: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list containing Layout objects.\n    :rtype: List[Layout]\n    \"\"\"\n\n    page_layouts = []\n    for layout_id in layout_ids:\n        if layout_id in page.child_ids:\n            page_layouts.append(id_json_map[layout_id])\n\n    leaf_layouts = []\n    container_layouts = []\n    parsed_blocks = set()\n    for i, block in enumerate(page_layouts):\n        if block[\"Id\"] in parsed_blocks:\n            continue\n        if block[\"BlockType\"] in (LAYOUT_LIST,):\n            container_layouts.append(\n                Layout(\n                    entity_id=block[\"Id\"],\n                    confidence=block[\"Confidence\"],\n                    reading_order=i,\n                    label=block[\"BlockType\"],\n                    bbox=BoundingBox.from_normalized_dict(\n                        block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n                    ),\n                )\n            )\n            parsed_blocks.add(block[\"Id\"])\n            for relationship in (block.get(\"Relationships\", []) or []):\n                if relationship[\"Type\"] != \"CHILD\":\n                    continue\n                for leaf_id in relationship[\"Ids\"]:\n                    block = id_json_map[leaf_id]\n                    parsed_blocks.add(leaf_id)\n                    container_layouts[-1].children.append(\n                        Layout(\n                            entity_id=block[\"Id\"],\n                            confidence=block[\"Confidence\"],\n                            reading_order=i,\n                            label=block[\"BlockType\"],\n                            bbox=BoundingBox.from_normalized_dict(\n                                block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n                            ),\n                        )\n                    )\n                    container_layouts[-1].children[-1].raw_object = block\n                    for relationship in (block.get(\"Relationships\", []) or []):\n                        if relationship[\"Type\"] != \"CHILD\":\n                            continue\n                        container_layouts[-1].children[-1].add_children(\n                            [line_by_id[line_id] for line_id in relationship[\"Ids\"] if line_id in line_by_id]\n                        )\n        else:\n            leaf_layouts.append(\n                Layout(\n                    entity_id=block[\"Id\"],\n                    confidence=block[\"Confidence\"],\n                    reading_order=i,\n                    label=block[\"BlockType\"],\n                    bbox=BoundingBox.from_normalized_dict(\n                        block[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n                    ),\n                )\n            )\n            leaf_layouts[-1].raw_object = block\n            for relationship in (block.get(\"Relationships\", []) or []):\n                if relationship[\"Type\"] != \"CHILD\":\n                    continue\n                leaf_layouts[-1].add_children(\n                    [line_by_id[line_id] for line_id in relationship[\"Ids\"] if line_id in line_by_id]\n                )\n\n    for layout in leaf_layouts + container_layouts:\n        layout.page = page.page_num\n        layout.page_id = page.id\n\n    return container_layouts, leaf_layouts\n\n\ndef _create_table_cell_objects(\n    page_tables: List[Any],\n    id_entity_map: Dict[str, List[str]],\n    id_json_map: Dict[str, str],\n    page: Page,\n) -> Tuple[Dict[str, TableCell], Dict[str, Any]]:\n    \"\"\"\n    Creates TableCell objects for all page_tables passed as input present on a single Page of the Document.\n\n    :param page_tables: List containing JSON structure of tables within the page.\n    :type page_tables: list\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a dictionary containing TableCells mapped with their IDs and dictionary containing ID: CELL JSON mapping.\n    :rtype: Dict[str, TableCell], Dict[str, Any]\n    \"\"\"\n    all_table_cells_info = {}\n    for table in page_tables:\n        for cell_id in _get_relationship_ids(table, relationship=\"CHILD\"):\n            # FIXME: This should be gated\n            if cell_id in id_entity_map and id_entity_map[cell_id] == CELL:\n                all_table_cells_info[cell_id] = id_json_map[cell_id]\n\n    table_cells = {}\n    for elem_id, elem in all_table_cells_info.items():\n        entity_types = elem.get(\"EntityTypes\", []) or []\n        table_cells[elem_id] = TableCell(\n            entity_id=elem_id,\n            bbox=BoundingBox.from_normalized_dict(\n                elem[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n            row_index=elem[\"RowIndex\"],\n            col_index=elem[\"ColumnIndex\"],\n            row_span=elem[\"RowSpan\"],\n            col_span=elem[\"ColumnSpan\"],\n            confidence=elem[\"Confidence\"],\n            is_column_header=COLUMN_HEADER in entity_types,\n            is_title=TABLE_TITLE in entity_types,\n            is_footer=TABLE_FOOTER in entity_types,\n            is_summary=TABLE_SUMMARY in entity_types,\n            is_section_title=TABLE_SECTION_TITLE in entity_types,\n        )\n        table_cells[elem_id].raw_object = elem\n\n    for cell in table_cells.values():\n        cell.page = page.page_num\n        cell.page_id = page.id\n    return table_cells, all_table_cells_info\n\n\ndef _create_table_objects(\n    table_ids: List[str],\n    id_json_map: Dict[str, Any],\n    id_entity_map: Dict[str, List[str]],\n    entity_id_map: Dict[str, List[str]],\n    existing_words: Dict[str, Word],\n    key_values: Dict[str, KeyValue],\n    checkboxes: Dict[str, SelectionElement],\n    page: Page,\n) -> Tuple[List[Table], List[Word]]:\n    \"\"\"\n    Creates list of Table objects for all tables in the Page derived from the API response JSON.\n    This includes creating TableCell objects and updating metadata for each cell. The TableCell objects are assigned as children\n    of the table.\n\n    :param table_ids: List of ids corresponding to the Tables in the page.\n    :type table_ids: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param entity_id_map: Dictionary containing entity_type:List[entity_id] mapping.\n    :type entity_id_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of table objects and list of words present in tables.\n    :rtype: List[Table], List[Word]\n    \"\"\"\n    # Create Tables\n    page_tables = []\n    for table_id in table_ids:\n        if table_id in page.child_ids:\n            page_tables.append(id_json_map[table_id])\n\n    tables = {}\n    for val in page_tables:\n        tables[val[\"Id\"]] = Table(\n            entity_id=val[\"Id\"],\n            bbox=BoundingBox.from_normalized_dict(\n                val[\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n        )\n        # Setting table type based on the entity types present in the table\n        if TABLE_STRUCTURED in (val.get(\"EntityTypes\", []) or []):\n            tables[val[\"Id\"]].table_type = TableTypes.STRUCTURED\n        elif TABLE_SEMI_STRUCTURED in (val.get(\"EntityTypes\", []) or []):\n            tables[val[\"Id\"]].table_type = TableTypes.SEMI_STRUCTURED\n        else:\n            tables[val[\"Id\"]].table_type = TableTypes.UNKNOWN\n        # Setting raw JSON in the resulting object\n        tables[val[\"Id\"]].raw_object = val\n\n    # Create Table Cells\n    table_cells, all_table_cells_info = _create_table_cell_objects(\n        page_tables, id_entity_map, id_json_map, page\n    )\n\n    merged_table_cells = [\n        id_json_map[merge_id] for merge_id in entity_id_map[MERGED_CELL]\n    ]\n\n    # Add children to cells\n    merged_child_map = {\n        merged_cell[\"Id\"]: _get_relationship_ids(merged_cell, relationship=\"CHILD\")\n        for merged_cell in merged_table_cells\n    }\n    merged_child_ids = sum([ids for ids in merged_child_map.values()], [])\n\n    table_words = []\n    added_key_values = set()\n    for cell_id, cell in all_table_cells_info.items():\n        children = _get_relationship_ids(cell, relationship=\"CHILD\")\n        # FIXME: This should be gated\n        cell_word_ids = [\n            child_id for child_id in children if (child_id in id_entity_map and id_entity_map[child_id] == WORD)\n        ]\n        # FIXME: This should be gated\n        selection_ids = [\n            child_id\n            for child_id in children\n            if child_id in id_entity_map and id_entity_map[child_id] == SELECTION_ELEMENT\n        ]\n\n        cell_words = _create_word_objects(\n            cell_word_ids, id_json_map, existing_words, page\n        )\n        for w in cell_words:\n            w.cell_id = table_cells[cell_id].id\n            w.cell_bbox = table_cells[cell_id].bbox\n            w.row_span = table_cells[cell_id].row_span\n            w.col_span = table_cells[cell_id].col_span\n            w.row_index = table_cells[cell_id].row_index\n            w.col_index = table_cells[cell_id].col_index\n        table_words.extend(cell_words)\n\n        table_cells[cell_id].add_children(cell_words)\n        \n        # There are two types of selection elements, one comes from Tables, the other for KVs\n        # This tries to reconcile both and to insert the selection element in the right place\n        for child_id in selection_ids:\n            if checkboxes[child_id].key_id in added_key_values:\n                continue\n            # This is a KeyValue\n            if checkboxes[child_id].key_id is not None:\n                kv = key_values[checkboxes[child_id].key_id]\n                try:\n                    if not kv.words:\n                        added_key_values.add(kv.id)\n                        continue\n                    i = table_cells[cell_id]._children.index(kv.words[0])\n                    table_cells[cell_id]._children.insert(i, kv)\n                    for w in kv.words:\n                        try:\n                            table_cells[cell_id]._children.remove(w)\n                        except ValueError:\n                            continue\n                    added_key_values.add(checkboxes[child_id].key_id)\n                except ValueError:\n                    # Word is not in the table cells words\n                    continue\n            # This is just a checkbox\n            else:\n                table_cells[cell_id]._children.append(checkboxes[child_id])\n\n        # update metadata\n        meta_info = cell.get(\"EntityTypes\", []) or []\n        merged_info = [MERGED_CELL] if cell_id in merged_child_ids else []\n        table_cells[cell_id]._update_response_metadata(meta_info + merged_info)\n\n    # This is problematic because a KV will usually not be within a single cell, but instead\n    # cover multiple cells (usually one for key, one for value)\n    for kv_id, kv in key_values.items():\n        if kv_id in added_key_values:\n            continue\n        for table in page_tables:\n            table = tables[table[\"Id\"]]\n            # If the kv is in the table bbox, we just drop it entirely\n            if all([w in table_words for w in kv.words]):\n                added_key_values.add(kv_id)\n\n    # optimize code\n    for merge_id, child_cells in merged_child_map.items():\n        for child_id in child_cells:\n            if child_id in table_cells.keys():\n                table_cells[child_id].parent_cell_id = merge_id\n                # FIXME: This should be gated\n                table_cells[child_id].siblings = [\n                    table_cells[cid] for cid in child_cells if cid in table_cells\n                ]  # CHECK IF IDS ARE BETTER THAN INSTANCES\n\n    # Create table title (if exists)\n    for table in page_tables:\n        children = _get_relationship_ids(table, relationship=\"TABLE_TITLE\")\n        for child_id in children:\n            if child_id not in id_json_map:\n                continue\n            tables[table[\"Id\"]].title = TableTitle(\n                entity_id=child_id,\n                bbox=BoundingBox.from_normalized_dict(\n                    id_json_map[child_id][\"Geometry\"][\"BoundingBox\"],\n                    spatial_object=page,\n                ),\n            )\n            children = _get_relationship_ids(\n                id_json_map[child_id], relationship=\"CHILD\"\n            )\n            tables[table[\"Id\"]].title.words = _create_word_objects(\n                # FIXME: This should be gated\n                [child_id for child_id in children if (child_id in id_entity_map and id_entity_map[child_id] == WORD)],\n                id_json_map,\n                existing_words,\n                page,\n            )\n\n    # Create table footer (if exists)\n    for table in page_tables:\n        children = _get_relationship_ids(table, relationship=\"TABLE_FOOTER\")\n        for child_id in children:\n            if child_id not in id_json_map:\n                continue\n            tables[table[\"Id\"]].footers.append(\n                TableFooter(\n                    entity_id=child_id,\n                    bbox=BoundingBox.from_normalized_dict(\n                        id_json_map[child_id][\"Geometry\"][\"BoundingBox\"],\n                        spatial_object=page,\n                    ),\n                )\n            )\n            children = _get_relationship_ids(\n                id_json_map[child_id], relationship=\"CHILD\"\n            )\n            tables[table[\"Id\"]].footers[-1].words = _create_word_objects(\n                [child_id for child_id in children if child_id in id_entity_map and id_entity_map[child_id] == WORD],\n                id_json_map,\n                existing_words,\n                page,\n            )\n\n    # Associate Children with Tables\n    for table in page_tables:\n        children = _get_relationship_ids(table, relationship=\"CHILD\")\n        children_cells = []\n        for child_id in children:\n            # FIXME: This should be gated\n            if child_id not in table_cells:\n                continue\n            children_cells.append(table_cells[child_id])\n            if table_cells[child_id].is_title and tables[table[\"Id\"]].title is not None:\n                tables[table[\"Id\"]].title.is_floating = False\n        # FIXME: This will be slow and there should be a better way to do it.\n        words = set()\n        for child_id in children:\n            if child_id not in table_cells:\n                continue\n            for w in table_cells[child_id].words:\n                words.add(w.id)\n        for footer in tables[table[\"Id\"]].footers:\n            for w in footer.words:\n                if w.id in words:\n                    footer.is_floating = False\n                    break\n\n        tables[table[\"Id\"]].add_cells(children_cells)\n        tables[table[\"Id\"]].add_children(children_cells)\n\n    # Assign tables to layout elements\n    table_added = set()\n    for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n        if layout.layout_type == LAYOUT_TABLE:\n            for table in sorted(list(tables.values()), key=lambda x: x.bbox.y):\n                if layout.bbox.get_intersection(table.bbox).area > THRESHOLD*table.bbox.area and table not in table_added:\n                    for w in table.words:\n                        layout.remove(w)\n                    layout.children.append(table)\n                    layout.bbox = BoundingBox.enclosing_bbox(layout.children)\n                    table_added.add(table)\n\n    tables_layout = []\n    for table in tables.values():\n        if table not in table_added:\n            table_added.add(table)\n            layout = Layout(\n                entity_id=str(uuid.uuid4()),\n                bbox=table.bbox,\n                label=LAYOUT_TABLE,\n                reading_order=-1,\n            )\n            layout.children.append(table)\n            layout.page = page.page_num\n            layout.page_id = page.id\n            tables_layout.append(layout)\n\n    layouts_to_remove = []\n    for layout in page.leaf_layouts:\n        layouts_that_intersect = []\n        for table_layout in tables_layout:\n            intersection = layout.bbox.get_intersection(table_layout.bbox).area\n            if intersection:\n                layouts_that_intersect.append(table_layout)\n        words_in_sub_layouts = set()\n        for i, intersect_layout in enumerate(\n            sorted(layouts_that_intersect, key=lambda l: (l.bbox.y, l.bbox.x))\n        ):\n            intersect_layout.reading_order = (\n                (layout.reading_order + (i + 1) * 0.1)\n                if intersect_layout.reading_order == -1\n                else min(\n                    intersect_layout.reading_order, layout.reading_order + (i + 1) * 0.1\n                )\n            )\n            for w in intersect_layout.children[0].words:\n                words_in_sub_layouts.add(w)\n        if words_in_sub_layouts:\n            for word in words_in_sub_layouts:\n                layout.remove(word)\n            if layout._children:\n                layout.bbox = BoundingBox.enclosing_bbox(layout._children)\n            else:\n                layouts_to_remove.append(layout)\n\n    for layout in layouts_to_remove:\n        page.leaf_layouts.remove(layout)\n\n    for layout in tables_layout:\n        page.leaf_layouts.append(layout)\n\n    tables = list(tables.values())\n    for table in tables:\n        table.page = page.page_num\n        table.page_id = page.id\n    return tables, table_words, added_key_values\n\n\ndef parse_document_api_response(response: dict) -> Document:\n    \"\"\"\n    Parses Textract JSON response and converts them into Document object containing Page objects.\n    A valid Page object must contain at least a unique name and physical dimensions.\n\n    :param response: JSON response data in a format readable by the ResponseParser\n    :type response: dict\n\n    :return: Document object containing the hierarchy of DocumentEntity descendants.\n    :rtype: Document\n    \"\"\"\n    document = _create_document_object(response)\n\n    id_entity_map, id_json_map, entity_id_map, existing_words = (\n        {},\n        {},\n        defaultdict(list),\n        {},\n    )\n    # Create de entity id map for faster lookup\n    for block in response[\"Blocks\"]:\n        id_entity_map[block[\"Id\"]] = block[\"BlockType\"]\n        id_json_map[block[\"Id\"]] = block\n        if block[\"BlockType\"].startswith(\"LAYOUT\"):\n            entity_id_map[\"LAYOUT\"].append(block[\"Id\"])\n        else:\n            entity_id_map[block[\"BlockType\"]].append(block[\"Id\"])\n\n    # Create the empty pages\n    pages, page_elements = _create_page_objects(response)\n    assert len(pages) == response[\"DocumentMetadata\"][\"Pages\"]\n\n    # Fill the page with the detected entities\n    for page_json in page_elements:\n        page = pages[page_json[\"Id\"]]\n\n        # Creating lines\n        lines, line_words = _create_line_objects(\n            entity_id_map[LINE], id_json_map, existing_words, page\n        )\n        page.lines = deepcopy(lines)\n\n        line_by_id = {l.id: l for l in lines}\n\n        # Creating layouts\n        container_layouts, leaf_layouts = _create_layout_objects(\n            entity_id_map[LAYOUT],\n            id_json_map,\n            entity_id_map,\n            line_by_id,\n            page,\n        )\n\n        # If no layouts were created, we create fake layouts\n        if not container_layouts and not leaf_layouts:\n            # We are in a scenario where the LAYOUT API was not called. We will fake wrap\n            # all the lines to get a good linearized output regardless.\n            for i, line in enumerate(lines):\n                layout = Layout(\n                    entity_id=line.id,\n                    bbox=line.bbox,\n                    label=LAYOUT_ENTITY,\n                    reading_order=i,\n                )\n                layout._children = [line]\n                layout.page = page.page_num\n                layout.page_id = page.id\n                leaf_layouts.append(layout)\n\n        page._container_layouts.extend(container_layouts)\n        page._leaf_layouts.extend(leaf_layouts)\n\n        # Create key value objects\n        key_values, kv_words, selection_elements = _create_keyvalue_objects(\n            entity_id_map[KEY_VALUE_SET],\n            id_json_map,\n            id_entity_map,\n            entity_id_map,\n            existing_words,\n            page,\n        )\n        kvs = [kv for kv in key_values if not kv.contains_checkbox]\n        checkboxes = [kv for kv in key_values if kv.contains_checkbox]\n\n        # For backward compatibility reason we split kvs and checkboxes under two attributes\n        page.key_values = kvs\n        page.checkboxes = checkboxes\n\n        for checkbox in checkboxes:\n            id_entity_map[checkbox.id] = SELECTION_ELEMENT\n\n        # Create the table objects\n        tables, table_words, kv_added = _create_table_objects(\n            entity_id_map[TABLE],\n            id_json_map,\n            id_entity_map,\n            entity_id_map,\n            existing_words,\n            # We pass the KeyValue objects because there will be overlap and we need to make\n            # sure that the layout children are unique.\n            {kv.id:kv for kv in key_values},\n            selection_elements,\n            page,\n        )\n        page.tables = tables\n\n        # Using the kv_added returned by _create_table_objects, we try to match the remaining KVs\n        # to existing layout elements.\n        for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n            if layout.layout_type == LAYOUT_ENTITY:\n                continue\n            for kv in sorted(key_values, key=lambda x: x.bbox.y):\n                if (\n                    layout.bbox.get_intersection(kv.bbox).area > THRESHOLD * kv.bbox.area\n                    and kv.id not in kv_added\n                ):\n                    # Ignore if the KV is already overlapping with a table\n                    if any([w.cell_id for w in kv.words]):\n                        kv_added.add(kv.id)\n                        continue\n                    # Removing the duplicate words\n                    for w in kv.words:\n                        layout.remove(w)\n                    # Adding the KV to the layout children (order is not relevant)\n                    layout.children.append(kv)\n                    kv_added.add(kv.id)\n                    key_values.remove(kv)\n\n        \n        page.leaf_layouts = [l for l in page.leaf_layouts if l.children or l.layout_type == LAYOUT_FIGURE]\n\n        # We create layout elements for the KeyValues that did not match to a layout element in the\n        # previous step\n        kv_layouts = []\n        for kv in key_values:\n            if kv.id not in kv_added:\n                kv_added.add(kv.id)\n                layout = Layout(\n                    entity_id=str(uuid.uuid4()),\n                    bbox=kv.bbox,\n                    label=LAYOUT_KEY_VALUE,\n                    reading_order=-1,\n                )\n                layout.children.append(kv)\n                layout.page = page.page_num\n                layout.page_id = page.id\n                kv_layouts.append(layout)\n\n        # We update the existing layout elements to avoid overlap, this should only happen to\n        # a few KV layouts as the previous step will have caught most overlap.\n        layouts_to_remove = []\n        kv_layouts_to_ignore = []\n        layouts_that_intersect = defaultdict(list)\n        for layout in page.leaf_layouts:\n            for kv_layout in kv_layouts:\n                intersection = layout.bbox.get_intersection(kv_layout.bbox).area\n                if intersection:\n                    layouts_that_intersect[layout].append(kv_layout)\n        for layout, intersections in layouts_that_intersect.items():\n            words_in_sub_layouts = set()\n            for i, intersect_layout in enumerate(\n                sorted(intersections, key=lambda l: (l.bbox.y, l.bbox.x))\n            ):\n                # If a new KV layout intersected with more than one layout, we ignore it\n                if sum([intersect_layout in intsects for intsects in layouts_that_intersect.values()]) > 1:\n                    kv_layouts_to_ignore.append(intersect_layout)\n                    continue\n                # We assign a slightly higher reading order to the intersected layout\n                intersect_layout.reading_order = (\n                    (layout.reading_order + (i + 1) * 0.1)\n                    if intersect_layout.reading_order == -1\n                    else min(\n                        intersect_layout.reading_order, layout.reading_order + (i + 1) * 0.1\n                    )\n                )\n                # We take only the first child as the intersected layout will only have the KV as\n                # its child. \n                for w in intersect_layout.children[0].words:\n                    words_in_sub_layouts.add(w)\n            for word in words_in_sub_layouts:\n                layout.remove(word)\n            if not layout.children and layout.layout_type != LAYOUT_FIGURE:\n                layouts_to_remove.append(layout)\n\n        # Clean up layouts that became empty due to the previous step. \n        for layout in layouts_to_remove:\n            page.leaf_layouts.remove(layout)\n\n        # Add the new KV layouts to the page\n        for layout in kv_layouts:\n            if layout not in kv_layouts_to_ignore:\n                page.leaf_layouts.append(layout)\n\n        # Set the page word, create lines for orphaned words\n        all_words = table_words + kv_words + line_words\n        for word in all_words:\n            if word.line is None:\n                line = Line(\n                    str(uuid.uuid4()),\n                    word.bbox,\n                    words=[word],\n                    confidence=word.confidence,\n                )\n                line.page = page.page_num\n                line.page_id = page.id\n                word.line = line\n                page.lines.append(line)\n        all_words = {word.id: word for word in all_words}\n\n        page.words = list(all_words.values())\n\n        # Create query objects\n        queries = _create_query_objects(\n            entity_id_map[QUERY], id_json_map, entity_id_map, page\n        )\n        page.queries = queries\n\n        # Create signature objects\n        signatures = _create_signature_objects(\n            entity_id_map[SIGNATURE], id_json_map, entity_id_map, page\n        )\n        page.signatures = signatures\n\n        # Final clean up of the layout objects\n        word_set = set()\n        for layout in sorted(page.layouts, key=lambda l: l.reading_order):\n            layout.visit(word_set)\n            if not layout.children and layout.layout_type != LAYOUT_FIGURE:\n                try:\n                    page.leaf_layouts.remove(layout)\n                except:\n                    page.container_layouts.remove(layout)\n\n    document.pages = sorted(list(pages.values()), key=lambda x: x.page_num)\n    document.response = response\n    return document\n\ndef parse_analyze_id_response(response):\n    id_documents = []\n    response[\"Blocks\"] = []\n    for doc in response[\"IdentityDocuments\"]:\n        fields = {}\n        for field in doc[\"IdentityDocumentFields\"]:\n            fields[field[\"Type\"][\"Text\"]] = {\n                \"key\": field[\"Type\"][\"Text\"],\n                \"value\": field[\"ValueDetection\"][\"Text\"],\n                \"confidence\": field[\"ValueDetection\"][\"Confidence\"],\n            }\n        id_documents.append(IdentityDocument(fields))\n        id_documents[-1].raw_object = doc\n        response[\"Blocks\"].extend(doc.get(\"Blocks\", []))\n    # FIXME: Quick fix, we need something more robust\n    document = parse_document_api_response(response)\n    del response[\"Blocks\"]\n    document.identity_documents = id_documents\n    document.response = response\n    return document\n\n\ndef create_expense_from_field(field: Dict, page: Page) -> ExpenseField:\n    if \"Type\" in field:\n        type_expense = ExpenseType(\n            field[\"Type\"][\"Text\"], field[\"Type\"][\"Confidence\"], field[\"Type\"]\n        )\n    else:\n        type_expense = None\n    if \"ValueDetection\" in field:\n        value_expense = Expense(\n            bbox=(\n                None\n                if not \"Geometry\" in field[\"ValueDetection\"]\n                else BoundingBox.from_normalized_dict(\n                    field[\"ValueDetection\"][\"Geometry\"][\"BoundingBox\"],\n                    spatial_object=page,\n                )\n            ),\n            text=field[\"ValueDetection\"][\"Text\"],\n            confidence=field[\"ValueDetection\"][\"Confidence\"],\n            page=page.page_num,\n        )\n        value_expense.raw_object = field[\"ValueDetection\"]\n    else:\n        value_expense = None\n    if \"LabelDetection\" in field:\n        label_expense = Expense(\n            bbox=BoundingBox.from_normalized_dict(\n                field[\"LabelDetection\"][\"Geometry\"][\"BoundingBox\"], spatial_object=page\n            ),\n            text=field[\"LabelDetection\"][\"Text\"],\n            confidence=field[\"LabelDetection\"][\"Confidence\"],\n            page=page.page_num,\n        )\n        label_expense.raw_object = field[\"LabelDetection\"]\n    else:\n        label_expense = None\n    group_properties = []\n    if \"GroupProperties\" in field:\n        for group_property in field[\"GroupProperties\"]:\n            group_properties.append(\n                ExpenseGroupProperty(\n                    id=group_property[\"Id\"], types=group_property[\"Types\"]\n                )\n            )\n    if \"Currency\" in field:\n        currency = field[\"Currency\"][\"Code\"]\n    else:\n        currency = None\n    return ExpenseField(\n        type_expense,\n        value_expense,\n        group_properties=group_properties,\n        label=label_expense,\n        currency=currency,\n        page=page.page_num,\n    )\n\n\ndef parser_analyze_expense_response(response):\n    response[\"Blocks\"] = [\n        b for doc in response[\"ExpenseDocuments\"] for b in doc.get(\"Blocks\", [])\n    ]\n    document = parse_document_api_response(response)\n    for doc in response[\"ExpenseDocuments\"]:\n        page_number = None\n        if len(doc[\"SummaryFields\"]):\n            page_number = doc[\"SummaryFields\"][0].get(\"PageNumber\")\n        elif len(doc[\"LineItemGroups\"]):\n            # A group must have at least one LineItem, and a LI must have at least one field:\n            first_field = doc[\"LineItemGroups\"][0][\"LineItems\"][0][\"LineItemExpenseFields\"][0]\n            page_number = first_field.get(\"PageNumber\")\n        if page_number is None:\n            logging.warning(\n                \"Skipping parsing ExpenseDocument %s as its page number could not be determined\"\n                % (doc[\"ExpenseIndex\"],)\n            )\n            continue\n\n        page = document.pages[page_number - 1]\n        summary_fields = []\n        for summary_field in doc[\"SummaryFields\"]:\n            summary_fields.append(create_expense_from_field(summary_field, page))\n            summary_fields[-1].raw_object = summary_field\n\n        line_items_groups = []\n        for line_items_group in doc[\"LineItemGroups\"]:\n            line_item_rows = []\n            for i, line_item in enumerate(line_items_group[\"LineItems\"]):\n                row_expenses = []\n                for line_item_field in line_item[\"LineItemExpenseFields\"]:\n                    row_expenses.append(\n                        create_expense_from_field(line_item_field, page)\n                    )\n                    row_expenses[-1].raw_object = line_item_field\n                line_item_rows.append(\n                    LineItemRow(\n                        index=i,\n                        line_item_expense_fields=row_expenses,\n                        page=page.page_num,\n                    )\n                )\n            if not line_item_rows:\n                continue\n            line_items_groups.append(\n                LineItemGroup(\n                    index=line_items_group[\"LineItemGroupIndex\"],\n                    line_item_rows=line_item_rows,\n                    page=page.page_num,\n                )\n            )\n\n        bbox = BoundingBox.enclosing_bbox(\n            bboxes=[s.bbox for s in summary_fields]\n            + [g.bbox for g in line_items_groups],\n            spatial_object=page,\n        )\n        expense_document = ExpenseDocument(\n            summary_fields=summary_fields,\n            line_items_groups=line_items_groups,\n            bounding_box=bbox,\n            page=page.page_num,\n        )\n        expense_document.raw_object = doc\n        document.pages[page_number - 1].expense_documents.append(\n            expense_document\n        )\n    document.response = response\n    return document\n\ndef parse(response: dict) -> Document:\n    \"\"\"\n    Ingests response data and API Call Mode and calls the appropriate function for it.\n    Presently supports only SYNC and ASYNC API calls. Will be extended to Analyze ID and Expense in the future.\n\n    :param response: JSON response data in a format readable by the ResponseParser.\n    :type response: dict\n\n    :return: Document object returned after making respective parse function calls.\n    :rtype: Document\n    \"\"\"\n    if \"IdentityDocuments\" in response:\n        return parse_analyze_id_response(response)\n    if \"ExpenseDocuments\" in response:\n        return parser_analyze_expense_response(response)\n    else:\n        return parse_document_api_response(converter(response))\n"
  },
  "GT_src_dict": {
    "textractor/entities/document.py": {
      "Document.open": {
        "code": "    def open(cls, fp: Union[dict, str, Path, IO[AnyStr]]):\n        \"\"\"Creates and returns a Document object by parsing input from various sources such as a JSON dictionary, a file path, or a file handle. The function supports loading documents stored in AWS S3 by checking if the input string begins with \"s3://\". It relies on the `response_parser` from the `textractor.parsers` module to perform the actual parsing of the input data into a Document object. The method raises an `InputError` if the input type does not match the expected types: dictionary, string, Path, or file handle.\n\nParameters:\n- fp (Union[dict, str, Path, IO[AnyStr]]): The input source for creating a Document object, which can be a response dictionary, a file path (string or Path), or a file handle.\n\nReturns:\n- Document: An instance of the Document class populated with parsed data.\n\nRaises:\n- InputError: If the provided input does not conform to the accepted types.\n\nDependencies:\n- Requires the `boto3` library for AWS S3 interactions.\n- Utilizes `json` for loading JSON data.\n- Interacts with the `response_parser` from `textractor.parsers` to handle the parsing logic.\"\"\"\n        'Create a Document object from a JSON file path, file handle or response dictionary\\n\\n        :param fp: _description_\\n        :type fp: Union[dict, str, Path, IO[AnyStr]]\\n        :raises InputError: Raised on input not being of type Union[dict, str, Path, IO[AnyStr]]\\n        :return: Document object\\n        :rtype: Document\\n        '\n        from textractor.parsers import response_parser\n        if isinstance(fp, dict):\n            return response_parser.parse(fp)\n        elif isinstance(fp, str):\n            if fp.startswith('s3://'):\n                client = boto3.client('s3')\n                return response_parser.parse(json.load(download_from_s3(client, fp)))\n            with open(fp, 'r') as f:\n                return response_parser.parse(json.load(f))\n        elif isinstance(fp, Path):\n            with open(fp, 'r') as f:\n                return response_parser.parse(json.load(f))\n        elif isinstance(fp, io.IOBase):\n            return response_parser.parse(json.load(fp))\n        else:\n            raise InputError(f'Document.open() input must be of type dict, str, Path or a file handle, not {type(fp)}')",
        "docstring": "Creates and returns a Document object by parsing input from various sources such as a JSON dictionary, a file path, or a file handle. The function supports loading documents stored in AWS S3 by checking if the input string begins with \"s3://\". It relies on the `response_parser` from the `textractor.parsers` module to perform the actual parsing of the input data into a Document object. The method raises an `InputError` if the input type does not match the expected types: dictionary, string, Path, or file handle.\n\nParameters:\n- fp (Union[dict, str, Path, IO[AnyStr]]): The input source for creating a Document object, which can be a response dictionary, a file path (string or Path), or a file handle.\n\nReturns:\n- Document: An instance of the Document class populated with parsed data.\n\nRaises:\n- InputError: If the provided input does not conform to the accepted types.\n\nDependencies:\n- Requires the `boto3` library for AWS S3 interactions.\n- Utilizes `json` for loading JSON data.\n- Interacts with the `response_parser` from `textractor.parsers` to handle the parsing logic.",
        "signature": "def open(cls, fp: Union[dict, str, Path, IO[AnyStr]]):",
        "type": "Method",
        "class_signature": "class Document(SpatialObject, Linearizable):"
      },
      "Document.identity_documents": {
        "code": "    def identity_documents(self, identity_documents: List[IdentityDocument]):\n        \"\"\"Sets the list of detected identity documents within the Document instance.\n\n:param identity_documents: A list of IdentityDocument objects representing the identity documents detected in the document. Each instance of IdentityDocument is assumed to encapsulate the relevant data and methods related to a single identity document extracted from the input.\n\nThis method updates the internal attribute `_identity_documents`, which stores these IdentityDocument objects, enabling other methods of the Document class to retrieve and manipulate the identity documents as needed. By maintaining a separate list, the class supports better organization and interaction with document entities, particularly for functionalities related to identity document processing.\"\"\"\n        '\\n        Set all the identity documents detected inside the Document\\n        '\n        self._identity_documents = identity_documents",
        "docstring": "Sets the list of detected identity documents within the Document instance.\n\n:param identity_documents: A list of IdentityDocument objects representing the identity documents detected in the document. Each instance of IdentityDocument is assumed to encapsulate the relevant data and methods related to a single identity document extracted from the input.\n\nThis method updates the internal attribute `_identity_documents`, which stores these IdentityDocument objects, enabling other methods of the Document class to retrieve and manipulate the identity documents as needed. By maintaining a separate list, the class supports better organization and interaction with document entities, particularly for functionalities related to identity document processing.",
        "signature": "def identity_documents(self, identity_documents: List[IdentityDocument]):",
        "type": "Method",
        "class_signature": "class Document(SpatialObject, Linearizable):"
      }
    },
    "textractor/visualizers/entitylist.py": {
      "EntityList.__init__": {
        "code": "    def __init__(self, objs=None):\n        \"\"\"Initializes an instance of the `EntityList` class, which extends the built-in list type to store document entities. This constructor allows for the initialization of the list with a custom collection of entity objects.\n\nParameters:\n- objs (Optional[list]): An initial list of entities to populate the `EntityList`. If None, the list will be initialized as empty. If a non-list object is provided, it is converted into a single-element list.\n\nReturns:\n- None: The method initializes the instance in place and does not return any value.\n\nUsage:\nThis constructor interacts with the `super().__init__()` method from the list class to ensure proper list initialization. The entities added to this list can be visualized and formatted through methods like `visualize()` and `pretty_print()`, which are defined in the same class. The handling of object types ensures that only valid entities are stored in the `EntityList`, promoting consistency throughout the application.\"\"\"\n        super().__init__()\n        if objs is None:\n            objs = []\n        elif not isinstance(objs, list):\n            objs = [objs]\n        self.extend(objs)",
        "docstring": "Initializes an instance of the `EntityList` class, which extends the built-in list type to store document entities. This constructor allows for the initialization of the list with a custom collection of entity objects.\n\nParameters:\n- objs (Optional[list]): An initial list of entities to populate the `EntityList`. If None, the list will be initialized as empty. If a non-list object is provided, it is converted into a single-element list.\n\nReturns:\n- None: The method initializes the instance in place and does not return any value.\n\nUsage:\nThis constructor interacts with the `super().__init__()` method from the list class to ensure proper list initialization. The entities added to this list can be visualized and formatted through methods like `visualize()` and `pretty_print()`, which are defined in the same class. The handling of object types ensures that only valid entities are stored in the `EntityList`, promoting consistency throughout the application.",
        "signature": "def __init__(self, objs=None):",
        "type": "Method",
        "class_signature": "class EntityList(list, Generic[T], Linearizable):"
      }
    },
    "textractor/entities/identity_document.py": {
      "IdentityDocument.fields": {
        "code": "    def fields(self, fields):\n        \"\"\"Sets the fields of the IdentityDocument instance.\n\n:param fields: A dictionary mapping field keys to IdentityField objects. These fields represent the information extracted from an ID document, including attributes like key, value, and confidence level.\n\nThis setter method updates the internal _fields attribute, which is a dictionary that allows accessing the individual IdentityField entries for retrieving specific information about the ID document. It interacts with the IdentityField class, which is responsible for encapsulating the data associated with each field, guaranteeing that the fields are represented consistently within the document.\"\"\"\n        self._fields = fields",
        "docstring": "Sets the fields of the IdentityDocument instance.\n\n:param fields: A dictionary mapping field keys to IdentityField objects. These fields represent the information extracted from an ID document, including attributes like key, value, and confidence level.\n\nThis setter method updates the internal _fields attribute, which is a dictionary that allows accessing the individual IdentityField entries for retrieving specific information about the ID document. It interacts with the IdentityField class, which is responsible for encapsulating the data associated with each field, guaranteeing that the fields are represented consistently within the document.",
        "signature": "def fields(self, fields):",
        "type": "Method",
        "class_signature": "class IdentityDocument(SpatialObject):"
      },
      "IdentityDocument.__getitem__": {
        "code": "    def __getitem__(self, key: Union[str, AnalyzeIDFields]) -> str:\n        \"\"\"Retrieves the value associated with a specified key from the IdentityDocument's fields.\n\nParameters:\n- key (Union[str, AnalyzeIDFields]): A string representing the key of the desired field or an instance of AnalyzeIDFields, which is an enumeration of field keys.\n\nReturns:\n- str: The value of the field corresponding to the provided key.\n- Raises a KeyError if the key does not exist in the document's fields.\n\nThis method directly interacts with the _fields attribute, which is a dictionary mapping field keys (either as strings or AnalyzeIDFields) to IdentityField objects. Each IdentityField contains a 'value' that represents the data extracted from the ID document.\"\"\"\n        return self._fields[key if isinstance(key, str) else key.value].value",
        "docstring": "Retrieves the value associated with a specified key from the IdentityDocument's fields.\n\nParameters:\n- key (Union[str, AnalyzeIDFields]): A string representing the key of the desired field or an instance of AnalyzeIDFields, which is an enumeration of field keys.\n\nReturns:\n- str: The value of the field corresponding to the provided key.\n- Raises a KeyError if the key does not exist in the document's fields.\n\nThis method directly interacts with the _fields attribute, which is a dictionary mapping field keys (either as strings or AnalyzeIDFields) to IdentityField objects. Each IdentityField contains a 'value' that represents the data extracted from the ID document.",
        "signature": "def __getitem__(self, key: Union[str, AnalyzeIDFields]) -> str:",
        "type": "Method",
        "class_signature": "class IdentityDocument(SpatialObject):"
      },
      "IdentityDocument.get": {
        "code": "    def get(self, key: Union[str, AnalyzeIDFields]) -> Union[str, None]:\n        \"\"\"Retrieves the value associated with a specified key from the document's fields.\n\nParameters:\n- key (Union[str, AnalyzeIDFields]): The key corresponding to the desired field. This can be a string or an instance of AnalyzeIDFields, which is an enumeration defined in the constants imported from `textractor.data.constants`.\n\nReturns:\n- Union[str, None]: The value associated with the specified key if it exists; otherwise, returns None.\n\nThis method interacts with the `_fields` attribute, which is a dictionary of `IdentityField` instances representing various fields of the identity document. If the provided key does not correspond to an existing field, the method gracefully handles the request by returning None instead of raising an error.\"\"\"\n        result = self._fields.get(key if isinstance(key, str) else key.value)\n        if result is None:\n            return None\n        return result.value",
        "docstring": "Retrieves the value associated with a specified key from the document's fields.\n\nParameters:\n- key (Union[str, AnalyzeIDFields]): The key corresponding to the desired field. This can be a string or an instance of AnalyzeIDFields, which is an enumeration defined in the constants imported from `textractor.data.constants`.\n\nReturns:\n- Union[str, None]: The value associated with the specified key if it exists; otherwise, returns None.\n\nThis method interacts with the `_fields` attribute, which is a dictionary of `IdentityField` instances representing various fields of the identity document. If the provided key does not correspond to an existing field, the method gracefully handles the request by returning None instead of raising an error.",
        "signature": "def get(self, key: Union[str, AnalyzeIDFields]) -> Union[str, None]:",
        "type": "Method",
        "class_signature": "class IdentityDocument(SpatialObject):"
      }
    },
    "textractor/entities/identity_field.py": {
      "IdentityField.value": {
        "code": "    def value(self) -> str:\n        \"\"\"Returns the value associated with the identity field.\n\nThis method provides access to the `_value` attribute of the IdentityField instance, which represents a specific value relevant to the identity being modeled. The value is a string that can be retrieved without any parameters. This method is primarily used to expose the internal representation of the identity's value, complementing the key and confidence properties.\n\nReturns:\n    str: The value of the identity field.\"\"\"\n        return self._value",
        "docstring": "Returns the value associated with the identity field.\n\nThis method provides access to the `_value` attribute of the IdentityField instance, which represents a specific value relevant to the identity being modeled. The value is a string that can be retrieved without any parameters. This method is primarily used to expose the internal representation of the identity's value, complementing the key and confidence properties.\n\nReturns:\n    str: The value of the identity field.",
        "signature": "def value(self) -> str:",
        "type": "Method",
        "class_signature": "class IdentityField:"
      }
    },
    "textractor/parsers/response_parser.py": {
      "parse": {
        "code": "def parse(response: dict) -> Document:\n    \"\"\"Parses the Textract API JSON response, identifying the type of document (such as Identity Documents or Expense Documents) and invoking the appropriate parsing function to transform it into a Document object format. Supports both SYNC and ASYNC API calls.\n\n:param response: JSON response data received from the Textract API, can include various document types.\n:type response: dict\n\n:return: A Document object containing parsed information such as pages, key-value pairs, tables, and other entities extracted from the input response.\n:rtype: Document\n\nThis function interacts with several helper functions defined in the same module, including `parse_analyze_id_response` for Identity Documents and `parser_analyze_expense_response` for Expense Documents. The function also utilizes the `converter` utility for processing the response, ensuring it meets the expected format before parsing. Constants and data structures defined in the module (like `KEY_VALUE_SET` or `TABLE`) are utilized indirectly through the helper functions to filter and structure the parsed data appropriately.\"\"\"\n    '\\n    Ingests response data and API Call Mode and calls the appropriate function for it.\\n    Presently supports only SYNC and ASYNC API calls. Will be extended to Analyze ID and Expense in the future.\\n\\n    :param response: JSON response data in a format readable by the ResponseParser.\\n    :type response: dict\\n\\n    :return: Document object returned after making respective parse function calls.\\n    :rtype: Document\\n    '\n    if 'IdentityDocuments' in response:\n        return parse_analyze_id_response(response)\n    if 'ExpenseDocuments' in response:\n        return parser_analyze_expense_response(response)\n    else:\n        return parse_document_api_response(converter(response))",
        "docstring": "Parses the Textract API JSON response, identifying the type of document (such as Identity Documents or Expense Documents) and invoking the appropriate parsing function to transform it into a Document object format. Supports both SYNC and ASYNC API calls.\n\n:param response: JSON response data received from the Textract API, can include various document types.\n:type response: dict\n\n:return: A Document object containing parsed information such as pages, key-value pairs, tables, and other entities extracted from the input response.\n:rtype: Document\n\nThis function interacts with several helper functions defined in the same module, including `parse_analyze_id_response` for Identity Documents and `parser_analyze_expense_response` for Expense Documents. The function also utilizes the `converter` utility for processing the response, ensuring it meets the expected format before parsing. Constants and data structures defined in the module (like `KEY_VALUE_SET` or `TABLE`) are utilized indirectly through the helper functions to filter and structure the parsed data appropriately.",
        "signature": "def parse(response: dict) -> Document:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {
    "textractor/entities/document.py:Document:open": {},
    "textractor/parsers/response_parser.py:parse": {
      "textractor/parsers/response_parser.py": {
        "parse_analyze_id_response": {
          "code": "def parse_analyze_id_response(response):\n    id_documents = []\n    response['Blocks'] = []\n    for doc in response['IdentityDocuments']:\n        fields = {}\n        for field in doc['IdentityDocumentFields']:\n            fields[field['Type']['Text']] = {'key': field['Type']['Text'], 'value': field['ValueDetection']['Text'], 'confidence': field['ValueDetection']['Confidence']}\n        id_documents.append(IdentityDocument(fields))\n        id_documents[-1].raw_object = doc\n        response['Blocks'].extend(doc.get('Blocks', []))\n    document = parse_document_api_response(response)\n    del response['Blocks']\n    document.identity_documents = id_documents\n    document.response = response\n    return document",
          "docstring": "",
          "signature": "def parse_analyze_id_response(response):",
          "type": "Function",
          "class_signature": null
        }
      }
    },
    "textractor/entities/document.py:Document:identity_documents": {},
    "textractor/visualizers/entitylist.py:EntityList:__init__": {},
    "textractor/entities/identity_document.py:IdentityDocument:get": {},
    "textractor/entities/identity_field.py:IdentityField:value": {},
    "textractor/entities/identity_document.py:IdentityDocument:__getitem__": {}
  },
  "call_tree": {
    "tests/test_analyze_id.py:TestTextractorAnalyzeID:test_analyze_id_from_image": {
      "tests/utils.py:get_fixture_path": {},
      "textractor/entities/document.py:Document:open": {
        "textractor/parsers/response_parser.py:parse": {
          "textractor/parsers/response_parser.py:parse_analyze_id_response": {
            "textractor/entities/identity_document.py:IdentityDocument:__init__": {
              "textractor/entities/bbox.py:SpatialObject:__init__": {},
              "textractor/entities/identity_document.py:IdentityDocument:_fields_to_dict": {
                "textractor/entities/identity_field.py:IdentityField:__init__": {}
              }
            },
            "textractor/parsers/response_parser.py:parse_document_api_response": {
              "textractor/parsers/response_parser.py:_create_document_object": {
                "textractor/entities/document.py:Document:__init__": {
                  "textractor/entities/bbox.py:SpatialObject:__init__": {}
                }
              },
              "textractor/parsers/response_parser.py:_create_page_objects": {
                "textractor/parsers/response_parser.py:_filter_block_type": {},
                "textractor/parsers/response_parser.py:_get_relationship_ids": {},
                "textractor/entities/page.py:Page:__init__": {
                  "textractor/entities/bbox.py:SpatialObject:__init__": {},
                  "textractor/visualizers/entitylist.py:EntityList:__init__": {}
                }
              },
              "textractor/parsers/response_parser.py:_create_line_objects": {
                "textractor/parsers/response_parser.py:_get_relationship_ids": {},
                "textractor/parsers/response_parser.py:_create_word_objects": {
                  "textractor/entities/bbox.py:BoundingBox:from_normalized_dict": {
                    "textractor/entities/bbox.py:BoundingBox:_from_dict": {
                      "textractor/entities/bbox.py:BoundingBox:__init__": {}
                    }
                  },
                  "textractor/entities/word.py:Word:__init__": {
                    "textractor/entities/document_entity.py:DocumentEntity:__init__": {}
                  },
                  "textractor/entities/document_entity.py:DocumentEntity:raw_object": {},
                  "textractor/entities/word.py:Word:page": {},
                  "textractor/entities/word.py:Word:page_id": {}
                },
                "textractor/entities/bbox.py:BoundingBox:from_normalized_dict": {
                  "textractor/entities/bbox.py:BoundingBox:_from_dict": {
                    "textractor/entities/bbox.py:BoundingBox:__init__": {
                      "textractor/entities/bbox.py:SpatialObject:__init__": {}
                    }
                  }
                },
                "textractor/entities/line.py:Line:__init__": {
                  "textractor/entities/document_entity.py:DocumentEntity:__init__": {},
                  "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
                },
                "textractor/entities/document_entity.py:DocumentEntity:bbox": {},
                "textractor/entities/document_entity.py:DocumentEntity:raw_object": {},
                "textractor/entities/line.py:Line:page": {},
                "textractor/entities/line.py:Line:page_id": {}
              },
              "textractor/entities/page.py:Page:lines": {
                "textractor/utils/geometry_util.py:sort_by_position": {
                  "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
                },
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_layout_objects": {},
              "textractor/entities/document_entity.py:DocumentEntity:bbox": {},
              "textractor/entities/layout.py:Layout:__init__": {
                "textractor/entities/document_entity.py:DocumentEntity:__init__": {}
              },
              "textractor/entities/layout.py:Layout:page": {},
              "textractor/entities/layout.py:Layout:page_id": {},
              "textractor/parsers/response_parser.py:_create_keyvalue_objects": {
                "textractor/parsers/response_parser.py:_filter_by_entity": {},
                "textractor/parsers/response_parser.py:_create_value_objects": {
                  "textractor/parsers/response_parser.py:_create_selection_objects": {}
                }
              },
              "textractor/entities/page.py:Page:key_values": {
                "textractor/utils/geometry_util.py:sort_by_position": {},
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/page.py:Page:checkboxes": {
                "textractor/utils/geometry_util.py:sort_by_position": {},
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_table_objects": {
                "textractor/parsers/response_parser.py:_create_table_cell_objects": {},
                "textractor/entities/page.py:Page:leaf_layouts": {},
                "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
              },
              "textractor/entities/page.py:Page:tables": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/page.py:Page:leaf_layouts": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/document_entity.py:DocumentEntity:children": {},
              "textractor/entities/page.py:Page:words": {
                "textractor/utils/geometry_util.py:sort_by_position": {
                  "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
                },
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_query_objects": {
                "textractor/parsers/response_parser.py:_create_query_result_objects": {}
              },
              "textractor/entities/page.py:Page:queries": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_signature_objects": {
                "textractor/entities/page.py:Page:leaf_layouts": {},
                "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
              },
              "textractor/entities/page.py:Page:signatures": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/page.py:Page:layouts": {
                "textractor/visualizers/entitylist.py:EntityList:__add__": {
                  "textractor/visualizers/entitylist.py:EntityList:__init__": {}
                },
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/document_entity.py:DocumentEntity:visit": {
                "textractor/entities/document_entity.py:DocumentEntity:visit": {
                  "[ignored_or_cut_off]": "..."
                }
              },
              "textractor/entities/document.py:Document:pages": {}
            },
            "textractor/entities/document.py:Document:identity_documents": {}
          }
        }
      },
      "textractor/entities/document.py:Document:identity_documents": {
        "textractor/visualizers/entitylist.py:EntityList:__init__": {}
      },
      "textractor/entities/identity_document.py:IdentityDocument:fields": {},
      "textractor/entities/identity_document.py:IdentityDocument:get": {
        "textractor/entities/identity_field.py:IdentityField:value": {}
      },
      "textractor/entities/identity_document.py:IdentityDocument:__getitem__": {
        "textractor/entities/identity_field.py:IdentityField:value": {}
      }
    },
    "tests/test_analyze_id.py:TestTextractorAnalyzeID:test_analyze_id_from_path": {
      "tests/utils.py:get_fixture_path": {},
      "textractor/entities/document.py:Document:open": {
        "textractor/parsers/response_parser.py:parse": {
          "textractor/parsers/response_parser.py:parse_analyze_id_response": {
            "textractor/entities/identity_document.py:IdentityDocument:__init__": {
              "textractor/entities/bbox.py:SpatialObject:__init__": {},
              "textractor/entities/identity_document.py:IdentityDocument:_fields_to_dict": {
                "textractor/entities/identity_field.py:IdentityField:__init__": {}
              }
            },
            "textractor/parsers/response_parser.py:parse_document_api_response": {
              "textractor/parsers/response_parser.py:_create_document_object": {
                "textractor/entities/document.py:Document:__init__": {
                  "textractor/entities/bbox.py:SpatialObject:__init__": {}
                }
              },
              "textractor/parsers/response_parser.py:_create_page_objects": {
                "textractor/parsers/response_parser.py:_filter_block_type": {},
                "textractor/parsers/response_parser.py:_get_relationship_ids": {},
                "textractor/entities/page.py:Page:__init__": {
                  "textractor/entities/bbox.py:SpatialObject:__init__": {},
                  "textractor/visualizers/entitylist.py:EntityList:__init__": {}
                }
              },
              "textractor/parsers/response_parser.py:_create_line_objects": {
                "textractor/parsers/response_parser.py:_get_relationship_ids": {},
                "textractor/parsers/response_parser.py:_create_word_objects": {
                  "textractor/entities/bbox.py:BoundingBox:from_normalized_dict": {
                    "textractor/entities/bbox.py:BoundingBox:_from_dict": {
                      "textractor/entities/bbox.py:BoundingBox:__init__": {}
                    }
                  },
                  "textractor/entities/word.py:Word:__init__": {
                    "textractor/entities/document_entity.py:DocumentEntity:__init__": {}
                  },
                  "textractor/entities/document_entity.py:DocumentEntity:raw_object": {},
                  "textractor/entities/word.py:Word:page": {},
                  "textractor/entities/word.py:Word:page_id": {}
                },
                "textractor/entities/bbox.py:BoundingBox:from_normalized_dict": {
                  "textractor/entities/bbox.py:BoundingBox:_from_dict": {
                    "textractor/entities/bbox.py:BoundingBox:__init__": {
                      "textractor/entities/bbox.py:SpatialObject:__init__": {}
                    }
                  }
                },
                "textractor/entities/line.py:Line:__init__": {
                  "textractor/entities/document_entity.py:DocumentEntity:__init__": {},
                  "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
                },
                "textractor/entities/document_entity.py:DocumentEntity:bbox": {},
                "textractor/entities/document_entity.py:DocumentEntity:raw_object": {},
                "textractor/entities/line.py:Line:page": {},
                "textractor/entities/line.py:Line:page_id": {}
              },
              "textractor/entities/page.py:Page:lines": {
                "textractor/utils/geometry_util.py:sort_by_position": {
                  "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
                },
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_layout_objects": {},
              "textractor/entities/document_entity.py:DocumentEntity:bbox": {},
              "textractor/entities/layout.py:Layout:__init__": {
                "textractor/entities/document_entity.py:DocumentEntity:__init__": {}
              },
              "textractor/entities/layout.py:Layout:page": {},
              "textractor/entities/layout.py:Layout:page_id": {},
              "textractor/parsers/response_parser.py:_create_keyvalue_objects": {
                "textractor/parsers/response_parser.py:_filter_by_entity": {},
                "textractor/parsers/response_parser.py:_create_value_objects": {
                  "textractor/parsers/response_parser.py:_create_selection_objects": {}
                }
              },
              "textractor/entities/page.py:Page:key_values": {
                "textractor/utils/geometry_util.py:sort_by_position": {},
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/page.py:Page:checkboxes": {
                "textractor/utils/geometry_util.py:sort_by_position": {},
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_table_objects": {
                "textractor/parsers/response_parser.py:_create_table_cell_objects": {},
                "textractor/entities/page.py:Page:leaf_layouts": {},
                "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
              },
              "textractor/entities/page.py:Page:tables": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/page.py:Page:leaf_layouts": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/document_entity.py:DocumentEntity:children": {},
              "textractor/entities/page.py:Page:words": {
                "textractor/utils/geometry_util.py:sort_by_position": {
                  "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
                },
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_query_objects": {
                "textractor/parsers/response_parser.py:_create_query_result_objects": {}
              },
              "textractor/entities/page.py:Page:queries": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/parsers/response_parser.py:_create_signature_objects": {
                "textractor/entities/page.py:Page:leaf_layouts": {},
                "textractor/entities/document_entity.py:DocumentEntity:bbox": {}
              },
              "textractor/entities/page.py:Page:signatures": {
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/page.py:Page:layouts": {
                "textractor/visualizers/entitylist.py:EntityList:__add__": {
                  "textractor/visualizers/entitylist.py:EntityList:__init__": {}
                },
                "textractor/visualizers/entitylist.py:EntityList:__init__": {}
              },
              "textractor/entities/document_entity.py:DocumentEntity:visit": {
                "textractor/entities/document_entity.py:DocumentEntity:visit": {
                  "[ignored_or_cut_off]": "..."
                }
              },
              "textractor/entities/document.py:Document:pages": {}
            },
            "textractor/entities/document.py:Document:identity_documents": {}
          }
        }
      },
      "textractor/entities/document.py:Document:identity_documents": {
        "textractor/visualizers/entitylist.py:EntityList:__init__": {}
      },
      "textractor/entities/identity_document.py:IdentityDocument:fields": {},
      "textractor/entities/identity_document.py:IdentityDocument:get": {
        "textractor/entities/identity_field.py:IdentityField:value": {}
      },
      "textractor/entities/identity_document.py:IdentityDocument:__getitem__": {
        "textractor/entities/identity_field.py:IdentityField:value": {}
      }
    }
  },
  "PRD": "# PROJECT NAME: amazon_textract_textractor-test_analyze_id\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 textractor/\n    \u251c\u2500\u2500 entities/\n    \u2502   \u251c\u2500\u2500 document.py\n    \u2502   \u2502   \u251c\u2500\u2500 Document.identity_documents\n    \u2502   \u2502   \u2514\u2500\u2500 Document.open\n    \u2502   \u251c\u2500\u2500 identity_document.py\n    \u2502   \u2502   \u251c\u2500\u2500 IdentityDocument.__getitem__\n    \u2502   \u2502   \u251c\u2500\u2500 IdentityDocument.fields\n    \u2502   \u2502   \u2514\u2500\u2500 IdentityDocument.get\n    \u2502   \u2514\u2500\u2500 identity_field.py\n    \u2502       \u2514\u2500\u2500 IdentityField.value\n    \u251c\u2500\u2500 parsers/\n    \u2502   \u2514\u2500\u2500 response_parser.py\n    \u2502       \u2514\u2500\u2500 parse\n    \u2514\u2500\u2500 visualizers/\n        \u2514\u2500\u2500 entitylist.py\n            \u2514\u2500\u2500 EntityList.__init__\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module facilitates the extraction and analysis of identity document data using AWS Textract, enabling efficient processing of structured data fields from images such as driver's licenses or ID cards. It provides functionality to analyze ID documents from both file paths and in-memory images, returning detailed structured data, including key fields like the individual\u2019s first name. By automating the extraction of critical information from identity documents, this module simplifies workflows for developers and users by eliminating the need for manual data entry or complex preprocessing, improving accuracy and operational efficiency.\n\n## FILE 1: textractor/entities/document.py\n\n- CLASS METHOD: Document.open\n  - CLASS SIGNATURE: class Document(SpatialObject, Linearizable):\n  - SIGNATURE: def open(cls, fp: Union[dict, str, Path, IO[AnyStr]]):\n  - DOCSTRING: \n```python\n\"\"\"\nCreates and returns a Document object by parsing input from various sources such as a JSON dictionary, a file path, or a file handle. The function supports loading documents stored in AWS S3 by checking if the input string begins with \"s3://\". It relies on the `response_parser` from the `textractor.parsers` module to perform the actual parsing of the input data into a Document object. The method raises an `InputError` if the input type does not match the expected types: dictionary, string, Path, or file handle.\n\nParameters:\n- fp (Union[dict, str, Path, IO[AnyStr]]): The input source for creating a Document object, which can be a response dictionary, a file path (string or Path), or a file handle.\n\nReturns:\n- Document: An instance of the Document class populated with parsed data.\n\nRaises:\n- InputError: If the provided input does not conform to the accepted types.\n\nDependencies:\n- Requires the `boto3` library for AWS S3 interactions.\n- Utilizes `json` for loading JSON data.\n- Interacts with the `response_parser` from `textractor.parsers` to handle the parsing logic.\n\"\"\"\n```\n\n- CLASS METHOD: Document.identity_documents\n  - CLASS SIGNATURE: class Document(SpatialObject, Linearizable):\n  - SIGNATURE: def identity_documents(self, identity_documents: List[IdentityDocument]):\n  - DOCSTRING: \n```python\n\"\"\"\nSets the list of detected identity documents within the Document instance.\n\n:param identity_documents: A list of IdentityDocument objects representing the identity documents detected in the document. Each instance of IdentityDocument is assumed to encapsulate the relevant data and methods related to a single identity document extracted from the input.\n\nThis method updates the internal attribute `_identity_documents`, which stores these IdentityDocument objects, enabling other methods of the Document class to retrieve and manipulate the identity documents as needed. By maintaining a separate list, the class supports better organization and interaction with document entities, particularly for functionalities related to identity document processing.\n\"\"\"\n```\n\n## FILE 2: textractor/visualizers/entitylist.py\n\n- CLASS METHOD: EntityList.__init__\n  - CLASS SIGNATURE: class EntityList(list, Generic[T], Linearizable):\n  - SIGNATURE: def __init__(self, objs=None):\n  - DOCSTRING: \n```python\n\"\"\"\nInitializes an instance of the `EntityList` class, which extends the built-in list type to store document entities. This constructor allows for the initialization of the list with a custom collection of entity objects.\n\nParameters:\n- objs (Optional[list]): An initial list of entities to populate the `EntityList`. If None, the list will be initialized as empty. If a non-list object is provided, it is converted into a single-element list.\n\nReturns:\n- None: The method initializes the instance in place and does not return any value.\n\nUsage:\nThis constructor interacts with the `super().__init__()` method from the list class to ensure proper list initialization. The entities added to this list can be visualized and formatted through methods like `visualize()` and `pretty_print()`, which are defined in the same class. The handling of object types ensures that only valid entities are stored in the `EntityList`, promoting consistency throughout the application.\n\"\"\"\n```\n\n## FILE 3: textractor/entities/identity_document.py\n\n- CLASS METHOD: IdentityDocument.fields\n  - CLASS SIGNATURE: class IdentityDocument(SpatialObject):\n  - SIGNATURE: def fields(self, fields):\n  - DOCSTRING: \n```python\n\"\"\"\nSets the fields of the IdentityDocument instance.\n\n:param fields: A dictionary mapping field keys to IdentityField objects. These fields represent the information extracted from an ID document, including attributes like key, value, and confidence level.\n\nThis setter method updates the internal _fields attribute, which is a dictionary that allows accessing the individual IdentityField entries for retrieving specific information about the ID document. It interacts with the IdentityField class, which is responsible for encapsulating the data associated with each field, guaranteeing that the fields are represented consistently within the document.\n\"\"\"\n```\n\n- CLASS METHOD: IdentityDocument.__getitem__\n  - CLASS SIGNATURE: class IdentityDocument(SpatialObject):\n  - SIGNATURE: def __getitem__(self, key: Union[str, AnalyzeIDFields]) -> str:\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieves the value associated with a specified key from the IdentityDocument's fields.\n\nParameters:\n- key (Union[str, AnalyzeIDFields]): A string representing the key of the desired field or an instance of AnalyzeIDFields, which is an enumeration of field keys.\n\nReturns:\n- str: The value of the field corresponding to the provided key.\n- Raises a KeyError if the key does not exist in the document's fields.\n\nThis method directly interacts with the _fields attribute, which is a dictionary mapping field keys (either as strings or AnalyzeIDFields) to IdentityField objects. Each IdentityField contains a 'value' that represents the data extracted from the ID document.\n\"\"\"\n```\n\n- CLASS METHOD: IdentityDocument.get\n  - CLASS SIGNATURE: class IdentityDocument(SpatialObject):\n  - SIGNATURE: def get(self, key: Union[str, AnalyzeIDFields]) -> Union[str, None]:\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieves the value associated with a specified key from the document's fields.\n\nParameters:\n- key (Union[str, AnalyzeIDFields]): The key corresponding to the desired field. This can be a string or an instance of AnalyzeIDFields, which is an enumeration defined in the constants imported from `textractor.data.constants`.\n\nReturns:\n- Union[str, None]: The value associated with the specified key if it exists; otherwise, returns None.\n\nThis method interacts with the `_fields` attribute, which is a dictionary of `IdentityField` instances representing various fields of the identity document. If the provided key does not correspond to an existing field, the method gracefully handles the request by returning None instead of raising an error.\n\"\"\"\n```\n\n## FILE 4: textractor/entities/identity_field.py\n\n- CLASS METHOD: IdentityField.value\n  - CLASS SIGNATURE: class IdentityField:\n  - SIGNATURE: def value(self) -> str:\n  - DOCSTRING: \n```python\n\"\"\"\nReturns the value associated with the identity field.\n\nThis method provides access to the `_value` attribute of the IdentityField instance, which represents a specific value relevant to the identity being modeled. The value is a string that can be retrieved without any parameters. This method is primarily used to expose the internal representation of the identity's value, complementing the key and confidence properties.\n\nReturns:\n    str: The value of the identity field.\n\"\"\"\n```\n\n## FILE 5: textractor/parsers/response_parser.py\n\n- FUNCTION NAME: parse\n  - SIGNATURE: def parse(response: dict) -> Document:\n  - DOCSTRING: \n```python\n\"\"\"\nParses the Textract API JSON response, identifying the type of document (such as Identity Documents or Expense Documents) and invoking the appropriate parsing function to transform it into a Document object format. Supports both SYNC and ASYNC API calls.\n\n:param response: JSON response data received from the Textract API, can include various document types.\n:type response: dict\n\n:return: A Document object containing parsed information such as pages, key-value pairs, tables, and other entities extracted from the input response.\n:rtype: Document\n\nThis function interacts with several helper functions defined in the same module, including `parse_analyze_id_response` for Identity Documents and `parser_analyze_expense_response` for Expense Documents. The function also utilizes the `converter` utility for processing the response, ensuring it meets the expected format before parsing. Constants and data structures defined in the module (like `KEY_VALUE_SET` or `TABLE`) are utilized indirectly through the helper functions to filter and structure the parsed data appropriately.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - textractor/entities/document.py:Document:open\n    - textractor/parsers/response_parser.py:parse_analyze_id_response\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "textractor/entities/document.py": "\"\"\"The Document class is defined to host all the various DocumentEntity objects within it. :class:`DocumentEntity` objects can be \naccessed, searched and exported the functions given below.\"\"\"\nimport boto3\nimport json\nimport os\nimport string\nimport logging\nimport xlsxwriter\nimport io\nfrom pathlib import Path\nfrom typing import List, IO, Union, AnyStr, Tuple\nfrom copy import deepcopy\nfrom collections import defaultdict\nfrom PIL import Image\nfrom textractor.entities.expense_document import ExpenseDocument\nfrom textractor.entities.identity_document import IdentityDocument\nfrom textractor.entities.word import Word\nfrom textractor.entities.line import Line\nfrom textractor.entities.page import Page\nfrom textractor.entities.table import Table\nfrom textractor.entities.query import Query\nfrom textractor.entities.signature import Signature\nfrom textractor.entities.layout import Layout\nfrom textractor.exceptions import InputError\nfrom textractor.entities.key_value import KeyValue\nfrom textractor.entities.bbox import SpatialObject\nfrom textractor.utils.s3_utils import download_from_s3\nfrom textractor.visualizers.entitylist import EntityList\nfrom textractor.data.constants import TextTypes, SimilarityMetric, Direction, DirectionalFinderType\nfrom textractor.utils.search_utils import SearchUtils\nfrom textractor.data.text_linearization_config import TextLinearizationConfig\nfrom textractor.data.html_linearization_config import HTMLLinearizationConfig\nfrom textractor.entities.linearizable import Linearizable\n\nclass Document(SpatialObject, Linearizable):\n    \"\"\"\n    Represents the description of a single document, as it would appear in the input to the Textract API.\n    Document serves as the root node of the object model hierarchy,\n    which should be used as an intermediate form for most analytic purposes.\n    The Document node also contains the metadata of the document.\n    \"\"\"\n\n    def __init__(self, num_pages: int=1):\n        \"\"\"\n        Creates a new document, ideally containing entity objects pertaining to each page.\n\n        :param num_pages: Number of pages in the input Document.\n        \"\"\"\n        super().__init__(width=0, height=0)\n        self.num_pages: int = num_pages\n        self._pages: List[Page] = []\n        self._identity_documents: List[IdentityDocument] = []\n        self._trp2_document = None\n        self.response = None\n\n    @property\n    def words(self) -> EntityList[Word]:\n        \"\"\"\n        Returns all the :class:`Word` objects present in the Document.\n\n        :return: List of Word objects, each representing a word within the Document.\n        :rtype: EntityList[Word]\n        \"\"\"\n        return EntityList(sum([page.words for page in self.pages], []))\n\n    @property\n    def text(self) -> str:\n        \"\"\"Returns the document text as one string\n\n        :return: Page text seperated by line return\n        :rtype: str\n        \"\"\"\n        return os.linesep.join([page.text for page in self.pages])\n\n    @property\n    def expense_documents(self) -> EntityList[ExpenseDocument]:\n        \"\"\"\n        Returns all the :class:`ExpenseDocument` objects present in the Document.\n\n        :return: List of ExpenseDocument objects, each representing an expense document within the Document.\n        :rtype: EntityList[ExpenseDocument]\n        \"\"\"\n        return EntityList(sum([page.expense_documents for page in self.pages], []))\n\n    @property\n    def lines(self) -> EntityList[Line]:\n        \"\"\"\n        Returns all the :class:`Line` objects present in the Document.\n\n        :return: List of Line objects, each representing a line within the Document.\n        :rtype: EntityList[Line]\n        \"\"\"\n        return EntityList(sum([page.lines for page in self.pages], []))\n\n    @property\n    def key_values(self) -> EntityList[KeyValue]:\n        \"\"\"\n        Returns all the :class:`KeyValue` objects present in the Document.\n\n        :return: List of KeyValue objects, each representing a key-value pair within the Document.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        return EntityList(sum([page.key_values for page in self.pages], []))\n\n    @property\n    def checkboxes(self) -> EntityList[KeyValue]:\n        \"\"\"\n        Returns all the :class:`KeyValue` objects with SelectionElements present in the Document.\n\n        :return: List of KeyValue objects, each representing a checkbox within the Document.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        return EntityList(sum([page.checkboxes for page in self.pages], []))\n\n    @property\n    def tables(self) -> EntityList[Table]:\n        \"\"\"\n        Returns all the :class:`Table` objects present in the Document.\n\n        :return: List of Table objects, each representing a table within the Document.\n        :rtype: EntityList[Table]\n        \"\"\"\n        return EntityList(sum([page.tables for page in self.pages], []))\n\n    @property\n    def queries(self) -> EntityList[Query]:\n        \"\"\"\n        Returns all the :class:`Query` objects present in the Document.\n\n        :return: List of Query objects.\n        :rtype: EntityList[Query]\n        \"\"\"\n        return EntityList(sum([page.queries for page in self.pages], []))\n\n    @property\n    def signatures(self) -> EntityList[Signature]:\n        \"\"\"\n        Returns all the :class:`Signature` objects present in the Document.\n\n        :return: List of Signature objects.\n        :rtype: EntityList[Signature]\n        \"\"\"\n        return EntityList(sum([page.signatures for page in self.pages], []))\n\n    @property\n    def layouts(self) -> EntityList[Layout]:\n        \"\"\"\n        Returns all the :class:`Layout` objects present in the Document\n\n        :return: List of Layout objects\n        :rtype: EntityList[Layout]\n        \"\"\"\n        return EntityList(sum([page.layouts for page in self.pages], []))\n\n    @property\n    def identity_document(self) -> EntityList[IdentityDocument]:\n        \"\"\"\n        Returns all the :class:`IdentityDocument` objects present in the Page.\n\n        :return: List of IdentityDocument objects.\n        :rtype: EntityList\n        \"\"\"\n        return EntityList(self._identity_documents)\n\n    @identity_document.setter\n    def identity_document(self, identity_documents: List[IdentityDocument]):\n        \"\"\"\n        Add IdentityDocument objects to the Page.\n\n        :param tables: List of IdentityDocument objects.\n        :type identity_documents: list\n        \"\"\"\n        self._identity_document = identity_documents\n\n    @property\n    def images(self) -> List[Image.Image]:\n        \"\"\"\n        Returns all the page images in the Document.\n\n        :return: List of PIL Image objects.\n        :rtype: PIL.Image\n        \"\"\"\n        return [page.image for page in self._pages]\n\n    @property\n    def pages(self) -> List[Page]:\n        \"\"\"\n        Returns all the :class:`Page` objects present in the Document.\n\n        :return: List of Page objects, each representing a Page within the Document.\n        :rtype: List\n        \"\"\"\n        return self._pages\n\n    @pages.setter\n    def pages(self, pages: List[Page]):\n        \"\"\"\n        Add Page objects to the Document.\n\n        :param pages: List of Page objects, each representing a page within the document.\n        No specific ordering is assumed with input.\n        :type pages: List[Page]\n        \"\"\"\n        self._pages = sorted(pages, key=lambda x: x.page_num)\n\n    def get_text_and_words(self, config: TextLinearizationConfig=TextLinearizationConfig()) -> Tuple[str, List]:\n        text, words_lists = zip(*[p.get_text_and_words(config) for p in self.pages])\n        flattened_words = []\n        for words in words_lists:\n            flattened_words.extend(words)\n        return (config.layout_element_separator.join(text), flattened_words)\n\n    def page(self, page_no: int=0):\n        \"\"\"\n        Returns :class:`Page` object/s depending on the input page_no. Follows zero-indexing.\n\n        :param page_no: if int, returns single Page Object, else if list, it returns a list of\n                        Page objects.\n        :type page_no: int if single page, list of int if multiple pages\n\n        :return: Filters and returns Page objects depending on the input page_no\n        :rtype: Page or List[Page]\n        \"\"\"\n        if isinstance(page_no, int):\n            return self.pages[page_no]\n        elif isinstance(page_no, list):\n            return [self.pages[num] for num in page_no]\n        else:\n            raise InputError(\"page_no parameter doesn't match required data type.\")\n\n    def to_html(self, config: HTMLLinearizationConfig=HTMLLinearizationConfig()):\n        \"\"\"\n        Returns the HTML representation of the document, effectively calls Linearizable.to_html()\n        but add <html><body></body></html> around the result and put each page in a <div>. \n\n        :return: HTML text of the entity\n        :rtype: str\n        \"\"\"\n        html = '<html><body>'\n        for page in self.pages:\n            html += f'<div>{page.to_html(config=config)}</div>'\n        html += '</body></html>'\n        return html\n\n    def __repr__(self):\n        return os.linesep.join(['This document holds the following data:', f'Pages - {len(self.pages)}', f'Words - {len(self.words)}', f'Lines - {len(self.lines)}', f'Key-values - {len(self.key_values)}', f'Checkboxes - {len(self.checkboxes)}', f'Tables - {len(self.tables)}', f'Queries - {len(self.queries)}', f'Signatures - {len(self.signatures)}', f'Identity Documents - {len(self.identity_documents)}', f'Expense Documents - {len(self.expense_documents)}'])\n\n    def to_trp2(self):\n        \"\"\"\n        Parses the response to the trp2 format for backward compatibility\n\n        :return: TDocument object that can be used with the older Textractor libraries\n        :rtype: TDocument\n        \"\"\"\n        from trp.trp2 import TDocument, TDocumentSchema\n        if not self._trp2_document:\n            self._trp2_document = TDocumentSchema().load(self.response)\n        return self._trp2_document\n\n    def visualize(self, *args, **kwargs):\n        \"\"\"\n        Returns the object's children in a visualization EntityList object\n\n        :return: Returns an EntityList object\n        :rtype: EntityList\n        \"\"\"\n        return EntityList(self.pages).visualize(*args, **kwargs)\n\n    def keys(self, include_checkboxes: bool=True) -> List[str]:\n        \"\"\"\n        Prints all keys for key-value pairs and checkboxes if the document contains them.\n\n        :param include_checkboxes: True/False. Set False if checkboxes need to be excluded.\n        :type include_checkboxes: bool\n\n        :return: List of strings containing key names in the Document\n        :rtype: List[str]\n        \"\"\"\n        keys = []\n        keys = [keyvalue.key for keyvalue in self.key_values]\n        if include_checkboxes:\n            keys += [keyvalue.key for keyvalue in self.checkboxes]\n        return keys\n\n    def filter_checkboxes(self, selected: bool=True, not_selected: bool=True) -> List[KeyValue]:\n        \"\"\"\n        Return a list of :class:`KeyValue` objects containing checkboxes if the document contains them.\n\n        :param selected: True/False Return SELECTED checkboxes\n        :type selected: bool\n        :param not_selected: True/False Return NOT_SELECTED checkboxes\n        :type not_selected: bool\n\n        :return: Returns checkboxes that match the conditions set by the flags.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        checkboxes = EntityList([])\n        for page in self.pages:\n            checkboxes.extend(page.filter_checkboxes(selected=selected, not_selected=not_selected))\n        return checkboxes\n\n    def get_words_by_type(self, text_type: TextTypes=TextTypes.PRINTED) -> List[Word]:\n        \"\"\"\n        Returns list of :class:`Word` entities that match the input text type.\n\n        :param text_type: TextTypes.PRINTED or TextTypes.HANDWRITING\n        :type text_type: TextTypes\n        :return: Returns list of Word entities that match the input text type.\n        :rtype: EntityList[Word]\n        \"\"\"\n        if not self.words:\n            logging.warn('Document contains no word entities.')\n            return []\n        filtered_words = EntityList()\n        for page in self.pages:\n            filtered_words.extend(page.get_words_by_type(text_type=text_type))\n        return filtered_words\n\n    def search_words(self, keyword: str, top_k: int=1, similarity_metric: SimilarityMetric=SimilarityMetric.LEVENSHTEIN, similarity_threshold: float=0.6) -> List[Word]:\n        \"\"\"\n        Return a list of top_k words that match the keyword.\n\n        :param keyword: Keyword that is used to query the document.\n        :type keyword: str\n        :param top_k: Number of closest word objects to be returned\n        :type top_k: int\n        :param similarity_metric: SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN or SimilarityMetric.LEVENSHTEIN. SimilarityMetric.COSINE is chosen as default.\n        :type similarity_metric: SimilarityMetric\n        :param similarity_threshold: Measure of how similar document key is to queried key. default=0.6\n        :type similarity_threshold: float\n\n        :return: Returns a list of words that match the queried key sorted from highest\n                 to lowest similarity.\n        :rtype: EntityList[Word]\n        \"\"\"\n        top_n_words = []\n        for page in self.pages:\n            top_n_words.extend(page._search_words_with_similarity(keyword=keyword, top_k=top_k, similarity_metric=similarity_metric, similarity_threshold=similarity_threshold))\n        top_n_words = sorted(top_n_words, key=lambda x: x[0], reverse=True)[:top_k]\n        top_n_words = EntityList([ent[1] for ent in top_n_words])\n        return top_n_words\n\n    def search_lines(self, keyword: str, top_k: int=1, similarity_metric: SimilarityMetric=SimilarityMetric.LEVENSHTEIN, similarity_threshold: float=0.6) -> List[Line]:\n        \"\"\"\n        Return a list of top_k lines that contain the queried keyword.\n\n        :param keyword: Keyword that is used to query the document.\n        :type keyword: str\n        :param top_k: Number of closest line objects to be returned\n        :type top_k: int\n        :param similarity_metric: SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN or SimilarityMetric.LEVENSHTEIN. SimilarityMetric.COSINE is chosen as default.\n        :type similarity_metric: SimilarityMetric\n        :param similarity_threshold: Measure of how similar document key is to queried key. default=0.6\n        :type similarity_threshold: float\n\n        :return: Returns a list of lines that contain the queried key sorted from highest\n                 to lowest similarity.\n        :rtype: EntityList[Line]\n        \"\"\"\n        if not isinstance(similarity_metric, SimilarityMetric):\n            raise InputError('similarity_metric parameter should be of SimilarityMetric type. Find input choices from textractor.data.constants')\n        top_n_lines = []\n        for page in self.pages:\n            top_n_lines.extend(page._search_lines_with_similarity(keyword=keyword, top_k=top_k, similarity_metric=similarity_metric, similarity_threshold=similarity_threshold))\n        top_n_lines = EntityList([ent[1] for ent in top_n_lines][:top_k])\n        return top_n_lines\n\n    def get(self, key: str, top_k_matches: int=1, similarity_metric: SimilarityMetric=SimilarityMetric.LEVENSHTEIN, similarity_threshold: float=0.6):\n        \"\"\"\n        Return upto top_k_matches of key-value pairs for the key that is queried from the document.\n\n        :param key: Query key to match\n        :type key: str\n        :param top_k_matches: Maximum number of matches to return\n        :type top_k_matches: int\n        :param similarity_metric: SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN or SimilarityMetric.LEVENSHTEIN. SimilarityMetric.COSINE is chosen as default.\n        :type similarity_metric: SimilarityMetric\n        :param similarity_threshold: Measure of how similar document key is to queried key. default=0.6\n        :type similarity_threshold: float\n\n        :return: Returns a list of key-value pairs that match the queried key sorted from highest to lowest similarity.\n        :rtype: EntityList[KeyValue]\n        \"\"\"\n        if not isinstance(similarity_metric, SimilarityMetric):\n            raise InputError('similarity_metric parameter should be of SimilarityMetric type. Find input choices from textractor.data.constants')\n        top_n = []\n        similarity_threshold = -similarity_threshold if similarity_metric == SimilarityMetric.EUCLIDEAN else similarity_threshold\n        lowest_similarity = similarity_threshold\n        for kv in self.key_values + self.checkboxes:\n            try:\n                edited_document_key = ''.join([char for char in kv.key.__repr__() if char not in string.punctuation])\n            except:\n                pass\n            key = ''.join([char for char in key if char not in string.punctuation])\n            similarity = [SearchUtils.get_word_similarity(key, word, similarity_metric) for word in edited_document_key.split(' ')]\n            similarity.append(SearchUtils.get_word_similarity(key, edited_document_key, similarity_metric))\n            similarity = min(similarity) if similarity_metric == SimilarityMetric.EUCLIDEAN else max(similarity)\n            if similarity > similarity_threshold:\n                if len(top_n) < top_k_matches:\n                    top_n.append((kv, similarity))\n                elif similarity > lowest_similarity:\n                    top_n[-1] = (kv, similarity)\n                top_n = sorted(top_n, key=lambda x: x[1], reverse=True)\n                lowest_similarity = top_n[-1][1]\n        if not top_n:\n            logging.warning(f'Query key does not match any existing keys in the document.{os.linesep}{self.keys()}')\n            return EntityList([])\n        logging.info(f'Query key matched {len(top_n)} key-values in the document.')\n        return EntityList([value[0] for value in top_n])\n\n    def export_kv_to_csv(self, include_kv: bool=True, include_checkboxes: bool=True, filepath: str='Key-Values.csv', sep: str=';'):\n        \"\"\"\n        Export key-value entities and checkboxes in csv format.\n\n        :param include_kv: True if KVs are to be exported. Else False.\n        :type include_kv: bool\n        :param include_checkboxes: True if checkboxes are to be exported. Else False.\n        :type include_checkboxes: bool\n        :param filepath: Path to where file is to be stored.\n        :type filepath: str\n        :param sep: Separator to be used in the csv file.\n        :type sep: str\n        \"\"\"\n        keys = []\n        values = []\n        if include_kv and (not self.key_values):\n            logging.warning('Document does not contain key-values.')\n        elif include_kv:\n            for kv in self.key_values:\n                keys.append(' '.join([w.text for w in kv.key]))\n                values.append(kv.value.get_text())\n        if include_checkboxes and (not self.checkboxes):\n            logging.warning('Document does not contain checkbox elements.')\n        elif include_checkboxes:\n            for kv in self.checkboxes:\n                keys.append(' '.join([w.text for w in kv.key]))\n                values.append(kv.value.children[0].status.name)\n        with open(filepath, 'w') as f:\n            f.write(f'Key{sep}Value{os.linesep}')\n            for k, v in zip(keys, values):\n                f.write(f'{k}{sep}{v}{os.linesep}')\n        logging.info(f'csv file stored at location {os.path.join(os.getcwd(), filepath)}')\n\n    def export_kv_to_txt(self, include_kv: bool=True, include_checkboxes: bool=True, filepath: str='Key-Values.txt'):\n        \"\"\"\n        Export key-value entities and checkboxes in txt format.\n\n        :param include_kv: True if KVs are to be exported. Else False.\n        :type include_kv: bool\n        :param include_checkboxes: True if checkboxes are to be exported. Else False.\n        :type include_checkboxes: bool\n        :param filepath: Path to where file is to be stored.\n        :type filepath: str\n        \"\"\"\n        export_str = ''\n        index = 1\n        if include_kv and (not self.key_values):\n            logging.warning('Document does not contain key-values.')\n        elif include_kv:\n            for kv in self.key_values:\n                export_str += f'{index}. {kv.key.__repr__()} : {kv.value.__repr__()}{os.linesep}'\n                index += 1\n        if include_checkboxes and (not self.checkboxes):\n            logging.warning('Document does not contain checkbox elements.')\n        elif include_checkboxes:\n            for kv in self.checkboxes:\n                export_str += f'{index}. {kv.key.__repr__()} : {kv.value.children[0].status.name}{os.linesep}'\n                index += 1\n        with open(filepath, 'w') as text_file:\n            text_file.write(export_str)\n        logging.info(f'txt file stored at location {os.path.join(os.getcwd(), filepath)}')\n\n    def export_tables_to_excel(self, filepath):\n        \"\"\"\n        Creates an excel file and writes each table on a separate worksheet within the workbook.\n        This is stored on the filepath passed by the user.\n\n        :param filepath: Path to store the exported Excel file.\n        :type filepath: str, required\n        \"\"\"\n        if not filepath:\n            logging.error('Filepath required to store excel file.')\n        workbook = xlsxwriter.Workbook(filepath)\n        for table in self.tables:\n            workbook = table.to_excel(filepath=None, workbook=workbook, save_workbook=False)\n        workbook.close()\n\n    def independent_words(self):\n        \"\"\"\n        :return: Return all words in the document, outside of tables, checkboxes, key-values.\n        :rtype: EntityList[Word]\n        \"\"\"\n        if not self.words:\n            logging.warning('Words have not been assigned to this Document object.')\n            return []\n        else:\n            table_words = sum([table.words for table in self.tables], [])\n            kv_words = sum([kv.words for kv in self.key_values], [])\n            checkbox_words = sum([kv.words for kv in self.checkboxes], [])\n            dependent_words = table_words + checkbox_words + kv_words\n            dependent_word_ids = set([word.id for word in dependent_words])\n            independent_words = [word for word in self.words if word.id not in dependent_word_ids]\n            return EntityList(independent_words)\n\n    def return_duplicates(self):\n        \"\"\"\n        Returns a dictionary containing page numbers as keys and list of :class:`EntityList` objects as values.\n        Each :class:`EntityList` instance contains the key-values and the last item is the table which contains duplicate information.\n        This function is intended to let the Textract user know of duplicate objects extracted by the various Textract models.\n\n        :return: Dictionary containing page numbers as keys and list of EntityList objects as values.\n        :rtype: Dict[page_num, List[EntityList[DocumentEntity]]]\n        \"\"\"\n        document_duplicates = defaultdict(list)\n        for page in self.pages:\n            document_duplicates[page.page_num].extend(page.return_duplicates())\n        return document_duplicates\n\n    def directional_finder(self, word_1: str='', word_2: str='', page: int=-1, prefix: str='', direction=Direction.BELOW, entities=[]):\n        \"\"\"\n        The function returns entity types present in entities by prepending the prefix provided by te user. This helps in cases of repeating\n        key-values and checkboxes. The user can manipulate original data or produce a copy. The main advantage of this function is to be able to define direction.\n\n        :param word_1: The reference word from where x1, y1 coordinates are derived\n        :type word_1: str, required\n        :param word_2: The second word preferably in the direction indicated by the parameter direction. When it isn't given the end of page coordinates are used in the given direction.\n        :type word_2: str, optional\n        :param page: page number of the page in the document to search the entities in.\n        :type page: int, required\n        :param prefix: User provided prefix to prepend to the key . Without prefix, the method acts as a search by geometry function\n        :type prefix: str, optional\n        :param entities: List of DirectionalFinderType inputs.\n        :type entities: List[DirectionalFinderType]\n\n        :return: Returns the EntityList of modified key-value and/or checkboxes\n        :rtype: EntityList\n        \"\"\"\n        if not word_1 or page == -1:\n            return EntityList([])\n        x1, x2, y1, y2 = self._get_coords(word_1, word_2, direction, page)\n        if x1 == -1:\n            return EntityList([])\n        page_obj = self.pages[page - 1]\n        entity_dict = {DirectionalFinderType.KEY_VALUE_SET: self.key_values, DirectionalFinderType.SELECTION_ELEMENT: self.checkboxes}\n        entitylist = []\n        for entity_type in entities:\n            entitylist.extend(list(entity_dict[entity_type]))\n        new_key_values = self._get_kv_with_direction(direction, entitylist, (x1, x2, y1, y2))\n        final_kv = []\n        for kv in new_key_values:\n            if kv.key:\n                key_words = [deepcopy(word) for word in kv.key]\n                key_words[0].text = prefix + key_words[0].text\n                new_kv = deepcopy(kv)\n                new_kv.key = key_words\n                final_kv.append(new_kv)\n            else:\n                final_kv.append(kv)\n        return EntityList(final_kv)\n\n    def _get_kv_with_direction(self, direction, entitylist, coords):\n        \"\"\"Return key-values and checkboxes in entitylist present in the direction given with respect to the coordinates.\"\"\"\n        if direction == Direction.ABOVE:\n            new_key_values = [kv for kv in entitylist if kv.bbox.y <= coords[2] and kv.bbox.y >= coords[-1]]\n        elif direction == Direction.BELOW:\n            new_key_values = [kv for kv in entitylist if kv.bbox.y >= coords[2] and kv.bbox.y <= coords[-1]]\n        elif direction == Direction.RIGHT:\n            new_key_values = [kv for kv in entitylist if kv.bbox.x >= coords[0] and kv.bbox.x <= coords[1]]\n            new_key_values = [kv for kv in new_key_values if kv.bbox.y >= coords[2] - kv.bbox.height and kv.bbox.y <= coords[-1] + 3 * kv.bbox.height]\n        elif direction == Direction.LEFT:\n            new_key_values = [kv for kv in entitylist if kv.bbox.x <= coords[0] and kv.bbox.x >= coords[1]]\n            new_key_values = [kv for kv in new_key_values if kv.bbox.y >= coords[2] - kv.bbox.height and kv.bbox.y <= coords[-1] + 3 * kv.bbox.height]\n        return new_key_values\n\n    def _get_coords(self, word_1, word_2, direction, page):\n        \"\"\"\n        Returns coordinates for the area within which to search for key-values with the directional_finder by retrieving coordinates of word_1         and word_2 if it exists else end of page.\n        \"\"\"\n        word_1_objects = self.search_lines(keyword=word_1, top_k=5, similarity_metric=SimilarityMetric.COSINE, similarity_threshold=0.5)\n        word_1_objects = [word for word in word_1_objects if word.page == page] if page != -1 else []\n        if not word_1_objects:\n            logging.warning(f'{word_1} not found in page {page}')\n            return (-1, -1, -1, -1)\n        else:\n            word_1_obj = word_1_objects[0]\n            x1, y1 = (word_1_obj.bbox.x, word_1_obj.bbox.y)\n        if word_2:\n            word_2_objects = self.search_lines(keyword=word_2, top_k=5, similarity_metric=SimilarityMetric.COSINE, similarity_threshold=0.5)\n            word_2_objects = [word for word in word_2_objects if word.page == page]\n            if not word_2_objects:\n                logging.warning(f'{word_2} not found in page {page}')\n                return (-1, -1, -1, -1)\n            else:\n                word_2_obj = word_2_objects[0]\n                x2, y2 = (word_2_obj.bbox.x, word_2_obj.bbox.y)\n        else:\n            x2, y2 = (x1, y1)\n        if direction == Direction.ABOVE:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if y2 < y1 else (x1, 0, y1, 0)\n        elif direction == Direction.BELOW:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if y2 > y1 else (x1, 1, y1, 1)\n        elif direction == Direction.RIGHT:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if x2 > x1 else (x1, 1, y1, y1)\n        elif direction == Direction.LEFT:\n            x1, x2, y1, y2 = (x1, x2, y1, y2) if x2 < x1 else (x1, 0, y1, y1)\n        else:\n            return (-1, -1, -1, -1)\n        return (x1, x2, y1, y2)",
    "textractor/visualizers/entitylist.py": "\"\"\"\nThe :class:`EntityList` is an extension of list type with custom functions to print document entities in a well formatted manner and visualize on top of the document page with their BoundingBox information. \n\nThe two main functions within this class are :code:`pretty_print()` and :code:`visualize()`.\nUse :code:`pretty_print()` to get a string formatted output of your custom list of entities.\nUse :code:`visualize()` to get the bounding box visualization of the entities on the document page images.\n\"\"\"\nimport os\nimport csv\nimport logging\nfrom enum import Enum\nfrom io import StringIO\nfrom tabulate import tabulate\nfrom typing import List, Optional, TypeVar, Generic, Any\nfrom collections import defaultdict\nfrom textractor.utils.geometry_util import get_indices\nfrom PIL import Image, ImageDraw, ImageColor, ImageFont\nfrom textractor.data.constants import TextractType, TableFormat, AnalyzeExpenseLineItemFields, AnalyzeExpenseFields\nfrom textractor.exceptions import EntityListCreationError, NoImageException\nfrom textractor.entities.linearizable import Linearizable\nfrom textractor.data.text_linearization_config import TextLinearizationConfig\nlogger = logging.getLogger(__name__)\npresent_path = os.path.abspath(os.path.dirname(__file__))\nT = TypeVar('T')\n\nclass EntityList(list, Generic[T], Linearizable):\n    \"\"\"\n    Creates a list type object, initially empty but extended with the list passed in objs.\n\n    :param objs: Custom list of objects that can be visualized with this class.\n    :type objs: list\n    \"\"\"\n\n    def visualize(self, with_text: bool=True, with_words: bool=True, with_confidence: bool=False, font_size_ratio: float=0.5) -> List:\n        \"\"\"\n        Returns list of PIL Images with bounding boxes drawn around the entities in the list.\n\n        :param with_text: Flag to print the OCR output of Textract on top of the text bounding box.\n        :type with_text: bool\n        :param with_confidence: Flag to print the confidence of prediction on top of the entity bounding box.\n        :type with_confidence: bool\n\n        :return: Returns list of PIL Images with bounding boxes drawn around the entities in the list.\n        :rtype: list\n        \"\"\"\n        if len(self) > 0 and any([ent.__class__.__name__ == 'Document' for ent in self]):\n            return EntityList(self[0].pages).visualize(with_text=with_text, with_words=with_words, with_confidence=with_confidence, font_size_ratio=font_size_ratio)\n        elif len(self) > 0 and any([ent.__class__.__name__ == 'Page' for ent in self]):\n            new_entity_list = []\n            for entity in self:\n                if not with_words and (entity.__class__.__name__ == 'Word' or entity.__class__.__name__ == 'Line'):\n                    continue\n                if entity.__class__.__name__ == 'Page':\n                    if with_words:\n                        new_entity_list.extend(entity.words)\n                        new_entity_list.extend(entity.lines)\n                    new_entity_list.extend(entity.tables)\n                    new_entity_list.extend(entity.key_values)\n                    new_entity_list.extend(entity.checkboxes)\n                    new_entity_list.extend(entity.layouts)\n                    for expense_document in entity.expense_documents:\n                        new_entity_list = self._add_expense_document_to_list(new_entity_list, expense_document)\n                elif entity.__class__.__name__ == 'ExpenseDocument':\n                    self._add_expense_document_to_list(new_entity_list, entity)\n                else:\n                    new_entity_list.append(entity)\n            return EntityList(list(dict.fromkeys(new_entity_list).keys())).visualize(with_text=with_text, with_words=with_words, with_confidence=with_confidence, font_size_ratio=font_size_ratio)\n        elif len(self) > 0 and self[0].bbox.spatial_object.image is None:\n            raise NoImageException('Image was not saved during the Textract API call. Set save_image=True when calling the Textractor methods to use the visualize() method.')\n        visualized_images = {}\n        entities_pagewise = defaultdict(list)\n        for obj in self:\n            entities_pagewise[obj.page].append(obj)\n            if obj.page is None:\n                print(obj.__class__.__name__)\n            try:\n                if with_words:\n                    entities_pagewise[obj.page].extend(obj.words)\n            except AttributeError:\n                pass\n        for page in list(entities_pagewise.keys()):\n            entities_pagewise[page] = list(dict.fromkeys(entities_pagewise[page]).keys())\n        for page in entities_pagewise.keys():\n            visualized_images[page] = _draw_bbox(entities_pagewise[page], with_text, with_confidence, font_size_ratio)\n        images = [image.convert('RGB') for image in visualized_images.values()]\n        images = images if len(images) != 1 else images[0]\n        return images\n\n    def _add_expense_document_to_list(self, entity_list, expense_document):\n        entity_list.append(expense_document)\n        for field in expense_document.summary_fields_list:\n            entity_list.append(field)\n        for line_item_group in expense_document.line_items_groups:\n            entity_list.append(line_item_group)\n            for row in line_item_group.rows:\n                entity_list.append(row)\n                for expense in row.expenses:\n                    if expense.type.text != AnalyzeExpenseLineItemFields.EXPENSE_ROW.name:\n                        entity_list.append(expense)\n        return entity_list\n\n    def pretty_print(self, table_format: TableFormat=TableFormat.GITHUB, with_confidence: bool=False, with_geo: bool=False, with_page_number: bool=False, trim: bool=False) -> str:\n        \"\"\"\n        Returns a formatted string output for each of the entities in the list according to its entity type.\n\n        :param table_format: Choose one of the defined TableFormat types to decorate the table output string. This is a predefined set of choices by the PyPI tabulate package. It is used only if there are KeyValues or Tables in the list of textractor.entities.\n        :type table_format: TableFormat\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n        :type with_geo: bool\n        :param with_page_number: Flag to add the page number to the entity string. default= False.\n        :type with_page_number: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n\n        :return: Returns a formatted string output for each of the entities in the list according to its entity type.\n        :rtype: str\n        \"\"\"\n        result_value = ''\n        result_value += self._get_text_string(with_page_number=with_page_number, with_confidence=with_confidence, trim=trim, textract_type=TextractType.WORDS)\n        result_value += self._get_text_string(with_page_number=with_page_number, with_confidence=with_confidence, trim=trim, textract_type=TextractType.LINES)\n        result_value += self._get_forms_string(table_format=table_format, with_confidence=with_confidence, with_geo=with_geo, trim=trim, textract_type=TextractType.KEY_VALUE_SET)\n        result_value += self._get_forms_string(table_format=table_format, with_confidence=with_confidence, with_geo=with_geo, trim=trim, textract_type=TextractType.SELECTION_ELEMENT)\n        result_value += self._get_tables_string(table_format=table_format, with_confidence=with_confidence, with_geo=with_geo, trim=trim)\n        result_value += self._get_queries_string()\n        result_value += self._get_expense_documents_string()\n        result_value += self._get_id_documents_string()\n        return result_value\n\n    def _get_text_string(self, with_page_number=False, with_confidence=False, trim=False, textract_type=TextractType.WORDS):\n        \"\"\"\n        Returns a formatted string output for the entity type stated in the textract_type param. This function is\n        specific to TextractType.WORDS and TextractType.LINES.\n\n        :param with_page_number: Flag to add the page number to the entity string. default= False.\n        :type with_page_number: bool\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n        :param textract_type: TextractType.WORDS / TextractType.LINES\n        :type textract_type: TextractType\n\n        :return: Returns a formatted string output for the entity type stated in the textract_type param.\n        :rtype: str\n        \"\"\"\n        result_value = ''\n        if textract_type == TextractType.WORDS:\n            objects = sorted([obj for obj in self if obj.__class__.__name__ == 'Word'], key=lambda x: x.page)\n        else:\n            objects = sorted([obj for obj in self if obj.__class__.__name__ == 'Line'], key=lambda x: x.page)\n        current_page = -1\n        for word in objects:\n            if with_page_number and word.page != current_page:\n                result_value += f'--------- page number: {word.page} - page ID: {word.page_id} --------------{os.linesep}'\n                current_page = word.page\n            if trim:\n                result_value += f'{word.text.strip()}'\n            else:\n                result_value += f'{word.text}'\n            if with_confidence:\n                result_value += f', {word.confidence}'\n            result_value += os.linesep\n        return result_value\n\n    def _get_forms_string(self, table_format: TableFormat=TableFormat.GITHUB, with_confidence: bool=False, with_geo: bool=False, trim: bool=False, textract_type=TextractType.KEY_VALUE_SET) -> str:\n        \"\"\"\n        Returns a formatted string output for the entity type stated in the textract_type param. This function is\n        specific to TextractType.KEY_VALUE_SET and TextractType.SELECTION_ELEMENT.\n\n        :param table_format: Choose one of the defined TableFormat types to decorate the table output string.\n                             This is a predefined set of choices by the PyPI tabulate package.\n        :type table_format: TableFormat\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n        :type with_geo: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n        :param textract_type: TextractType.KEY_VALUE_SET / TextractType.SELECTION_ELEMENT\n        :type textract_type: TextractType\n\n        :return: Returns a formatted string output for the entity type stated in the textract_type param.\n        :rtype: str\n        \"\"\"\n        logger.debug(f'table_format: {table_format}')\n        result_value = ''\n        if textract_type == TextractType.KEY_VALUE_SET:\n            key_value_objects = [obj for obj in self if obj.__class__.__name__ == 'KeyValue' and (not obj.contains_checkbox)]\n        else:\n            key_value_objects = [obj for obj in self if obj.__class__.__name__ == 'KeyValue' and obj.contains_checkbox]\n        kv_dict = {obj.page: [] for obj in key_value_objects}\n        for obj in key_value_objects:\n            kv_dict[obj.page].append(obj)\n        if not table_format == TableFormat.CSV:\n            for page in kv_dict.keys():\n                forms_list = _convert_form_to_list(kv_dict[page], with_confidence=with_confidence, with_geo=with_geo, trim=trim, textract_type=textract_type)\n                result_value += tabulate(forms_list, tablefmt=table_format.name.lower()) + os.linesep + os.linesep\n        if table_format == TableFormat.CSV:\n            logger.debug(f'pretty print - csv')\n            csv_output = StringIO()\n            csv_writer = csv.writer(csv_output, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n            for page in kv_dict.keys():\n                forms_list = _convert_form_to_list(kv_dict[page], with_confidence=with_confidence, with_geo=with_geo, trim=trim, textract_type=textract_type)\n                csv_writer.writerows(forms_list)\n            csv_writer.writerow([])\n            result_value = csv_output.getvalue()\n        return result_value\n\n    def _get_tables_string(self, table_format: TableFormat=TableFormat.GITHUB, with_confidence: bool=False, with_geo: bool=False, trim: bool=False) -> str:\n        \"\"\"\n        Returns a formatted string output for the Table entity type.\n\n        :param table_format: Choose one of the defined TableFormat types to decorate the table output string.\n                             This is a predefined set of choices by the PyPI tabulate package.\n        :type table_format: TableFormat\n        :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n        :type with_confidence: bool\n        :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n        :type with_geo: bool\n        :param trim: Flag to trim text in the entity string. default= False.\n        :type trim: bool\n\n        :return: Returns a formatted string output for the Table entity type.\n        :rtype: str\n        \"\"\"\n        logger.debug(f'table_format: {table_format}')\n        tables = {}\n        for obj in self:\n            if obj.__class__.__name__ == 'Table':\n                tables[obj.id] = obj\n            elif obj.__class__.__name__ == 'TableCell':\n                if obj.table_id in tables.keys():\n                    tables[obj.table_id].append(obj)\n                else:\n                    tables[obj.table_id] = [obj]\n        result_value = ''\n        if not table_format == TableFormat.CSV:\n            for table_id in tables.keys():\n                table_type = TextractType.TABLES if tables[table_id].__class__.__name__ == 'Table' else TextractType.TABLE_CELL\n                table_list = _convert_table_to_list(tables[table_id], with_confidence=with_confidence, with_geo=with_geo, trim=trim, textract_type=table_type)\n                result_value += tabulate(table_list, tablefmt=table_format.name.lower()) + os.linesep + os.linesep\n        if table_format == TableFormat.CSV:\n            logger.debug(f'pretty print - csv')\n            for table_id in tables.keys():\n                table_type = TextractType.TABLES if tables[table_id].__class__.__name__ == 'Table' else TextractType.TABLE_CELL\n                csv_output = StringIO()\n                csv_writer = csv.writer(csv_output, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n                table_list = _convert_table_to_list(tables[table_id], with_confidence=with_confidence, with_geo=with_geo, trim=trim, textract_type=table_type)\n                csv_writer.writerows(table_list)\n                csv_writer.writerow([])\n                result_value += csv_output.getvalue()\n        return result_value\n\n    def _get_queries_string(self):\n        result_value = ''\n        queries = [obj for obj in self if obj.__class__.__name__ == 'Query']\n        for query in queries:\n            if query.result is not None:\n                result_value += f'{query.query} => {query.result.answer}{os.linesep}'\n            else:\n                result_value += f'{query.query} => {os.linesep}'\n        return result_value\n\n    def _get_expense_documents_string(self):\n        result_value = ''\n        expense_documents = [obj for obj in self if obj.__class__.__name__ == 'ExpenseDocument']\n        for i, expense_document in enumerate(expense_documents):\n            result_value += f'Expense Document {i + 1}:{os.linesep}'\n            result_value += f'### Summary Fields:{os.linesep}'\n            result_value += f'{expense_document.summary_fields}{os.linesep}'\n            result_value += f'### Line Item Groups: {os.linesep}'\n            for line_item_group in expense_document.line_items_groups:\n                result_value += f'{line_item_group}{os.linesep}'\n        return result_value\n\n    def _get_id_documents_string(self):\n        result_value = ''\n        id_documents = [obj for obj in self if obj.__class__.__name__ == 'IdentityDocument']\n        for id_document in id_documents:\n            result_value += f'{id_document}{os.linesep}'\n        return result_value\n\n    def __add__(self, list2):\n        return EntityList([*self, *list2])\n\n    def get_text_and_words(self, config: TextLinearizationConfig=TextLinearizationConfig()):\n        texts, words = ([], [])\n        separator = config.same_paragraph_separator if all([entity.__class__.__name__ == 'Word' for entity in self]) else config.layout_element_separator\n        for entity in self:\n            entity_text, entity_words = entity.get_text_and_words(config)\n            texts.append(entity_text)\n            words.extend(entity_words)\n        return (separator.join(texts), words)\n\ndef _convert_form_to_list(form_objects, with_confidence: bool=False, with_geo: bool=False, trim: bool=False, textract_type=TextractType.KEY_VALUE_SET) -> List:\n    \"\"\"\n    Converts KeyValue objects (KEY_VALUE_SET in JSON) to row-wise list format to pretty_print using the\n    PyPI tabulate package.\n\n    :param form_objects: KeyValue instances to be formatted into strings\n    :type form_objects: KeyValue\n    :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n    :type with_confidence: bool\n    :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n    :type with_geo: bool\n    :param trim: Flag to trim text in the entity string. default= False.\n    :type trim: bool\n    :param textract_type: TextractType.KEY_VALUE_SET / TextractType.SELECTION_ELEMENT\n    :type textract_type: TextractType\n\n    :return: Returns a list of lists, each inner list containing a key-value pair.\n    :rtype: List[List[str]]\n    \"\"\"\n    rows_list = list()\n    rows_list.append(['Key', 'Value'])\n    for field in form_objects:\n        t_key = ''\n        t_value = ''\n        if field.key:\n            text = ' '.join([word.text for word in field.key])\n            if trim:\n                t_key = text.strip()\n            else:\n                t_key = text\n            if with_geo:\n                t_key += ' {' + field.bbox.__repr__() + '} '\n            if with_confidence:\n                t_key += f' ({field.key.confidence:.1f})'\n        if field.value:\n            text = field.value.words if textract_type == TextractType.SELECTION_ELEMENT else ' '.join([word.text for word in field.value.words])\n            if trim:\n                t_value = text.strip()\n            else:\n                t_value = text\n            if with_geo:\n                t_value += ' {' + field.value.bbox.__repr__() + '} '\n            if with_confidence:\n                t_value += f' ({field.value.confidence:.1f})'\n        rows_list.append([t_key, t_value])\n    return rows_list\n\ndef _convert_table_to_list(table_object, with_confidence: bool=False, with_geo: bool=False, trim: bool=False, textract_type=TextractType.TABLES) -> List:\n    \"\"\"\n    Converts Table objects (TABLE in JSON) to row-wise list format to pretty_print using the\n    PyPI tabulate package.\n\n    :param table_object: Table instance to be formatted into strings\n    :type table_object: Table\n    :param with_confidence: Flag to add the confidence of prediction to the entity string. default= False.\n    :type with_confidence: bool\n    :param with_geo: Flag to add the bounding box information to the entity string. default= False.\n    :type with_geo: bool\n    :param trim: Flag to trim text in the entity string. default= False.\n    :type trim: bool\n    :param textract_type: TextractType.TABLES / TextractType.TABLE_CELL\n    :type textract_type: TextractType\n\n    :return: Returns a list of lists, each inner list containing a row of table data.\n    :rtype: List[List]\n    \"\"\"\n    if textract_type == TextractType.TABLES:\n        rowwise_table = table_object._get_table_cells()\n    else:\n        rowwise_table = {cell.row_index: [] for cell in table_object}\n        for cell in table_object:\n            rowwise_table[cell.row_index].append(cell)\n    table_rows = []\n    for row in rowwise_table.keys():\n        row_data = []\n        for cell in rowwise_table[row]:\n            text = cell.__repr__().split('>')[-1][1:]\n            if trim:\n                t_key = text.strip()\n            else:\n                t_key = text\n            if with_geo:\n                t_key += ' {' + cell.bbox.__repr__() + '} '\n            if with_confidence:\n                t_key += f' ({cell.confidence:.1f})'\n            row_data.append(t_key)\n        table_rows.append(row_data)\n    return table_rows\n\ndef _draw_bbox(entities: List[Any], with_text: bool=False, with_confidence: bool=False, font_size_ratio: float=0.5):\n    \"\"\"\n    Function to draw bounding boxes on all objects in entities present in a particular page.\n\n    :param entities: List of entities to be visualized on top of the document page\n    :type entities: list, required\n    :param with_text: Flag to indicate if text is to be printed on top of the bounding box\n    :type with_text: bool, optional\n    :param with_word_text_only: Flag to print only the word-level OCR output of Textract on top of the text bounding box.\n    :type with_word_text_only: bool\n    :param with_confidence: Flag to print the confidence of prediction on top of the entity bounding box.\n    :type with_confidence: bool\n    :param with_word_confidence_only: Flag to print only the word-level confidence of Textract OCR.\n    :type with_word_confidence_only: bool\n\n    :return: Returns PIL.Image with bounding boxes drawn for the entities passed to the function\n    :rtype: PIL.Image\n    \"\"\"\n    image = entities[0].bbox.spatial_object.image\n    if image is None:\n        for e in entities:\n            if e.bbox.spatial_object.image is not None:\n                image = e.bbox.spatial_object.image\n                break\n        else:\n            raise Exception('Could not find an entity with an associated image!')\n    image = image.convert('RGBA')\n    overlay = Image.new('RGBA', image.size, (255, 255, 255, 0))\n    drw = ImageDraw.Draw(overlay, 'RGBA')\n    text_locations = {}\n    for entity in entities:\n        if entity.bbox is None:\n            continue\n        width, height = image.size\n        if entity.__class__.__name__ == 'Table':\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=2)\n            if entity.title:\n                drw.rectangle((int(entity.title.bbox.x * width), int(entity.title.bbox.y * height), int((entity.title.bbox.x + entity.title.bbox.width) * width), int((entity.title.bbox.y + entity.title.bbox.height) * height)), outline=overlayer_data['color'], fill=ImageColor.getrgb('red') + (120,), width=2)\n            for footer in entity.footers:\n                drw.rectangle((int(footer.bbox.x * width), int(footer.bbox.y * height), int((footer.bbox.x + footer.bbox.width) * width), int((footer.bbox.y + footer.bbox.height) * height)), outline=overlayer_data['color'], fill=ImageColor.getrgb('cyan') + (120,), width=2)\n            processed_cells = set()\n            for cell in entity.table_cells:\n                if cell.id in processed_cells:\n                    continue\n                if cell.siblings:\n                    for c in cell.siblings:\n                        processed_cells.add(c.id)\n                    min_x, min_y, max_x, max_y = list(zip(*[(c.bbox.x, c.bbox.y, c.bbox.x + c.bbox.width, c.bbox.y + c.bbox.height) for c in cell.siblings + [cell]]))\n                    min_x, min_y, max_x, max_y = (min(min_x), min(min_y), max(max_x), max(max_y))\n                else:\n                    processed_cells.add(cell.id)\n                    min_x, min_y, max_x, max_y = (cell.bbox.x, cell.bbox.y, cell.bbox.x + cell.bbox.width, cell.bbox.y + cell.bbox.height)\n                fill_color = None\n                if cell.is_column_header:\n                    fill_color = ImageColor.getrgb('blue') + (120,)\n                if cell.is_title:\n                    fill_color = ImageColor.getrgb('red') + (120,)\n                if cell.is_footer:\n                    fill_color = ImageColor.getrgb('cyan') + (120,)\n                if cell.is_summary:\n                    fill_color = ImageColor.getrgb('yellow') + (120,)\n                if cell.is_section_title:\n                    fill_color = ImageColor.getrgb('green') + (120,)\n                drw.rectangle((int(min_x * width), int(min_y * height), int(max_x * width), int(max_y * height)), outline=overlayer_data['color'], fill=fill_color, width=2)\n                for checkbox in cell.checkboxes:\n                    drw.rectangle((int(checkbox.bbox.x * width), int(checkbox.bbox.y * height), int((checkbox.bbox.x + checkbox.bbox.width) * width), int((checkbox.bbox.y + checkbox.bbox.height) * height)), outline=ImageColor.getrgb('lightgreen') if checkbox.is_selected() else ImageColor.getrgb('indianred'))\n    for entity in entities:\n        if entity.bbox is None:\n            continue\n        if entity.__class__.__name__ == 'Query':\n            overlayer_data = _get_overlayer_data(entity.result, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=2)\n        elif entity.__class__.__name__ == 'TableTitle':\n            overlayer_data = _get_overlayer_data(entity.result, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=2)\n        elif entity.__class__.__name__ == 'TableFooter':\n            overlayer_data = _get_overlayer_data(entity.result, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=2)\n        elif entity.__class__.__name__ == 'ExpenseField':\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(xy=overlayer_data['coords_value'], outline=overlayer_data['color_value'], width=2)\n            if entity.key is not None:\n                b1 = entity.key.bbox\n                b2 = entity.value.bbox\n                drw.rectangle(xy=overlayer_data['coords_key'], outline=overlayer_data['color_key'], width=2)\n                drw.line([((b1.x + b1.width / 2) * width, (b1.y + b1.height / 2) * height), ((b2.x + b2.width / 2) * width, (b2.y + b2.height / 2) * height)], fill=overlayer_data['color_key'], width=2)\n        elif entity.__class__.__name__ == 'ExpenseDocument':\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=2)\n            for coord, text in zip(overlayer_data['coords_list'], overlayer_data['coords_list']):\n                drw.rectangle(xy=coord, outline=overlayer_data['color_expense_group'], width=2)\n        elif entity.__class__.__name__.startswith('Layout'):\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=4)\n        else:\n            overlayer_data = _get_overlayer_data(entity, width, height)\n            drw.rectangle(xy=overlayer_data['coords'], outline=overlayer_data['color'], width=2)\n            if entity.__class__.__name__ == 'KeyValue':\n                drw.rectangle(xy=overlayer_data['value_bbox'], outline=overlayer_data['color_value'], width=2)\n                b1 = overlayer_data['value_bbox']\n                b2 = overlayer_data['coords']\n                drw.line([((b1[0] + b1[2]) / 2, (b1[1] + b1[3]) / 2), ((b2[0] + b2[2]) / 2, (b2[1] + b2[3]) / 2)], fill=overlayer_data['color_value'], width=1)\n    if with_text:\n        for entity in entities:\n            if entity.bbox is None:\n                continue\n            if entity.__class__.__name__ == 'Word':\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n                final_txt = ''\n                bbox_height = overlayer_data['coords'][3] - overlayer_data['coords'][1]\n                text_height = int(bbox_height * font_size_ratio)\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                final_txt += overlayer_data['text']\n                if with_confidence:\n                    final_txt += ' (' + str(overlayer_data['confidence'])[:4] + ')'\n                drw.text((overlayer_data['coords'][0], overlayer_data['coords'][1] - text_height), final_txt, font=fnt, fill=overlayer_data['text_color'])\n            elif entity.__class__.__name__ == 'KeyValue':\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n                final_txt = ''\n                bbox_height = overlayer_data['coords'][3] - overlayer_data['coords'][1]\n                text_height = min(int(0.03 * height), int(bbox_height * font_size_ratio))\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                final_txt += overlayer_data['text']\n                if with_confidence:\n                    final_txt += ' (' + str(overlayer_data['confidence'])[:4] + ')'\n                drw.text((overlayer_data['coords'][0], overlayer_data['coords'][3] + 1), final_txt, font=fnt, fill=overlayer_data['color'])\n                final_txt = overlayer_data['value_text']\n                bbox_height = overlayer_data['value_bbox'][3] - overlayer_data['value_bbox'][1]\n                text_height = min(int(0.01 * height), int(bbox_height * font_size_ratio))\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                if with_confidence:\n                    final_txt += ' (' + str(overlayer_data['value_conf'])[:4] + ')'\n                drw.text((overlayer_data['value_bbox'][0], overlayer_data['value_bbox'][3] + 1), final_txt, font=fnt, fill=overlayer_data['color_value'])\n            elif entity.__class__.__name__ == 'ExpenseField':\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n                final_txt = overlayer_data['text']\n                text_height = int(0.018 * height * font_size_ratio)\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                if entity.key is not None:\n                    x = overlayer_data['coords_key'][0] + 0.3 * (overlayer_data['coords_key'][2] - overlayer_data['coords_key'][0])\n                    y = overlayer_data['coords_key'][1] - text_height - 1\n                else:\n                    x = int(overlayer_data['coords'][0] + 0.3 * (overlayer_data['coords'][2] - overlayer_data['coords'][0]))\n                    y = overlayer_data['coords'][1] - text_height - 1\n                while (x, y) in text_locations and text_locations[x, y] != final_txt:\n                    y = y - text_height - 1\n                text_locations[x, y] = final_txt\n                drw.text((x, y), final_txt, font=fnt, fill=overlayer_data['text_color'])\n            elif entity.__class__.__name__ == 'ExpenseDocument':\n                width, height = image.size\n                text_height = int(0.018 * height * font_size_ratio)\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                overlayer_data = _get_overlayer_data(entity, width, height)\n                for coord, text in zip(overlayer_data['coords_list'], overlayer_data['text_list']):\n                    drw.text((coord[0], coord[3]), text, font=fnt, fill=overlayer_data['color_expense_group'])\n            elif entity.__class__.__name__ == 'Query':\n                if entity.result is None:\n                    continue\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity.result, width, height)\n                final_txt = entity.query + ' ' + overlayer_data['text']\n                bbox_height = overlayer_data['coords'][3] - overlayer_data['coords'][1]\n                text_height = int(bbox_height * font_size_ratio)\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                if with_confidence:\n                    final_txt += ' (' + str(entity.result.confidence)[:4] + ')'\n                drw.text((overlayer_data['coords'][0], overlayer_data['coords'][1] - text_height), final_txt, font=fnt, fill=overlayer_data['text_color'])\n            elif entity.__class__.__name__.startswith('Layout'):\n                width, height = image.size\n                overlayer_data = _get_overlayer_data(entity, width, height)\n                final_txt = ''\n                bbox_height = overlayer_data['coords'][3] - overlayer_data['coords'][1]\n                text_height = min(20, int(bbox_height * font_size_ratio))\n                fnt = ImageFont.truetype(os.path.join(present_path, 'arial.ttf'), text_height)\n                final_txt += overlayer_data['text']\n                if with_confidence:\n                    final_txt += ' (' + str(overlayer_data['confidence'])[:4] + ')'\n                drw.text((overlayer_data['coords'][0], overlayer_data['coords'][1] - text_height), final_txt, font=fnt, fill=overlayer_data['text_color'])\n    del drw\n    image = Image.alpha_composite(image, overlay)\n    return image\n\ndef _get_overlayer_data(entity: Any, width: float, height: float) -> dict:\n    \"\"\"\n    Returns a dictionary with all the necessary details to draw a bounding box for an entity depending on the information\n    present in it. This includes the bounding box coordinates, color of bounding box, confidence of detection and OCR text.\n\n    :param entity: DocumentEntity object for which the data needs to be created\n    :type entity: DocumentEntity\n    :param width: width of the Page object the entity belongs to\n    :type width: float, required\n    :param height: height of the Page object the entity belongs to\n    :type height: float, required\n\n    :return: Dictionary containing all the information to draw the bounding box for a DocumentEntity.\n    :rtype: dict\n    \"\"\"\n    data = {}\n    bbox = entity.bbox\n    x, y, w, h = (bbox.x * width, bbox.y * height, bbox.width * width, bbox.height * height)\n    data['coords'] = [x, y, x + w, y + h]\n    data['confidence'] = entity.confidence if entity.__class__.__name__ not in ['Table', 'ExpenseField', 'ExpenseDocument', 'LineItemRow', 'LineItemGroup'] else ''\n    data['color'] = (0, 0, 0)\n    data['text_color'] = (0, 0, 0)\n    if entity.__class__.__name__ == 'Word':\n        data['text'] = entity.text\n        data['color'] = ImageColor.getrgb('blue')\n    elif entity.__class__.__name__ == 'Line':\n        data['text'] = entity.text\n        data['color'] = ImageColor.getrgb('lightgrey')\n        data['coords'] = [x - 1, y - 1, x + w + 1, y + h + 1]\n    elif entity.__class__.__name__ == 'KeyValue':\n        data['text'] = entity.key.__repr__()\n        data['color'] = ImageColor.getrgb('brown')\n        data['value_text'] = entity.value.__repr__()\n        data['coords'] = [x - 2, y - 2, x + w + 2, y + h + 2]\n        if entity.contains_checkbox and entity.children:\n            value_bbox = entity.children[0].bbox\n            data['value_conf'] = entity.children[0].confidence\n        else:\n            value_bbox = entity.value.bbox\n            data['value_conf'] = entity.value.confidence\n        data['color_value'] = ImageColor.getrgb('orange')\n        x, y, w, h = (value_bbox.x * width - 2, value_bbox.y * height - 2, value_bbox.width * width + 2, value_bbox.height * height + 2)\n        data['value_bbox'] = [x, y, x + w, y + h]\n    elif entity.__class__.__name__ == 'Table':\n        data['color'] = ImageColor.getrgb('green')\n        data['text'] = ''\n    elif entity.__class__.__name__ == 'TableTitle':\n        data['color'] = ImageColor.getrgb('green')\n        data['text'] = ''\n    elif entity.__class__.__name__ == 'TableFooter':\n        data['color'] = ImageColor.getrgb('green')\n        data['text'] = ''\n    elif entity.__class__.__name__ == 'TableCell':\n        data['color'] = ImageColor.getrgb('skyblue')\n        data['text'] = entity.__repr__().split('>')[-1][1:]\n    elif entity.__class__.__name__ == 'QueryResult':\n        data['color'] = ImageColor.getrgb('mediumturquoise')\n        data['text'] = entity.answer\n    elif entity.__class__.__name__ == 'Signature':\n        data['color'] = ImageColor.getrgb('coral')\n    elif entity.__class__.__name__ == 'ExpenseField':\n        data['text'] = entity.type.text\n        data['text_color'] = ImageColor.getrgb('brown')\n        data['coords'] = [x - 5, y - 5, x + w + 5, y + h + 5]\n        if entity.key:\n            data['color_key'] = ImageColor.getrgb('brown')\n            data['coords_key'] = (entity.key.bbox.x * width - 3, entity.key.bbox.y * height - 3, (entity.key.bbox.x + entity.key.bbox.width) * width + 3, (entity.key.bbox.y + entity.key.bbox.height) * height + 3)\n        data['color_value'] = ImageColor.getrgb('orange')\n        data['coords_value'] = (entity.value.bbox.x * width - 3, entity.value.bbox.y * height - 3, (entity.value.bbox.x + entity.value.bbox.width) * width + 3, (entity.value.bbox.y + entity.value.bbox.height) * height + 3)\n    elif entity.__class__.__name__ == 'Expense':\n        data['text'] = entity.text\n        data['coords'] = [x - 3, y - 3, x + w + 3, y + h + 3]\n    elif entity.__class__.__name__ == 'ExpenseDocument':\n        data['color'] = ImageColor.getrgb('beige')\n        data['coords_list'] = []\n        data['text_list'] = []\n        for group in entity.summary_groups:\n            bboxes = entity.summary_groups.get_group_bboxes(group)\n            for bbox in bboxes:\n                data['coords_list'].append((bbox.x * width - 5, bbox.y * height - 5, (bbox.x + bbox.width) * width + 3, (bbox.y + bbox.height) * height + 3))\n                data['text_list'].append(group)\n        data['color_expense_group'] = ImageColor.getrgb('coral')\n    elif entity.__class__.__name__ == 'LineItemGroup':\n        data['color'] = ImageColor.getrgb('lightblue')\n        data['coords'] = [x - 10, y - 10, x + w + 10, y + h + 10]\n    elif entity.__class__.__name__ == 'LineItemRow':\n        data['color'] = ImageColor.getrgb('lightyellow')\n        data['coords'] = [x - 7, y - 7, x + w + 7, y + h + 7]\n    elif entity.__class__.__name__.startswith('Layout'):\n        data['color'] = ImageColor.getrgb('teal')\n        data['text'] = f'{entity.layout_type} - {entity.reading_order}'\n    else:\n        pass\n    return data",
    "textractor/entities/identity_document.py": "\"\"\"The IdentityDocument class is the object representation of an AnalyzeID response. It is similar to a dictionary. Despite its name it does not inherit from Document as the AnalyzeID response does not contains position information.\"\"\"\nimport os\nimport string\nimport logging\nimport xlsxwriter\nfrom typing import List, Dict, Union\nfrom copy import deepcopy\nfrom collections import defaultdict\nfrom textractor.data.constants import AnalyzeIDFields\nfrom textractor.entities.bbox import SpatialObject\nfrom textractor.entities.identity_field import IdentityField\nfrom textractor.exceptions import InputError\n\nclass IdentityDocument(SpatialObject):\n    \"\"\"\n    Represents the description of a single ID document.\n    \"\"\"\n\n    def __init__(self, fields=None):\n        \"\"\"\n        Creates a new document, ideally containing entity objects pertaining to each page.\n\n        :param num_pages: Number of pages in the input Document.\n        \"\"\"\n        super().__init__(width=0, height=0)\n        self._fields = IdentityDocument._fields_to_dict(fields)\n\n    @classmethod\n    def _fields_to_dict(cls, fields: Union[List[IdentityField], Dict[str, dict]]):\n        if not fields:\n            return {}\n        elif isinstance(fields, list) and isinstance(fields[0], IdentityField):\n            return {id_field.key: id_field for id_field in fields}\n        elif isinstance(fields, dict):\n            field_dict = {}\n            for id_field in fields.values():\n                field_dict[id_field['key']] = IdentityField(id_field['key'], id_field['value'], id_field['confidence'])\n            return field_dict\n        else:\n            raise InputError(f'fields needs to be a list of IdentityFields or a list of dictionaries, not {type(fields)}')\n\n    def keys(self) -> List[str]:\n        keys = [key for key in self._fields.keys()]\n        return keys\n\n    def values(self) -> List[str]:\n        values = [field.value for field in self._fields.values()]\n        return values\n\n    def __repr__(self):\n        return os.linesep.join([f'{str(k)}: {str(v)}' for k, v in self.fields.items()])",
    "textractor/entities/identity_field.py": "class IdentityField:\n\n    def __init__(self, key, value, confidence):\n        self._key = key\n        self._value = value\n        self._confidence = confidence\n\n    @property\n    def key(self) -> str:\n        return self._key\n\n    @property\n    def confidence(self) -> float:\n        return self._confidence\n\n    def __repr__(self) -> str:\n        return self.value",
    "textractor/parsers/response_parser.py": "\"\"\"\nConsumes Textract JSON response and converts them to a Document object format.\nThis class contains all the necessary utilities to create entity objects from JSON blocks within the response.\nUse ResponseParser's parse function to handle API response and convert them to Document objects.\n\"\"\"\nimport logging\nimport uuid\nfrom copy import deepcopy\nfrom typing import Any, List, Dict, Tuple\nfrom collections import defaultdict\nfrom textractor.entities.identity_document import IdentityDocument\nfrom textractor.entities.expense_document import ExpenseDocument\nfrom textractor.entities.expense_field import Expense, ExpenseField, ExpenseType, ExpenseGroupProperty, LineItemGroup, LineItemRow\nfrom textractor.entities.page import Page\nfrom textractor.entities.query_result import QueryResult\nfrom textractor.entities.signature import Signature\nfrom textractor.entities.word import Word\nfrom textractor.entities.line import Line\nfrom textractor.entities.value import Value\nfrom textractor.entities.table import Table\nfrom textractor.entities.bbox import BoundingBox\nfrom textractor.entities.document import Document\nfrom textractor.entities.key_value import KeyValue\nfrom textractor.entities.table_cell import TableCell\nfrom textractor.entities.table_title import TableTitle\nfrom textractor.entities.table_footer import TableFooter\nfrom textractor.entities.query import Query\nfrom textractor.entities.selection_element import SelectionElement\nfrom textractor.entities.layout import Layout\nfrom textractor.data.constants import LAYOUT_ENTITY, LAYOUT_FIGURE, TABLE_FOOTER, TABLE_TITLE, COLUMN_HEADER, TABLE_SUMMARY, TABLE_SECTION_TITLE, TABLE_STRUCTURED, TABLE_SEMI_STRUCTURED, SelectionStatus, TextTypes, TableTypes, HANDWRITING, PRINTED, WORD, LINE, KEY_VALUE_SET, CELL, TABLE, SELECTION_ELEMENT, PAGE, MERGED_CELL, QUERY, SIGNATURE, LAYOUT, LAYOUT_LIST, LAYOUT_TABLE, LAYOUT_KEY_VALUE\nfrom textractor.utils.legacy_utils import converter\nTHRESHOLD = 0.95\n\ndef _create_document_object(response: dict) -> Document:\n    \"\"\"\n    Consumes API Response in JSON format and creates a Document object.\n\n    :param response: json response from Textract API\n    :type response: dict\n\n    :return: Returns a Document object populated with metadata on number of pages.\n    :rtype: Document\n    \"\"\"\n    doc = Document(num_pages=response['DocumentMetadata']['Pages'])\n    return doc\n\ndef _filter_block_type(response: dict, entity: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    Consumes entire JSON response, filters and returns list of blocks corresponding to the entity\n    parameter from API response JSON.\n\n    :param response: JSON response from Textract API\n    :type response: dict\n    :param entity: Entity to be extracted from the JSON response\n    :type entity: str\n\n    :return: Returns a list of JSON blocks that match entity parameter.\n    :rtype: List\n    \"\"\"\n    return [block for block in response['Blocks'] if block['BlockType'] == entity]\n\ndef _filter_by_entity(block_json: List[Dict[str, Any]], entity_type: str) -> Dict[str, Any]:\n    \"\"\"\n    Filters and returns dictionary of blocks corresponding to the entity_type from API response JSON.\n\n    :param block_json: list of blocks belonging to a specific entity\n    :type block_json: List[Dict[str, Any]]\n    :param entity_type: EntityType used to select/filter from list of blocks\n    :type entity_type: str\n\n    :return: Dictionary mapping of block ID with JSON block for entity type.\n    :rtype: Dict[str, Any]\n    \"\"\"\n    return {block['Id']: block for block in block_json if 'EntityTypes' in block and len(block['EntityTypes']) and (block['EntityTypes'][0] == entity_type)}\n\ndef _get_relationship_ids(block_json: Dict[str, Any], relationship: str) -> List[str]:\n    \"\"\"\n    Takes the JSON block corresponding to an entity and returns the Ids of the chosen Relationship if the Relationship exists.\n\n    :param block_json: JSON block corresponding to an entity\n    :type block_json: List[Dict[str, Any]]\n    :relationship: CHILD or VALUE as input\n    :type relationship: str\n\n    :return: List of IDs with type Relationship to entity\n    :rtype: List\n    \"\"\"\n    ids = []\n    try:\n        ids = [rel['Ids'] for rel in block_json['Relationships'] if rel['Type'] == relationship][0]\n    except:\n        logging.info(f'{block_json['BlockType']} - {block_json['Id']} does not have ids with {relationship} relationship.')\n    return ids\n\ndef _create_page_objects(response: dict) -> Tuple[Dict[str, Page], List[Dict[str, Any]]]:\n    \"\"\"\n    Consumes API Response in JSON format and returns Page objects for the Document.\n\n    :param response: JSON response from Textract API\n    :type response: dict\n\n    :return: Returns dictionary with page ID - Page object mapping,  list of JSON blocks belonging to PAGE blocks.\n    :rtype: Dict[str, Page], List[str]\n    \"\"\"\n    pages = []\n    page_elements = _filter_block_type(response, entity=PAGE)\n    for page_json in page_elements:\n        asset_id = page_json['Id']\n        width = page_json['Geometry']['BoundingBox']['Width']\n        height = page_json['Geometry']['BoundingBox']['Height']\n        page_num = page_json['Page'] if len(page_elements) > 1 else 1\n        page_children = _get_relationship_ids(page_json, relationship='CHILD')\n        page = Page(id=asset_id, width=width, height=height, page_num=page_num, child_ids=page_children)\n        pages.append(page)\n    pages = {page.id: page for page in pages}\n    return (pages, page_elements)\n\ndef _create_word_objects(word_ids: List[str], id_json_map: Dict[str, str], existing_words: Dict[str, Word], page: Page) -> List[Word]:\n    \"\"\"\n    Creates list of Word objects for all word_ids passed to the function.\n\n    :param word_ids: List of ids corresponding to the words present within Page.\n    :type word_ids: list\n    :param id_json_map: Dictionary containing entity_id: JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of Word objects for the IDs passed in word_ids.\n    :rtype: list\n    \"\"\"\n    words = []\n    text_type = {PRINTED: TextTypes.PRINTED, HANDWRITING: TextTypes.HANDWRITING}\n    for word_id in word_ids:\n        if word_id in existing_words:\n            words.append(existing_words[word_id])\n        else:\n            if not word_id in id_json_map:\n                continue\n            elem = id_json_map[word_id]\n            word = Word(entity_id=elem['Id'], bbox=BoundingBox.from_normalized_dict(elem['Geometry']['BoundingBox'], spatial_object=page), text=elem.get('Text'), text_type=text_type[elem.get('TextType')], confidence=elem['Confidence'])\n            word.raw_object = elem\n            words.append(word)\n            existing_words[word_id] = word\n    for word in words:\n        word.page = page.page_num\n        word.page_id = page.id\n    return words\n\ndef _create_line_objects(line_ids: List[str], id_json_map: Dict[str, str], existing_words: Dict[str, Word], page: Page) -> Tuple[List[Line], List[Word]]:\n    \"\"\"\n    Creates list of Line objects for all lines in the Page derived from the API JSON response.\n\n    :param line_ids: List of IDs corresponding to the lines present within Page.\n    :type line_ids: list\n    :param id_json_map: Dictionary containing entity_id: JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of Line objects for the IDs passed in line_ids and list of Word objects\n             belonging to the corresponding Line objects.\n    :rtype: List[Line], List[Word]\n    \"\"\"\n    page_lines = []\n    for line_id in line_ids:\n        if line_id in page.child_ids:\n            page_lines.append(id_json_map[line_id])\n    lines = []\n    page_words = []\n    for line in page_lines:\n        if _get_relationship_ids(line, relationship='CHILD'):\n            line_words = _create_word_objects(_get_relationship_ids(line, relationship='CHILD'), id_json_map, existing_words, page)\n            page_words.extend(line_words)\n            lines.append(Line(entity_id=line['Id'], bbox=BoundingBox.from_normalized_dict(line['Geometry']['BoundingBox'], spatial_object=page), words=line_words, confidence=line['Confidence']))\n            for word in line_words:\n                word.line = lines[-1]\n                word.line_id = lines[-1].id\n                word.line_bbox = lines[-1].bbox\n            lines[-1]._children = line_words\n            lines[-1].raw_object = line\n    for line in lines:\n        line.page = page.page_num\n        line.page_id = page.id\n    return (lines, page_words)\n\ndef _create_selection_objects(selection_ids: List[str], id_json_map: Dict[str, Any], page: Page) -> Dict[str, SelectionElement]:\n    \"\"\"\n    Creates dictionary mapping of SelectionElement ID with SelectionElement objects for all ids passed in selection_ids.\n\n    :param selection_ids: List of ids corresponding to the SelectionElements.\n    :type selection_ids: list\n    :param id_json_map: Dictionary containing entity_id: JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a dictionary mapping of SelectionElement IDs with SelectionElement objects for the IDs present in\n             selection_ids.\n    :rtype: Dict[str, SelectionElement]\n    \"\"\"\n    checkbox_elements = [id_json_map[selection_id] for selection_id in selection_ids]\n    status = {'SELECTED': SelectionStatus.SELECTED, 'NOT_SELECTED': SelectionStatus.NOT_SELECTED}\n    checkboxes = {}\n    for block in checkbox_elements:\n        checkboxes[block['Id']] = SelectionElement(entity_id=block['Id'], bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page), status=status[block['SelectionStatus']], confidence=block['Confidence'])\n        checkboxes[block['Id']].raw_object = block\n    for c in checkboxes.values():\n        c.page = page.page_num\n        c.page_id = page.id\n    return checkboxes\n\ndef _create_value_objects(value_ids: List[str], id_json_map: Dict[str, Any], entity_id_map: Dict[str, list], existing_words: Dict[str, Word], page: Page) -> Tuple[Dict[str, Value], Dict[str, SelectionElement]]:\n    \"\"\"\n    Creates dictionary containing Value objects for all value_ids in the Page derived from the API response JSON.\n\n    :param value_ids: List of ids corresponding to the Values in the page.\n    :type value_ids: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param entity_id_map: Dictionary containing entity_type:List[entity_id] mapping.\n    :type entity_id_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Dictionary mapping value_ids to Value objects.\n    :rtype: Dict[str, Value]\n    \"\"\"\n    values_info = {value_id: id_json_map.get(value_id, None) for value_id in value_ids}\n    values = {}\n    for block_id, block in values_info.items():\n        if block is None:\n            continue\n        values[block_id] = Value(entity_id=block_id, bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page), confidence=block['Confidence'])\n        values[block_id].raw_object = block\n    checkboxes = _create_selection_objects(entity_id_map[SELECTION_ELEMENT], id_json_map, page)\n    for val_id in values.keys():\n        val_child_ids = _get_relationship_ids(values_info[val_id], relationship='CHILD')\n        for child_id in val_child_ids:\n            if child_id not in id_json_map:\n                continue\n            if id_json_map[child_id]['BlockType'] == WORD:\n                words = _create_word_objects([child_id], id_json_map, existing_words, page)\n                values[val_id].words += words\n                values[val_id].add_children(words)\n            elif id_json_map[child_id]['BlockType'] == SIGNATURE:\n                continue\n            else:\n                checkbox = checkboxes[child_id]\n                checkbox.value_id = val_id\n                values[val_id].add_children([checkbox])\n                values[val_id].contains_checkbox = True\n            values[val_id].page = page.page_num\n            values[val_id].page_id = page.id\n    return (values, checkboxes)\n\ndef _create_query_objects(query_ids: List[str], id_json_map: Dict[str, str], entity_id_map: Dict[str, list], page: Page) -> List[Query]:\n    page_queries = []\n    for query_id in query_ids:\n        if query_id in page.child_ids:\n            page_queries.append(id_json_map[query_id])\n    query_result_id_map = {}\n    for block in page_queries:\n        answer = _get_relationship_ids(block, relationship='ANSWER')\n        query_result_id_map[block['Id']] = answer[0] if answer else None\n    query_results = _create_query_result_objects(list(query_result_id_map.values()), id_json_map, entity_id_map, page)\n    queries = []\n    for query in page_queries:\n        query_result = query_results.get(query_result_id_map[query['Id']])\n        query_obj = Query(query['Id'], query['Query']['Text'], query['Query'].get('Alias'), query_result, query_result.bbox if query_result is not None else None)\n        query_obj.raw_object = query\n        queries.append(query_obj)\n    return queries\n\ndef _create_query_result_objects(query_result_ids: List[str], id_json_map: Dict[str, str], entity_id_map: Dict[str, list], page: Page) -> Dict[str, QueryResult]:\n    page_query_results = []\n    for query_result_id in query_result_ids:\n        if query_result_id in page.child_ids and query_result_id in id_json_map:\n            page_query_results.append(id_json_map[query_result_id])\n    query_results = {}\n    for block in page_query_results:\n        query_results[block['Id']] = QueryResult(entity_id=block['Id'], confidence=block['Confidence'], result_bbox=BoundingBox.from_normalized_dict((block.get('Geometry') or {'BoundingBox': {'Width': 1.0, 'Height': 1.0, 'Left': 0.0, 'Top': 0.0}})['BoundingBox'], spatial_object=page), answer=block['Text'])\n        query_results[block['Id']].raw_object = block\n    for query_result_id, query_result in query_results.items():\n        query_result.page = page.page_num\n        query_result.page_id = page.id\n    return query_results\n\ndef _create_signature_objects(signature_ids: List[str], id_json_map: Dict[str, str], entity_id_map: Dict[str, list], page: Page) -> Dict[str, Signature]:\n    page_signatures = []\n    for signature_id in signature_ids:\n        if signature_id in page.child_ids:\n            page_signatures.append(id_json_map[signature_id])\n    signatures = {}\n    for block in page_signatures:\n        signatures[block['Id']] = Signature(entity_id=block['Id'], confidence=block['Confidence'], bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page))\n        signatures[block['Id']].raw_object = block\n    for signature_id, signature in signatures.items():\n        signature.page = page.page_num\n        signature.page_id = page.id\n    signatures_added = set()\n    for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n        if layout.layout_type == LAYOUT_ENTITY:\n            continue\n        for signature in sorted(signatures.values(), key=lambda x: x.bbox.y):\n            if layout.bbox.get_intersection(signature.bbox).area > THRESHOLD * signature.bbox.area and signature not in signatures_added:\n                layout.children.append(signature)\n                signatures_added.add(signature)\n                del signatures[signature.id]\n    signature_layouts = []\n    for signature in signatures.values():\n        if signature not in signatures_added:\n            signatures_added.add(signature)\n            layout = Layout(entity_id=str(uuid.uuid4()), bbox=signature.bbox, label=LAYOUT_ENTITY, reading_order=-1)\n            layout.children.append(signature)\n            layout.page = page.page_num\n            layout.page_id = page.id\n            signature_layouts.append(layout)\n    layouts_to_remove = []\n    for layout in page.leaf_layouts:\n        layouts_that_intersect = []\n        for signature_layout in signature_layouts:\n            intersection = layout.bbox.get_intersection(signature_layout.bbox).area\n            if intersection:\n                layouts_that_intersect.append(signature_layout)\n        words_in_sub_layouts = set()\n        for i, intersect_layout in enumerate(sorted(layouts_that_intersect, key=lambda l: (l.bbox.y, l.bbox.x))):\n            intersect_layout.reading_order = layout.reading_order + (i + 1) * 0.1 if intersect_layout.reading_order == -1 else min(intersect_layout.reading_order, layout.reading_order + (i + 1) * 0.1)\n            for w in intersect_layout.children[0].words:\n                words_in_sub_layouts.add(w.id)\n        if words_in_sub_layouts:\n            remaining_words = []\n            for w in layout.words:\n                if w.id not in words_in_sub_layouts:\n                    remaining_words.append(w)\n            if remaining_words:\n                layout.bbox = BoundingBox.enclosing_bbox([w.bbox for w in remaining_words])\n                layout._children = list(set([w.line for w in remaining_words]))\n            else:\n                layouts_to_remove.append(layout)\n    for layout in layouts_to_remove:\n        page.leaf_layouts.remove(layout)\n    for layout in signature_layouts:\n        page.leaf_layouts.append(layout)\n    return list(signatures_added)\n\ndef _create_keyvalue_objects(key_value_ids: List[str], id_json_map: Dict[str, Any], id_entity_map: Dict[str, str], entity_id_map: Dict[str, list], existing_words: Dict[str, Word], page: Page) -> Tuple[List[KeyValue], List[Word], Dict[str, SelectionElement]]:\n    \"\"\"\n    Creates list of KeyValue objects for all key-value pairs in the Page derived from the API response JSON.\n\n    :param key_value_ids: List of ids corresponding to the KeyValues in the page.\n    :type key_value_ids: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param entity_id_map: Dictionary containing entity_type:List[entity_id] mapping.\n    :type entity_id_map: dict\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of KeyValue objects and list of Word objects with CHILD relationship\n             to the KeyValue objects.\n    :rtype: List[KeyValue], List[Word]\n    \"\"\"\n    page_kv = []\n    for kv_id in key_value_ids:\n        if kv_id in page.child_ids:\n            page_kv.append(id_json_map[kv_id])\n    keys_info = _filter_by_entity(page_kv, entity_type='KEY')\n    key_value_id_map = {block['Id']: _get_relationship_ids(block, relationship='VALUE')[0] for block in keys_info.values()}\n    values, selection_elements = _create_value_objects(list(key_value_id_map.values()), id_json_map, entity_id_map, existing_words, page)\n    keys = {}\n    for block in keys_info.values():\n        keys[block['Id']] = KeyValue(entity_id=block['Id'], bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page), contains_checkbox=key_value_id_map[block['Id']] in values and values[key_value_id_map[block['Id']]].contains_checkbox, value=values.get(key_value_id_map[block['Id']]), confidence=block['Confidence'])\n        keys[block['Id']].raw_object = block\n    kv_words = []\n    for key_id in keys.keys():\n        if keys[key_id].value is None:\n            continue\n        keys[key_id].value.key_id = key_id\n        if keys[key_id].contains_checkbox:\n            keys[key_id].value.children[0].key_id = key_id\n            keys[key_id].selection_status = [c for c in keys[key_id].value.children if c.__class__.__name__ == 'SelectionElement'][0].status\n        else:\n            kv_words.extend(values[key_value_id_map[key_id]].words)\n        key_child_ids = _get_relationship_ids(keys_info[key_id], relationship='CHILD')\n        key_word_ids = [child_id for child_id in key_child_ids if child_id in id_json_map and id_json_map[child_id]['BlockType'] == WORD]\n        key_words = _create_word_objects(key_word_ids, id_json_map, existing_words, page)\n        key_child_ids = [child_id for child_id in key_child_ids if child_id not in key_word_ids]\n        keys[key_id].key = key_words\n        keys[key_id].add_children(key_words)\n        keys[key_id].add_children([keys[key_id].value])\n        kv_words.extend(key_words)\n    key_values = list(keys.values())\n    for kv in key_values:\n        kv.bbox = BoundingBox.enclosing_bbox([kv.bbox] + ([kv.value.bbox] if kv.value is not None else []))\n        kv.page = page.page_num\n        kv.page_id = page.id\n    return (key_values, kv_words, selection_elements)\n\ndef _create_layout_objects(layout_ids: List[Any], id_json_map: Dict[str, str], id_entity_map: Dict[str, List[str]], line_by_id: Dict[str, Line], page: Page) -> Tuple[List[Layout], List[Layout]]:\n    \"\"\"\n    Creates Layout objects.\n\n    :param page_layouts: Reading-ordered list containing JSON structure of tables within the page.\n    :type page_layouts: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list containing Layout objects.\n    :rtype: List[Layout]\n    \"\"\"\n    page_layouts = []\n    for layout_id in layout_ids:\n        if layout_id in page.child_ids:\n            page_layouts.append(id_json_map[layout_id])\n    leaf_layouts = []\n    container_layouts = []\n    parsed_blocks = set()\n    for i, block in enumerate(page_layouts):\n        if block['Id'] in parsed_blocks:\n            continue\n        if block['BlockType'] in (LAYOUT_LIST,):\n            container_layouts.append(Layout(entity_id=block['Id'], confidence=block['Confidence'], reading_order=i, label=block['BlockType'], bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page)))\n            parsed_blocks.add(block['Id'])\n            for relationship in block.get('Relationships', []) or []:\n                if relationship['Type'] != 'CHILD':\n                    continue\n                for leaf_id in relationship['Ids']:\n                    block = id_json_map[leaf_id]\n                    parsed_blocks.add(leaf_id)\n                    container_layouts[-1].children.append(Layout(entity_id=block['Id'], confidence=block['Confidence'], reading_order=i, label=block['BlockType'], bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page)))\n                    container_layouts[-1].children[-1].raw_object = block\n                    for relationship in block.get('Relationships', []) or []:\n                        if relationship['Type'] != 'CHILD':\n                            continue\n                        container_layouts[-1].children[-1].add_children([line_by_id[line_id] for line_id in relationship['Ids'] if line_id in line_by_id])\n        else:\n            leaf_layouts.append(Layout(entity_id=block['Id'], confidence=block['Confidence'], reading_order=i, label=block['BlockType'], bbox=BoundingBox.from_normalized_dict(block['Geometry']['BoundingBox'], spatial_object=page)))\n            leaf_layouts[-1].raw_object = block\n            for relationship in block.get('Relationships', []) or []:\n                if relationship['Type'] != 'CHILD':\n                    continue\n                leaf_layouts[-1].add_children([line_by_id[line_id] for line_id in relationship['Ids'] if line_id in line_by_id])\n    for layout in leaf_layouts + container_layouts:\n        layout.page = page.page_num\n        layout.page_id = page.id\n    return (container_layouts, leaf_layouts)\n\ndef _create_table_cell_objects(page_tables: List[Any], id_entity_map: Dict[str, List[str]], id_json_map: Dict[str, str], page: Page) -> Tuple[Dict[str, TableCell], Dict[str, Any]]:\n    \"\"\"\n    Creates TableCell objects for all page_tables passed as input present on a single Page of the Document.\n\n    :param page_tables: List containing JSON structure of tables within the page.\n    :type page_tables: list\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a dictionary containing TableCells mapped with their IDs and dictionary containing ID: CELL JSON mapping.\n    :rtype: Dict[str, TableCell], Dict[str, Any]\n    \"\"\"\n    all_table_cells_info = {}\n    for table in page_tables:\n        for cell_id in _get_relationship_ids(table, relationship='CHILD'):\n            if cell_id in id_entity_map and id_entity_map[cell_id] == CELL:\n                all_table_cells_info[cell_id] = id_json_map[cell_id]\n    table_cells = {}\n    for elem_id, elem in all_table_cells_info.items():\n        entity_types = elem.get('EntityTypes', []) or []\n        table_cells[elem_id] = TableCell(entity_id=elem_id, bbox=BoundingBox.from_normalized_dict(elem['Geometry']['BoundingBox'], spatial_object=page), row_index=elem['RowIndex'], col_index=elem['ColumnIndex'], row_span=elem['RowSpan'], col_span=elem['ColumnSpan'], confidence=elem['Confidence'], is_column_header=COLUMN_HEADER in entity_types, is_title=TABLE_TITLE in entity_types, is_footer=TABLE_FOOTER in entity_types, is_summary=TABLE_SUMMARY in entity_types, is_section_title=TABLE_SECTION_TITLE in entity_types)\n        table_cells[elem_id].raw_object = elem\n    for cell in table_cells.values():\n        cell.page = page.page_num\n        cell.page_id = page.id\n    return (table_cells, all_table_cells_info)\n\ndef _create_table_objects(table_ids: List[str], id_json_map: Dict[str, Any], id_entity_map: Dict[str, List[str]], entity_id_map: Dict[str, List[str]], existing_words: Dict[str, Word], key_values: Dict[str, KeyValue], checkboxes: Dict[str, SelectionElement], page: Page) -> Tuple[List[Table], List[Word]]:\n    \"\"\"\n    Creates list of Table objects for all tables in the Page derived from the API response JSON.\n    This includes creating TableCell objects and updating metadata for each cell. The TableCell objects are assigned as children\n    of the table.\n\n    :param table_ids: List of ids corresponding to the Tables in the page.\n    :type table_ids: list\n    :param id_json_map: Dictionary containing entity_id:JSON block mapping.\n    :type id_json_map: dict\n    :param id_entity_map: Dictionary containing entity_id:entity_type mapping.\n    :type id_entity_map: dict\n    :param entity_id_map: Dictionary containing entity_type:List[entity_id] mapping.\n    :type entity_id_map: dict\n    :param page: Instance of parent Page object.\n    :type page: Page\n\n    :return: Returns a list of table objects and list of words present in tables.\n    :rtype: List[Table], List[Word]\n    \"\"\"\n    page_tables = []\n    for table_id in table_ids:\n        if table_id in page.child_ids:\n            page_tables.append(id_json_map[table_id])\n    tables = {}\n    for val in page_tables:\n        tables[val['Id']] = Table(entity_id=val['Id'], bbox=BoundingBox.from_normalized_dict(val['Geometry']['BoundingBox'], spatial_object=page))\n        if TABLE_STRUCTURED in (val.get('EntityTypes', []) or []):\n            tables[val['Id']].table_type = TableTypes.STRUCTURED\n        elif TABLE_SEMI_STRUCTURED in (val.get('EntityTypes', []) or []):\n            tables[val['Id']].table_type = TableTypes.SEMI_STRUCTURED\n        else:\n            tables[val['Id']].table_type = TableTypes.UNKNOWN\n        tables[val['Id']].raw_object = val\n    table_cells, all_table_cells_info = _create_table_cell_objects(page_tables, id_entity_map, id_json_map, page)\n    merged_table_cells = [id_json_map[merge_id] for merge_id in entity_id_map[MERGED_CELL]]\n    merged_child_map = {merged_cell['Id']: _get_relationship_ids(merged_cell, relationship='CHILD') for merged_cell in merged_table_cells}\n    merged_child_ids = sum([ids for ids in merged_child_map.values()], [])\n    table_words = []\n    added_key_values = set()\n    for cell_id, cell in all_table_cells_info.items():\n        children = _get_relationship_ids(cell, relationship='CHILD')\n        cell_word_ids = [child_id for child_id in children if child_id in id_entity_map and id_entity_map[child_id] == WORD]\n        selection_ids = [child_id for child_id in children if child_id in id_entity_map and id_entity_map[child_id] == SELECTION_ELEMENT]\n        cell_words = _create_word_objects(cell_word_ids, id_json_map, existing_words, page)\n        for w in cell_words:\n            w.cell_id = table_cells[cell_id].id\n            w.cell_bbox = table_cells[cell_id].bbox\n            w.row_span = table_cells[cell_id].row_span\n            w.col_span = table_cells[cell_id].col_span\n            w.row_index = table_cells[cell_id].row_index\n            w.col_index = table_cells[cell_id].col_index\n        table_words.extend(cell_words)\n        table_cells[cell_id].add_children(cell_words)\n        for child_id in selection_ids:\n            if checkboxes[child_id].key_id in added_key_values:\n                continue\n            if checkboxes[child_id].key_id is not None:\n                kv = key_values[checkboxes[child_id].key_id]\n                try:\n                    if not kv.words:\n                        added_key_values.add(kv.id)\n                        continue\n                    i = table_cells[cell_id]._children.index(kv.words[0])\n                    table_cells[cell_id]._children.insert(i, kv)\n                    for w in kv.words:\n                        try:\n                            table_cells[cell_id]._children.remove(w)\n                        except ValueError:\n                            continue\n                    added_key_values.add(checkboxes[child_id].key_id)\n                except ValueError:\n                    continue\n            else:\n                table_cells[cell_id]._children.append(checkboxes[child_id])\n        meta_info = cell.get('EntityTypes', []) or []\n        merged_info = [MERGED_CELL] if cell_id in merged_child_ids else []\n        table_cells[cell_id]._update_response_metadata(meta_info + merged_info)\n    for kv_id, kv in key_values.items():\n        if kv_id in added_key_values:\n            continue\n        for table in page_tables:\n            table = tables[table['Id']]\n            if all([w in table_words for w in kv.words]):\n                added_key_values.add(kv_id)\n    for merge_id, child_cells in merged_child_map.items():\n        for child_id in child_cells:\n            if child_id in table_cells.keys():\n                table_cells[child_id].parent_cell_id = merge_id\n                table_cells[child_id].siblings = [table_cells[cid] for cid in child_cells if cid in table_cells]\n    for table in page_tables:\n        children = _get_relationship_ids(table, relationship='TABLE_TITLE')\n        for child_id in children:\n            if child_id not in id_json_map:\n                continue\n            tables[table['Id']].title = TableTitle(entity_id=child_id, bbox=BoundingBox.from_normalized_dict(id_json_map[child_id]['Geometry']['BoundingBox'], spatial_object=page))\n            children = _get_relationship_ids(id_json_map[child_id], relationship='CHILD')\n            tables[table['Id']].title.words = _create_word_objects([child_id for child_id in children if child_id in id_entity_map and id_entity_map[child_id] == WORD], id_json_map, existing_words, page)\n    for table in page_tables:\n        children = _get_relationship_ids(table, relationship='TABLE_FOOTER')\n        for child_id in children:\n            if child_id not in id_json_map:\n                continue\n            tables[table['Id']].footers.append(TableFooter(entity_id=child_id, bbox=BoundingBox.from_normalized_dict(id_json_map[child_id]['Geometry']['BoundingBox'], spatial_object=page)))\n            children = _get_relationship_ids(id_json_map[child_id], relationship='CHILD')\n            tables[table['Id']].footers[-1].words = _create_word_objects([child_id for child_id in children if child_id in id_entity_map and id_entity_map[child_id] == WORD], id_json_map, existing_words, page)\n    for table in page_tables:\n        children = _get_relationship_ids(table, relationship='CHILD')\n        children_cells = []\n        for child_id in children:\n            if child_id not in table_cells:\n                continue\n            children_cells.append(table_cells[child_id])\n            if table_cells[child_id].is_title and tables[table['Id']].title is not None:\n                tables[table['Id']].title.is_floating = False\n        words = set()\n        for child_id in children:\n            if child_id not in table_cells:\n                continue\n            for w in table_cells[child_id].words:\n                words.add(w.id)\n        for footer in tables[table['Id']].footers:\n            for w in footer.words:\n                if w.id in words:\n                    footer.is_floating = False\n                    break\n        tables[table['Id']].add_cells(children_cells)\n        tables[table['Id']].add_children(children_cells)\n    table_added = set()\n    for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n        if layout.layout_type == LAYOUT_TABLE:\n            for table in sorted(list(tables.values()), key=lambda x: x.bbox.y):\n                if layout.bbox.get_intersection(table.bbox).area > THRESHOLD * table.bbox.area and table not in table_added:\n                    for w in table.words:\n                        layout.remove(w)\n                    layout.children.append(table)\n                    layout.bbox = BoundingBox.enclosing_bbox(layout.children)\n                    table_added.add(table)\n    tables_layout = []\n    for table in tables.values():\n        if table not in table_added:\n            table_added.add(table)\n            layout = Layout(entity_id=str(uuid.uuid4()), bbox=table.bbox, label=LAYOUT_TABLE, reading_order=-1)\n            layout.children.append(table)\n            layout.page = page.page_num\n            layout.page_id = page.id\n            tables_layout.append(layout)\n    layouts_to_remove = []\n    for layout in page.leaf_layouts:\n        layouts_that_intersect = []\n        for table_layout in tables_layout:\n            intersection = layout.bbox.get_intersection(table_layout.bbox).area\n            if intersection:\n                layouts_that_intersect.append(table_layout)\n        words_in_sub_layouts = set()\n        for i, intersect_layout in enumerate(sorted(layouts_that_intersect, key=lambda l: (l.bbox.y, l.bbox.x))):\n            intersect_layout.reading_order = layout.reading_order + (i + 1) * 0.1 if intersect_layout.reading_order == -1 else min(intersect_layout.reading_order, layout.reading_order + (i + 1) * 0.1)\n            for w in intersect_layout.children[0].words:\n                words_in_sub_layouts.add(w)\n        if words_in_sub_layouts:\n            for word in words_in_sub_layouts:\n                layout.remove(word)\n            if layout._children:\n                layout.bbox = BoundingBox.enclosing_bbox(layout._children)\n            else:\n                layouts_to_remove.append(layout)\n    for layout in layouts_to_remove:\n        page.leaf_layouts.remove(layout)\n    for layout in tables_layout:\n        page.leaf_layouts.append(layout)\n    tables = list(tables.values())\n    for table in tables:\n        table.page = page.page_num\n        table.page_id = page.id\n    return (tables, table_words, added_key_values)\n\ndef parse_document_api_response(response: dict) -> Document:\n    \"\"\"\n    Parses Textract JSON response and converts them into Document object containing Page objects.\n    A valid Page object must contain at least a unique name and physical dimensions.\n\n    :param response: JSON response data in a format readable by the ResponseParser\n    :type response: dict\n\n    :return: Document object containing the hierarchy of DocumentEntity descendants.\n    :rtype: Document\n    \"\"\"\n    document = _create_document_object(response)\n    id_entity_map, id_json_map, entity_id_map, existing_words = ({}, {}, defaultdict(list), {})\n    for block in response['Blocks']:\n        id_entity_map[block['Id']] = block['BlockType']\n        id_json_map[block['Id']] = block\n        if block['BlockType'].startswith('LAYOUT'):\n            entity_id_map['LAYOUT'].append(block['Id'])\n        else:\n            entity_id_map[block['BlockType']].append(block['Id'])\n    pages, page_elements = _create_page_objects(response)\n    assert len(pages) == response['DocumentMetadata']['Pages']\n    for page_json in page_elements:\n        page = pages[page_json['Id']]\n        lines, line_words = _create_line_objects(entity_id_map[LINE], id_json_map, existing_words, page)\n        page.lines = deepcopy(lines)\n        line_by_id = {l.id: l for l in lines}\n        container_layouts, leaf_layouts = _create_layout_objects(entity_id_map[LAYOUT], id_json_map, entity_id_map, line_by_id, page)\n        if not container_layouts and (not leaf_layouts):\n            for i, line in enumerate(lines):\n                layout = Layout(entity_id=line.id, bbox=line.bbox, label=LAYOUT_ENTITY, reading_order=i)\n                layout._children = [line]\n                layout.page = page.page_num\n                layout.page_id = page.id\n                leaf_layouts.append(layout)\n        page._container_layouts.extend(container_layouts)\n        page._leaf_layouts.extend(leaf_layouts)\n        key_values, kv_words, selection_elements = _create_keyvalue_objects(entity_id_map[KEY_VALUE_SET], id_json_map, id_entity_map, entity_id_map, existing_words, page)\n        kvs = [kv for kv in key_values if not kv.contains_checkbox]\n        checkboxes = [kv for kv in key_values if kv.contains_checkbox]\n        page.key_values = kvs\n        page.checkboxes = checkboxes\n        for checkbox in checkboxes:\n            id_entity_map[checkbox.id] = SELECTION_ELEMENT\n        tables, table_words, kv_added = _create_table_objects(entity_id_map[TABLE], id_json_map, id_entity_map, entity_id_map, existing_words, {kv.id: kv for kv in key_values}, selection_elements, page)\n        page.tables = tables\n        for layout in sorted(page.leaf_layouts, key=lambda x: x.bbox.y):\n            if layout.layout_type == LAYOUT_ENTITY:\n                continue\n            for kv in sorted(key_values, key=lambda x: x.bbox.y):\n                if layout.bbox.get_intersection(kv.bbox).area > THRESHOLD * kv.bbox.area and kv.id not in kv_added:\n                    if any([w.cell_id for w in kv.words]):\n                        kv_added.add(kv.id)\n                        continue\n                    for w in kv.words:\n                        layout.remove(w)\n                    layout.children.append(kv)\n                    kv_added.add(kv.id)\n                    key_values.remove(kv)\n        page.leaf_layouts = [l for l in page.leaf_layouts if l.children or l.layout_type == LAYOUT_FIGURE]\n        kv_layouts = []\n        for kv in key_values:\n            if kv.id not in kv_added:\n                kv_added.add(kv.id)\n                layout = Layout(entity_id=str(uuid.uuid4()), bbox=kv.bbox, label=LAYOUT_KEY_VALUE, reading_order=-1)\n                layout.children.append(kv)\n                layout.page = page.page_num\n                layout.page_id = page.id\n                kv_layouts.append(layout)\n        layouts_to_remove = []\n        kv_layouts_to_ignore = []\n        layouts_that_intersect = defaultdict(list)\n        for layout in page.leaf_layouts:\n            for kv_layout in kv_layouts:\n                intersection = layout.bbox.get_intersection(kv_layout.bbox).area\n                if intersection:\n                    layouts_that_intersect[layout].append(kv_layout)\n        for layout, intersections in layouts_that_intersect.items():\n            words_in_sub_layouts = set()\n            for i, intersect_layout in enumerate(sorted(intersections, key=lambda l: (l.bbox.y, l.bbox.x))):\n                if sum([intersect_layout in intsects for intsects in layouts_that_intersect.values()]) > 1:\n                    kv_layouts_to_ignore.append(intersect_layout)\n                    continue\n                intersect_layout.reading_order = layout.reading_order + (i + 1) * 0.1 if intersect_layout.reading_order == -1 else min(intersect_layout.reading_order, layout.reading_order + (i + 1) * 0.1)\n                for w in intersect_layout.children[0].words:\n                    words_in_sub_layouts.add(w)\n            for word in words_in_sub_layouts:\n                layout.remove(word)\n            if not layout.children and layout.layout_type != LAYOUT_FIGURE:\n                layouts_to_remove.append(layout)\n        for layout in layouts_to_remove:\n            page.leaf_layouts.remove(layout)\n        for layout in kv_layouts:\n            if layout not in kv_layouts_to_ignore:\n                page.leaf_layouts.append(layout)\n        all_words = table_words + kv_words + line_words\n        for word in all_words:\n            if word.line is None:\n                line = Line(str(uuid.uuid4()), word.bbox, words=[word], confidence=word.confidence)\n                line.page = page.page_num\n                line.page_id = page.id\n                word.line = line\n                page.lines.append(line)\n        all_words = {word.id: word for word in all_words}\n        page.words = list(all_words.values())\n        queries = _create_query_objects(entity_id_map[QUERY], id_json_map, entity_id_map, page)\n        page.queries = queries\n        signatures = _create_signature_objects(entity_id_map[SIGNATURE], id_json_map, entity_id_map, page)\n        page.signatures = signatures\n        word_set = set()\n        for layout in sorted(page.layouts, key=lambda l: l.reading_order):\n            layout.visit(word_set)\n            if not layout.children and layout.layout_type != LAYOUT_FIGURE:\n                try:\n                    page.leaf_layouts.remove(layout)\n                except:\n                    page.container_layouts.remove(layout)\n    document.pages = sorted(list(pages.values()), key=lambda x: x.page_num)\n    document.response = response\n    return document\n\ndef parse_analyze_id_response(response):\n    id_documents = []\n    response['Blocks'] = []\n    for doc in response['IdentityDocuments']:\n        fields = {}\n        for field in doc['IdentityDocumentFields']:\n            fields[field['Type']['Text']] = {'key': field['Type']['Text'], 'value': field['ValueDetection']['Text'], 'confidence': field['ValueDetection']['Confidence']}\n        id_documents.append(IdentityDocument(fields))\n        id_documents[-1].raw_object = doc\n        response['Blocks'].extend(doc.get('Blocks', []))\n    document = parse_document_api_response(response)\n    del response['Blocks']\n    document.identity_documents = id_documents\n    document.response = response\n    return document\n\ndef create_expense_from_field(field: Dict, page: Page) -> ExpenseField:\n    if 'Type' in field:\n        type_expense = ExpenseType(field['Type']['Text'], field['Type']['Confidence'], field['Type'])\n    else:\n        type_expense = None\n    if 'ValueDetection' in field:\n        value_expense = Expense(bbox=None if not 'Geometry' in field['ValueDetection'] else BoundingBox.from_normalized_dict(field['ValueDetection']['Geometry']['BoundingBox'], spatial_object=page), text=field['ValueDetection']['Text'], confidence=field['ValueDetection']['Confidence'], page=page.page_num)\n        value_expense.raw_object = field['ValueDetection']\n    else:\n        value_expense = None\n    if 'LabelDetection' in field:\n        label_expense = Expense(bbox=BoundingBox.from_normalized_dict(field['LabelDetection']['Geometry']['BoundingBox'], spatial_object=page), text=field['LabelDetection']['Text'], confidence=field['LabelDetection']['Confidence'], page=page.page_num)\n        label_expense.raw_object = field['LabelDetection']\n    else:\n        label_expense = None\n    group_properties = []\n    if 'GroupProperties' in field:\n        for group_property in field['GroupProperties']:\n            group_properties.append(ExpenseGroupProperty(id=group_property['Id'], types=group_property['Types']))\n    if 'Currency' in field:\n        currency = field['Currency']['Code']\n    else:\n        currency = None\n    return ExpenseField(type_expense, value_expense, group_properties=group_properties, label=label_expense, currency=currency, page=page.page_num)\n\ndef parser_analyze_expense_response(response):\n    response['Blocks'] = [b for doc in response['ExpenseDocuments'] for b in doc.get('Blocks', [])]\n    document = parse_document_api_response(response)\n    for doc in response['ExpenseDocuments']:\n        page_number = None\n        if len(doc['SummaryFields']):\n            page_number = doc['SummaryFields'][0].get('PageNumber')\n        elif len(doc['LineItemGroups']):\n            first_field = doc['LineItemGroups'][0]['LineItems'][0]['LineItemExpenseFields'][0]\n            page_number = first_field.get('PageNumber')\n        if page_number is None:\n            logging.warning('Skipping parsing ExpenseDocument %s as its page number could not be determined' % (doc['ExpenseIndex'],))\n            continue\n        page = document.pages[page_number - 1]\n        summary_fields = []\n        for summary_field in doc['SummaryFields']:\n            summary_fields.append(create_expense_from_field(summary_field, page))\n            summary_fields[-1].raw_object = summary_field\n        line_items_groups = []\n        for line_items_group in doc['LineItemGroups']:\n            line_item_rows = []\n            for i, line_item in enumerate(line_items_group['LineItems']):\n                row_expenses = []\n                for line_item_field in line_item['LineItemExpenseFields']:\n                    row_expenses.append(create_expense_from_field(line_item_field, page))\n                    row_expenses[-1].raw_object = line_item_field\n                line_item_rows.append(LineItemRow(index=i, line_item_expense_fields=row_expenses, page=page.page_num))\n            if not line_item_rows:\n                continue\n            line_items_groups.append(LineItemGroup(index=line_items_group['LineItemGroupIndex'], line_item_rows=line_item_rows, page=page.page_num))\n        bbox = BoundingBox.enclosing_bbox(bboxes=[s.bbox for s in summary_fields] + [g.bbox for g in line_items_groups], spatial_object=page)\n        expense_document = ExpenseDocument(summary_fields=summary_fields, line_items_groups=line_items_groups, bounding_box=bbox, page=page.page_num)\n        expense_document.raw_object = doc\n        document.pages[page_number - 1].expense_documents.append(expense_document)\n    document.response = response\n    return document"
  }
}