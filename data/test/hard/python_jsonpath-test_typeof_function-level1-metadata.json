{
  "dir_path": "/app/python_jsonpath",
  "package_name": "python_jsonpath",
  "sample_name": "python_jsonpath-test_typeof_function",
  "src_dir": "jsonpath/",
  "test_dir": "tests/",
  "test_file": "tests/test_typeof_function.py",
  "test_code": "import asyncio\nimport dataclasses\nimport operator\nfrom typing import Any\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Sequence\nfrom typing import Union\n\nimport pytest\n\nfrom jsonpath import JSONPathEnvironment\n\n\n@dataclasses.dataclass\nclass Case:\n    description: str\n    path: str\n    data: Union[Sequence[Any], Mapping[str, Any]]\n    want: Union[Sequence[Any], Mapping[str, Any]]\n\n\nSOME_OBJECT = object()\n\nTEST_CASES = [\n    Case(\n        description=\"type of a string\",\n        path=\"$.some[?type(@.thing) == 'string']\",\n        data={\"some\": [{\"thing\": \"foo\"}]},\n        want=[{\"thing\": \"foo\"}],\n    ),\n    Case(\n        description=\"not a string\",\n        path=\"$.some[?type(@.thing) == 'string']\",\n        data={\"some\": [{\"thing\": 1}]},\n        want=[],\n    ),\n    Case(\n        description=\"type of undefined\",\n        path=\"$.some[?type(@.other) == 'undefined']\",  # things without `other`\n        data={\"some\": [{\"thing\": \"foo\"}]},\n        want=[{\"thing\": \"foo\"}],\n    ),\n    Case(\n        description=\"type of None\",\n        path=\"$.some[?type(@.thing) == 'null']\",\n        data={\"some\": [{\"thing\": None}]},\n        want=[{\"thing\": None}],\n    ),\n    Case(\n        description=\"type of array-like\",\n        path=\"$.some[?type(@.thing) == 'array']\",\n        data={\"some\": [{\"thing\": [1, 2, 3]}]},\n        want=[{\"thing\": [1, 2, 3]}],\n    ),\n    Case(\n        description=\"type of mapping\",\n        path=\"$.some[?type(@.thing) == 'object']\",\n        data={\"some\": [{\"thing\": {\"other\": 1}}]},\n        want=[{\"thing\": {\"other\": 1}}],\n    ),\n    Case(\n        description=\"type of bool\",\n        path=\"$.some[?type(@.thing) == 'boolean']\",\n        data={\"some\": [{\"thing\": True}]},\n        want=[{\"thing\": True}],\n    ),\n    Case(\n        description=\"type of int\",\n        path=\"$.some[?type(@.thing) == 'number']\",\n        data={\"some\": [{\"thing\": 1}]},\n        want=[{\"thing\": 1}],\n    ),\n    Case(\n        description=\"type of float\",\n        path=\"$.some[?type(@.thing) == 'number']\",\n        data={\"some\": [{\"thing\": 1.1}]},\n        want=[{\"thing\": 1.1}],\n    ),\n    Case(\n        description=\"none of the above\",\n        path=\"$.some[?type(@.thing) == 'object']\",\n        data={\"some\": [{\"thing\": SOME_OBJECT}]},\n        want=[{\"thing\": SOME_OBJECT}],\n    ),\n]\n\n\n@pytest.fixture()\ndef env() -> JSONPathEnvironment:\n    return JSONPathEnvironment()\n\n\n@pytest.mark.parametrize(\"case\", TEST_CASES, ids=operator.attrgetter(\"description\"))\ndef test_typeof_function(env: JSONPathEnvironment, case: Case) -> None:\n    path = env.compile(case.path)\n    assert path.findall(case.data) == case.want\n\n\n@pytest.mark.parametrize(\"case\", TEST_CASES, ids=operator.attrgetter(\"description\"))\ndef test_typeof_function_async(env: JSONPathEnvironment, case: Case) -> None:\n    path = env.compile(case.path)\n\n    async def coro() -> List[object]:\n        return await path.findall_async(case.data)\n\n    assert asyncio.run(coro()) == case.want\n\n\n# TODO: test single_number_type is False\n",
  "GT_file_code": {
    "jsonpath/env.py": "\"\"\"Core JSONPath configuration object.\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom decimal import Decimal\nfrom operator import getitem\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import AsyncIterable\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Type\nfrom typing import Union\n\nfrom . import function_extensions\nfrom .exceptions import JSONPathNameError\nfrom .exceptions import JSONPathSyntaxError\nfrom .exceptions import JSONPathTypeError\nfrom .filter import UNDEFINED\nfrom .filter import VALUE_TYPE_EXPRESSIONS\nfrom .filter import FilterExpression\nfrom .filter import FunctionExtension\nfrom .filter import InfixExpression\nfrom .filter import Path\nfrom .fluent_api import Query\nfrom .function_extensions import ExpressionType\nfrom .function_extensions import FilterFunction\nfrom .function_extensions import validate\nfrom .lex import Lexer\nfrom .match import JSONPathMatch\nfrom .match import NodeList\nfrom .parse import Parser\nfrom .path import CompoundJSONPath\nfrom .path import JSONPath\nfrom .stream import TokenStream\nfrom .token import TOKEN_EOF\nfrom .token import TOKEN_FAKE_ROOT\nfrom .token import TOKEN_INTERSECTION\nfrom .token import TOKEN_UNION\nfrom .token import Token\n\nif TYPE_CHECKING:\n    from io import IOBase\n\n    from .match import FilterContextVars\n\n\nclass JSONPathEnvironment:\n    \"\"\"JSONPath configuration.\n\n    This class contains settings for path tokenization, parsing and resolution\n    behavior, plus convenience methods for matching an unparsed path to some\n    data.\n\n    Most applications will want to create a single `JSONPathEnvironment`, or\n    use `jsonpath.compile()`, `jsonpath.findall()`, etc. from the package-level\n    default environment.\n\n    ## Environment customization\n\n    Environment customization is achieved by subclassing `JSONPathEnvironment`\n    and overriding class attributes and/or methods. Some of these\n    customizations include:\n\n    - Changing the root (`$`), self (`@`) or filter context (`_`) token with\n      class attributes `root_token`, `self_token` and `filter_context_token`.\n    - Registering a custom lexer or parser with the class attributes\n      `lexer_class` or `parser_class`. `lexer_class` must be a subclass of\n      [`Lexer`]() and `parser_class` must be a subclass of [`Parser`]().\n    - Setup built-in function extensions by overriding\n      `setup_function_extensions()`\n    - Hook in to mapping and sequence item getting by overriding `getitem()`.\n    - Change filter comparison operator behavior by overriding `compare()`.\n\n    Arguments:\n        filter_caching (bool): If `True`, filter expressions will be cached\n            where possible.\n        unicode_escape: If `True`, decode UTF-16 escape sequences found in\n            JSONPath string literals.\n        well_typed: Control well-typedness checks on filter function expressions.\n            If `True` (the default), JSONPath expressions are checked for\n            well-typedness as compile time.\n\n            **New in version 0.10.0**\n\n    ## Class attributes\n\n    Attributes:\n        fake_root_token (str): The pattern used to select a \"fake\" root node, one level\n            above the real root node.\n        filter_context_token (str): The pattern used to select extra filter context\n            data. Defaults to `\"_\"`.\n        intersection_token (str): The pattern used as the intersection operator.\n            Defaults to `\"&\"`.\n        key_token (str): The pattern used to identify the current key or index when\n            filtering a, mapping or sequence. Defaults to `\"#\"`.\n        keys_selector_token (str): The pattern used as the \"keys\" selector. Defaults to\n            `\"~\"`.\n        lexer_class: The lexer to use when tokenizing path strings.\n        max_int_index (int): The maximum integer allowed when selecting array items by\n            index. Defaults to `(2**53) - 1`.\n        min_int_index (int): The minimum integer allowed when selecting array items by\n            index. Defaults to `-(2**53) + 1`.\n        parser_class: The parser to use when parsing tokens from the lexer.\n        root_token (str): The pattern used to select the root node in a JSON document.\n            Defaults to `\"$\"`.\n        self_token (str): The pattern used to select the current node in a JSON\n            document. Defaults to `\"@\"`\n        union_token (str): The pattern used as the union operator. Defaults to `\"|\"`.\n    \"\"\"\n\n    # These should be unescaped strings. `re.escape` will be called\n    # on them automatically when compiling lexer rules.\n    fake_root_token = \"^\"\n    filter_context_token = \"_\"\n    intersection_token = \"&\"\n    key_token = \"#\"\n    keys_selector_token = \"~\"\n    root_token = \"$\"\n    self_token = \"@\"\n    union_token = \"|\"\n\n    max_int_index = (2**53) - 1\n    min_int_index = -(2**53) + 1\n\n    # Override these to customize path tokenization and parsing.\n    lexer_class: Type[Lexer] = Lexer\n    parser_class: Type[Parser] = Parser\n    match_class: Type[JSONPathMatch] = JSONPathMatch\n\n    def __init__(\n        self,\n        *,\n        filter_caching: bool = True,\n        unicode_escape: bool = True,\n        well_typed: bool = True,\n    ) -> None:\n        self.filter_caching: bool = filter_caching\n        \"\"\"Enable or disable filter expression caching.\"\"\"\n\n        self.unicode_escape: bool = unicode_escape\n        \"\"\"Enable or disable decoding of UTF-16 escape sequences found in\n        JSONPath string literals.\"\"\"\n\n        self.well_typed: bool = well_typed\n        \"\"\"Control well-typedness checks on filter function expressions.\"\"\"\n\n        self.lexer: Lexer = self.lexer_class(env=self)\n        \"\"\"The lexer bound to this environment.\"\"\"\n\n        self.parser: Parser = self.parser_class(env=self)\n        \"\"\"The parser bound to this environment.\"\"\"\n\n        self.function_extensions: Dict[str, Callable[..., Any]] = {}\n        \"\"\"A list of function extensions available to filters.\"\"\"\n\n        self.setup_function_extensions()\n\n    def compile(self, path: str) -> Union[JSONPath, CompoundJSONPath]:  # noqa: A003\n        \"\"\"Prepare a path string ready for repeated matching against different data.\n\n        Arguments:\n            path: A JSONPath as a string.\n\n        Returns:\n            A `JSONPath` or `CompoundJSONPath`, ready to match against some data.\n                Expect a `CompoundJSONPath` if the path string uses the _union_ or\n                _intersection_ operators.\n\n        Raises:\n            JSONPathSyntaxError: If _path_ is invalid.\n            JSONPathTypeError: If filter functions are given arguments of an\n                unacceptable type.\n        \"\"\"\n        tokens = self.lexer.tokenize(path)\n        stream = TokenStream(tokens)\n        fake_root = stream.current.kind == TOKEN_FAKE_ROOT\n        _path: Union[JSONPath, CompoundJSONPath] = JSONPath(\n            env=self, selectors=self.parser.parse(stream), fake_root=fake_root\n        )\n\n        if stream.current.kind != TOKEN_EOF:\n            _path = CompoundJSONPath(env=self, path=_path)\n            while stream.current.kind != TOKEN_EOF:\n                if stream.peek.kind == TOKEN_EOF:\n                    # trailing union or intersection\n                    raise JSONPathSyntaxError(\n                        f\"expected a path after {stream.current.value!r}\",\n                        token=stream.current,\n                    )\n\n                if stream.current.kind == TOKEN_UNION:\n                    stream.next_token()\n                    fake_root = stream.current.kind == TOKEN_FAKE_ROOT\n                    _path = _path.union(\n                        JSONPath(\n                            env=self,\n                            selectors=self.parser.parse(stream),\n                            fake_root=fake_root,\n                        )\n                    )\n                elif stream.current.kind == TOKEN_INTERSECTION:\n                    stream.next_token()\n                    fake_root = stream.current.kind == TOKEN_FAKE_ROOT\n                    _path = _path.intersection(\n                        JSONPath(\n                            env=self,\n                            selectors=self.parser.parse(stream),\n                            fake_root=fake_root,\n                        )\n                    )\n                else:  # pragma: no cover\n                    # Parser.parse catches this too\n                    raise JSONPathSyntaxError(  # noqa: TRY003\n                        f\"unexpected token {stream.current.value!r}\",\n                        token=stream.current,\n                    )\n\n        return _path\n\n    def findall(\n        self,\n        path: str,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> List[object]:\n        \"\"\"Find all objects in _data_ matching the JSONPath _path_.\n\n        If _data_ is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A list of matched objects. If there are no matches, the list will\n                be empty.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return self.compile(path).findall(data, filter_context=filter_context)\n\n    def finditer(\n        self,\n        path: str,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match of _path_ in _data_.\n\n        If _data_ is a string or a file-like objects, it will be loaded using\n        `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return self.compile(path).finditer(data, filter_context=filter_context)\n\n    def match(\n        self,\n        path: str,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Union[JSONPathMatch, None]:\n        \"\"\"Return a `JSONPathMatch` instance for the first object found in _data_.\n\n        `None` is returned if there are no matches.\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A `JSONPathMatch` object for the first match, or `None` if there were\n                no matches.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return self.compile(path).match(data, filter_context=filter_context)\n\n    def query(\n        self,\n        path: str,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Query:\n        \"\"\"Return a `Query` iterator over matches found by applying _path_ to _data_.\n\n        `Query` objects are iterable.\n\n        ```\n        for match in jsonpath.query(\"$.foo..bar\", data):\n            ...\n        ```\n\n        You can skip and limit results with `Query.skip()` and `Query.limit()`.\n\n        ```\n        matches = (\n            jsonpath.query(\"$.foo..bar\", data)\n            .skip(5)\n            .limit(10)\n        )\n\n        for match in matches\n            ...\n        ```\n\n        `Query.tail()` will get the last _n_ results.\n\n        ```\n        for match in jsonpath.query(\"$.foo..bar\", data).tail(5):\n            ...\n        ```\n\n        Get values for each match using `Query.values()`.\n\n        ```\n        for obj in jsonpath.query(\"$.foo..bar\", data).limit(5).values():\n            ...\n        ```\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A query iterator.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return Query(self.finditer(path, data, filter_context=filter_context), self)\n\n    async def findall_async(\n        self,\n        path: str,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> List[object]:\n        \"\"\"An async version of `findall()`.\"\"\"\n        return await self.compile(path).findall_async(\n            data, filter_context=filter_context\n        )\n\n    async def finditer_async(\n        self,\n        path: str,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `finditer()`.\"\"\"\n        return await self.compile(path).finditer_async(\n            data, filter_context=filter_context\n        )\n\n    def setup_function_extensions(self) -> None:\n        \"\"\"Initialize function extensions.\"\"\"\n        self.function_extensions[\"length\"] = function_extensions.Length()\n        self.function_extensions[\"count\"] = function_extensions.Count()\n        self.function_extensions[\"match\"] = function_extensions.Match()\n        self.function_extensions[\"search\"] = function_extensions.Search()\n        self.function_extensions[\"value\"] = function_extensions.Value()\n        self.function_extensions[\"isinstance\"] = function_extensions.IsInstance()\n        self.function_extensions[\"is\"] = self.function_extensions[\"isinstance\"]\n        self.function_extensions[\"typeof\"] = function_extensions.TypeOf()\n        self.function_extensions[\"type\"] = self.function_extensions[\"typeof\"]\n\n    def validate_function_extension_signature(\n        self, token: Token, args: List[Any]\n    ) -> List[Any]:\n        \"\"\"Compile-time validation of function extension arguments.\n\n        RFC 9535 requires us to reject paths that use filter functions with\n        too many or too few arguments.\n        \"\"\"\n        try:\n            func = self.function_extensions[token.value]\n        except KeyError as err:\n            raise JSONPathNameError(\n                f\"function {token.value!r} is not defined\", token=token\n            ) from err\n\n        # Type-aware function extensions use the spec's type system.\n        if self.well_typed and isinstance(func, FilterFunction):\n            self.check_well_typedness(token, func, args)\n            return args\n\n        # A callable with a `validate` method?\n        if hasattr(func, \"validate\"):\n            args = func.validate(self, args, token)\n            assert isinstance(args, list)\n            return args\n\n        # Generic validation using introspection.\n        return validate(self, func, args, token)\n\n    def check_well_typedness(\n        self,\n        token: Token,\n        func: FilterFunction,\n        args: List[FilterExpression],\n    ) -> None:\n        \"\"\"Check the well-typedness of a function's arguments at compile-time.\"\"\"\n        # Correct number of arguments?\n        if len(args) != len(func.arg_types):\n            raise JSONPathTypeError(\n                f\"{token.value!r}() requires {len(func.arg_types)} arguments\",\n                token=token,\n            )\n\n        # Argument types\n        for idx, typ in enumerate(func.arg_types):\n            arg = args[idx]\n            if typ == ExpressionType.VALUE:\n                if not (\n                    isinstance(arg, VALUE_TYPE_EXPRESSIONS)\n                    or (isinstance(arg, Path) and arg.path.singular_query())\n                    or (self._function_return_type(arg) == ExpressionType.VALUE)\n                ):\n                    raise JSONPathTypeError(\n                        f\"{token.value}() argument {idx} must be of ValueType\",\n                        token=token,\n                    )\n            elif typ == ExpressionType.LOGICAL:\n                if not isinstance(arg, (Path, InfixExpression)):\n                    raise JSONPathTypeError(\n                        f\"{token.value}() argument {idx} must be of LogicalType\",\n                        token=token,\n                    )\n            elif typ == ExpressionType.NODES and not (\n                isinstance(arg, Path)\n                or self._function_return_type(arg) == ExpressionType.NODES\n            ):\n                raise JSONPathTypeError(\n                    f\"{token.value}() argument {idx} must be of NodesType\",\n                    token=token,\n                )\n\n    def _function_return_type(self, expr: FilterExpression) -> Optional[ExpressionType]:\n        \"\"\"Return the type returned from a filter function.\n\n        If _expr_ is not a `FunctionExtension` or the registered function definition is\n        not type-aware, return `None`.\n        \"\"\"\n        if not isinstance(expr, FunctionExtension):\n            return None\n        func = self.function_extensions.get(expr.name)\n        if isinstance(func, FilterFunction):\n            return func.return_type\n        return None\n\n    def getitem(self, obj: Any, key: Any) -> Any:\n        \"\"\"Sequence and mapping item getter used throughout JSONPath resolution.\n\n        The default implementation of `getitem` simply calls `operators.getitem()`\n        from Python's standard library. Same as `obj[key]`.\n\n        Arguments:\n            obj: A mapping or sequence that might contain _key_.\n            key: A mapping key, sequence index or sequence slice.\n        \"\"\"\n        return getitem(obj, key)\n\n    async def getitem_async(self, obj: Any, key: object) -> Any:\n        \"\"\"An async sequence and mapping item getter.\"\"\"\n        if hasattr(obj, \"__getitem_async__\"):\n            return await obj.__getitem_async__(key)\n        return getitem(obj, key)\n\n    def is_truthy(self, obj: object) -> bool:\n        \"\"\"Test for truthiness when evaluating JSONPath filter expressions.\n\n        In some cases, RFC 9535 requires us to test for existence rather than\n        truthiness. So the default implementation returns `True` for empty\n        collections and `None`. The special `UNDEFINED` object means that\n        _obj_ was missing, as opposed to an explicit `None`.\n\n        Arguments:\n            obj: Any object.\n\n        Returns:\n            `True` if the object exists and is not `False` or `0`.\n        \"\"\"\n        if isinstance(obj, NodeList) and len(obj) == 0:\n            return False\n        if obj is UNDEFINED:\n            return False\n        if obj is None:\n            return True\n        return bool(obj)\n\n    def compare(  # noqa: PLR0911\n        self, left: object, operator: str, right: object\n    ) -> bool:\n        \"\"\"Object comparison within JSONPath filters.\n\n        Override this to customize filter expression comparison operator\n        behavior.\n\n        Args:\n            left: The left hand side of the comparison expression.\n            operator: The comparison expression's operator.\n            right: The right hand side of the comparison expression.\n\n        Returns:\n            `True` if the comparison between _left_ and _right_, with the\n            given _operator_, is truthy. `False` otherwise.\n        \"\"\"\n        if operator == \"&&\":\n            return self.is_truthy(left) and self.is_truthy(right)\n        if operator == \"||\":\n            return self.is_truthy(left) or self.is_truthy(right)\n        if operator == \"==\":\n            return self._eq(left, right)\n        if operator == \"!=\":\n            return not self._eq(left, right)\n        if operator == \"<\":\n            return self._lt(left, right)\n        if operator == \">\":\n            return self._lt(right, left)\n        if operator == \">=\":\n            return self._lt(right, left) or self._eq(left, right)\n        if operator == \"<=\":\n            return self._lt(left, right) or self._eq(left, right)\n        if operator == \"in\" and isinstance(right, (Mapping, Sequence)):\n            return left in right\n        if operator == \"contains\" and isinstance(left, (Mapping, Sequence)):\n            return right in left\n        if operator == \"=~\" and isinstance(right, re.Pattern) and isinstance(left, str):\n            return bool(right.fullmatch(left))\n        return False\n\n    def _eq(self, left: object, right: object) -> bool:  # noqa: PLR0911\n        if isinstance(right, NodeList):\n            left, right = right, left\n\n        if isinstance(left, NodeList):\n            if isinstance(right, NodeList):\n                return left == right\n            if left.empty():\n                return right is UNDEFINED\n            if len(left) == 1:\n                return left[0] == right\n            return False\n\n        if left is UNDEFINED and right is UNDEFINED:\n            return True\n\n        # Remember 1 == True and 0 == False in Python\n        if isinstance(right, bool):\n            left, right = right, left\n\n        if isinstance(left, bool):\n            return isinstance(right, bool) and left == right\n\n        return left == right\n\n    def _lt(self, left: object, right: object) -> bool:\n        if isinstance(left, str) and isinstance(right, str):\n            return left < right\n\n        if isinstance(left, (int, float, Decimal)) and isinstance(\n            right, (int, float, Decimal)\n        ):\n            return left < right\n\n        return False\n",
    "jsonpath/filter.py": "\"\"\"Filter expression nodes.\"\"\"\n\nfrom __future__ import annotations\n\nimport copy\nimport json\nimport re\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Generic\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Pattern\nfrom typing import Sequence\nfrom typing import TypeVar\n\nfrom jsonpath.function_extensions.filter_function import ExpressionType\n\nfrom .exceptions import JSONPathTypeError\nfrom .function_extensions import FilterFunction\nfrom .match import NodeList\nfrom .selectors import Filter as FilterSelector\nfrom .selectors import ListSelector\n\nif TYPE_CHECKING:\n    from .path import JSONPath\n    from .selectors import FilterContext\n\n# ruff: noqa: D102\n\n\nclass FilterExpression(ABC):\n    \"\"\"Base class for all filter expression nodes.\"\"\"\n\n    __slots__ = (\"volatile\",)\n\n    FORCE_CACHE = False\n\n    def __init__(self) -> None:\n        self.volatile: bool = any(child.volatile for child in self.children())\n\n    @abstractmethod\n    def evaluate(self, context: FilterContext) -> object:\n        \"\"\"Resolve the filter expression in the given _context_.\n\n        Arguments:\n            context: Contextual information the expression might choose\n                use during evaluation.\n\n        Returns:\n            The result of evaluating the expression.\n        \"\"\"\n\n    @abstractmethod\n    async def evaluate_async(self, context: FilterContext) -> object:\n        \"\"\"An async version of `evaluate`.\"\"\"\n\n    @abstractmethod\n    def children(self) -> List[FilterExpression]:\n        \"\"\"Return a list of direct child expressions.\"\"\"\n\n    @abstractmethod\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        \"\"\"Update this expression's child expressions.\n\n        _children_ is assumed to have the same number of items as is returned\n        by _self.children_, and in the same order.\n        \"\"\"\n\n\nclass Nil(FilterExpression):\n    \"\"\"The constant `nil`.\n\n    Also aliased as `null` and `None`, sometimes.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __eq__(self, other: object) -> bool:\n        return other is None or isinstance(other, Nil)\n\n    def __repr__(self) -> str:  # pragma: no cover\n        return \"NIL()\"\n\n    def __str__(self) -> str:  # pragma: no cover\n        return \"nil\"\n\n    def evaluate(self, _: FilterContext) -> None:\n        return None\n\n    async def evaluate_async(self, _: FilterContext) -> None:\n        return None\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        return\n\n\nNIL = Nil()\n\n\nclass _Undefined:\n    __slots__ = ()\n\n    def __eq__(self, other: object) -> bool:\n        return (\n            other is UNDEFINED_LITERAL\n            or other is UNDEFINED\n            or (isinstance(other, NodeList) and other.empty())\n        )\n\n    def __str__(self) -> str:\n        return \"<UNDEFINED>\"\n\n    def __repr__(self) -> str:\n        return \"<UNDEFINED>\"\n\n\n# This is equivalent to the spec's special `Nothing` value.\nUNDEFINED = _Undefined()\n\n\nclass Undefined(FilterExpression):\n    \"\"\"The constant `undefined`.\"\"\"\n\n    __slots__ = ()\n\n    def __eq__(self, other: object) -> bool:\n        return (\n            isinstance(other, Undefined)\n            or other is UNDEFINED\n            or (isinstance(other, NodeList) and len(other) == 0)\n        )\n\n    def __str__(self) -> str:\n        return \"undefined\"\n\n    def evaluate(self, _: FilterContext) -> object:\n        return UNDEFINED\n\n    async def evaluate_async(self, _: FilterContext) -> object:\n        return UNDEFINED\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        return\n\n\nUNDEFINED_LITERAL = Undefined()\n\nLITERAL_EXPRESSION_T = TypeVar(\"LITERAL_EXPRESSION_T\")\n\n\nclass Literal(FilterExpression, Generic[LITERAL_EXPRESSION_T]):\n    \"\"\"Base class for filter expression literals.\"\"\"\n\n    __slots__ = (\"value\",)\n\n    def __init__(self, *, value: LITERAL_EXPRESSION_T) -> None:\n        self.value = value\n        super().__init__()\n\n    def __str__(self) -> str:\n        return repr(self.value).lower()\n\n    def __eq__(self, other: object) -> bool:\n        return self.value == other\n\n    def __hash__(self) -> int:\n        return hash(self.value)\n\n    def evaluate(self, _: FilterContext) -> LITERAL_EXPRESSION_T:\n        return self.value\n\n    async def evaluate_async(self, _: FilterContext) -> LITERAL_EXPRESSION_T:\n        return self.value\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        return\n\n\nclass BooleanLiteral(Literal[bool]):\n    \"\"\"A Boolean `True` or `False`.\"\"\"\n\n    __slots__ = ()\n\n\nTRUE = BooleanLiteral(value=True)\n\n\nFALSE = BooleanLiteral(value=False)\n\n\nclass StringLiteral(Literal[str]):\n    \"\"\"A string literal.\"\"\"\n\n    __slots__ = ()\n\n    def __str__(self) -> str:\n        return json.dumps(self.value)\n\n\nclass IntegerLiteral(Literal[int]):\n    \"\"\"An integer literal.\"\"\"\n\n    __slots__ = ()\n\n\nclass FloatLiteral(Literal[float]):\n    \"\"\"A float literal.\"\"\"\n\n    __slots__ = ()\n\n\nclass RegexLiteral(Literal[Pattern[str]]):\n    \"\"\"A regex literal.\"\"\"\n\n    __slots__ = ()\n\n    RE_FLAG_MAP = {\n        re.A: \"a\",\n        re.I: \"i\",\n        re.M: \"m\",\n        re.S: \"s\",\n    }\n\n    RE_UNESCAPE = re.compile(r\"\\\\(.)\")\n\n    def __str__(self) -> str:\n        flags: List[str] = []\n        for flag, ch in self.RE_FLAG_MAP.items():\n            if self.value.flags & flag:\n                flags.append(ch)\n\n        pattern = re.sub(r\"\\\\(.)\", r\"\\1\", self.value.pattern)\n        return f\"/{pattern}/{''.join(flags)}\"\n\n\nclass ListLiteral(FilterExpression):\n    \"\"\"A list literal.\"\"\"\n\n    __slots__ = (\"items\",)\n\n    def __init__(self, items: List[FilterExpression]) -> None:\n        self.items = items\n        super().__init__()\n\n    def __str__(self) -> str:\n        items = \", \".join(str(item) for item in self.items)\n        return f\"[{items}]\"\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, ListLiteral) and self.items == other.items\n\n    def evaluate(self, context: FilterContext) -> object:\n        return [item.evaluate(context) for item in self.items]\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return [await item.evaluate_async(context) for item in self.items]\n\n    def children(self) -> List[FilterExpression]:\n        return self.items\n\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        self.items = children\n\n\nclass PrefixExpression(FilterExpression):\n    \"\"\"An expression composed of a prefix operator and another expression.\"\"\"\n\n    __slots__ = (\"operator\", \"right\")\n\n    def __init__(self, operator: str, right: FilterExpression):\n        self.operator = operator\n        self.right = right\n        super().__init__()\n\n    def __str__(self) -> str:\n        return f\"{self.operator}{self.right}\"\n\n    def __eq__(self, other: object) -> bool:\n        return (\n            isinstance(other, PrefixExpression)\n            and self.operator == other.operator\n            and self.right == other.right\n        )\n\n    def _evaluate(self, context: FilterContext, right: object) -> object:\n        if self.operator == \"!\":\n            return not context.env.is_truthy(right)\n        raise JSONPathTypeError(f\"unknown operator {self.operator} {self.right}\")\n\n    def evaluate(self, context: FilterContext) -> object:\n        return self._evaluate(context, self.right.evaluate(context))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return self._evaluate(context, await self.right.evaluate_async(context))\n\n    def children(self) -> List[FilterExpression]:\n        return [self.right]\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == 1\n        self.right = children[0]\n\n\nclass InfixExpression(FilterExpression):\n    \"\"\"A pair of expressions and a comparison or logical operator.\"\"\"\n\n    __slots__ = (\"left\", \"operator\", \"right\", \"logical\")\n\n    def __init__(\n        self,\n        left: FilterExpression,\n        operator: str,\n        right: FilterExpression,\n    ):\n        self.left = left\n        self.operator = operator\n        self.right = right\n        self.logical = operator in (\"&&\", \"||\")\n        super().__init__()\n\n    def __str__(self) -> str:\n        if self.logical:\n            return f\"({self.left} {self.operator} {self.right})\"\n        return f\"{self.left} {self.operator} {self.right}\"\n\n    def __eq__(self, other: object) -> bool:\n        return (\n            isinstance(other, InfixExpression)\n            and self.left == other.left\n            and self.operator == other.operator\n            and self.right == other.right\n        )\n\n    def evaluate(self, context: FilterContext) -> bool:\n        left = self.left.evaluate(context)\n        if not self.logical and isinstance(left, NodeList) and len(left) == 1:\n            left = left[0].obj\n\n        right = self.right.evaluate(context)\n        if not self.logical and isinstance(right, NodeList) and len(right) == 1:\n            right = right[0].obj\n\n        return context.env.compare(left, self.operator, right)\n\n    async def evaluate_async(self, context: FilterContext) -> bool:\n        left = await self.left.evaluate_async(context)\n        if not self.logical and isinstance(left, NodeList) and len(left) == 1:\n            left = left[0].obj\n\n        right = await self.right.evaluate_async(context)\n        if not self.logical and isinstance(right, NodeList) and len(right) == 1:\n            right = right[0].obj\n\n        return context.env.compare(left, self.operator, right)\n\n    def children(self) -> List[FilterExpression]:\n        return [self.left, self.right]\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == 2  # noqa: PLR2004\n        self.left = children[0]\n        self.right = children[1]\n\n\nclass BooleanExpression(FilterExpression):\n    \"\"\"An expression that always evaluates to `True` or `False`.\"\"\"\n\n    __slots__ = (\"expression\",)\n\n    def __init__(self, expression: FilterExpression):\n        self.expression = expression\n        super().__init__()\n\n    def cache_tree(self) -> BooleanExpression:\n        \"\"\"Return a copy of _self.expression_ augmented with caching nodes.\"\"\"\n\n        def _cache_tree(expr: FilterExpression) -> FilterExpression:\n            children = expr.children()\n            if expr.volatile:\n                _expr = copy.copy(expr)\n            elif not expr.FORCE_CACHE and len(children) == 0:\n                _expr = expr\n            else:\n                _expr = CachingFilterExpression(copy.copy(expr))\n            _expr.set_children([_cache_tree(child) for child in children])\n            return _expr\n\n        return BooleanExpression(_cache_tree(copy.copy(self.expression)))\n\n    def cacheable_nodes(self) -> bool:\n        \"\"\"Return `True` if there are any cacheable nodes in this expression tree.\"\"\"\n        return any(\n            isinstance(node, CachingFilterExpression)\n            for node in walk(self.cache_tree())\n        )\n\n    def __str__(self) -> str:\n        return str(self.expression)\n\n    def __eq__(self, other: object) -> bool:\n        return (\n            isinstance(other, BooleanExpression) and self.expression == other.expression\n        )\n\n    def evaluate(self, context: FilterContext) -> bool:\n        return context.env.is_truthy(self.expression.evaluate(context))\n\n    async def evaluate_async(self, context: FilterContext) -> bool:\n        return context.env.is_truthy(await self.expression.evaluate_async(context))\n\n    def children(self) -> List[FilterExpression]:\n        return [self.expression]\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == 1\n        self.expression = children[0]\n\n\nclass CachingFilterExpression(FilterExpression):\n    \"\"\"A FilterExpression wrapper that caches the result.\"\"\"\n\n    __slots__ = (\n        \"_cached\",\n        \"_expr\",\n    )\n\n    _UNSET = object()\n\n    def __init__(self, expression: FilterExpression):\n        self.volatile = False\n        self._expr = expression\n        self._cached: object = self._UNSET\n\n    def evaluate(self, context: FilterContext) -> object:\n        if self._cached is self._UNSET:\n            self._cached = self._expr.evaluate(context)\n        return self._cached\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        if self._cached is self._UNSET:\n            self._cached = await self._expr.evaluate_async(context)\n        return self._cached\n\n    def children(self) -> List[FilterExpression]:\n        return self._expr.children()\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        self._expr.set_children(children)\n\n\nclass Path(FilterExpression, ABC):\n    \"\"\"Base expression for all _sub paths_ found in filter expressions.\"\"\"\n\n    __slots__ = (\"path\",)\n\n    def __init__(self, path: JSONPath) -> None:\n        self.path = path\n        super().__init__()\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, Path) and str(self) == str(other)\n\n    def children(self) -> List[FilterExpression]:\n        _children: List[FilterExpression] = []\n        for segment in self.path.selectors:\n            if isinstance(segment, ListSelector):\n                _children.extend(\n                    selector.expression\n                    for selector in segment.items\n                    if isinstance(selector, FilterSelector)\n                )\n        return _children\n\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        # self.path has its own cache\n        return\n\n\nclass SelfPath(Path):\n    \"\"\"A JSONPath starting at the current node.\"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, path: JSONPath) -> None:\n        super().__init__(path)\n        self.volatile = True\n\n    def __str__(self) -> str:\n        return \"@\" + str(self.path)[1:]\n\n    def evaluate(self, context: FilterContext) -> object:\n        if isinstance(context.current, str):  # TODO: refactor\n            if self.path.empty():\n                return context.current\n            return NodeList()\n        if not isinstance(context.current, (Sequence, Mapping)):\n            if self.path.empty():\n                return context.current\n            return NodeList()\n\n        return NodeList(self.path.finditer(context.current))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        if isinstance(context.current, str):  # TODO: refactor\n            if self.path.empty():\n                return context.current\n            return NodeList()\n        if not isinstance(context.current, (Sequence, Mapping)):\n            if self.path.empty():\n                return context.current\n            return NodeList()\n\n        return NodeList(\n            [match async for match in await self.path.finditer_async(context.current)]\n        )\n\n\nclass RootPath(Path):\n    \"\"\"A JSONPath starting at the root node.\"\"\"\n\n    __slots__ = ()\n\n    FORCE_CACHE = True\n\n    def __init__(self, path: JSONPath) -> None:\n        super().__init__(path)\n        self.volatile = False\n\n    def __str__(self) -> str:\n        return str(self.path)\n\n    def evaluate(self, context: FilterContext) -> object:\n        return NodeList(self.path.finditer(context.root))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return NodeList(\n            [match async for match in await self.path.finditer_async(context.root)]\n        )\n\n\nclass FilterContextPath(Path):\n    \"\"\"A JSONPath starting at the root of any extra context data.\"\"\"\n\n    __slots__ = ()\n\n    FORCE_CACHE = True\n\n    def __init__(self, path: JSONPath) -> None:\n        super().__init__(path)\n        self.volatile = False\n\n    def __str__(self) -> str:\n        path_repr = str(self.path)\n        return \"_\" + path_repr[1:]\n\n    def evaluate(self, context: FilterContext) -> object:\n        return NodeList(self.path.finditer(context.extra_context))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return NodeList(\n            [\n                match\n                async for match in await self.path.finditer_async(context.extra_context)\n            ]\n        )\n\n\nclass FunctionExtension(FilterExpression):\n    \"\"\"A filter function.\"\"\"\n\n    __slots__ = (\"name\", \"args\")\n\n    def __init__(self, name: str, args: Sequence[FilterExpression]) -> None:\n        self.name = name\n        self.args = args\n        super().__init__()\n\n    def __str__(self) -> str:\n        args = [str(arg) for arg in self.args]\n        return f\"{self.name}({', '.join(args)})\"\n\n    def __eq__(self, other: object) -> bool:\n        return (\n            isinstance(other, FunctionExtension)\n            and other.name == self.name\n            and other.args == self.args\n        )\n\n    def evaluate(self, context: FilterContext) -> object:\n        try:\n            func = context.env.function_extensions[self.name]\n        except KeyError:\n            return UNDEFINED  # TODO: should probably raise an exception\n        args = [arg.evaluate(context) for arg in self.args]\n        return func(*self._unpack_node_lists(func, args))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        try:\n            func = context.env.function_extensions[self.name]\n        except KeyError:\n            return UNDEFINED  # TODO: should probably raise an exception\n        args = [await arg.evaluate_async(context) for arg in self.args]\n        return func(*self._unpack_node_lists(func, args))\n\n    def _unpack_node_lists(\n        self, func: Callable[..., Any], args: List[object]\n    ) -> List[object]:\n        if isinstance(func, FilterFunction):\n            _args: List[object] = []\n            for idx, arg in enumerate(args):\n                if func.arg_types[idx] != ExpressionType.NODES and isinstance(\n                    arg, NodeList\n                ):\n                    if len(arg) == 0:\n                        # If the query results in an empty nodelist, the\n                        # argument is the special result Nothing.\n                        _args.append(UNDEFINED)\n                    elif len(arg) == 1:\n                        # If the query results in a nodelist consisting of a\n                        # single node, the argument is the value of the node\n                        _args.append(arg[0].obj)\n                    else:\n                        # This should not be possible as a non-singular query\n                        # would have been rejected when checking function\n                        # well-typedness.\n                        _args.append(arg)\n                else:\n                    _args.append(arg)\n            return _args\n\n        # Legacy way to indicate that a filter function wants node lists as arguments.\n        if getattr(func, \"with_node_lists\", False):\n            return args\n\n        return [\n            obj.values_or_singular() if isinstance(obj, NodeList) else obj\n            for obj in args\n        ]\n\n    def children(self) -> List[FilterExpression]:\n        return list(self.args)\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == len(self.args)\n        self.args = children\n\n\nclass CurrentKey(FilterExpression):\n    \"\"\"The key/property or index associated with the current object.\"\"\"\n\n    __slots__ = ()\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.volatile = True\n\n    def __str__(self) -> str:\n        return \"#\"\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, CurrentKey)\n\n    def evaluate(self, context: FilterContext) -> object:\n        if context.current_key is None:\n            return UNDEFINED\n        return context.current_key\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return self.evaluate(context)\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:  # noqa: ARG002\n        return\n\n\nCURRENT_KEY = CurrentKey()\n\n\ndef walk(expr: FilterExpression) -> Iterable[FilterExpression]:\n    \"\"\"Walk the filter expression tree starting at _expr_.\"\"\"\n    yield expr\n    for child in expr.children():\n        yield from walk(child)\n\n\nVALUE_TYPE_EXPRESSIONS = (\n    Nil,\n    Undefined,\n    Literal,\n    ListLiteral,\n    CurrentKey,\n)\n",
    "jsonpath/path.py": "# noqa: D100\nfrom __future__ import annotations\n\nimport itertools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import AsyncIterable\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import TypeVar\nfrom typing import Union\n\nfrom jsonpath._data import load_data\nfrom jsonpath.fluent_api import Query\nfrom jsonpath.match import FilterContextVars\nfrom jsonpath.match import JSONPathMatch\nfrom jsonpath.selectors import IndexSelector\nfrom jsonpath.selectors import ListSelector\nfrom jsonpath.selectors import PropertySelector\n\nif TYPE_CHECKING:\n    from io import IOBase\n\n    from .env import JSONPathEnvironment\n    from .selectors import JSONPathSelector\n\n\nclass JSONPath:\n    \"\"\"A compiled JSONPath ready to be applied to a JSON string or Python object.\n\n    Arguments:\n        env: The `JSONPathEnvironment` this path is bound to.\n        selectors: An iterable of `JSONPathSelector` objects, as generated by\n            a `Parser`.\n        fake_root: Indicates if target JSON values should be wrapped in a single-\n            element array, so as to make the target root value selectable.\n\n\n    Attributes:\n        env: The `JSONPathEnvironment` this path is bound to.\n        selectors: The `JSONPathSelector` instances that make up this path.\n    \"\"\"\n\n    __slots__ = (\"env\", \"fake_root\", \"selectors\")\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        selectors: Iterable[JSONPathSelector],\n        fake_root: bool = False,\n    ) -> None:\n        self.env = env\n        self.selectors = tuple(selectors)\n        self.fake_root = fake_root\n\n    def __str__(self) -> str:\n        return self.env.root_token + \"\".join(\n            str(selector) for selector in self.selectors\n        )\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, JSONPath) and self.selectors == __value.selectors\n\n    def __hash__(self) -> int:\n        return hash(self.selectors)\n\n    def findall(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> List[object]:\n        \"\"\"Find all objects in `data` matching the given JSONPath `path`.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A list of matched objects. If there are no matches, the list will\n            be empty.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return [\n            match.obj for match in self.finditer(data, filter_context=filter_context)\n        ]\n\n    def finditer(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        _data = load_data(data)\n        matches: Iterable[JSONPathMatch] = [\n            JSONPathMatch(\n                filter_context=filter_context or {},\n                obj=[_data] if self.fake_root else _data,\n                parent=None,\n                path=self.env.root_token,\n                parts=(),\n                root=_data,\n            )\n        ]\n\n        for selector in self.selectors:\n            matches = selector.resolve(matches)\n\n        return matches\n\n    async def findall_async(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> List[object]:\n        \"\"\"An async version of `findall()`.\"\"\"\n        return [\n            match.obj\n            async for match in await self.finditer_async(\n                data, filter_context=filter_context\n            )\n        ]\n\n    async def finditer_async(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `finditer()`.\"\"\"\n        _data = load_data(data)\n\n        async def root_iter() -> AsyncIterable[JSONPathMatch]:\n            yield self.env.match_class(\n                filter_context=filter_context or {},\n                obj=[_data] if self.fake_root else _data,\n                parent=None,\n                path=self.env.root_token,\n                parts=(),\n                root=_data,\n            )\n\n        matches: AsyncIterable[JSONPathMatch] = root_iter()\n\n        for selector in self.selectors:\n            matches = selector.resolve_async(matches)\n\n        return matches\n\n    def match(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Union[JSONPathMatch, None]:\n        \"\"\"Return a `JSONPathMatch` instance for the first object found in _data_.\n\n        `None` is returned if there are no matches.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A `JSONPathMatch` object for the first match, or `None` if there were\n                no matches.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        try:\n            return next(iter(self.finditer(data, filter_context=filter_context)))\n        except StopIteration:\n            return None\n\n    def query(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Query:\n        \"\"\"Return a `Query` iterator over matches found by applying this path to _data_.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A query iterator.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return Query(self.finditer(data, filter_context=filter_context), self.env)\n\n    def empty(self) -> bool:\n        \"\"\"Return `True` if this path has no selectors.\"\"\"\n        return not bool(self.selectors)\n\n    def singular_query(self) -> bool:\n        \"\"\"Return `True` if this JSONPath query is a singular query.\"\"\"\n        for selector in self.selectors:\n            if isinstance(selector, (PropertySelector, IndexSelector)):\n                continue\n            if (\n                isinstance(selector, ListSelector)\n                and len(selector.items) == 1\n                and isinstance(selector.items[0], (PropertySelector, IndexSelector))\n            ):\n                continue\n            return False\n        return True\n\n\nclass CompoundJSONPath:\n    \"\"\"Multiple `JSONPath`s combined.\"\"\"\n\n    __slots__ = (\"env\", \"path\", \"paths\")\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        path: Union[JSONPath, CompoundJSONPath],\n        paths: Iterable[Tuple[str, JSONPath]] = (),\n    ) -> None:\n        self.env = env\n        self.path = path\n        self.paths = tuple(paths)\n\n    def __str__(self) -> str:\n        buf: List[str] = [str(self.path)]\n        for op, path in self.paths:\n            buf.append(f\" {op} \")\n            buf.append(str(path))\n        return \"\".join(buf)\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, CompoundJSONPath)\n            and self.path == __value.path\n            and self.paths == __value.paths\n        )\n\n    def __hash__(self) -> int:\n        return hash((self.path, self.paths))\n\n    def findall(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> List[object]:\n        \"\"\"Find all objects in `data` matching the given JSONPath `path`.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A list of matched objects. If there are no matches, the list will\n                be empty.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        objs = self.path.findall(data, filter_context=filter_context)\n\n        for op, path in self.paths:\n            _objs = path.findall(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                objs.extend(_objs)\n            else:\n                assert op == self.env.intersection_token, op\n                objs = [obj for obj in objs if obj in _objs]\n\n        return objs\n\n    def finditer(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        matches = self.path.finditer(data, filter_context=filter_context)\n\n        for op, path in self.paths:\n            _matches = path.finditer(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                matches = itertools.chain(matches, _matches)\n            else:\n                assert op == self.env.intersection_token\n                _objs = [match.obj for match in _matches]\n                matches = (match for match in matches if match.obj in _objs)\n\n        return matches\n\n    def match(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Union[JSONPathMatch, None]:\n        \"\"\"Return a `JSONPathMatch` instance for the first object found in _data_.\n\n        `None` is returned if there are no matches.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A `JSONPathMatch` object for the first match, or `None` if there were\n                no matches.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        try:\n            return next(iter(self.finditer(data, filter_context=filter_context)))\n        except StopIteration:\n            return None\n\n    async def findall_async(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> List[object]:\n        \"\"\"An async version of `findall()`.\"\"\"\n        objs = await self.path.findall_async(data, filter_context=filter_context)\n\n        for op, path in self.paths:\n            _objs = await path.findall_async(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                objs.extend(_objs)\n            else:\n                assert op == self.env.intersection_token\n                objs = [obj for obj in objs if obj in _objs]\n\n        return objs\n\n    async def finditer_async(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `finditer()`.\"\"\"\n        matches = await self.path.finditer_async(data, filter_context=filter_context)\n\n        for op, path in self.paths:\n            _matches = await path.finditer_async(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                matches = _achain(matches, _matches)\n            else:\n                assert op == self.env.intersection_token\n                _objs = [match.obj async for match in _matches]\n                matches = (match async for match in matches if match.obj in _objs)\n\n        return matches\n\n    def query(\n        self,\n        data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]],\n        *,\n        filter_context: Optional[FilterContextVars] = None,\n    ) -> Query:\n        \"\"\"Return a `Query` iterator over matches found by applying this path to _data_.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A query iterator.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return Query(self.finditer(data, filter_context=filter_context), self.env)\n\n    def union(self, path: JSONPath) -> CompoundJSONPath:\n        \"\"\"Union of this path and another path.\"\"\"\n        return self.__class__(\n            env=self.env,\n            path=self.path,\n            paths=self.paths + ((self.env.union_token, path),),\n        )\n\n    def intersection(self, path: JSONPath) -> CompoundJSONPath:\n        \"\"\"Intersection of this path and another path.\"\"\"\n        return self.__class__(\n            env=self.env,\n            path=self.path,\n            paths=self.paths + ((self.env.intersection_token, path),),\n        )\n\n\nT = TypeVar(\"T\")\n\n\nasync def _achain(*iterables: AsyncIterable[T]) -> AsyncIterable[T]:\n    for it in iterables:\n        async for element in it:\n            yield element\n",
    "jsonpath/match.py": "\"\"\"The JSONPath match object, as returned from `JSONPath.finditer()`.\"\"\"\nfrom __future__ import annotations\n\nfrom typing import Any\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import Union\n\nfrom .pointer import JSONPointer\n\nFilterContextVars = Mapping[str, Any]\nPathPart = Union[int, str]\n\n\nclass JSONPathMatch:\n    \"\"\"A matched object with a concrete path.\n\n    Attributes:\n        children: Matched child nodes. This will only be populated after\n            all children have been visited, usually by using `findall()`\n            or `list(finditer())`.\n        obj: The matched object.\n        parent: The immediate parent to this match in the JSON document.\n            If this is the root node, _parent_ will be `None`.\n        path: The canonical string representation of the path to this match.\n        parts: The keys, indices and/or slices that make up the path to this\n            match.\n        root: A reference to the root node in the JSON document.\n    \"\"\"\n\n    __slots__ = (\n        \"_filter_context\",\n        \"children\",\n        \"obj\",\n        \"parent\",\n        \"parts\",\n        \"path\",\n        \"root\",\n    )\n\n    pointer_class = JSONPointer\n\n    def __init__(\n        self,\n        *,\n        filter_context: FilterContextVars,\n        obj: object,\n        parent: Optional[JSONPathMatch],\n        path: str,\n        parts: Tuple[PathPart, ...],\n        root: Union[Sequence[Any], Mapping[str, Any]],\n    ) -> None:\n        self._filter_context = filter_context\n        self.children: List[JSONPathMatch] = []\n        self.obj: object = obj\n        self.parent: Optional[JSONPathMatch] = parent\n        self.parts: Tuple[PathPart, ...] = parts\n        self.path: str = path\n        self.root: Union[Sequence[Any], Mapping[str, Any]] = root\n\n    def __str__(self) -> str:\n        return f\"{_truncate(str(self.obj), 5)!r} @ {_truncate(self.path, 5)}\"\n\n    def add_child(self, *children: JSONPathMatch) -> None:\n        \"\"\"Append one or more children to this match.\"\"\"\n        self.children.extend(children)\n\n    def filter_context(self) -> FilterContextVars:\n        \"\"\"Return filter context data for this match.\"\"\"\n        return self._filter_context\n\n    def pointer(self) -> JSONPointer:\n        \"\"\"Return a `JSONPointer` pointing to this match's path.\"\"\"\n        return JSONPointer.from_match(self)\n\n    @property\n    def value(self) -> object:\n        \"\"\"Return the value associated with this match/node.\"\"\"\n        return self.obj\n\n\ndef _truncate(val: str, num: int, end: str = \"...\") -> str:\n    # Replaces consecutive whitespace with a single newline.\n    # Treats quoted whitespace the same as unquoted whitespace.\n    words = val.split()\n    if len(words) < num:\n        return \" \".join(words)\n    return \" \".join(words[:num]) + end\n\n\nclass NodeList(List[JSONPathMatch]):\n    \"\"\"List of JSONPathMatch objects, analogous to the spec's nodelist.\"\"\"\n\n    def values(self) -> List[object]:\n        \"\"\"Return the values from this node list.\"\"\"\n        return [match.obj for match in self]\n\n    def values_or_singular(self) -> object:\n        \"\"\"Return the values from this node list.\"\"\"\n        if len(self) == 1:\n            return self[0].obj\n        return [match.obj for match in self]\n\n    def empty(self) -> bool:\n        \"\"\"Return `True` if this node list is empty.\"\"\"\n        return not bool(self)\n\n    def __str__(self) -> str:\n        return f\"NodeList{super().__str__()}\"\n",
    "jsonpath/selectors.py": "\"\"\"JSONPath segments and selectors, as returned from `Parser.parse`.\"\"\"\nfrom __future__ import annotations\n\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom contextlib import suppress\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import AsyncIterable\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import TypeVar\nfrom typing import Union\n\nfrom .exceptions import JSONPathIndexError\nfrom .exceptions import JSONPathTypeError\n\nif TYPE_CHECKING:\n    from .env import JSONPathEnvironment\n    from .filter import BooleanExpression\n    from .match import JSONPathMatch\n    from .token import Token\n\n# ruff: noqa: D102\n\n\nclass JSONPathSelector(ABC):\n    \"\"\"Base class for all JSONPath segments and selectors.\"\"\"\n\n    __slots__ = (\"env\", \"token\")\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token) -> None:\n        self.env = env\n        self.token = token\n\n    @abstractmethod\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        \"\"\"Apply the segment/selector to each node in _matches_.\n\n        Arguments:\n            matches: Nodes matched by preceding segments/selectors. This is like\n                a lazy _NodeList_, as described in RFC 9535, but each match carries\n                more than the node's value and location.\n\n        Returns:\n            The `JSONPathMatch` instances created by applying this selector to each\n            preceding node.\n        \"\"\"\n\n    @abstractmethod\n    def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `resolve`.\"\"\"\n\n\nclass PropertySelector(JSONPathSelector):\n    \"\"\"A shorthand or bracketed property selector.\"\"\"\n\n    __slots__ = (\"name\", \"shorthand\")\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        token: Token,\n        name: str,\n        shorthand: bool,\n    ) -> None:\n        super().__init__(env=env, token=token)\n        self.name = name\n        self.shorthand = shorthand\n\n    def __str__(self) -> str:\n        return f\"['{self.name}']\" if self.shorthand else f\"'{self.name}'\"\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, PropertySelector)\n            and self.name == __value.name\n            and self.token == __value.token\n        )\n\n    def __hash__(self) -> int:\n        return hash((self.name, self.token))\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if not isinstance(match.obj, Mapping):\n                continue\n\n            with suppress(KeyError):\n                _match = self.env.match_class(\n                    filter_context=match.filter_context(),\n                    obj=self.env.getitem(match.obj, self.name),\n                    parent=match,\n                    parts=match.parts + (self.name,),\n                    path=match.path + f\"['{self.name}']\",\n                    root=match.root,\n                )\n                match.add_child(_match)\n                yield _match\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if not isinstance(match.obj, Mapping):\n                continue\n\n            with suppress(KeyError):\n                _match = self.env.match_class(\n                    filter_context=match.filter_context(),\n                    obj=await self.env.getitem_async(match.obj, self.name),\n                    parent=match,\n                    parts=match.parts + (self.name,),\n                    path=match.path + f\"['{self.name}']\",\n                    root=match.root,\n                )\n                match.add_child(_match)\n                yield _match\n\n\nclass IndexSelector(JSONPathSelector):\n    \"\"\"Select an element from an array by index.\n\n    Considering we don't require mapping (JSON object) keys/properties to\n    be quoted, and that we support mappings with numeric keys, we also check\n    to see if the \"index\" is a mapping key, which is non-standard.\n    \"\"\"\n\n    __slots__ = (\"index\", \"_as_key\")\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        token: Token,\n        index: int,\n    ) -> None:\n        if index < env.min_int_index or index > env.max_int_index:\n            raise JSONPathIndexError(\"index out of range\", token=token)\n\n        super().__init__(env=env, token=token)\n        self.index = index\n        self._as_key = str(self.index)\n\n    def __str__(self) -> str:\n        return str(self.index)\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, IndexSelector)\n            and self.index == __value.index\n            and self.token == __value.token\n        )\n\n    def __hash__(self) -> int:\n        return hash((self.index, self.token))\n\n    def _normalized_index(self, obj: Sequence[object]) -> int:\n        if self.index < 0 and len(obj) >= abs(self.index):\n            return len(obj) + self.index\n        return self.index\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if isinstance(match.obj, Mapping):\n                # Try the string representation of the index as a key.\n                with suppress(KeyError):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=self.env.getitem(match.obj, self._as_key),\n                        parent=match,\n                        parts=match.parts + (self._as_key,),\n                        path=f\"{match.path}['{self.index}']\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence) and not isinstance(match.obj, str):\n                norm_index = self._normalized_index(match.obj)\n                with suppress(IndexError):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=self.env.getitem(match.obj, self.index),\n                        parent=match,\n                        parts=match.parts + (norm_index,),\n                        path=match.path + f\"[{norm_index}]\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if isinstance(match.obj, Mapping):\n                # Try the string representation of the index as a key.\n                with suppress(KeyError):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=await self.env.getitem_async(match.obj, self._as_key),\n                        parent=match,\n                        parts=match.parts + (self._as_key,),\n                        path=f\"{match.path}['{self.index}']\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence) and not isinstance(match.obj, str):\n                norm_index = self._normalized_index(match.obj)\n                with suppress(IndexError):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=await self.env.getitem_async(match.obj, self.index),\n                        parent=match,\n                        parts=match.parts + (norm_index,),\n                        path=match.path + f\"[{norm_index}]\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n\n\nclass KeysSelector(JSONPathSelector):\n    \"\"\"Select mapping/object keys/properties.\n\n    NOTE: This is a non-standard selector.\n    \"\"\"\n\n    __slots__ = (\"shorthand\",)\n\n    def __init__(\n        self, *, env: JSONPathEnvironment, token: Token, shorthand: bool\n    ) -> None:\n        super().__init__(env=env, token=token)\n        self.shorthand = shorthand\n\n    def __str__(self) -> str:\n        return (\n            f\"[{self.env.keys_selector_token}]\"\n            if self.shorthand\n            else self.env.keys_selector_token\n        )\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, KeysSelector) and self.token == __value.token\n\n    def __hash__(self) -> int:\n        return hash(self.token)\n\n    def _keys(self, match: JSONPathMatch) -> Iterable[JSONPathMatch]:\n        if isinstance(match.obj, Mapping):\n            for i, key in enumerate(match.obj.keys()):\n                _match = self.env.match_class(\n                    filter_context=match.filter_context(),\n                    obj=key,\n                    parent=match,\n                    parts=match.parts + (f\"{self.env.keys_selector_token}{key}\",),\n                    path=f\"{match.path}[{self.env.keys_selector_token}][{i}]\",\n                    root=match.root,\n                )\n                match.add_child(_match)\n                yield _match\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            yield from self._keys(match)\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            for _match in self._keys(match):\n                yield _match\n\n\nclass SliceSelector(JSONPathSelector):\n    \"\"\"Sequence slicing selector.\"\"\"\n\n    __slots__ = (\"slice\",)\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        token: Token,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        step: Optional[int] = None,\n    ) -> None:\n        super().__init__(env=env, token=token)\n        self._check_range(start, stop, step)\n        self.slice = slice(start, stop, step)\n\n    def __str__(self) -> str:\n        stop = self.slice.stop if self.slice.stop is not None else \"\"\n        start = self.slice.start if self.slice.start is not None else \"\"\n        step = self.slice.step if self.slice.step is not None else \"1\"\n        return f\"{start}:{stop}:{step}\"\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, SliceSelector)\n            and self.slice == __value.slice\n            and self.token == __value.token\n        )\n\n    def __hash__(self) -> int:\n        return hash((str(self), self.token))\n\n    def _check_range(self, *indices: Optional[int]) -> None:\n        for i in indices:\n            if i is not None and (\n                i < self.env.min_int_index or i > self.env.max_int_index\n            ):\n                raise JSONPathIndexError(\"index out of range\", token=self.token)\n\n    def _normalized_index(self, obj: Sequence[object], index: int) -> int:\n        if index < 0 and len(obj) >= abs(index):\n            return len(obj) + index\n        return index\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if not isinstance(match.obj, Sequence) or self.slice.step == 0:\n                continue\n\n            idx = self.slice.start or 0\n            step = self.slice.step or 1\n            for obj in self.env.getitem(match.obj, self.slice):\n                norm_index = self._normalized_index(match.obj, idx)\n                _match = self.env.match_class(\n                    filter_context=match.filter_context(),\n                    obj=obj,\n                    parent=match,\n                    parts=match.parts + (norm_index,),\n                    path=f\"{match.path}[{norm_index}]\",\n                    root=match.root,\n                )\n                match.add_child(_match)\n                yield _match\n                idx += step\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if not isinstance(match.obj, Sequence) or self.slice.step == 0:\n                continue\n\n            idx = self.slice.start or 0\n            step = self.slice.step or 1\n            for obj in await self.env.getitem_async(match.obj, self.slice):\n                norm_index = self._normalized_index(match.obj, idx)\n                _match = self.env.match_class(\n                    filter_context=match.filter_context(),\n                    obj=obj,\n                    parent=match,\n                    parts=match.parts + (norm_index,),\n                    path=f\"{match.path}[{norm_index}]\",\n                    root=match.root,\n                )\n                match.add_child(_match)\n                yield _match\n                idx += step\n\n\nclass WildSelector(JSONPathSelector):\n    \"\"\"Select all items from a sequence/array or values from a mapping/object.\"\"\"\n\n    __slots__ = (\"shorthand\",)\n\n    def __init__(\n        self, *, env: JSONPathEnvironment, token: Token, shorthand: bool\n    ) -> None:\n        super().__init__(env=env, token=token)\n        self.shorthand = shorthand\n\n    def __str__(self) -> str:\n        return \"[*]\" if self.shorthand else \"*\"\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, WildSelector) and self.token == __value.token\n\n    def __hash__(self) -> int:\n        return hash(self.token)\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if isinstance(match.obj, str):\n                continue\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=val,\n                        parent=match,\n                        parts=match.parts + (key,),\n                        path=match.path + f\"['{key}']\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence):\n                for i, val in enumerate(match.obj):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=val,\n                        parent=match,\n                        parts=match.parts + (i,),\n                        path=f\"{match.path}[{i}]\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=val,\n                        parent=match,\n                        parts=match.parts + (key,),\n                        path=match.path + f\"['{key}']\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence):\n                for i, val in enumerate(match.obj):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=val,\n                        parent=match,\n                        parts=match.parts + (i,),\n                        path=f\"{match.path}[{i}]\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n\n\nclass RecursiveDescentSelector(JSONPathSelector):\n    \"\"\"A JSONPath selector that visits all nodes recursively.\n\n    NOTE: Strictly this is a \"segment\", not a \"selector\".\n    \"\"\"\n\n    def __str__(self) -> str:\n        return \"..\"\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, RecursiveDescentSelector)\n            and self.token == __value.token\n        )\n\n    def __hash__(self) -> int:\n        return hash(self.token)\n\n    def _expand(self, match: JSONPathMatch) -> Iterable[JSONPathMatch]:\n        if isinstance(match.obj, Mapping):\n            for key, val in match.obj.items():\n                if isinstance(val, str):\n                    pass\n                elif isinstance(val, (Mapping, Sequence)):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=val,\n                        parent=match,\n                        parts=match.parts + (key,),\n                        path=match.path + f\"['{key}']\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n                    yield from self._expand(_match)\n        elif isinstance(match.obj, Sequence) and not isinstance(match.obj, str):\n            for i, val in enumerate(match.obj):\n                if isinstance(val, str):\n                    pass\n                elif isinstance(val, (Mapping, Sequence)):\n                    _match = self.env.match_class(\n                        filter_context=match.filter_context(),\n                        obj=val,\n                        parent=match,\n                        parts=match.parts + (i,),\n                        path=f\"{match.path}[{i}]\",\n                        root=match.root,\n                    )\n                    match.add_child(_match)\n                    yield _match\n                    yield from self._expand(_match)\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            yield match\n            yield from self._expand(match)\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            yield match\n            for _match in self._expand(match):\n                yield _match\n\n\nT = TypeVar(\"T\")\n\n\nasync def _alist(it: List[T]) -> AsyncIterable[T]:\n    for item in it:\n        yield item\n\n\nclass ListSelector(JSONPathSelector):\n    \"\"\"A bracketed list of selectors, the results of which are concatenated together.\n\n    NOTE: Strictly this is a \"segment\", not a \"selector\".\n    \"\"\"\n\n    __slots__ = (\"items\",)\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        token: Token,\n        items: List[\n            Union[\n                SliceSelector,\n                KeysSelector,\n                IndexSelector,\n                PropertySelector,\n                WildSelector,\n                Filter,\n            ]\n        ],\n    ) -> None:\n        super().__init__(env=env, token=token)\n        self.items = tuple(items)\n\n    def __str__(self) -> str:\n        return f\"[{', '.join(str(itm) for itm in self.items)}]\"\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, ListSelector)\n            and self.items == __value.items\n            and self.token == __value.token\n        )\n\n    def __hash__(self) -> int:\n        return hash((self.items, self.token))\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match_ in matches:\n            for item in self.items:\n                yield from item.resolve([match_])\n\n    async def resolve_async(\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        async for match_ in matches:\n            for item in self.items:\n                async for m in item.resolve_async(_alist([match_])):\n                    yield m\n\n\nclass Filter(JSONPathSelector):\n    \"\"\"Filter sequence/array items or mapping/object values with a filter expression.\"\"\"\n\n    __slots__ = (\"expression\", \"cacheable_nodes\")\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        token: Token,\n        expression: BooleanExpression,\n    ) -> None:\n        super().__init__(env=env, token=token)\n        self.expression = expression\n        # Compile-time check for cacheable nodes.\n        self.cacheable_nodes = self.expression.cacheable_nodes()\n\n    def __str__(self) -> str:\n        return f\"?{self.expression}\"\n\n    def __eq__(self, __value: object) -> bool:\n        return (\n            isinstance(__value, Filter)\n            and self.expression == __value.expression\n            and self.token == __value.token\n        )\n\n    def __hash__(self) -> int:\n        return hash((str(self.expression), self.token))\n\n    def resolve(  # noqa: PLR0912\n        self, matches: Iterable[JSONPathMatch]\n    ) -> Iterable[JSONPathMatch]:\n        if self.cacheable_nodes and self.env.filter_caching:\n            expr = self.expression.cache_tree()\n        else:\n            expr = self.expression\n\n        for match in matches:\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    context = FilterContext(\n                        env=self.env,\n                        current=val,\n                        root=match.root,\n                        extra_context=match.filter_context(),\n                        current_key=key,\n                    )\n                    try:\n                        if expr.evaluate(context):\n                            _match = self.env.match_class(\n                                filter_context=match.filter_context(),\n                                obj=val,\n                                parent=match,\n                                parts=match.parts + (key,),\n                                path=match.path + f\"['{key}']\",\n                                root=match.root,\n                            )\n                            match.add_child(_match)\n                            yield _match\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n\n            elif isinstance(match.obj, Sequence) and not isinstance(match.obj, str):\n                for i, obj in enumerate(match.obj):\n                    context = FilterContext(\n                        env=self.env,\n                        current=obj,\n                        root=match.root,\n                        extra_context=match.filter_context(),\n                        current_key=i,\n                    )\n                    try:\n                        if expr.evaluate(context):\n                            _match = self.env.match_class(\n                                filter_context=match.filter_context(),\n                                obj=obj,\n                                parent=match,\n                                parts=match.parts + (i,),\n                                path=f\"{match.path}[{i}]\",\n                                root=match.root,\n                            )\n                            match.add_child(_match)\n                            yield _match\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n\n    async def resolve_async(  # noqa: PLR0912\n        self, matches: AsyncIterable[JSONPathMatch]\n    ) -> AsyncIterable[JSONPathMatch]:\n        if self.cacheable_nodes and self.env.filter_caching:\n            expr = self.expression.cache_tree()\n        else:\n            expr = self.expression\n\n        async for match in matches:\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    context = FilterContext(\n                        env=self.env,\n                        current=val,\n                        root=match.root,\n                        extra_context=match.filter_context(),\n                        current_key=key,\n                    )\n\n                    try:\n                        result = await expr.evaluate_async(context)\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n\n                    if result:\n                        _match = self.env.match_class(\n                            filter_context=match.filter_context(),\n                            obj=val,\n                            parent=match,\n                            parts=match.parts + (key,),\n                            path=match.path + f\"['{key}']\",\n                            root=match.root,\n                        )\n                        match.add_child(_match)\n                        yield _match\n\n            elif isinstance(match.obj, Sequence) and not isinstance(match.obj, str):\n                for i, obj in enumerate(match.obj):\n                    context = FilterContext(\n                        env=self.env,\n                        current=obj,\n                        root=match.root,\n                        extra_context=match.filter_context(),\n                        current_key=i,\n                    )\n\n                    try:\n                        result = await expr.evaluate_async(context)\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n                    if result:\n                        _match = self.env.match_class(\n                            filter_context=match.filter_context(),\n                            obj=obj,\n                            parent=match,\n                            parts=match.parts + (i,),\n                            path=f\"{match.path}[{i}]\",\n                            root=match.root,\n                        )\n                        match.add_child(_match)\n                        yield _match\n\n\nclass FilterContext:\n    \"\"\"Contextual information and data for evaluating a filter expression.\"\"\"\n\n    __slots__ = (\n        \"current_key\",\n        \"current\",\n        \"env\",\n        \"extra_context\",\n        \"root\",\n    )\n\n    def __init__(\n        self,\n        *,\n        env: JSONPathEnvironment,\n        current: object,\n        root: Union[Sequence[Any], Mapping[str, Any]],\n        extra_context: Optional[Mapping[str, Any]] = None,\n        current_key: Union[str, int, None] = None,\n    ) -> None:\n        self.env = env\n        self.current = current\n        self.root = root\n        self.extra_context = extra_context or {}\n        self.current_key = current_key\n\n    def __str__(self) -> str:\n        return (\n            f\"FilterContext(current={self.current}, \"\n            f\"extra_context={self.extra_context!r})\"\n        )\n"
  },
  "GT_src_dict": {
    "jsonpath/env.py": {
      "JSONPathEnvironment.__init__": {
        "code": "    def __init__(self, *, filter_caching: bool=True, unicode_escape: bool=True, well_typed: bool=True) -> None:\n        \"\"\"Initialize a new instance of the JSONPathEnvironment class, which provides the configuration and setup for JSONPath parsing and querying.\n\nParameters:\n- filter_caching (bool): Controls whether filter expressions are cached for efficiency. Default is True.\n- unicode_escape (bool): Enables decoding of UTF-16 escape sequences found in JSONPath string literals. Default is True.\n- well_typed (bool): If True, enforces checks for well-typedness on filter function expressions during compilation. Default is True.\n\nAttributes Initialized:\n- self.filter_caching: Stores the state of filter caching.\n- self.unicode_escape: Stores the state of UTF-16 decoding.\n- self.well_typed: Stores the state of well-typedness enforcement.\n- self.lexer: Creates an instance of the lexer defined by lexer_class, bound to this environment.\n- self.parser: Creates an instance of the parser defined by parser_class, also bound to this environment.\n- self.function_extensions: Initializes a dictionary to store available function extensions for filters.\n  \nSide Effects:\nInvokes the setup_function_extensions method to populate the function_extensions attribute with predefined filter functions.\n\nConstants used:\n- lexer_class (Type[Lexer]): The default lexer class utilized for tokenizing JSONPath strings.\n- parser_class (Type[Parser]): The default parser class utilized for parsing tokens produced by the lexer. These classes are expected to be subclasses of Lexer and Parser, respectively, defined within the same package.\"\"\"\n        self.filter_caching: bool = filter_caching\n        'Enable or disable filter expression caching.'\n        self.unicode_escape: bool = unicode_escape\n        'Enable or disable decoding of UTF-16 escape sequences found in\\n        JSONPath string literals.'\n        self.well_typed: bool = well_typed\n        'Control well-typedness checks on filter function expressions.'\n        self.lexer: Lexer = self.lexer_class(env=self)\n        'The lexer bound to this environment.'\n        self.parser: Parser = self.parser_class(env=self)\n        'The parser bound to this environment.'\n        self.function_extensions: Dict[str, Callable[..., Any]] = {}\n        'A list of function extensions available to filters.'\n        self.setup_function_extensions()",
        "docstring": "Initialize a new instance of the JSONPathEnvironment class, which provides the configuration and setup for JSONPath parsing and querying.\n\nParameters:\n- filter_caching (bool): Controls whether filter expressions are cached for efficiency. Default is True.\n- unicode_escape (bool): Enables decoding of UTF-16 escape sequences found in JSONPath string literals. Default is True.\n- well_typed (bool): If True, enforces checks for well-typedness on filter function expressions during compilation. Default is True.\n\nAttributes Initialized:\n- self.filter_caching: Stores the state of filter caching.\n- self.unicode_escape: Stores the state of UTF-16 decoding.\n- self.well_typed: Stores the state of well-typedness enforcement.\n- self.lexer: Creates an instance of the lexer defined by lexer_class, bound to this environment.\n- self.parser: Creates an instance of the parser defined by parser_class, also bound to this environment.\n- self.function_extensions: Initializes a dictionary to store available function extensions for filters.\n  \nSide Effects:\nInvokes the setup_function_extensions method to populate the function_extensions attribute with predefined filter functions.\n\nConstants used:\n- lexer_class (Type[Lexer]): The default lexer class utilized for tokenizing JSONPath strings.\n- parser_class (Type[Parser]): The default parser class utilized for parsing tokens produced by the lexer. These classes are expected to be subclasses of Lexer and Parser, respectively, defined within the same package.",
        "signature": "def __init__(self, *, filter_caching: bool=True, unicode_escape: bool=True, well_typed: bool=True) -> None:",
        "type": "Method",
        "class_signature": "class JSONPathEnvironment:"
      },
      "JSONPathEnvironment.compile": {
        "code": "    def compile(self, path: str) -> Union[JSONPath, CompoundJSONPath]:\n        \"\"\"Prepare a JSONPath expression for repeated matching against various data structures.\n\nThis method takes a JSONPath string, tokenizes it using the associated lexer, and parses the tokens using the associated parser to create a `JSONPath` or `CompoundJSONPath` object. It verifies the syntactical correctness of the input path, handling potential union and intersection operations.\n\nArguments:\n    path (str): A JSONPath expression as a string.\n\nReturns:\n    Union[JSONPath, CompoundJSONPath]: An instance of `JSONPath` or `CompoundJSONPath`, which is ready for data matching.\n\nRaises:\n    JSONPathSyntaxError: If the provided path is invalid or improperly formed.\n    JSONPathTypeError: If filter functions within the path are given arguments of incorrect types.\n\nConstants Used:\n- `TOKEN_EOF`: Indicates the end of the token stream, defined within the module, used to check if all tokens have been processed.\n- `TOKEN_UNION`: Identifies the union operator in the token stream, allowing for compound path creation.\n- `TOKEN_INTERSECTION`: Identifies the intersection operator in the token stream, allowing for compound path creation.\n\nThe method leverages class attributes such as `lexer_class` and `parser_class` to instantiate the necessary tokenizer and parser based on the environment configuration, which may be customized by subclassing the `JSONPathEnvironment`.\"\"\"\n        'Prepare a path string ready for repeated matching against different data.\\n\\n        Arguments:\\n            path: A JSONPath as a string.\\n\\n        Returns:\\n            A `JSONPath` or `CompoundJSONPath`, ready to match against some data.\\n                Expect a `CompoundJSONPath` if the path string uses the _union_ or\\n                _intersection_ operators.\\n\\n        Raises:\\n            JSONPathSyntaxError: If _path_ is invalid.\\n            JSONPathTypeError: If filter functions are given arguments of an\\n                unacceptable type.\\n        '\n        tokens = self.lexer.tokenize(path)\n        stream = TokenStream(tokens)\n        fake_root = stream.current.kind == TOKEN_FAKE_ROOT\n        _path: Union[JSONPath, CompoundJSONPath] = JSONPath(env=self, selectors=self.parser.parse(stream), fake_root=fake_root)\n        if stream.current.kind != TOKEN_EOF:\n            _path = CompoundJSONPath(env=self, path=_path)\n            while stream.current.kind != TOKEN_EOF:\n                if stream.peek.kind == TOKEN_EOF:\n                    raise JSONPathSyntaxError(f'expected a path after {stream.current.value!r}', token=stream.current)\n                if stream.current.kind == TOKEN_UNION:\n                    stream.next_token()\n                    fake_root = stream.current.kind == TOKEN_FAKE_ROOT\n                    _path = _path.union(JSONPath(env=self, selectors=self.parser.parse(stream), fake_root=fake_root))\n                elif stream.current.kind == TOKEN_INTERSECTION:\n                    stream.next_token()\n                    fake_root = stream.current.kind == TOKEN_FAKE_ROOT\n                    _path = _path.intersection(JSONPath(env=self, selectors=self.parser.parse(stream), fake_root=fake_root))\n                else:\n                    raise JSONPathSyntaxError(f'unexpected token {stream.current.value!r}', token=stream.current)\n        return _path",
        "docstring": "Prepare a JSONPath expression for repeated matching against various data structures.\n\nThis method takes a JSONPath string, tokenizes it using the associated lexer, and parses the tokens using the associated parser to create a `JSONPath` or `CompoundJSONPath` object. It verifies the syntactical correctness of the input path, handling potential union and intersection operations.\n\nArguments:\n    path (str): A JSONPath expression as a string.\n\nReturns:\n    Union[JSONPath, CompoundJSONPath]: An instance of `JSONPath` or `CompoundJSONPath`, which is ready for data matching.\n\nRaises:\n    JSONPathSyntaxError: If the provided path is invalid or improperly formed.\n    JSONPathTypeError: If filter functions within the path are given arguments of incorrect types.\n\nConstants Used:\n- `TOKEN_EOF`: Indicates the end of the token stream, defined within the module, used to check if all tokens have been processed.\n- `TOKEN_UNION`: Identifies the union operator in the token stream, allowing for compound path creation.\n- `TOKEN_INTERSECTION`: Identifies the intersection operator in the token stream, allowing for compound path creation.\n\nThe method leverages class attributes such as `lexer_class` and `parser_class` to instantiate the necessary tokenizer and parser based on the environment configuration, which may be customized by subclassing the `JSONPathEnvironment`.",
        "signature": "def compile(self, path: str) -> Union[JSONPath, CompoundJSONPath]:",
        "type": "Method",
        "class_signature": "class JSONPathEnvironment:"
      }
    },
    "jsonpath/filter.py": {},
    "jsonpath/path.py": {
      "JSONPath.findall": {
        "code": "    def findall(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:\n        \"\"\"Find all objects in the given data that match the JSONPath expression represented by this `JSONPath` instance.\n\nThe `data` can be a JSON string, a file-like object, a sequence, or a mapping. If a string is provided, it will be parsed into a JSON object using `json.loads()`. The `filter_context` allows additional arbitrary data to be made available to filters through the _filter context_ selector.\n\nParameters:\n- `data`: A JSON document (as a string or a file-like object) or a Python object (implementing `Sequence` or `Mapping`).\n- `filter_context`: An optional mapping of arbitrary data accessible to filters.\n\nReturns:\n- A list of matched objects. If no matches are found, an empty list is returned.\n\nRaises:\n- `JSONPathSyntaxError`: If the JSONPath expression is invalid.\n- `JSONPathTypeError`: If there are type incompatibilities in filter expressions.\n\nThis method internally calls `finditer()` to generate an iterable of matches, from which it extracts the matched objects.\"\"\"\n        'Find all objects in `data` matching the given JSONPath `path`.\\n\\n        If `data` is a string or a file-like objects, it will be loaded\\n        using `json.loads()` and the default `JSONDecoder`.\\n\\n        Arguments:\\n            data: A JSON document or Python object implementing the `Sequence`\\n                or `Mapping` interfaces.\\n            filter_context: Arbitrary data made available to filters using\\n                the _filter context_ selector.\\n\\n        Returns:\\n            A list of matched objects. If there are no matches, the list will\\n            be empty.\\n\\n        Raises:\\n            JSONPathSyntaxError: If the path is invalid.\\n            JSONPathTypeError: If a filter expression attempts to use types in\\n                an incompatible way.\\n        '\n        return [match.obj for match in self.finditer(data, filter_context=filter_context)]",
        "docstring": "Find all objects in the given data that match the JSONPath expression represented by this `JSONPath` instance.\n\nThe `data` can be a JSON string, a file-like object, a sequence, or a mapping. If a string is provided, it will be parsed into a JSON object using `json.loads()`. The `filter_context` allows additional arbitrary data to be made available to filters through the _filter context_ selector.\n\nParameters:\n- `data`: A JSON document (as a string or a file-like object) or a Python object (implementing `Sequence` or `Mapping`).\n- `filter_context`: An optional mapping of arbitrary data accessible to filters.\n\nReturns:\n- A list of matched objects. If no matches are found, an empty list is returned.\n\nRaises:\n- `JSONPathSyntaxError`: If the JSONPath expression is invalid.\n- `JSONPathTypeError`: If there are type incompatibilities in filter expressions.\n\nThis method internally calls `finditer()` to generate an iterable of matches, from which it extracts the matched objects.",
        "signature": "def findall(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:",
        "type": "Method",
        "class_signature": "class JSONPath:"
      }
    },
    "jsonpath/match.py": {},
    "jsonpath/selectors.py": {}
  },
  "dependency_dict": {
    "jsonpath/env.py:JSONPathEnvironment:__init__": {
      "jsonpath/lex.py": {
        "Lexer.__init__": {
          "code": "    def __init__(self, *, env: JSONPathEnvironment) -> None:\n        self.env = env\n\n        self.double_quote_pattern = r'\"(?P<G_DQUOTE>(?:(?!(?<!\\\\)\").)*)\"'\n        self.single_quote_pattern = r\"'(?P<G_SQUOTE>(?:(?!(?<!\\\\)').)*)'\"\n\n        # .thing\n        self.dot_property_pattern = rf\"\\.(?P<G_PROP>{self.key_pattern})\"\n\n        self.slice_list_pattern = (\n            r\"(?P<G_LSLICE_START>\\-?\\d*)\\s*\"\n            r\":\\s*(?P<G_LSLICE_STOP>\\-?\\d*)\\s*\"\n            r\"(?::\\s*(?P<G_LSLICE_STEP>\\-?\\d*))?\"\n        )\n\n        # /pattern/ or /pattern/flags\n        self.re_pattern = r\"/(?P<G_RE>.+?)/(?P<G_RE_FLAGS>[aims]*)\"\n\n        # func(\n        self.function_pattern = r\"(?P<G_FUNC>[a-z][a-z_0-9]+)\\(\\s*\"\n\n        self.rules = self.compile_rules()",
          "docstring": "",
          "signature": "def __init__(self, *, env: JSONPathEnvironment) -> None:",
          "type": "Method",
          "class_signature": "class Lexer:"
        }
      },
      "jsonpath/parse.py": {
        "Parser.__init__": {
          "code": "    def __init__(self, *, env: JSONPathEnvironment) -> None:\n        self.env = env\n\n        self.token_map: Dict[str, Callable[[TokenStream], FilterExpression]] = {\n            TOKEN_DOUBLE_QUOTE_STRING: self.parse_string_literal,\n            TOKEN_FAKE_ROOT: self.parse_root_path,\n            TOKEN_FALSE: self.parse_boolean,\n            TOKEN_FILTER_CONTEXT: self.parse_filter_context_path,\n            TOKEN_FLOAT: self.parse_float_literal,\n            TOKEN_FUNCTION: self.parse_function_extension,\n            TOKEN_INT: self.parse_integer_literal,\n            TOKEN_KEY: self.parse_current_key,\n            TOKEN_LIST_START: self.parse_list_literal,\n            TOKEN_LPAREN: self.parse_grouped_expression,\n            TOKEN_MISSING: self.parse_undefined,\n            TOKEN_NIL: self.parse_nil,\n            TOKEN_NONE: self.parse_nil,\n            TOKEN_NOT: self.parse_prefix_expression,\n            TOKEN_NULL: self.parse_nil,\n            TOKEN_RE_PATTERN: self.parse_regex,\n            TOKEN_ROOT: self.parse_root_path,\n            TOKEN_SELF: self.parse_self_path,\n            TOKEN_SINGLE_QUOTE_STRING: self.parse_string_literal,\n            TOKEN_TRUE: self.parse_boolean,\n            TOKEN_UNDEFINED: self.parse_undefined,\n        }\n\n        self.list_item_map: Dict[str, Callable[[TokenStream], FilterExpression]] = {\n            TOKEN_FALSE: self.parse_boolean,\n            TOKEN_FLOAT: self.parse_float_literal,\n            TOKEN_INT: self.parse_integer_literal,\n            TOKEN_NIL: self.parse_nil,\n            TOKEN_NONE: self.parse_nil,\n            TOKEN_NULL: self.parse_nil,\n            TOKEN_DOUBLE_QUOTE_STRING: self.parse_string_literal,\n            TOKEN_SINGLE_QUOTE_STRING: self.parse_string_literal,\n            TOKEN_TRUE: self.parse_boolean,\n        }\n\n        self.function_argument_map: Dict[\n            str, Callable[[TokenStream], FilterExpression]\n        ] = {\n            TOKEN_DOUBLE_QUOTE_STRING: self.parse_string_literal,\n            TOKEN_FAKE_ROOT: self.parse_root_path,\n            TOKEN_FALSE: self.parse_boolean,\n            TOKEN_FILTER_CONTEXT: self.parse_filter_context_path,\n            TOKEN_FLOAT: self.parse_float_literal,\n            TOKEN_FUNCTION: self.parse_function_extension,\n            TOKEN_INT: self.parse_integer_literal,\n            TOKEN_KEY: self.parse_current_key,\n            TOKEN_NIL: self.parse_nil,\n            TOKEN_NONE: self.parse_nil,\n            TOKEN_NULL: self.parse_nil,\n            TOKEN_ROOT: self.parse_root_path,\n            TOKEN_SELF: self.parse_self_path,\n            TOKEN_SINGLE_QUOTE_STRING: self.parse_string_literal,\n            TOKEN_TRUE: self.parse_boolean,\n        }",
          "docstring": "",
          "signature": "def __init__(self, *, env: JSONPathEnvironment) -> None:",
          "type": "Method",
          "class_signature": "class Parser:"
        }
      },
      "jsonpath/env.py": {
        "JSONPathEnvironment.setup_function_extensions": {
          "code": "    def setup_function_extensions(self) -> None:\n        \"\"\"Initialize function extensions.\"\"\"\n        self.function_extensions['length'] = function_extensions.Length()\n        self.function_extensions['count'] = function_extensions.Count()\n        self.function_extensions['match'] = function_extensions.Match()\n        self.function_extensions['search'] = function_extensions.Search()\n        self.function_extensions['value'] = function_extensions.Value()\n        self.function_extensions['isinstance'] = function_extensions.IsInstance()\n        self.function_extensions['is'] = self.function_extensions['isinstance']\n        self.function_extensions['typeof'] = function_extensions.TypeOf()\n        self.function_extensions['type'] = self.function_extensions['typeof']",
          "docstring": "Initialize function extensions.",
          "signature": "def setup_function_extensions(self) -> None:",
          "type": "Method",
          "class_signature": "class JSONPathEnvironment:"
        }
      }
    },
    "jsonpath/env.py:JSONPathEnvironment:compile": {
      "jsonpath/path.py": {
        "JSONPath.__init__": {
          "code": "    def __init__(self, *, env: JSONPathEnvironment, selectors: Iterable[JSONPathSelector], fake_root: bool=False) -> None:\n        self.env = env\n        self.selectors = tuple(selectors)\n        self.fake_root = fake_root",
          "docstring": "",
          "signature": "def __init__(self, *, env: JSONPathEnvironment, selectors: Iterable[JSONPathSelector], fake_root: bool=False) -> None:",
          "type": "Method",
          "class_signature": "class JSONPath:"
        }
      },
      "jsonpath/stream.py": {
        "TokenStreamIterator.__init__": {
          "code": "        def __init__(self, stream: TokenStream):\n            self.stream = stream",
          "docstring": "",
          "signature": "def __init__(self, stream: TokenStream):",
          "type": "Method",
          "class_signature": "class TokenStreamIterator:"
        }
      }
    },
    "jsonpath/path.py:JSONPath:findall": {
      "jsonpath/path.py": {
        "JSONPath.finditer": {
          "code": "    def finditer(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        _data = load_data(data)\n        matches: Iterable[JSONPathMatch] = [JSONPathMatch(filter_context=filter_context or {}, obj=[_data] if self.fake_root else _data, parent=None, path=self.env.root_token, parts=(), root=_data)]\n        for selector in self.selectors:\n            matches = selector.resolve(matches)\n        return matches",
          "docstring": "Generate `JSONPathMatch` objects for each match.\n\nIf `data` is a string or a file-like objects, it will be loaded\nusing `json.loads()` and the default `JSONDecoder`.\n\nArguments:\n    data: A JSON document or Python object implementing the `Sequence`\n        or `Mapping` interfaces.\n    filter_context: Arbitrary data made available to filters using\n        the _filter context_ selector.\n\nReturns:\n    An iterator yielding `JSONPathMatch` objects for each match.\n\nRaises:\n    JSONPathSyntaxError: If the path is invalid.\n    JSONPathTypeError: If a filter expression attempts to use types in\n        an incompatible way.",
          "signature": "def finditer(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Iterable[JSONPathMatch]:",
          "type": "Method",
          "class_signature": "class JSONPath:"
        }
      },
      "jsonpath/selectors.py": {
        "ListSelector.resolve": {
          "code": "    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match_ in matches:\n            for item in self.items:\n                yield from item.resolve([match_])",
          "docstring": "",
          "signature": "def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:",
          "type": "Method",
          "class_signature": "class ListSelector(JSONPathSelector):"
        }
      }
    },
    "jsonpath/path.py:JSONPath:findall_async": {}
  },
  "call_tree": {
    "tests/test_typeof_function.py:env": {
      "jsonpath/env.py:JSONPathEnvironment:__init__": {
        "jsonpath/lex.py:Lexer:__init__": {
          "jsonpath/lex.py:Lexer:compile_rules": {}
        },
        "jsonpath/parse.py:Parser:__init__": {},
        "jsonpath/env.py:JSONPathEnvironment:setup_function_extensions": {
          "jsonpath/function_extensions/typeof.py:TypeOf:__init__": {}
        }
      }
    },
    "tests/test_typeof_function.py:test_typeof_function": {
      "jsonpath/env.py:JSONPathEnvironment:compile": {
        "jsonpath/stream.py:TokenStreamIterator:__init__": {
          "jsonpath/token.py:Token:__init__": {},
          "jsonpath/stream.py:TokenStreamIterator:__next__": {
            "jsonpath/lex.py:Lexer:tokenize": {
              "jsonpath/token.py:Token:__init__": {}
            }
          }
        },
        "jsonpath/path.py:JSONPath:__init__": {
          "jsonpath/parse.py:Parser:parse": {
            "jsonpath/stream.py:TokenStreamIterator:next_token": {
              "jsonpath/stream.py:TokenStreamIterator:__next__": {
                "jsonpath/lex.py:Lexer:tokenize": {
                  "jsonpath/token.py:Token:__init__": {}
                }
              }
            },
            "jsonpath/parse.py:Parser:parse_path": {
              "jsonpath/selectors.py:PropertySelector:__init__": {
                "jsonpath/selectors.py:JSONPathSelector:__init__": {}
              },
              "jsonpath/stream.py:TokenStreamIterator:next_token": {
                "jsonpath/stream.py:TokenStreamIterator:__next__": {
                  "jsonpath/lex.py:Lexer:tokenize": {
                    "jsonpath/token.py:Token:__init__": {}
                  },
                  "jsonpath/stream.py:TokenStreamIterator:close": {
                    "jsonpath/token.py:Token:__init__": {}
                  }
                }
              },
              "jsonpath/parse.py:Parser:parse_selector_list": {
                "jsonpath/stream.py:TokenStreamIterator:next_token": {
                  "jsonpath/stream.py:TokenStreamIterator:__next__": {
                    "jsonpath/lex.py:Lexer:tokenize": {
                      "jsonpath/token.py:Token:__init__": {}
                    }
                  }
                },
                "jsonpath/parse.py:Parser:parse_filter": {
                  "jsonpath/filter.py:FunctionExtension:FunctionExtension": {},
                  "jsonpath/function_extensions/filter_function.py:FilterFunction:FilterFunction": {},
                  "jsonpath/stream.py:TokenStreamIterator:next_token": {
                    "jsonpath/stream.py:TokenStreamIterator:__next__": {
                      "jsonpath/lex.py:Lexer:tokenize": {}
                    }
                  },
                  "jsonpath/parse.py:Parser:parse_filter_selector": {
                    "jsonpath/parse.py:Parser:parse_function_extension": {
                      "jsonpath/stream.py:TokenStreamIterator:next_token": {},
                      "jsonpath/parse.py:Parser:parse_self_path": {},
                      "jsonpath/stream.py:TokenStreamIterator:peek": {},
                      "jsonpath/env.py:JSONPathEnvironment:validate_function_extension_signature": {
                        "jsonpath/function_extensions/filter_function.py:FilterFunction:FilterFunction": {}
                      },
                      "jsonpath/filter.py:FunctionExtension:__init__": {}
                    },
                    "jsonpath/stream.py:TokenStreamIterator:peek": {
                      "jsonpath/stream.py:TokenStreamIterator:__next__": {},
                      "jsonpath/stream.py:TokenStreamIterator:push": {}
                    },
                    "jsonpath/stream.py:TokenStreamIterator:next_token": {
                      "jsonpath/stream.py:TokenStreamIterator:__next__": {}
                    },
                    "jsonpath/parse.py:Parser:parse_infix_expression": {
                      "jsonpath/stream.py:TokenStreamIterator:next_token": {},
                      "jsonpath/parse.py:Parser:parse_filter_selector": {
                        "[ignored_or_cut_off]": "..."
                      },
                      "jsonpath/parse.py:Parser:_raise_for_non_comparable_function": {
                        "jsonpath/filter.py:Path:Path": {},
                        "jsonpath/filter.py:FunctionExtension:FunctionExtension": {},
                        "jsonpath/function_extensions/filter_function.py:FilterFunction:FilterFunction": {}
                      },
                      "jsonpath/filter.py:InfixExpression:__init__": {}
                    }
                  },
                  "jsonpath/filter.py:BooleanExpression:__init__": {
                    "jsonpath/filter.py:FilterExpression:__init__": {
                      "jsonpath/filter.py:BooleanExpression:children": {}
                    }
                  },
                  "jsonpath/selectors.py:Filter:__init__": {
                    "jsonpath/selectors.py:JSONPathSelector:__init__": {},
                    "jsonpath/filter.py:BooleanExpression:cacheable_nodes": {
                      "jsonpath/filter.py:CachingFilterExpression:CachingFilterExpression": {},
                      "jsonpath/filter.py:BooleanExpression:cache_tree": {}
                    }
                  }
                },
                "jsonpath/stream.py:TokenStreamIterator:peek": {
                  "jsonpath/stream.py:TokenStreamIterator:__next__": {},
                  "jsonpath/stream.py:TokenStreamIterator:push": {}
                },
                "jsonpath/selectors.py:ListSelector:__init__": {
                  "jsonpath/selectors.py:JSONPathSelector:__init__": {}
                }
              }
            }
          }
        }
      },
      "jsonpath/path.py:JSONPath:findall": {
        "jsonpath/path.py:JSONPath:finditer": {
          "jsonpath/_data.py:load_data": {},
          "jsonpath/match.py:JSONPathMatch:__init__": {}
        },
        "jsonpath/selectors.py:ListSelector:resolve": {
          "jsonpath/selectors.py:PropertySelector:resolve": {
            "jsonpath/match.py:JSONPathMatch:filter_context": {},
            "jsonpath/env.py:JSONPathEnvironment:getitem": {},
            "jsonpath/match.py:JSONPathMatch:__init__": {},
            "jsonpath/match.py:JSONPathMatch:add_child": {}
          },
          "jsonpath/selectors.py:Filter:resolve": {
            "jsonpath/match.py:JSONPathMatch:filter_context": {},
            "jsonpath/selectors.py:FilterContext:__init__": {},
            "jsonpath/filter.py:BooleanExpression:evaluate": {
              "jsonpath/filter.py:InfixExpression:evaluate": {
                "jsonpath/match.py:NodeList:NodeList": {},
                "jsonpath/filter.py:FunctionExtension:evaluate": {
                  "jsonpath/filter.py:SelfPath:evaluate": {
                    "jsonpath/path.py:JSONPath:finditer": {
                      "jsonpath/_data.py:load_data": {},
                      "jsonpath/match.py:JSONPathMatch:__init__": {}
                    },
                    "jsonpath/selectors.py:PropertySelector:resolve": {
                      "jsonpath/match.py:JSONPathMatch:filter_context": {},
                      "jsonpath/env.py:JSONPathEnvironment:getitem": {},
                      "jsonpath/match.py:JSONPathMatch:__init__": {},
                      "jsonpath/match.py:JSONPathMatch:add_child": {}
                    }
                  },
                  "jsonpath/filter.py:FunctionExtension:_unpack_node_lists": {
                    "jsonpath/function_extensions/filter_function.py:FilterFunction:FilterFunction": {},
                    "jsonpath/match.py:NodeList:NodeList": {}
                  },
                  "jsonpath/function_extensions/typeof.py:TypeOf:__call__": {
                    "jsonpath/match.py:NodeList:values_or_singular": {}
                  }
                },
                "jsonpath/filter.py:Literal:evaluate": {},
                "jsonpath/env.py:JSONPathEnvironment:compare": {
                  "jsonpath/env.py:JSONPathEnvironment:_eq": {
                    "jsonpath/match.py:NodeList:NodeList": {}
                  }
                }
              },
              "jsonpath/env.py:JSONPathEnvironment:is_truthy": {
                "jsonpath/match.py:NodeList:NodeList": {}
              }
            },
            "jsonpath/match.py:JSONPathMatch:__init__": {},
            "jsonpath/match.py:JSONPathMatch:add_child": {}
          }
        }
      }
    },
    "tests/test_typeof_function.py:test_typeof_function_async": {
      "jsonpath/env.py:JSONPathEnvironment:compile": {
        "jsonpath/stream.py:TokenStreamIterator:__init__": {
          "jsonpath/token.py:Token:__init__": {},
          "jsonpath/stream.py:TokenStreamIterator:__next__": {
            "jsonpath/lex.py:Lexer:tokenize": {
              "jsonpath/token.py:Token:__init__": {}
            }
          }
        },
        "jsonpath/path.py:JSONPath:__init__": {
          "jsonpath/parse.py:Parser:parse": {
            "jsonpath/stream.py:TokenStreamIterator:next_token": {
              "jsonpath/stream.py:TokenStreamIterator:__next__": {
                "jsonpath/lex.py:Lexer:tokenize": {
                  "jsonpath/token.py:Token:__init__": {}
                }
              }
            },
            "jsonpath/parse.py:Parser:parse_path": {
              "jsonpath/selectors.py:PropertySelector:__init__": {
                "jsonpath/selectors.py:JSONPathSelector:__init__": {}
              },
              "jsonpath/stream.py:TokenStreamIterator:next_token": {
                "jsonpath/stream.py:TokenStreamIterator:__next__": {
                  "jsonpath/lex.py:Lexer:tokenize": {
                    "jsonpath/token.py:Token:__init__": {}
                  },
                  "jsonpath/stream.py:TokenStreamIterator:close": {
                    "jsonpath/token.py:Token:__init__": {}
                  }
                }
              },
              "jsonpath/parse.py:Parser:parse_selector_list": {
                "jsonpath/stream.py:TokenStreamIterator:next_token": {
                  "jsonpath/stream.py:TokenStreamIterator:__next__": {
                    "jsonpath/lex.py:Lexer:tokenize": {
                      "jsonpath/token.py:Token:__init__": {}
                    }
                  }
                },
                "jsonpath/parse.py:Parser:parse_filter": {
                  "jsonpath/stream.py:TokenStreamIterator:next_token": {
                    "jsonpath/stream.py:TokenStreamIterator:__next__": {
                      "jsonpath/lex.py:Lexer:tokenize": {}
                    }
                  },
                  "jsonpath/parse.py:Parser:parse_filter_selector": {
                    "jsonpath/parse.py:Parser:parse_function_extension": {
                      "jsonpath/stream.py:TokenStreamIterator:next_token": {},
                      "jsonpath/parse.py:Parser:parse_self_path": {},
                      "jsonpath/stream.py:TokenStreamIterator:peek": {},
                      "jsonpath/env.py:JSONPathEnvironment:validate_function_extension_signature": {},
                      "jsonpath/filter.py:FunctionExtension:__init__": {}
                    },
                    "jsonpath/stream.py:TokenStreamIterator:peek": {
                      "jsonpath/stream.py:TokenStreamIterator:__next__": {},
                      "jsonpath/stream.py:TokenStreamIterator:push": {}
                    },
                    "jsonpath/stream.py:TokenStreamIterator:next_token": {
                      "jsonpath/stream.py:TokenStreamIterator:__next__": {}
                    },
                    "jsonpath/parse.py:Parser:parse_infix_expression": {
                      "jsonpath/stream.py:TokenStreamIterator:next_token": {},
                      "jsonpath/parse.py:Parser:parse_filter_selector": {
                        "[ignored_or_cut_off]": "..."
                      },
                      "jsonpath/parse.py:Parser:_raise_for_non_comparable_function": {},
                      "jsonpath/filter.py:InfixExpression:__init__": {}
                    }
                  },
                  "jsonpath/filter.py:BooleanExpression:__init__": {
                    "jsonpath/filter.py:FilterExpression:__init__": {
                      "jsonpath/filter.py:BooleanExpression:children": {}
                    }
                  },
                  "jsonpath/selectors.py:Filter:__init__": {
                    "jsonpath/selectors.py:JSONPathSelector:__init__": {},
                    "jsonpath/filter.py:BooleanExpression:cacheable_nodes": {
                      "jsonpath/filter.py:BooleanExpression:cache_tree": {}
                    }
                  }
                },
                "jsonpath/stream.py:TokenStreamIterator:peek": {
                  "jsonpath/stream.py:TokenStreamIterator:__next__": {},
                  "jsonpath/stream.py:TokenStreamIterator:push": {}
                },
                "jsonpath/selectors.py:ListSelector:__init__": {
                  "jsonpath/selectors.py:JSONPathSelector:__init__": {}
                }
              }
            }
          }
        }
      },
      "tests/test_typeof_function.py:coro": {
        "jsonpath/path.py:JSONPath:findall_async": {
          "jsonpath/path.py:JSONPath:finditer_async": {
            "jsonpath/_data.py:load_data": {}
          },
          "jsonpath/selectors.py:ListSelector:resolve_async": {
            "jsonpath/selectors.py:PropertySelector:resolve_async": {
              "jsonpath/path.py:JSONPath:root_iter": {
                "jsonpath/match.py:JSONPathMatch:__init__": {}
              },
              "jsonpath/match.py:JSONPathMatch:filter_context": {},
              "jsonpath/env.py:JSONPathEnvironment:getitem_async": {},
              "jsonpath/match.py:JSONPathMatch:__init__": {},
              "jsonpath/match.py:JSONPathMatch:add_child": {}
            },
            "jsonpath/selectors.py:Filter:resolve_async": {
              "jsonpath/selectors.py:_alist": {},
              "jsonpath/match.py:JSONPathMatch:filter_context": {},
              "jsonpath/selectors.py:FilterContext:__init__": {},
              "jsonpath/filter.py:BooleanExpression:evaluate_async": {
                "jsonpath/filter.py:InfixExpression:evaluate_async": {
                  "jsonpath/filter.py:FunctionExtension:evaluate_async": {
                    "jsonpath/filter.py:SelfPath:evaluate_async": {
                      "jsonpath/path.py:JSONPath:finditer_async": {},
                      "jsonpath/selectors.py:PropertySelector:resolve_async": {}
                    },
                    "jsonpath/filter.py:FunctionExtension:_unpack_node_lists": {},
                    "jsonpath/function_extensions/typeof.py:TypeOf:__call__": {
                      "jsonpath/match.py:NodeList:values_or_singular": {}
                    }
                  },
                  "jsonpath/filter.py:Literal:evaluate_async": {},
                  "jsonpath/env.py:JSONPathEnvironment:compare": {
                    "jsonpath/env.py:JSONPathEnvironment:_eq": {}
                  }
                },
                "jsonpath/env.py:JSONPathEnvironment:is_truthy": {}
              },
              "jsonpath/match.py:JSONPathMatch:__init__": {},
              "jsonpath/match.py:JSONPathMatch:add_child": {}
            }
          }
        }
      }
    },
    "tests/test_typeof_function.py:coro": {
      "jsonpath/path.py:JSONPath:findall_async": {
        "jsonpath/selectors.py:ListSelector:resolve_async": {
          "jsonpath/selectors.py:Filter:resolve_async": {
            "jsonpath/filter.py:BooleanExpression:evaluate_async": {
              "jsonpath/filter.py:InfixExpression:evaluate_async": {
                "jsonpath/filter.py:FunctionExtension:evaluate_async": {
                  "jsonpath/filter.py:SelfPath:evaluate_async": {
                    "jsonpath/path.py:JSONPath:finditer_async": {
                      "jsonpath/_data.py:load_data": {}
                    },
                    "jsonpath/selectors.py:PropertySelector:resolve_async": {
                      "jsonpath/path.py:JSONPath:root_iter": {},
                      "jsonpath/match.py:JSONPathMatch:filter_context": {},
                      "jsonpath/env.py:JSONPathEnvironment:getitem_async": {},
                      "jsonpath/match.py:JSONPathMatch:__init__": {},
                      "jsonpath/match.py:JSONPathMatch:add_child": {}
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_filter_expression_caching.py:test_cache_root_path": {
      "jsonpath/path.py:JSONPath:JSONPath": {},
      "jsonpath/selectors.py:ListSelector:ListSelector": {},
      "jsonpath/filter.py:BooleanExpression:BooleanExpression": {},
      "jsonpath/filter.py:InfixExpression:InfixExpression": {},
      "jsonpath/filter.py:SelfPath:SelfPath": {},
      "jsonpath/filter.py:RootPath:RootPath": {},
      "jsonpath/filter.py:CachingFilterExpression:CachingFilterExpression": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_filter_expression_caching.py:test_cache_context_path": {
      "jsonpath/path.py:JSONPath:JSONPath": {},
      "jsonpath/selectors.py:ListSelector:ListSelector": {},
      "jsonpath/filter.py:BooleanExpression:BooleanExpression": {},
      "jsonpath/filter.py:InfixExpression:InfixExpression": {},
      "jsonpath/filter.py:FilterContextPath:FilterContextPath": {},
      "jsonpath/filter.py:SelfPath:SelfPath": {},
      "jsonpath/filter.py:CachingFilterExpression:CachingFilterExpression": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_filter_expression_caching.py:test_uncacheable_filter": {
      "jsonpath/path.py:JSONPath:JSONPath": {},
      "jsonpath/selectors.py:ListSelector:ListSelector": {},
      "jsonpath/filter.py:BooleanExpression:BooleanExpression": {},
      "jsonpath/filter.py:InfixExpression:InfixExpression": {},
      "jsonpath/filter.py:SelfPath:SelfPath": {},
      "jsonpath/filter.py:IntegerLiteral:IntegerLiteral": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_fluent_api.py:test_query_first_one": {
      "jsonpath/match.py:JSONPathMatch:JSONPathMatch": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_fluent_api.py:test_query_one": {
      "jsonpath/match.py:JSONPathMatch:JSONPathMatch": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_fluent_api.py:test_query_last_one": {
      "jsonpath/match.py:JSONPathMatch:JSONPathMatch": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/python_jsonpath-image-test_typeof_function/python_jsonpath-test_typeof_function/tests/test_walk_filter_expression_tree.py:test_is_volatile": {
      "jsonpath/selectors.py:ListSelector:ListSelector": {}
    }
  },
  "PRD": "# PROJECT NAME: python_jsonpath-test_typeof_function\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 jsonpath/\n    \u251c\u2500\u2500 env.py\n    \u2502   \u251c\u2500\u2500 JSONPathEnvironment.__init__\n    \u2502   \u2514\u2500\u2500 JSONPathEnvironment.compile\n    \u251c\u2500\u2500 filter.py\n    \u2502   \u251c\u2500\u2500 BooleanExpression.BooleanExpression\n    \u2502   \u251c\u2500\u2500 CachingFilterExpression.CachingFilterExpression\n    \u2502   \u251c\u2500\u2500 FilterContextPath.FilterContextPath\n    \u2502   \u251c\u2500\u2500 InfixExpression.InfixExpression\n    \u2502   \u251c\u2500\u2500 IntegerLiteral.IntegerLiteral\n    \u2502   \u251c\u2500\u2500 RootPath.RootPath\n    \u2502   \u2514\u2500\u2500 SelfPath.SelfPath\n    \u251c\u2500\u2500 match.py\n    \u2502   \u2514\u2500\u2500 JSONPathMatch.JSONPathMatch\n    \u251c\u2500\u2500 path.py\n    \u2502   \u251c\u2500\u2500 JSONPath.JSONPath\n    \u2502   \u251c\u2500\u2500 JSONPath.findall\n    \u2502   \u2514\u2500\u2500 JSONPath.findall_async\n    \u2514\u2500\u2500 selectors.py\n        \u2514\u2500\u2500 ListSelector.ListSelector\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module facilitates validation and testing of JSONPath expressions that determine the types of elements within JSON-like data structures. It supports evaluating JSONPath queries to filter elements based on their types (e.g., string, number, boolean, array, or object) and ensures returned results match expected outputs. By providing functionality for both synchronous and asynchronous evaluation, it accommodates diverse application scenarios and enhances the flexibility of JSON data querying. This module addresses the need for robust and accurate type-based JSONPath query processing, enabling developers to reliably analyze and manipulate complex JSON datasets.\n\n## FILE 1: jsonpath/env.py\n\n- CLASS METHOD: JSONPathEnvironment.compile\n  - CLASS SIGNATURE: class JSONPathEnvironment:\n  - SIGNATURE: def compile(self, path: str) -> Union[JSONPath, CompoundJSONPath]:\n  - DOCSTRING: \n```python\n\"\"\"\nPrepare a JSONPath expression for repeated matching against various data structures.\n\nThis method takes a JSONPath string, tokenizes it using the associated lexer, and parses the tokens using the associated parser to create a `JSONPath` or `CompoundJSONPath` object. It verifies the syntactical correctness of the input path, handling potential union and intersection operations.\n\nArguments:\n    path (str): A JSONPath expression as a string.\n\nReturns:\n    Union[JSONPath, CompoundJSONPath]: An instance of `JSONPath` or `CompoundJSONPath`, which is ready for data matching.\n\nRaises:\n    JSONPathSyntaxError: If the provided path is invalid or improperly formed.\n    JSONPathTypeError: If filter functions within the path are given arguments of incorrect types.\n\nConstants Used:\n- `TOKEN_EOF`: Indicates the end of the token stream, defined within the module, used to check if all tokens have been processed.\n- `TOKEN_UNION`: Identifies the union operator in the token stream, allowing for compound path creation.\n- `TOKEN_INTERSECTION`: Identifies the intersection operator in the token stream, allowing for compound path creation.\n\nThe method leverages class attributes such as `lexer_class` and `parser_class` to instantiate the necessary tokenizer and parser based on the environment configuration, which may be customized by subclassing the `JSONPathEnvironment`.\n\"\"\"\n```\n\n- CLASS METHOD: JSONPathEnvironment.__init__\n  - CLASS SIGNATURE: class JSONPathEnvironment:\n  - SIGNATURE: def __init__(self, *, filter_caching: bool=True, unicode_escape: bool=True, well_typed: bool=True) -> None:\n  - DOCSTRING: \n```python\n\"\"\"\nInitialize a new instance of the JSONPathEnvironment class, which provides the configuration and setup for JSONPath parsing and querying.\n\nParameters:\n- filter_caching (bool): Controls whether filter expressions are cached for efficiency. Default is True.\n- unicode_escape (bool): Enables decoding of UTF-16 escape sequences found in JSONPath string literals. Default is True.\n- well_typed (bool): If True, enforces checks for well-typedness on filter function expressions during compilation. Default is True.\n\nAttributes Initialized:\n- self.filter_caching: Stores the state of filter caching.\n- self.unicode_escape: Stores the state of UTF-16 decoding.\n- self.well_typed: Stores the state of well-typedness enforcement.\n- self.lexer: Creates an instance of the lexer defined by lexer_class, bound to this environment.\n- self.parser: Creates an instance of the parser defined by parser_class, also bound to this environment.\n- self.function_extensions: Initializes a dictionary to store available function extensions for filters.\n  \nSide Effects:\nInvokes the setup_function_extensions method to populate the function_extensions attribute with predefined filter functions.\n\nConstants used:\n- lexer_class (Type[Lexer]): The default lexer class utilized for tokenizing JSONPath strings.\n- parser_class (Type[Parser]): The default parser class utilized for parsing tokens produced by the lexer. These classes are expected to be subclasses of Lexer and Parser, respectively, defined within the same package.\n\"\"\"\n```\n\n## FILE 2: jsonpath/filter.py\n\n## FILE 3: jsonpath/path.py\n\n- CLASS METHOD: JSONPath.findall\n  - CLASS SIGNATURE: class JSONPath:\n  - SIGNATURE: def findall(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:\n  - DOCSTRING: \n```python\n\"\"\"\nFind all objects in the given data that match the JSONPath expression represented by this `JSONPath` instance.\n\nThe `data` can be a JSON string, a file-like object, a sequence, or a mapping. If a string is provided, it will be parsed into a JSON object using `json.loads()`. The `filter_context` allows additional arbitrary data to be made available to filters through the _filter context_ selector.\n\nParameters:\n- `data`: A JSON document (as a string or a file-like object) or a Python object (implementing `Sequence` or `Mapping`).\n- `filter_context`: An optional mapping of arbitrary data accessible to filters.\n\nReturns:\n- A list of matched objects. If no matches are found, an empty list is returned.\n\nRaises:\n- `JSONPathSyntaxError`: If the JSONPath expression is invalid.\n- `JSONPathTypeError`: If there are type incompatibilities in filter expressions.\n\nThis method internally calls `finditer()` to generate an iterable of matches, from which it extracts the matched objects.\n\"\"\"\n```\n\n## FILE 4: jsonpath/match.py\n\n## FILE 5: jsonpath/selectors.py\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "jsonpath/env.py": "\"\"\"Core JSONPath configuration object.\"\"\"\nfrom __future__ import annotations\nimport re\nfrom decimal import Decimal\nfrom operator import getitem\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import AsyncIterable\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Type\nfrom typing import Union\nfrom . import function_extensions\nfrom .exceptions import JSONPathNameError\nfrom .exceptions import JSONPathSyntaxError\nfrom .exceptions import JSONPathTypeError\nfrom .filter import UNDEFINED\nfrom .filter import VALUE_TYPE_EXPRESSIONS\nfrom .filter import FilterExpression\nfrom .filter import FunctionExtension\nfrom .filter import InfixExpression\nfrom .filter import Path\nfrom .fluent_api import Query\nfrom .function_extensions import ExpressionType\nfrom .function_extensions import FilterFunction\nfrom .function_extensions import validate\nfrom .lex import Lexer\nfrom .match import JSONPathMatch\nfrom .match import NodeList\nfrom .parse import Parser\nfrom .path import CompoundJSONPath\nfrom .path import JSONPath\nfrom .stream import TokenStream\nfrom .token import TOKEN_EOF\nfrom .token import TOKEN_FAKE_ROOT\nfrom .token import TOKEN_INTERSECTION\nfrom .token import TOKEN_UNION\nfrom .token import Token\nif TYPE_CHECKING:\n    from io import IOBase\n    from .match import FilterContextVars\n\nclass JSONPathEnvironment:\n    \"\"\"JSONPath configuration.\n\n    This class contains settings for path tokenization, parsing and resolution\n    behavior, plus convenience methods for matching an unparsed path to some\n    data.\n\n    Most applications will want to create a single `JSONPathEnvironment`, or\n    use `jsonpath.compile()`, `jsonpath.findall()`, etc. from the package-level\n    default environment.\n\n    ## Environment customization\n\n    Environment customization is achieved by subclassing `JSONPathEnvironment`\n    and overriding class attributes and/or methods. Some of these\n    customizations include:\n\n    - Changing the root (`$`), self (`@`) or filter context (`_`) token with\n      class attributes `root_token`, `self_token` and `filter_context_token`.\n    - Registering a custom lexer or parser with the class attributes\n      `lexer_class` or `parser_class`. `lexer_class` must be a subclass of\n      [`Lexer`]() and `parser_class` must be a subclass of [`Parser`]().\n    - Setup built-in function extensions by overriding\n      `setup_function_extensions()`\n    - Hook in to mapping and sequence item getting by overriding `getitem()`.\n    - Change filter comparison operator behavior by overriding `compare()`.\n\n    Arguments:\n        filter_caching (bool): If `True`, filter expressions will be cached\n            where possible.\n        unicode_escape: If `True`, decode UTF-16 escape sequences found in\n            JSONPath string literals.\n        well_typed: Control well-typedness checks on filter function expressions.\n            If `True` (the default), JSONPath expressions are checked for\n            well-typedness as compile time.\n\n            **New in version 0.10.0**\n\n    ## Class attributes\n\n    Attributes:\n        fake_root_token (str): The pattern used to select a \"fake\" root node, one level\n            above the real root node.\n        filter_context_token (str): The pattern used to select extra filter context\n            data. Defaults to `\"_\"`.\n        intersection_token (str): The pattern used as the intersection operator.\n            Defaults to `\"&\"`.\n        key_token (str): The pattern used to identify the current key or index when\n            filtering a, mapping or sequence. Defaults to `\"#\"`.\n        keys_selector_token (str): The pattern used as the \"keys\" selector. Defaults to\n            `\"~\"`.\n        lexer_class: The lexer to use when tokenizing path strings.\n        max_int_index (int): The maximum integer allowed when selecting array items by\n            index. Defaults to `(2**53) - 1`.\n        min_int_index (int): The minimum integer allowed when selecting array items by\n            index. Defaults to `-(2**53) + 1`.\n        parser_class: The parser to use when parsing tokens from the lexer.\n        root_token (str): The pattern used to select the root node in a JSON document.\n            Defaults to `\"$\"`.\n        self_token (str): The pattern used to select the current node in a JSON\n            document. Defaults to `\"@\"`\n        union_token (str): The pattern used as the union operator. Defaults to `\"|\"`.\n    \"\"\"\n    fake_root_token = '^'\n    filter_context_token = '_'\n    intersection_token = '&'\n    key_token = '#'\n    keys_selector_token = '~'\n    root_token = '$'\n    self_token = '@'\n    union_token = '|'\n    max_int_index = 2 ** 53 - 1\n    min_int_index = -2 ** 53 + 1\n    lexer_class: Type[Lexer] = Lexer\n    parser_class: Type[Parser] = Parser\n    match_class: Type[JSONPathMatch] = JSONPathMatch\n\n    def findall(self, path: str, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:\n        \"\"\"Find all objects in _data_ matching the JSONPath _path_.\n\n        If _data_ is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A list of matched objects. If there are no matches, the list will\n                be empty.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return self.compile(path).findall(data, filter_context=filter_context)\n\n    def finditer(self, path: str, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match of _path_ in _data_.\n\n        If _data_ is a string or a file-like objects, it will be loaded using\n        `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return self.compile(path).finditer(data, filter_context=filter_context)\n\n    def match(self, path: str, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Union[JSONPathMatch, None]:\n        \"\"\"Return a `JSONPathMatch` instance for the first object found in _data_.\n\n        `None` is returned if there are no matches.\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A `JSONPathMatch` object for the first match, or `None` if there were\n                no matches.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return self.compile(path).match(data, filter_context=filter_context)\n\n    def query(self, path: str, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], filter_context: Optional[FilterContextVars]=None) -> Query:\n        \"\"\"Return a `Query` iterator over matches found by applying _path_ to _data_.\n\n        `Query` objects are iterable.\n\n        ```\n        for match in jsonpath.query(\"$.foo..bar\", data):\n            ...\n        ```\n\n        You can skip and limit results with `Query.skip()` and `Query.limit()`.\n\n        ```\n        matches = (\n            jsonpath.query(\"$.foo..bar\", data)\n            .skip(5)\n            .limit(10)\n        )\n\n        for match in matches\n            ...\n        ```\n\n        `Query.tail()` will get the last _n_ results.\n\n        ```\n        for match in jsonpath.query(\"$.foo..bar\", data).tail(5):\n            ...\n        ```\n\n        Get values for each match using `Query.values()`.\n\n        ```\n        for obj in jsonpath.query(\"$.foo..bar\", data).limit(5).values():\n            ...\n        ```\n\n        Arguments:\n            path: The JSONPath as a string.\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A query iterator.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return Query(self.finditer(path, data, filter_context=filter_context), self)\n\n    async def findall_async(self, path: str, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:\n        \"\"\"An async version of `findall()`.\"\"\"\n        return await self.compile(path).findall_async(data, filter_context=filter_context)\n\n    async def finditer_async(self, path: str, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `finditer()`.\"\"\"\n        return await self.compile(path).finditer_async(data, filter_context=filter_context)\n\n    def setup_function_extensions(self) -> None:\n        \"\"\"Initialize function extensions.\"\"\"\n        self.function_extensions['length'] = function_extensions.Length()\n        self.function_extensions['count'] = function_extensions.Count()\n        self.function_extensions['match'] = function_extensions.Match()\n        self.function_extensions['search'] = function_extensions.Search()\n        self.function_extensions['value'] = function_extensions.Value()\n        self.function_extensions['isinstance'] = function_extensions.IsInstance()\n        self.function_extensions['is'] = self.function_extensions['isinstance']\n        self.function_extensions['typeof'] = function_extensions.TypeOf()\n        self.function_extensions['type'] = self.function_extensions['typeof']\n\n    def validate_function_extension_signature(self, token: Token, args: List[Any]) -> List[Any]:\n        \"\"\"Compile-time validation of function extension arguments.\n\n        RFC 9535 requires us to reject paths that use filter functions with\n        too many or too few arguments.\n        \"\"\"\n        try:\n            func = self.function_extensions[token.value]\n        except KeyError as err:\n            raise JSONPathNameError(f'function {token.value!r} is not defined', token=token) from err\n        if self.well_typed and isinstance(func, FilterFunction):\n            self.check_well_typedness(token, func, args)\n            return args\n        if hasattr(func, 'validate'):\n            args = func.validate(self, args, token)\n            assert isinstance(args, list)\n            return args\n        return validate(self, func, args, token)\n\n    def check_well_typedness(self, token: Token, func: FilterFunction, args: List[FilterExpression]) -> None:\n        \"\"\"Check the well-typedness of a function's arguments at compile-time.\"\"\"\n        if len(args) != len(func.arg_types):\n            raise JSONPathTypeError(f'{token.value!r}() requires {len(func.arg_types)} arguments', token=token)\n        for idx, typ in enumerate(func.arg_types):\n            arg = args[idx]\n            if typ == ExpressionType.VALUE:\n                if not (isinstance(arg, VALUE_TYPE_EXPRESSIONS) or (isinstance(arg, Path) and arg.path.singular_query()) or self._function_return_type(arg) == ExpressionType.VALUE):\n                    raise JSONPathTypeError(f'{token.value}() argument {idx} must be of ValueType', token=token)\n            elif typ == ExpressionType.LOGICAL:\n                if not isinstance(arg, (Path, InfixExpression)):\n                    raise JSONPathTypeError(f'{token.value}() argument {idx} must be of LogicalType', token=token)\n            elif typ == ExpressionType.NODES and (not (isinstance(arg, Path) or self._function_return_type(arg) == ExpressionType.NODES)):\n                raise JSONPathTypeError(f'{token.value}() argument {idx} must be of NodesType', token=token)\n\n    def _function_return_type(self, expr: FilterExpression) -> Optional[ExpressionType]:\n        \"\"\"Return the type returned from a filter function.\n\n        If _expr_ is not a `FunctionExtension` or the registered function definition is\n        not type-aware, return `None`.\n        \"\"\"\n        if not isinstance(expr, FunctionExtension):\n            return None\n        func = self.function_extensions.get(expr.name)\n        if isinstance(func, FilterFunction):\n            return func.return_type\n        return None\n\n    def getitem(self, obj: Any, key: Any) -> Any:\n        \"\"\"Sequence and mapping item getter used throughout JSONPath resolution.\n\n        The default implementation of `getitem` simply calls `operators.getitem()`\n        from Python's standard library. Same as `obj[key]`.\n\n        Arguments:\n            obj: A mapping or sequence that might contain _key_.\n            key: A mapping key, sequence index or sequence slice.\n        \"\"\"\n        return getitem(obj, key)\n\n    async def getitem_async(self, obj: Any, key: object) -> Any:\n        \"\"\"An async sequence and mapping item getter.\"\"\"\n        if hasattr(obj, '__getitem_async__'):\n            return await obj.__getitem_async__(key)\n        return getitem(obj, key)\n\n    def is_truthy(self, obj: object) -> bool:\n        \"\"\"Test for truthiness when evaluating JSONPath filter expressions.\n\n        In some cases, RFC 9535 requires us to test for existence rather than\n        truthiness. So the default implementation returns `True` for empty\n        collections and `None`. The special `UNDEFINED` object means that\n        _obj_ was missing, as opposed to an explicit `None`.\n\n        Arguments:\n            obj: Any object.\n\n        Returns:\n            `True` if the object exists and is not `False` or `0`.\n        \"\"\"\n        if isinstance(obj, NodeList) and len(obj) == 0:\n            return False\n        if obj is UNDEFINED:\n            return False\n        if obj is None:\n            return True\n        return bool(obj)\n\n    def compare(self, left: object, operator: str, right: object) -> bool:\n        \"\"\"Object comparison within JSONPath filters.\n\n        Override this to customize filter expression comparison operator\n        behavior.\n\n        Args:\n            left: The left hand side of the comparison expression.\n            operator: The comparison expression's operator.\n            right: The right hand side of the comparison expression.\n\n        Returns:\n            `True` if the comparison between _left_ and _right_, with the\n            given _operator_, is truthy. `False` otherwise.\n        \"\"\"\n        if operator == '&&':\n            return self.is_truthy(left) and self.is_truthy(right)\n        if operator == '||':\n            return self.is_truthy(left) or self.is_truthy(right)\n        if operator == '==':\n            return self._eq(left, right)\n        if operator == '!=':\n            return not self._eq(left, right)\n        if operator == '<':\n            return self._lt(left, right)\n        if operator == '>':\n            return self._lt(right, left)\n        if operator == '>=':\n            return self._lt(right, left) or self._eq(left, right)\n        if operator == '<=':\n            return self._lt(left, right) or self._eq(left, right)\n        if operator == 'in' and isinstance(right, (Mapping, Sequence)):\n            return left in right\n        if operator == 'contains' and isinstance(left, (Mapping, Sequence)):\n            return right in left\n        if operator == '=~' and isinstance(right, re.Pattern) and isinstance(left, str):\n            return bool(right.fullmatch(left))\n        return False\n\n    def _eq(self, left: object, right: object) -> bool:\n        if isinstance(right, NodeList):\n            left, right = (right, left)\n        if isinstance(left, NodeList):\n            if isinstance(right, NodeList):\n                return left == right\n            if left.empty():\n                return right is UNDEFINED\n            if len(left) == 1:\n                return left[0] == right\n            return False\n        if left is UNDEFINED and right is UNDEFINED:\n            return True\n        if isinstance(right, bool):\n            left, right = (right, left)\n        if isinstance(left, bool):\n            return isinstance(right, bool) and left == right\n        return left == right\n\n    def _lt(self, left: object, right: object) -> bool:\n        if isinstance(left, str) and isinstance(right, str):\n            return left < right\n        if isinstance(left, (int, float, Decimal)) and isinstance(right, (int, float, Decimal)):\n            return left < right\n        return False",
    "jsonpath/filter.py": "\"\"\"Filter expression nodes.\"\"\"\nfrom __future__ import annotations\nimport copy\nimport json\nimport re\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Generic\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Pattern\nfrom typing import Sequence\nfrom typing import TypeVar\nfrom jsonpath.function_extensions.filter_function import ExpressionType\nfrom .exceptions import JSONPathTypeError\nfrom .function_extensions import FilterFunction\nfrom .match import NodeList\nfrom .selectors import Filter as FilterSelector\nfrom .selectors import ListSelector\nif TYPE_CHECKING:\n    from .path import JSONPath\n    from .selectors import FilterContext\n\nclass FilterExpression(ABC):\n    \"\"\"Base class for all filter expression nodes.\"\"\"\n    __slots__ = ('volatile',)\n    FORCE_CACHE = False\n\n    def __init__(self) -> None:\n        self.volatile: bool = any((child.volatile for child in self.children()))\n\n    @abstractmethod\n    def evaluate(self, context: FilterContext) -> object:\n        \"\"\"Resolve the filter expression in the given _context_.\n\n        Arguments:\n            context: Contextual information the expression might choose\n                use during evaluation.\n\n        Returns:\n            The result of evaluating the expression.\n        \"\"\"\n\n    @abstractmethod\n    async def evaluate_async(self, context: FilterContext) -> object:\n        \"\"\"An async version of `evaluate`.\"\"\"\n\n    @abstractmethod\n    def children(self) -> List[FilterExpression]:\n        \"\"\"Return a list of direct child expressions.\"\"\"\n\n    @abstractmethod\n    def set_children(self, children: List[FilterExpression]) -> None:\n        \"\"\"Update this expression's child expressions.\n\n        _children_ is assumed to have the same number of items as is returned\n        by _self.children_, and in the same order.\n        \"\"\"\n\nclass Nil(FilterExpression):\n    \"\"\"The constant `nil`.\n\n    Also aliased as `null` and `None`, sometimes.\n    \"\"\"\n    __slots__ = ()\n\n    def __eq__(self, other: object) -> bool:\n        return other is None or isinstance(other, Nil)\n\n    def __repr__(self) -> str:\n        return 'NIL()'\n\n    def __str__(self) -> str:\n        return 'nil'\n\n    def evaluate(self, _: FilterContext) -> None:\n        return None\n\n    async def evaluate_async(self, _: FilterContext) -> None:\n        return None\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        return\nNIL = Nil()\n\nclass _Undefined:\n    __slots__ = ()\n\n    def __eq__(self, other: object) -> bool:\n        return other is UNDEFINED_LITERAL or other is UNDEFINED or (isinstance(other, NodeList) and other.empty())\n\n    def __str__(self) -> str:\n        return '<UNDEFINED>'\n\n    def __repr__(self) -> str:\n        return '<UNDEFINED>'\nUNDEFINED = _Undefined()\n\nclass Undefined(FilterExpression):\n    \"\"\"The constant `undefined`.\"\"\"\n    __slots__ = ()\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, Undefined) or other is UNDEFINED or (isinstance(other, NodeList) and len(other) == 0)\n\n    def __str__(self) -> str:\n        return 'undefined'\n\n    def evaluate(self, _: FilterContext) -> object:\n        return UNDEFINED\n\n    async def evaluate_async(self, _: FilterContext) -> object:\n        return UNDEFINED\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        return\nUNDEFINED_LITERAL = Undefined()\nLITERAL_EXPRESSION_T = TypeVar('LITERAL_EXPRESSION_T')\n\nclass Literal(FilterExpression, Generic[LITERAL_EXPRESSION_T]):\n    \"\"\"Base class for filter expression literals.\"\"\"\n    __slots__ = ('value',)\n\n    def __init__(self, *, value: LITERAL_EXPRESSION_T) -> None:\n        self.value = value\n        super().__init__()\n\n    def __str__(self) -> str:\n        return repr(self.value).lower()\n\n    def __eq__(self, other: object) -> bool:\n        return self.value == other\n\n    def __hash__(self) -> int:\n        return hash(self.value)\n\n    def evaluate(self, _: FilterContext) -> LITERAL_EXPRESSION_T:\n        return self.value\n\n    async def evaluate_async(self, _: FilterContext) -> LITERAL_EXPRESSION_T:\n        return self.value\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        return\n\nclass BooleanLiteral(Literal[bool]):\n    \"\"\"A Boolean `True` or `False`.\"\"\"\n    __slots__ = ()\nTRUE = BooleanLiteral(value=True)\nFALSE = BooleanLiteral(value=False)\n\nclass StringLiteral(Literal[str]):\n    \"\"\"A string literal.\"\"\"\n    __slots__ = ()\n\n    def __str__(self) -> str:\n        return json.dumps(self.value)\n\nclass IntegerLiteral(Literal[int]):\n    \"\"\"An integer literal.\"\"\"\n    __slots__ = ()\n\nclass FloatLiteral(Literal[float]):\n    \"\"\"A float literal.\"\"\"\n    __slots__ = ()\n\nclass RegexLiteral(Literal[Pattern[str]]):\n    \"\"\"A regex literal.\"\"\"\n    __slots__ = ()\n    RE_FLAG_MAP = {re.A: 'a', re.I: 'i', re.M: 'm', re.S: 's'}\n    RE_UNESCAPE = re.compile('\\\\\\\\(.)')\n\n    def __str__(self) -> str:\n        flags: List[str] = []\n        for flag, ch in self.RE_FLAG_MAP.items():\n            if self.value.flags & flag:\n                flags.append(ch)\n        pattern = re.sub('\\\\\\\\(.)', '\\\\1', self.value.pattern)\n        return f'/{pattern}/{''.join(flags)}'\n\nclass ListLiteral(FilterExpression):\n    \"\"\"A list literal.\"\"\"\n    __slots__ = ('items',)\n\n    def __init__(self, items: List[FilterExpression]) -> None:\n        self.items = items\n        super().__init__()\n\n    def __str__(self) -> str:\n        items = ', '.join((str(item) for item in self.items))\n        return f'[{items}]'\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, ListLiteral) and self.items == other.items\n\n    def evaluate(self, context: FilterContext) -> object:\n        return [item.evaluate(context) for item in self.items]\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return [await item.evaluate_async(context) for item in self.items]\n\n    def children(self) -> List[FilterExpression]:\n        return self.items\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        self.items = children\n\nclass PrefixExpression(FilterExpression):\n    \"\"\"An expression composed of a prefix operator and another expression.\"\"\"\n    __slots__ = ('operator', 'right')\n\n    def __init__(self, operator: str, right: FilterExpression):\n        self.operator = operator\n        self.right = right\n        super().__init__()\n\n    def __str__(self) -> str:\n        return f'{self.operator}{self.right}'\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, PrefixExpression) and self.operator == other.operator and (self.right == other.right)\n\n    def _evaluate(self, context: FilterContext, right: object) -> object:\n        if self.operator == '!':\n            return not context.env.is_truthy(right)\n        raise JSONPathTypeError(f'unknown operator {self.operator} {self.right}')\n\n    def evaluate(self, context: FilterContext) -> object:\n        return self._evaluate(context, self.right.evaluate(context))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return self._evaluate(context, await self.right.evaluate_async(context))\n\n    def children(self) -> List[FilterExpression]:\n        return [self.right]\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == 1\n        self.right = children[0]\n\nclass InfixExpression(FilterExpression):\n    \"\"\"A pair of expressions and a comparison or logical operator.\"\"\"\n    __slots__ = ('left', 'operator', 'right', 'logical')\n\n    def __init__(self, left: FilterExpression, operator: str, right: FilterExpression):\n        self.left = left\n        self.operator = operator\n        self.right = right\n        self.logical = operator in ('&&', '||')\n        super().__init__()\n\n    def __str__(self) -> str:\n        if self.logical:\n            return f'({self.left} {self.operator} {self.right})'\n        return f'{self.left} {self.operator} {self.right}'\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, InfixExpression) and self.left == other.left and (self.operator == other.operator) and (self.right == other.right)\n\n    def evaluate(self, context: FilterContext) -> bool:\n        left = self.left.evaluate(context)\n        if not self.logical and isinstance(left, NodeList) and (len(left) == 1):\n            left = left[0].obj\n        right = self.right.evaluate(context)\n        if not self.logical and isinstance(right, NodeList) and (len(right) == 1):\n            right = right[0].obj\n        return context.env.compare(left, self.operator, right)\n\n    async def evaluate_async(self, context: FilterContext) -> bool:\n        left = await self.left.evaluate_async(context)\n        if not self.logical and isinstance(left, NodeList) and (len(left) == 1):\n            left = left[0].obj\n        right = await self.right.evaluate_async(context)\n        if not self.logical and isinstance(right, NodeList) and (len(right) == 1):\n            right = right[0].obj\n        return context.env.compare(left, self.operator, right)\n\n    def children(self) -> List[FilterExpression]:\n        return [self.left, self.right]\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == 2\n        self.left = children[0]\n        self.right = children[1]\n\nclass BooleanExpression(FilterExpression):\n    \"\"\"An expression that always evaluates to `True` or `False`.\"\"\"\n    __slots__ = ('expression',)\n\n    def __init__(self, expression: FilterExpression):\n        self.expression = expression\n        super().__init__()\n\n    def cache_tree(self) -> BooleanExpression:\n        \"\"\"Return a copy of _self.expression_ augmented with caching nodes.\"\"\"\n\n        def _cache_tree(expr: FilterExpression) -> FilterExpression:\n            children = expr.children()\n            if expr.volatile:\n                _expr = copy.copy(expr)\n            elif not expr.FORCE_CACHE and len(children) == 0:\n                _expr = expr\n            else:\n                _expr = CachingFilterExpression(copy.copy(expr))\n            _expr.set_children([_cache_tree(child) for child in children])\n            return _expr\n        return BooleanExpression(_cache_tree(copy.copy(self.expression)))\n\n    def cacheable_nodes(self) -> bool:\n        \"\"\"Return `True` if there are any cacheable nodes in this expression tree.\"\"\"\n        return any((isinstance(node, CachingFilterExpression) for node in walk(self.cache_tree())))\n\n    def __str__(self) -> str:\n        return str(self.expression)\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, BooleanExpression) and self.expression == other.expression\n\n    def evaluate(self, context: FilterContext) -> bool:\n        return context.env.is_truthy(self.expression.evaluate(context))\n\n    async def evaluate_async(self, context: FilterContext) -> bool:\n        return context.env.is_truthy(await self.expression.evaluate_async(context))\n\n    def children(self) -> List[FilterExpression]:\n        return [self.expression]\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == 1\n        self.expression = children[0]\n\nclass CachingFilterExpression(FilterExpression):\n    \"\"\"A FilterExpression wrapper that caches the result.\"\"\"\n    __slots__ = ('_cached', '_expr')\n    _UNSET = object()\n\n    def __init__(self, expression: FilterExpression):\n        self.volatile = False\n        self._expr = expression\n        self._cached: object = self._UNSET\n\n    def evaluate(self, context: FilterContext) -> object:\n        if self._cached is self._UNSET:\n            self._cached = self._expr.evaluate(context)\n        return self._cached\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        if self._cached is self._UNSET:\n            self._cached = await self._expr.evaluate_async(context)\n        return self._cached\n\n    def children(self) -> List[FilterExpression]:\n        return self._expr.children()\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        self._expr.set_children(children)\n\nclass Path(FilterExpression, ABC):\n    \"\"\"Base expression for all _sub paths_ found in filter expressions.\"\"\"\n    __slots__ = ('path',)\n\n    def __init__(self, path: JSONPath) -> None:\n        self.path = path\n        super().__init__()\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, Path) and str(self) == str(other)\n\n    def children(self) -> List[FilterExpression]:\n        _children: List[FilterExpression] = []\n        for segment in self.path.selectors:\n            if isinstance(segment, ListSelector):\n                _children.extend((selector.expression for selector in segment.items if isinstance(selector, FilterSelector)))\n        return _children\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        return\n\nclass SelfPath(Path):\n    \"\"\"A JSONPath starting at the current node.\"\"\"\n    __slots__ = ()\n\n    def __init__(self, path: JSONPath) -> None:\n        super().__init__(path)\n        self.volatile = True\n\n    def __str__(self) -> str:\n        return '@' + str(self.path)[1:]\n\n    def evaluate(self, context: FilterContext) -> object:\n        if isinstance(context.current, str):\n            if self.path.empty():\n                return context.current\n            return NodeList()\n        if not isinstance(context.current, (Sequence, Mapping)):\n            if self.path.empty():\n                return context.current\n            return NodeList()\n        return NodeList(self.path.finditer(context.current))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        if isinstance(context.current, str):\n            if self.path.empty():\n                return context.current\n            return NodeList()\n        if not isinstance(context.current, (Sequence, Mapping)):\n            if self.path.empty():\n                return context.current\n            return NodeList()\n        return NodeList([match async for match in await self.path.finditer_async(context.current)])\n\nclass RootPath(Path):\n    \"\"\"A JSONPath starting at the root node.\"\"\"\n    __slots__ = ()\n    FORCE_CACHE = True\n\n    def __init__(self, path: JSONPath) -> None:\n        super().__init__(path)\n        self.volatile = False\n\n    def __str__(self) -> str:\n        return str(self.path)\n\n    def evaluate(self, context: FilterContext) -> object:\n        return NodeList(self.path.finditer(context.root))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return NodeList([match async for match in await self.path.finditer_async(context.root)])\n\nclass FilterContextPath(Path):\n    \"\"\"A JSONPath starting at the root of any extra context data.\"\"\"\n    __slots__ = ()\n    FORCE_CACHE = True\n\n    def __init__(self, path: JSONPath) -> None:\n        super().__init__(path)\n        self.volatile = False\n\n    def __str__(self) -> str:\n        path_repr = str(self.path)\n        return '_' + path_repr[1:]\n\n    def evaluate(self, context: FilterContext) -> object:\n        return NodeList(self.path.finditer(context.extra_context))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return NodeList([match async for match in await self.path.finditer_async(context.extra_context)])\n\nclass FunctionExtension(FilterExpression):\n    \"\"\"A filter function.\"\"\"\n    __slots__ = ('name', 'args')\n\n    def __init__(self, name: str, args: Sequence[FilterExpression]) -> None:\n        self.name = name\n        self.args = args\n        super().__init__()\n\n    def __str__(self) -> str:\n        args = [str(arg) for arg in self.args]\n        return f'{self.name}({', '.join(args)})'\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, FunctionExtension) and other.name == self.name and (other.args == self.args)\n\n    def evaluate(self, context: FilterContext) -> object:\n        try:\n            func = context.env.function_extensions[self.name]\n        except KeyError:\n            return UNDEFINED\n        args = [arg.evaluate(context) for arg in self.args]\n        return func(*self._unpack_node_lists(func, args))\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        try:\n            func = context.env.function_extensions[self.name]\n        except KeyError:\n            return UNDEFINED\n        args = [await arg.evaluate_async(context) for arg in self.args]\n        return func(*self._unpack_node_lists(func, args))\n\n    def _unpack_node_lists(self, func: Callable[..., Any], args: List[object]) -> List[object]:\n        if isinstance(func, FilterFunction):\n            _args: List[object] = []\n            for idx, arg in enumerate(args):\n                if func.arg_types[idx] != ExpressionType.NODES and isinstance(arg, NodeList):\n                    if len(arg) == 0:\n                        _args.append(UNDEFINED)\n                    elif len(arg) == 1:\n                        _args.append(arg[0].obj)\n                    else:\n                        _args.append(arg)\n                else:\n                    _args.append(arg)\n            return _args\n        if getattr(func, 'with_node_lists', False):\n            return args\n        return [obj.values_or_singular() if isinstance(obj, NodeList) else obj for obj in args]\n\n    def children(self) -> List[FilterExpression]:\n        return list(self.args)\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        assert len(children) == len(self.args)\n        self.args = children\n\nclass CurrentKey(FilterExpression):\n    \"\"\"The key/property or index associated with the current object.\"\"\"\n    __slots__ = ()\n\n    def __init__(self) -> None:\n        super().__init__()\n        self.volatile = True\n\n    def __str__(self) -> str:\n        return '#'\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, CurrentKey)\n\n    def evaluate(self, context: FilterContext) -> object:\n        if context.current_key is None:\n            return UNDEFINED\n        return context.current_key\n\n    async def evaluate_async(self, context: FilterContext) -> object:\n        return self.evaluate(context)\n\n    def children(self) -> List[FilterExpression]:\n        return []\n\n    def set_children(self, children: List[FilterExpression]) -> None:\n        return\nCURRENT_KEY = CurrentKey()\n\ndef walk(expr: FilterExpression) -> Iterable[FilterExpression]:\n    \"\"\"Walk the filter expression tree starting at _expr_.\"\"\"\n    yield expr\n    for child in expr.children():\n        yield from walk(child)\nVALUE_TYPE_EXPRESSIONS = (Nil, Undefined, Literal, ListLiteral, CurrentKey)",
    "jsonpath/path.py": "from __future__ import annotations\nimport itertools\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import AsyncIterable\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import TypeVar\nfrom typing import Union\nfrom jsonpath._data import load_data\nfrom jsonpath.fluent_api import Query\nfrom jsonpath.match import FilterContextVars\nfrom jsonpath.match import JSONPathMatch\nfrom jsonpath.selectors import IndexSelector\nfrom jsonpath.selectors import ListSelector\nfrom jsonpath.selectors import PropertySelector\nif TYPE_CHECKING:\n    from io import IOBase\n    from .env import JSONPathEnvironment\n    from .selectors import JSONPathSelector\n\nclass JSONPath:\n    \"\"\"A compiled JSONPath ready to be applied to a JSON string or Python object.\n\n    Arguments:\n        env: The `JSONPathEnvironment` this path is bound to.\n        selectors: An iterable of `JSONPathSelector` objects, as generated by\n            a `Parser`.\n        fake_root: Indicates if target JSON values should be wrapped in a single-\n            element array, so as to make the target root value selectable.\n\n\n    Attributes:\n        env: The `JSONPathEnvironment` this path is bound to.\n        selectors: The `JSONPathSelector` instances that make up this path.\n    \"\"\"\n    __slots__ = ('env', 'fake_root', 'selectors')\n\n    def __init__(self, *, env: JSONPathEnvironment, selectors: Iterable[JSONPathSelector], fake_root: bool=False) -> None:\n        self.env = env\n        self.selectors = tuple(selectors)\n        self.fake_root = fake_root\n\n    def __str__(self) -> str:\n        return self.env.root_token + ''.join((str(selector) for selector in self.selectors))\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, JSONPath) and self.selectors == __value.selectors\n\n    def __hash__(self) -> int:\n        return hash(self.selectors)\n\n    def finditer(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        _data = load_data(data)\n        matches: Iterable[JSONPathMatch] = [JSONPathMatch(filter_context=filter_context or {}, obj=[_data] if self.fake_root else _data, parent=None, path=self.env.root_token, parts=(), root=_data)]\n        for selector in self.selectors:\n            matches = selector.resolve(matches)\n        return matches\n\n    async def finditer_async(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `finditer()`.\"\"\"\n        _data = load_data(data)\n\n        async def root_iter() -> AsyncIterable[JSONPathMatch]:\n            yield self.env.match_class(filter_context=filter_context or {}, obj=[_data] if self.fake_root else _data, parent=None, path=self.env.root_token, parts=(), root=_data)\n        matches: AsyncIterable[JSONPathMatch] = root_iter()\n        for selector in self.selectors:\n            matches = selector.resolve_async(matches)\n        return matches\n\n    def match(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Union[JSONPathMatch, None]:\n        \"\"\"Return a `JSONPathMatch` instance for the first object found in _data_.\n\n        `None` is returned if there are no matches.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A `JSONPathMatch` object for the first match, or `None` if there were\n                no matches.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        try:\n            return next(iter(self.finditer(data, filter_context=filter_context)))\n        except StopIteration:\n            return None\n\n    def query(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Query:\n        \"\"\"Return a `Query` iterator over matches found by applying this path to _data_.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A query iterator.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return Query(self.finditer(data, filter_context=filter_context), self.env)\n\n    def empty(self) -> bool:\n        \"\"\"Return `True` if this path has no selectors.\"\"\"\n        return not bool(self.selectors)\n\n    def singular_query(self) -> bool:\n        \"\"\"Return `True` if this JSONPath query is a singular query.\"\"\"\n        for selector in self.selectors:\n            if isinstance(selector, (PropertySelector, IndexSelector)):\n                continue\n            if isinstance(selector, ListSelector) and len(selector.items) == 1 and isinstance(selector.items[0], (PropertySelector, IndexSelector)):\n                continue\n            return False\n        return True\n\nclass CompoundJSONPath:\n    \"\"\"Multiple `JSONPath`s combined.\"\"\"\n    __slots__ = ('env', 'path', 'paths')\n\n    def __init__(self, *, env: JSONPathEnvironment, path: Union[JSONPath, CompoundJSONPath], paths: Iterable[Tuple[str, JSONPath]]=()) -> None:\n        self.env = env\n        self.path = path\n        self.paths = tuple(paths)\n\n    def __str__(self) -> str:\n        buf: List[str] = [str(self.path)]\n        for op, path in self.paths:\n            buf.append(f' {op} ')\n            buf.append(str(path))\n        return ''.join(buf)\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, CompoundJSONPath) and self.path == __value.path and (self.paths == __value.paths)\n\n    def __hash__(self) -> int:\n        return hash((self.path, self.paths))\n\n    def findall(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:\n        \"\"\"Find all objects in `data` matching the given JSONPath `path`.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A list of matched objects. If there are no matches, the list will\n                be empty.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        objs = self.path.findall(data, filter_context=filter_context)\n        for op, path in self.paths:\n            _objs = path.findall(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                objs.extend(_objs)\n            else:\n                assert op == self.env.intersection_token, op\n                objs = [obj for obj in objs if obj in _objs]\n        return objs\n\n    def finditer(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Iterable[JSONPathMatch]:\n        \"\"\"Generate `JSONPathMatch` objects for each match.\n\n        If `data` is a string or a file-like objects, it will be loaded\n        using `json.loads()` and the default `JSONDecoder`.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            An iterator yielding `JSONPathMatch` objects for each match.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        matches = self.path.finditer(data, filter_context=filter_context)\n        for op, path in self.paths:\n            _matches = path.finditer(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                matches = itertools.chain(matches, _matches)\n            else:\n                assert op == self.env.intersection_token\n                _objs = [match.obj for match in _matches]\n                matches = (match for match in matches if match.obj in _objs)\n        return matches\n\n    def match(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Union[JSONPathMatch, None]:\n        \"\"\"Return a `JSONPathMatch` instance for the first object found in _data_.\n\n        `None` is returned if there are no matches.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A `JSONPathMatch` object for the first match, or `None` if there were\n                no matches.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        try:\n            return next(iter(self.finditer(data, filter_context=filter_context)))\n        except StopIteration:\n            return None\n\n    async def findall_async(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> List[object]:\n        \"\"\"An async version of `findall()`.\"\"\"\n        objs = await self.path.findall_async(data, filter_context=filter_context)\n        for op, path in self.paths:\n            _objs = await path.findall_async(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                objs.extend(_objs)\n            else:\n                assert op == self.env.intersection_token\n                objs = [obj for obj in objs if obj in _objs]\n        return objs\n\n    async def finditer_async(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `finditer()`.\"\"\"\n        matches = await self.path.finditer_async(data, filter_context=filter_context)\n        for op, path in self.paths:\n            _matches = await path.finditer_async(data, filter_context=filter_context)\n            if op == self.env.union_token:\n                matches = _achain(matches, _matches)\n            else:\n                assert op == self.env.intersection_token\n                _objs = [match.obj async for match in _matches]\n                matches = (match async for match in matches if match.obj in _objs)\n        return matches\n\n    def query(self, data: Union[str, IOBase, Sequence[Any], Mapping[str, Any]], *, filter_context: Optional[FilterContextVars]=None) -> Query:\n        \"\"\"Return a `Query` iterator over matches found by applying this path to _data_.\n\n        Arguments:\n            data: A JSON document or Python object implementing the `Sequence`\n                or `Mapping` interfaces.\n            filter_context: Arbitrary data made available to filters using\n                the _filter context_ selector.\n\n        Returns:\n            A query iterator.\n\n        Raises:\n            JSONPathSyntaxError: If the path is invalid.\n            JSONPathTypeError: If a filter expression attempts to use types in\n                an incompatible way.\n        \"\"\"\n        return Query(self.finditer(data, filter_context=filter_context), self.env)\n\n    def union(self, path: JSONPath) -> CompoundJSONPath:\n        \"\"\"Union of this path and another path.\"\"\"\n        return self.__class__(env=self.env, path=self.path, paths=self.paths + ((self.env.union_token, path),))\n\n    def intersection(self, path: JSONPath) -> CompoundJSONPath:\n        \"\"\"Intersection of this path and another path.\"\"\"\n        return self.__class__(env=self.env, path=self.path, paths=self.paths + ((self.env.intersection_token, path),))\nT = TypeVar('T')\n\nasync def _achain(*iterables: AsyncIterable[T]) -> AsyncIterable[T]:\n    for it in iterables:\n        async for element in it:\n            yield element",
    "jsonpath/match.py": "\"\"\"The JSONPath match object, as returned from `JSONPath.finditer()`.\"\"\"\nfrom __future__ import annotations\nfrom typing import Any\nfrom typing import List\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import Union\nfrom .pointer import JSONPointer\nFilterContextVars = Mapping[str, Any]\nPathPart = Union[int, str]\n\nclass JSONPathMatch:\n    \"\"\"A matched object with a concrete path.\n\n    Attributes:\n        children: Matched child nodes. This will only be populated after\n            all children have been visited, usually by using `findall()`\n            or `list(finditer())`.\n        obj: The matched object.\n        parent: The immediate parent to this match in the JSON document.\n            If this is the root node, _parent_ will be `None`.\n        path: The canonical string representation of the path to this match.\n        parts: The keys, indices and/or slices that make up the path to this\n            match.\n        root: A reference to the root node in the JSON document.\n    \"\"\"\n    __slots__ = ('_filter_context', 'children', 'obj', 'parent', 'parts', 'path', 'root')\n    pointer_class = JSONPointer\n\n    def __init__(self, *, filter_context: FilterContextVars, obj: object, parent: Optional[JSONPathMatch], path: str, parts: Tuple[PathPart, ...], root: Union[Sequence[Any], Mapping[str, Any]]) -> None:\n        self._filter_context = filter_context\n        self.children: List[JSONPathMatch] = []\n        self.obj: object = obj\n        self.parent: Optional[JSONPathMatch] = parent\n        self.parts: Tuple[PathPart, ...] = parts\n        self.path: str = path\n        self.root: Union[Sequence[Any], Mapping[str, Any]] = root\n\n    def __str__(self) -> str:\n        return f'{_truncate(str(self.obj), 5)!r} @ {_truncate(self.path, 5)}'\n\n    def add_child(self, *children: JSONPathMatch) -> None:\n        \"\"\"Append one or more children to this match.\"\"\"\n        self.children.extend(children)\n\n    def filter_context(self) -> FilterContextVars:\n        \"\"\"Return filter context data for this match.\"\"\"\n        return self._filter_context\n\n    def pointer(self) -> JSONPointer:\n        \"\"\"Return a `JSONPointer` pointing to this match's path.\"\"\"\n        return JSONPointer.from_match(self)\n\n    @property\n    def value(self) -> object:\n        \"\"\"Return the value associated with this match/node.\"\"\"\n        return self.obj\n\ndef _truncate(val: str, num: int, end: str='...') -> str:\n    words = val.split()\n    if len(words) < num:\n        return ' '.join(words)\n    return ' '.join(words[:num]) + end\n\nclass NodeList(List[JSONPathMatch]):\n    \"\"\"List of JSONPathMatch objects, analogous to the spec's nodelist.\"\"\"\n\n    def values(self) -> List[object]:\n        \"\"\"Return the values from this node list.\"\"\"\n        return [match.obj for match in self]\n\n    def values_or_singular(self) -> object:\n        \"\"\"Return the values from this node list.\"\"\"\n        if len(self) == 1:\n            return self[0].obj\n        return [match.obj for match in self]\n\n    def empty(self) -> bool:\n        \"\"\"Return `True` if this node list is empty.\"\"\"\n        return not bool(self)\n\n    def __str__(self) -> str:\n        return f'NodeList{super().__str__()}'",
    "jsonpath/selectors.py": "\"\"\"JSONPath segments and selectors, as returned from `Parser.parse`.\"\"\"\nfrom __future__ import annotations\nfrom abc import ABC\nfrom abc import abstractmethod\nfrom collections.abc import Mapping\nfrom collections.abc import Sequence\nfrom contextlib import suppress\nfrom typing import TYPE_CHECKING\nfrom typing import Any\nfrom typing import AsyncIterable\nfrom typing import Iterable\nfrom typing import List\nfrom typing import Optional\nfrom typing import TypeVar\nfrom typing import Union\nfrom .exceptions import JSONPathIndexError\nfrom .exceptions import JSONPathTypeError\nif TYPE_CHECKING:\n    from .env import JSONPathEnvironment\n    from .filter import BooleanExpression\n    from .match import JSONPathMatch\n    from .token import Token\n\nclass JSONPathSelector(ABC):\n    \"\"\"Base class for all JSONPath segments and selectors.\"\"\"\n    __slots__ = ('env', 'token')\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token) -> None:\n        self.env = env\n        self.token = token\n\n    @abstractmethod\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        \"\"\"Apply the segment/selector to each node in _matches_.\n\n        Arguments:\n            matches: Nodes matched by preceding segments/selectors. This is like\n                a lazy _NodeList_, as described in RFC 9535, but each match carries\n                more than the node's value and location.\n\n        Returns:\n            The `JSONPathMatch` instances created by applying this selector to each\n            preceding node.\n        \"\"\"\n\n    @abstractmethod\n    def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        \"\"\"An async version of `resolve`.\"\"\"\n\nclass PropertySelector(JSONPathSelector):\n    \"\"\"A shorthand or bracketed property selector.\"\"\"\n    __slots__ = ('name', 'shorthand')\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, name: str, shorthand: bool) -> None:\n        super().__init__(env=env, token=token)\n        self.name = name\n        self.shorthand = shorthand\n\n    def __str__(self) -> str:\n        return f\"['{self.name}']\" if self.shorthand else f\"'{self.name}'\"\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, PropertySelector) and self.name == __value.name and (self.token == __value.token)\n\n    def __hash__(self) -> int:\n        return hash((self.name, self.token))\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if not isinstance(match.obj, Mapping):\n                continue\n            with suppress(KeyError):\n                _match = self.env.match_class(filter_context=match.filter_context(), obj=self.env.getitem(match.obj, self.name), parent=match, parts=match.parts + (self.name,), path=match.path + f\"['{self.name}']\", root=match.root)\n                match.add_child(_match)\n                yield _match\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if not isinstance(match.obj, Mapping):\n                continue\n            with suppress(KeyError):\n                _match = self.env.match_class(filter_context=match.filter_context(), obj=await self.env.getitem_async(match.obj, self.name), parent=match, parts=match.parts + (self.name,), path=match.path + f\"['{self.name}']\", root=match.root)\n                match.add_child(_match)\n                yield _match\n\nclass IndexSelector(JSONPathSelector):\n    \"\"\"Select an element from an array by index.\n\n    Considering we don't require mapping (JSON object) keys/properties to\n    be quoted, and that we support mappings with numeric keys, we also check\n    to see if the \"index\" is a mapping key, which is non-standard.\n    \"\"\"\n    __slots__ = ('index', '_as_key')\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, index: int) -> None:\n        if index < env.min_int_index or index > env.max_int_index:\n            raise JSONPathIndexError('index out of range', token=token)\n        super().__init__(env=env, token=token)\n        self.index = index\n        self._as_key = str(self.index)\n\n    def __str__(self) -> str:\n        return str(self.index)\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, IndexSelector) and self.index == __value.index and (self.token == __value.token)\n\n    def __hash__(self) -> int:\n        return hash((self.index, self.token))\n\n    def _normalized_index(self, obj: Sequence[object]) -> int:\n        if self.index < 0 and len(obj) >= abs(self.index):\n            return len(obj) + self.index\n        return self.index\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if isinstance(match.obj, Mapping):\n                with suppress(KeyError):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=self.env.getitem(match.obj, self._as_key), parent=match, parts=match.parts + (self._as_key,), path=f\"{match.path}['{self.index}']\", root=match.root)\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence) and (not isinstance(match.obj, str)):\n                norm_index = self._normalized_index(match.obj)\n                with suppress(IndexError):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=self.env.getitem(match.obj, self.index), parent=match, parts=match.parts + (norm_index,), path=match.path + f'[{norm_index}]', root=match.root)\n                    match.add_child(_match)\n                    yield _match\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if isinstance(match.obj, Mapping):\n                with suppress(KeyError):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=await self.env.getitem_async(match.obj, self._as_key), parent=match, parts=match.parts + (self._as_key,), path=f\"{match.path}['{self.index}']\", root=match.root)\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence) and (not isinstance(match.obj, str)):\n                norm_index = self._normalized_index(match.obj)\n                with suppress(IndexError):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=await self.env.getitem_async(match.obj, self.index), parent=match, parts=match.parts + (norm_index,), path=match.path + f'[{norm_index}]', root=match.root)\n                    match.add_child(_match)\n                    yield _match\n\nclass KeysSelector(JSONPathSelector):\n    \"\"\"Select mapping/object keys/properties.\n\n    NOTE: This is a non-standard selector.\n    \"\"\"\n    __slots__ = ('shorthand',)\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, shorthand: bool) -> None:\n        super().__init__(env=env, token=token)\n        self.shorthand = shorthand\n\n    def __str__(self) -> str:\n        return f'[{self.env.keys_selector_token}]' if self.shorthand else self.env.keys_selector_token\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, KeysSelector) and self.token == __value.token\n\n    def __hash__(self) -> int:\n        return hash(self.token)\n\n    def _keys(self, match: JSONPathMatch) -> Iterable[JSONPathMatch]:\n        if isinstance(match.obj, Mapping):\n            for i, key in enumerate(match.obj.keys()):\n                _match = self.env.match_class(filter_context=match.filter_context(), obj=key, parent=match, parts=match.parts + (f'{self.env.keys_selector_token}{key}',), path=f'{match.path}[{self.env.keys_selector_token}][{i}]', root=match.root)\n                match.add_child(_match)\n                yield _match\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            yield from self._keys(match)\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            for _match in self._keys(match):\n                yield _match\n\nclass SliceSelector(JSONPathSelector):\n    \"\"\"Sequence slicing selector.\"\"\"\n    __slots__ = ('slice',)\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, start: Optional[int]=None, stop: Optional[int]=None, step: Optional[int]=None) -> None:\n        super().__init__(env=env, token=token)\n        self._check_range(start, stop, step)\n        self.slice = slice(start, stop, step)\n\n    def __str__(self) -> str:\n        stop = self.slice.stop if self.slice.stop is not None else ''\n        start = self.slice.start if self.slice.start is not None else ''\n        step = self.slice.step if self.slice.step is not None else '1'\n        return f'{start}:{stop}:{step}'\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, SliceSelector) and self.slice == __value.slice and (self.token == __value.token)\n\n    def __hash__(self) -> int:\n        return hash((str(self), self.token))\n\n    def _check_range(self, *indices: Optional[int]) -> None:\n        for i in indices:\n            if i is not None and (i < self.env.min_int_index or i > self.env.max_int_index):\n                raise JSONPathIndexError('index out of range', token=self.token)\n\n    def _normalized_index(self, obj: Sequence[object], index: int) -> int:\n        if index < 0 and len(obj) >= abs(index):\n            return len(obj) + index\n        return index\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if not isinstance(match.obj, Sequence) or self.slice.step == 0:\n                continue\n            idx = self.slice.start or 0\n            step = self.slice.step or 1\n            for obj in self.env.getitem(match.obj, self.slice):\n                norm_index = self._normalized_index(match.obj, idx)\n                _match = self.env.match_class(filter_context=match.filter_context(), obj=obj, parent=match, parts=match.parts + (norm_index,), path=f'{match.path}[{norm_index}]', root=match.root)\n                match.add_child(_match)\n                yield _match\n                idx += step\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if not isinstance(match.obj, Sequence) or self.slice.step == 0:\n                continue\n            idx = self.slice.start or 0\n            step = self.slice.step or 1\n            for obj in await self.env.getitem_async(match.obj, self.slice):\n                norm_index = self._normalized_index(match.obj, idx)\n                _match = self.env.match_class(filter_context=match.filter_context(), obj=obj, parent=match, parts=match.parts + (norm_index,), path=f'{match.path}[{norm_index}]', root=match.root)\n                match.add_child(_match)\n                yield _match\n                idx += step\n\nclass WildSelector(JSONPathSelector):\n    \"\"\"Select all items from a sequence/array or values from a mapping/object.\"\"\"\n    __slots__ = ('shorthand',)\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, shorthand: bool) -> None:\n        super().__init__(env=env, token=token)\n        self.shorthand = shorthand\n\n    def __str__(self) -> str:\n        return '[*]' if self.shorthand else '*'\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, WildSelector) and self.token == __value.token\n\n    def __hash__(self) -> int:\n        return hash(self.token)\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            if isinstance(match.obj, str):\n                continue\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (key,), path=match.path + f\"['{key}']\", root=match.root)\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence):\n                for i, val in enumerate(match.obj):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (i,), path=f'{match.path}[{i}]', root=match.root)\n                    match.add_child(_match)\n                    yield _match\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (key,), path=match.path + f\"['{key}']\", root=match.root)\n                    match.add_child(_match)\n                    yield _match\n            elif isinstance(match.obj, Sequence):\n                for i, val in enumerate(match.obj):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (i,), path=f'{match.path}[{i}]', root=match.root)\n                    match.add_child(_match)\n                    yield _match\n\nclass RecursiveDescentSelector(JSONPathSelector):\n    \"\"\"A JSONPath selector that visits all nodes recursively.\n\n    NOTE: Strictly this is a \"segment\", not a \"selector\".\n    \"\"\"\n\n    def __str__(self) -> str:\n        return '..'\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, RecursiveDescentSelector) and self.token == __value.token\n\n    def __hash__(self) -> int:\n        return hash(self.token)\n\n    def _expand(self, match: JSONPathMatch) -> Iterable[JSONPathMatch]:\n        if isinstance(match.obj, Mapping):\n            for key, val in match.obj.items():\n                if isinstance(val, str):\n                    pass\n                elif isinstance(val, (Mapping, Sequence)):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (key,), path=match.path + f\"['{key}']\", root=match.root)\n                    match.add_child(_match)\n                    yield _match\n                    yield from self._expand(_match)\n        elif isinstance(match.obj, Sequence) and (not isinstance(match.obj, str)):\n            for i, val in enumerate(match.obj):\n                if isinstance(val, str):\n                    pass\n                elif isinstance(val, (Mapping, Sequence)):\n                    _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (i,), path=f'{match.path}[{i}]', root=match.root)\n                    match.add_child(_match)\n                    yield _match\n                    yield from self._expand(_match)\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match in matches:\n            yield match\n            yield from self._expand(match)\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match in matches:\n            yield match\n            for _match in self._expand(match):\n                yield _match\nT = TypeVar('T')\n\nasync def _alist(it: List[T]) -> AsyncIterable[T]:\n    for item in it:\n        yield item\n\nclass ListSelector(JSONPathSelector):\n    \"\"\"A bracketed list of selectors, the results of which are concatenated together.\n\n    NOTE: Strictly this is a \"segment\", not a \"selector\".\n    \"\"\"\n    __slots__ = ('items',)\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, items: List[Union[SliceSelector, KeysSelector, IndexSelector, PropertySelector, WildSelector, Filter]]) -> None:\n        super().__init__(env=env, token=token)\n        self.items = tuple(items)\n\n    def __str__(self) -> str:\n        return f'[{', '.join((str(itm) for itm in self.items))}]'\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, ListSelector) and self.items == __value.items and (self.token == __value.token)\n\n    def __hash__(self) -> int:\n        return hash((self.items, self.token))\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        for match_ in matches:\n            for item in self.items:\n                yield from item.resolve([match_])\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        async for match_ in matches:\n            for item in self.items:\n                async for m in item.resolve_async(_alist([match_])):\n                    yield m\n\nclass Filter(JSONPathSelector):\n    \"\"\"Filter sequence/array items or mapping/object values with a filter expression.\"\"\"\n    __slots__ = ('expression', 'cacheable_nodes')\n\n    def __init__(self, *, env: JSONPathEnvironment, token: Token, expression: BooleanExpression) -> None:\n        super().__init__(env=env, token=token)\n        self.expression = expression\n        self.cacheable_nodes = self.expression.cacheable_nodes()\n\n    def __str__(self) -> str:\n        return f'?{self.expression}'\n\n    def __eq__(self, __value: object) -> bool:\n        return isinstance(__value, Filter) and self.expression == __value.expression and (self.token == __value.token)\n\n    def __hash__(self) -> int:\n        return hash((str(self.expression), self.token))\n\n    def resolve(self, matches: Iterable[JSONPathMatch]) -> Iterable[JSONPathMatch]:\n        if self.cacheable_nodes and self.env.filter_caching:\n            expr = self.expression.cache_tree()\n        else:\n            expr = self.expression\n        for match in matches:\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    context = FilterContext(env=self.env, current=val, root=match.root, extra_context=match.filter_context(), current_key=key)\n                    try:\n                        if expr.evaluate(context):\n                            _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (key,), path=match.path + f\"['{key}']\", root=match.root)\n                            match.add_child(_match)\n                            yield _match\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n            elif isinstance(match.obj, Sequence) and (not isinstance(match.obj, str)):\n                for i, obj in enumerate(match.obj):\n                    context = FilterContext(env=self.env, current=obj, root=match.root, extra_context=match.filter_context(), current_key=i)\n                    try:\n                        if expr.evaluate(context):\n                            _match = self.env.match_class(filter_context=match.filter_context(), obj=obj, parent=match, parts=match.parts + (i,), path=f'{match.path}[{i}]', root=match.root)\n                            match.add_child(_match)\n                            yield _match\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n\n    async def resolve_async(self, matches: AsyncIterable[JSONPathMatch]) -> AsyncIterable[JSONPathMatch]:\n        if self.cacheable_nodes and self.env.filter_caching:\n            expr = self.expression.cache_tree()\n        else:\n            expr = self.expression\n        async for match in matches:\n            if isinstance(match.obj, Mapping):\n                for key, val in match.obj.items():\n                    context = FilterContext(env=self.env, current=val, root=match.root, extra_context=match.filter_context(), current_key=key)\n                    try:\n                        result = await expr.evaluate_async(context)\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n                    if result:\n                        _match = self.env.match_class(filter_context=match.filter_context(), obj=val, parent=match, parts=match.parts + (key,), path=match.path + f\"['{key}']\", root=match.root)\n                        match.add_child(_match)\n                        yield _match\n            elif isinstance(match.obj, Sequence) and (not isinstance(match.obj, str)):\n                for i, obj in enumerate(match.obj):\n                    context = FilterContext(env=self.env, current=obj, root=match.root, extra_context=match.filter_context(), current_key=i)\n                    try:\n                        result = await expr.evaluate_async(context)\n                    except JSONPathTypeError as err:\n                        if not err.token:\n                            err.token = self.token\n                        raise\n                    if result:\n                        _match = self.env.match_class(filter_context=match.filter_context(), obj=obj, parent=match, parts=match.parts + (i,), path=f'{match.path}[{i}]', root=match.root)\n                        match.add_child(_match)\n                        yield _match\n\nclass FilterContext:\n    \"\"\"Contextual information and data for evaluating a filter expression.\"\"\"\n    __slots__ = ('current_key', 'current', 'env', 'extra_context', 'root')\n\n    def __init__(self, *, env: JSONPathEnvironment, current: object, root: Union[Sequence[Any], Mapping[str, Any]], extra_context: Optional[Mapping[str, Any]]=None, current_key: Union[str, int, None]=None) -> None:\n        self.env = env\n        self.current = current\n        self.root = root\n        self.extra_context = extra_context or {}\n        self.current_key = current_key\n\n    def __str__(self) -> str:\n        return f'FilterContext(current={self.current}, extra_context={self.extra_context!r})'"
  }
}