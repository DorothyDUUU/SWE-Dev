{
  "dir_path": "/app/skforecast",
  "package_name": "skforecast",
  "sample_name": "skforecast-test_extract_data_folds_multiseries",
  "src_dir": "skforecast/",
  "test_dir": "tests/",
  "test_file": "skforecast/model_selection/tests/tests_utils/test_extract_data_folds_multiseries.py",
  "test_code": "# Unit test _extract_data_folds_multiseries\n# ==============================================================================\nimport pytest\nimport numpy as np\nimport pandas as pd\nfrom skforecast.model_selection._utils import _extract_data_folds_multiseries\n\n# Fixtures\nseries = pd.DataFrame({\n    'l1': np.arange(50, dtype=float),\n    'l2': np.arange(50, 100, dtype=float),\n    'l3': np.arange(100, 150, dtype=float)\n})\nexog = pd.DataFrame({\n    'exog_1': np.arange(1000, 1050, dtype=float),\n    'exog_2': np.arange(1050, 1100, dtype=float),\n    'exog_3': np.arange(1100, 1150, dtype=float)\n})\n\n\n@pytest.mark.parametrize(\"dropna_last_window\", \n                         [True, False], \n                         ids=lambda dropna: f'dropna_last_window: {dropna}')\ndef test_extract_data_folds_multiseries_series_DataFrame_exog_None_RangeIndex(dropna_last_window):\n    \"\"\"\n    Test _extract_data_folds_multiseries with series DataFrame and exog None.\n    \"\"\"\n\n    # Train, last_window, test_no_gap\n    folds = [\n        [[0, 30], [25, 30], [30, 37]], \n        [[0, 35], [30, 35], [35, 42]]\n    ]\n    span_index = pd.RangeIndex(start=0, stop=50, step=1)\n    window_size = 5\n\n    data_folds = list(\n        _extract_data_folds_multiseries(\n            series             = series, \n            folds              = folds, \n            span_index         = span_index, \n            window_size        = window_size, \n            exog               = None, \n            dropna_last_window = dropna_last_window, \n            externally_fitted  = False\n        )\n    )\n\n    expected_data_folds = [\n        (\n            pd.DataFrame(\n                data = {'l1': np.arange(0, 30, dtype=float),\n                        'l2': np.arange(50, 80, dtype=float),\n                        'l3': np.arange(100, 130, dtype=float)\n                },\n                index = pd.RangeIndex(start=0, stop=30, step=1)\n            ), \n            pd.DataFrame(\n                data = {'l1': np.arange(25, 30, dtype=float),\n                        'l2': np.arange(75, 80, dtype=float),\n                        'l3': np.arange(125, 130, dtype=float)\n                },\n                index = pd.RangeIndex(start=25, stop=30, step=1)\n            ),\n            ['l1', 'l2', 'l3'],\n            None, \n            None, \n            folds[0]\n        ),\n        (\n            pd.DataFrame(\n                data = {'l1': np.arange(0, 35, dtype=float),\n                        'l2': np.arange(50, 85, dtype=float),\n                        'l3': np.arange(100, 135, dtype=float)\n                },\n                index = pd.RangeIndex(start=0, stop=35, step=1)\n            ), \n            pd.DataFrame(\n                data = {'l1': np.arange(30, 35, dtype=float),\n                        'l2': np.arange(80, 85, dtype=float),\n                        'l3': np.arange(130, 135, dtype=float)\n                },\n                index = pd.RangeIndex(start=30, stop=35, step=1)\n            ),\n            ['l1', 'l2', 'l3'],\n            None,\n            None,\n            folds[1]\n        )\n    ]\n\n    for i, data_fold in enumerate(data_folds):\n\n        assert isinstance(data_fold, tuple)\n        assert len(data_fold) == 6\n        \n        pd.testing.assert_frame_equal(data_fold[0], expected_data_folds[i][0])\n        pd.testing.assert_frame_equal(data_fold[1], expected_data_folds[i][1])\n        assert data_fold[2] == expected_data_folds[i][2]\n        assert data_fold[3] is None\n        assert data_fold[4] is None\n        assert data_fold[5] == expected_data_folds[i][5]\n\n\n@pytest.mark.parametrize(\"dropna_last_window\", \n                         [True, False], \n                         ids=lambda dropna: f'dropna_last_window: {dropna}')\ndef test_extract_data_folds_multiseries_series_DataFrame_with_NaN_exog_RangeIndex(dropna_last_window):\n    \"\"\"\n    Test _extract_data_folds_multiseries with series DataFrame and exog None with\n    RangeIndex.\n    \"\"\"\n    series_nan = series.copy()\n    series_nan.loc[:28, 'l2'] = np.nan\n    series_nan['l3'] = np.nan\n\n    # Train, last_window, test_no_gap\n    folds = [\n        [[0, 30], [25, 30], [30, 37]], \n        [[0, 35], [30, 35], [35, 42]]\n    ]\n    span_index = pd.RangeIndex(start=0, stop=50, step=1)\n    window_size = 5\n\n    data_folds = list(\n        _extract_data_folds_multiseries(\n            series             = series_nan, \n            folds              = folds, \n            span_index         = span_index, \n            window_size        = window_size, \n            exog               = exog, \n            dropna_last_window = dropna_last_window, \n            externally_fitted  = False\n        )\n    )\n\n    expected_data_folds = [\n        (\n            pd.DataFrame(\n                data = {'l1': np.arange(0, 30, dtype=float)\n                },\n                index = pd.RangeIndex(start=0, stop=30, step=1)\n            ),\n            pd.DataFrame(\n                data = {'l1': np.arange(25, 30, dtype=float)\n                },\n                index = pd.RangeIndex(start=25, stop=30, step=1)\n            ),\n            ['l1'],\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1000, 1030, dtype=float),\n                        'exog_2': np.arange(1050, 1080, dtype=float),\n                        'exog_3': np.arange(1100, 1130, dtype=float)\n                },\n                index = pd.RangeIndex(start=0, stop=30, step=1)\n            ),\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1030, 1037, dtype=float),\n                        'exog_2': np.arange(1080, 1087, dtype=float),\n                        'exog_3': np.arange(1130, 1137, dtype=float)\n                },\n                index = pd.RangeIndex(start=30, stop=37, step=1)\n            ),\n            folds[0]\n        ),\n        (\n            pd.DataFrame(\n                data = {'l1': np.arange(0, 35, dtype=float),\n                        'l2': [np.nan]*29 + list(range(79, 85))\n                },\n                index = pd.RangeIndex(start=0, stop=35, step=1)\n            ).astype({'l2': float}), \n            pd.DataFrame(\n                data = {'l1': np.arange(30, 35, dtype=float),\n                        'l2': np.arange(80, 85, dtype=float)\n                },\n                index = pd.RangeIndex(start=30, stop=35, step=1)\n            ),\n            ['l1', 'l2'],\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1000, 1035, dtype=float),\n                        'exog_2': np.arange(1050, 1085, dtype=float),\n                        'exog_3': np.arange(1100, 1135, dtype=float)\n                },\n                index = pd.RangeIndex(start=0, stop=35, step=1)\n            ),\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1035, 1042, dtype=float),\n                        'exog_2': np.arange(1085, 1092, dtype=float),\n                        'exog_3': np.arange(1135, 1142, dtype=float)\n                },\n                index = pd.RangeIndex(start=35, stop=42, step=1)\n            ),\n            folds[1]\n        )\n    ]\n\n    for i, data_fold in enumerate(data_folds):\n\n        assert isinstance(data_fold, tuple)\n        assert len(data_fold) == 6\n        \n        pd.testing.assert_frame_equal(data_fold[0], expected_data_folds[i][0])\n        pd.testing.assert_frame_equal(data_fold[1], expected_data_folds[i][1])\n        assert data_fold[2] == expected_data_folds[i][2]\n        pd.testing.assert_frame_equal(data_fold[3], expected_data_folds[i][3])\n        pd.testing.assert_frame_equal(data_fold[4], expected_data_folds[i][4])\n        assert data_fold[5] == expected_data_folds[i][5]\n\n\ndef test_extract_data_folds_multiseries_series_DataFrame_with_NaN_exog_DatetimeIndex():\n    \"\"\"\n    Test _extract_data_folds_multiseries with series DataFrame with NaNs and exog \n    with DatetimeIndex.\n    \"\"\"\n    series_nan = series.copy()\n    series_nan.loc[28, 'l2'] = np.nan # 29th value of 'l2' is NaN (affected by window_size=5)\n    series_nan.loc[:15, 'l3'] = np.nan # First 16 values of 'l3' are NaN\n\n    series_nan.index = pd.date_range(start='2020-01-01', periods=50, freq='D')\n    exog_datetime = exog.copy()\n    exog_datetime.index = pd.date_range(start='2020-01-01', periods=50, freq='D')\n\n    # Train, last_window, test_no_gap\n    folds = [\n        [[0, 30], [25, 30], [30, 37]], \n        [[0, 35], [30, 35], [35, 42]]\n    ]\n    span_index = pd.date_range(start='2020-01-01', periods=50, freq='D')\n    window_size = 5\n\n    data_folds = list(\n        _extract_data_folds_multiseries(\n            series             = series_nan, \n            folds              = folds, \n            span_index         = span_index, \n            window_size        = window_size, \n            exog               = exog_datetime, \n            dropna_last_window = True, \n            externally_fitted  = False\n        )\n    )\n\n    expected_data_folds = [\n        (\n            pd.DataFrame(\n                data = {'l1': np.arange(0, 30, dtype=float),\n                        'l2': list(range(50, 78)) + [np.nan] + [79],\n                        'l3': [np.nan]*16 + list(range(116, 130))\n                },\n                index = pd.date_range(start='2020-01-01', periods=30, freq='D')\n            ).astype({'l2': float, 'l3': float}),\n            pd.DataFrame(\n                data = {'l1': np.arange(25, 30, dtype=float),\n                        'l3': np.arange(125, 130, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-26', periods=5, freq='D')\n            ),\n            ['l1', 'l3'],\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1000, 1030, dtype=float),\n                        'exog_2': np.arange(1050, 1080, dtype=float),\n                        'exog_3': np.arange(1100, 1130, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-01', periods=30, freq='D')\n            ),\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1030, 1037, dtype=float),\n                        'exog_2': np.arange(1080, 1087, dtype=float),\n                        'exog_3': np.arange(1130, 1137, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-31', periods=7, freq='D')\n            ),\n            folds[0]\n        ),\n        (\n            pd.DataFrame(\n                data = {'l1': np.arange(0, 35, dtype=float),\n                        'l2': list(range(50, 78)) + [np.nan] + list(range(79, 85)),\n                        'l3': [np.nan]*16 + list(range(116, 135))\n                },\n                index = pd.date_range(start='2020-01-01', periods=35, freq='D')\n            ).astype({'l2': float}), \n            pd.DataFrame(\n                data = {'l1': np.arange(30, 35, dtype=float),\n                        'l2': np.arange(80, 85, dtype=float),\n                        'l3': np.arange(130, 135, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-31', periods=5, freq='D')\n            ),\n            ['l1', 'l2', 'l3'],\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1000, 1035, dtype=float),\n                        'exog_2': np.arange(1050, 1085, dtype=float),\n                        'exog_3': np.arange(1100, 1135, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-01', periods=35, freq='D')\n            ),\n            pd.DataFrame(\n                data = {'exog_1': np.arange(1035, 1042, dtype=float),\n                        'exog_2': np.arange(1085, 1092, dtype=float),\n                        'exog_3': np.arange(1135, 1142, dtype=float)\n                },\n                index = pd.date_range(start='2020-02-05', periods=7, freq='D')\n            ),\n            folds[1]\n        )\n    ]\n\n    for i, data_fold in enumerate(data_folds):\n\n        assert isinstance(data_fold, tuple)\n        assert len(data_fold) == 6\n        \n        pd.testing.assert_frame_equal(data_fold[0], expected_data_folds[i][0])\n        pd.testing.assert_frame_equal(data_fold[1], expected_data_folds[i][1])\n        assert data_fold[2] == expected_data_folds[i][2]\n        pd.testing.assert_frame_equal(data_fold[3], expected_data_folds[i][3])\n        pd.testing.assert_frame_equal(data_fold[4], expected_data_folds[i][4])\n        assert data_fold[5] == expected_data_folds[i][5]\n\n\n@pytest.mark.parametrize(\"dropna_last_window\", \n                         [True, False], \n                         ids=lambda dropna: f'dropna_last_window: {dropna}')\ndef test_extract_data_folds_multiseries_series_dict_exog_dict_DatetimeIndex(dropna_last_window):\n    \"\"\"\n    Test _extract_data_folds_multiseries with series DataFrame and exog None with\n    DatetimeIndex.\n    \"\"\"\n    series_datetime = series.copy()\n    series_datetime.index = pd.date_range(start='2020-01-01', periods=50, freq='D')\n\n    series_dict = {\n        'l1': series_datetime['l1'],\n        'l2': series_datetime['l2'].iloc[10:],\n        'l3': series_datetime['l3'].iloc[:20]\n    }\n\n    exog_datetime = exog.copy()\n    exog_datetime.index = pd.date_range(start='2020-01-01', periods=50, freq='D')\n\n    exog_dict = {\n        'l1': exog_datetime,\n        'l2': exog_datetime[['exog_1', 'exog_2']].iloc[15:],\n        'l3': exog_datetime['exog_3'].iloc[30:]\n    }\n\n    # Train, last_window, test_no_gap\n    folds = [\n        [[0, 30], [25, 30], [30, 37]], \n        [[0, 35], [30, 35], [35, 42]]\n    ]\n    span_index = pd.date_range(start='2020-01-01', periods=50, freq='D')\n    window_size = 5\n\n    data_folds = list(\n        _extract_data_folds_multiseries(\n            series             = series_dict, \n            folds              = folds, \n            span_index         = span_index, \n            window_size        = window_size, \n            exog               = exog_dict, \n            dropna_last_window = dropna_last_window, \n            externally_fitted  = False\n        )\n    )\n\n    expected_data_folds = [\n        (\n            {\n                'l1': pd.Series(\n                          data  = np.arange(0, 30, dtype=float), \n                          index = pd.date_range(start='2020-01-01', periods=30, freq='D'),\n                          name  = 'l1'\n                      ),\n                'l2': pd.Series(\n                          data  = np.arange(60, 80, dtype=float), \n                          index = pd.date_range(start='2020-01-11', periods=20, freq='D'),\n                          name  = 'l2'\n                      ),\n                'l3': pd.Series(\n                          data  = np.arange(100, 120, dtype=float), \n                          index = pd.date_range(start='2020-01-01', periods=20, freq='D'),\n                          name  = 'l3'\n                      )\n            },\n            pd.DataFrame(\n                data = {'l1': np.arange(25, 30, dtype=float),\n                        'l2': np.arange(75, 80, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-26', periods=5, freq='D')\n            ),\n            ['l1', 'l2'],\n            {\n                'l1': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1000, 1030, dtype=float),\n                                   'exog_2': np.arange(1050, 1080, dtype=float),\n                                   'exog_3': np.arange(1100, 1130, dtype=float)}, \n                          index = pd.date_range(start='2020-01-01', periods=30, freq='D')\n                      ),\n                'l2': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1015, 1030, dtype=float),\n                                   'exog_2': np.arange(1065, 1080, dtype=float)}, \n                          index = pd.date_range(start='2020-01-16', periods=15, freq='D')\n                      )\n            },\n            {\n                'l1': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1030, 1037, dtype=float),\n                                   'exog_2': np.arange(1080, 1087, dtype=float),\n                                   'exog_3': np.arange(1130, 1137, dtype=float)}, \n                          index = pd.date_range(start='2020-01-31', periods=7, freq='D')\n                      ),\n                'l2': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1030, 1037, dtype=float),\n                                   'exog_2': np.arange(1080, 1087, dtype=float)}, \n                          index = pd.date_range(start='2020-01-31', periods=7, freq='D')\n                      )\n            },\n            folds[0]\n        ),\n        (\n            {\n                'l1': pd.Series(\n                          data  = np.arange(0, 35, dtype=float), \n                          index = pd.date_range(start='2020-01-01', periods=35, freq='D'),\n                          name  = 'l1'\n                      ),\n                'l2': pd.Series(\n                          data  = np.arange(60, 85, dtype=float), \n                          index = pd.date_range(start='2020-01-11', periods=25, freq='D'),\n                          name  = 'l2'\n                      ),\n                'l3': pd.Series(\n                          data  = np.arange(100, 120, dtype=float), \n                          index = pd.date_range(start='2020-01-01', periods=20, freq='D'),\n                          name  = 'l3'\n                      )\n            }, \n            pd.DataFrame(\n                data = {'l1': np.arange(30, 35, dtype=float),\n                        'l2': np.arange(80, 85, dtype=float)\n                },\n                index = pd.date_range(start='2020-01-31', periods=5, freq='D')\n            ),\n            ['l1', 'l2'],\n            {\n                'l1': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1000, 1035, dtype=float),\n                                   'exog_2': np.arange(1050, 1085, dtype=float),\n                                   'exog_3': np.arange(1100, 1135, dtype=float)}, \n                          index = pd.date_range(start='2020-01-01', periods=35, freq='D')\n                      ),\n                'l2': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1015, 1035, dtype=float),\n                                   'exog_2': np.arange(1065, 1085, dtype=float)}, \n                          index = pd.date_range(start='2020-01-16', periods=20, freq='D')\n                      ),\n                'l3': pd.Series(\n                          data  = np.arange(1130, 1135, dtype=float), \n                          index = pd.date_range(start='2020-01-31', periods=5, freq='D'),\n                          name  = 'exog_3'\n                      )\n            },\n            {\n                'l1': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1035, 1042, dtype=float),\n                                   'exog_2': np.arange(1085, 1092, dtype=float),\n                                   'exog_3': np.arange(1135, 1142, dtype=float)}, \n                          index = pd.date_range(start='2020-02-05', periods=7, freq='D')\n                      ),\n                'l2': pd.DataFrame(\n                          data  = {'exog_1': np.arange(1035, 1042, dtype=float),\n                                   'exog_2': np.arange(1085, 1092, dtype=float)}, \n                          index = pd.date_range(start='2020-02-05', periods=7, freq='D')\n                      ),\n                'l3': pd.Series(\n                          data  = np.arange(1135, 1142, dtype=float), \n                          index = pd.date_range(start='2020-02-05', periods=7, freq='D'),\n                          name  = 'exog_3'\n                      )\n            },\n            folds[1]\n        )\n    ]\n\n    for i, data_fold in enumerate(data_folds):\n\n        assert isinstance(data_fold, tuple)\n        assert len(data_fold) == 6\n        \n        for key in data_fold[0].keys():\n            pd.testing.assert_series_equal(data_fold[0][key], expected_data_folds[i][0][key])\n        pd.testing.assert_frame_equal(data_fold[1], expected_data_folds[i][1])\n\n        assert data_fold[2] == expected_data_folds[i][2]\n\n        for key in data_fold[3].keys():\n            if isinstance(expected_data_folds[i][3][key], pd.DataFrame):\n                pd.testing.assert_frame_equal(data_fold[3][key], expected_data_folds[i][3][key])\n            else:\n                pd.testing.assert_series_equal(data_fold[3][key], expected_data_folds[i][3][key])\n        for key in data_fold[4].keys():\n            if isinstance(expected_data_folds[i][4][key], pd.DataFrame):\n                pd.testing.assert_frame_equal(data_fold[4][key], expected_data_folds[i][4][key])\n            else:\n                pd.testing.assert_series_equal(data_fold[4][key], expected_data_folds[i][4][key])\n\n        assert data_fold[5] == expected_data_folds[i][5]",
  "GT_file_code": {
    "skforecast/model_selection/_utils.py": "################################################################################\n#                     skforecast.model_selection._utils                        #\n#                                                                              #\n# This work by skforecast team is licensed under the BSD 3-Clause License.     #\n################################################################################\n# coding=utf-8\n\nfrom typing import Union, Tuple, Optional, Callable, Generator\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom joblib import cpu_count\nfrom tqdm.auto import tqdm\nfrom sklearn.pipeline import Pipeline\nimport sklearn.linear_model\nfrom sklearn.exceptions import NotFittedError\n\nfrom ..exceptions import IgnoredArgumentWarning\nfrom ..metrics import add_y_train_argument, _get_metric\nfrom ..utils import check_interval\n\n\ndef initialize_lags_grid(\n    forecaster: object, \n    lags_grid: Optional[Union[list, dict]] = None\n) -> Tuple[dict, str]:\n    \"\"\"\n    Initialize lags grid and lags label for model selection. \n\n    Parameters\n    ----------\n    forecaster : Forecaster\n        Forecaster model. ForecasterRecursive, ForecasterDirect, \n        ForecasterRecursiveMultiSeries, ForecasterDirectMultiVariate.\n    lags_grid : list, dict, default `None`\n        Lists of lags to try, containing int, lists, numpy ndarray, or range \n        objects. If `dict`, the keys are used as labels in the `results` \n        DataFrame, and the values are used as the lists of lags to try.\n\n    Returns\n    -------\n    lags_grid : dict\n        Dictionary with lags configuration for each iteration.\n    lags_label : str\n        Label for lags representation in the results object.\n\n    \"\"\"\n\n    if not isinstance(lags_grid, (list, dict, type(None))):\n        raise TypeError(\n            (f\"`lags_grid` argument must be a list, dict or None. \"\n             f\"Got {type(lags_grid)}.\")\n        )\n\n    lags_label = 'values'\n    if isinstance(lags_grid, list):\n        lags_grid = {f'{lags}': lags for lags in lags_grid}\n    elif lags_grid is None:\n        lags = [int(lag) for lag in forecaster.lags]  # Required since numpy 2.0\n        lags_grid = {f'{lags}': lags}\n    else:\n        lags_label = 'keys'\n\n    return lags_grid, lags_label\n\n\ndef check_backtesting_input(\n    forecaster: object,\n    cv: object,\n    metric: Union[str, Callable, list],\n    add_aggregated_metric: bool = True,\n    y: Optional[pd.Series] = None,\n    series: Optional[Union[pd.DataFrame, dict]] = None,\n    exog: Optional[Union[pd.Series, pd.DataFrame, dict]] = None,\n    interval: Optional[list] = None,\n    alpha: Optional[float] = None,\n    n_boot: int = 250,\n    random_state: int = 123,\n    use_in_sample_residuals: bool = True,\n    use_binned_residuals: bool = False,\n    n_jobs: Union[int, str] = 'auto',\n    show_progress: bool = True,\n    suppress_warnings: bool = False,\n    suppress_warnings_fit: bool = False\n) -> None:\n    \"\"\"\n    This is a helper function to check most inputs of backtesting functions in \n    modules `model_selection`.\n\n    Parameters\n    ----------\n    forecaster : Forecaster\n        Forecaster model.\n    cv : TimeSeriesFold\n        TimeSeriesFold object with the information needed to split the data into folds.\n    metric : str, Callable, list\n        Metric used to quantify the goodness of fit of the model.\n    add_aggregated_metric : bool, default `True`\n        If `True`, the aggregated metrics (average, weighted average and pooling)\n        over all levels are also returned (only multiseries).\n    y : pandas Series, default `None`\n        Training time series for uni-series forecasters.\n    series : pandas DataFrame, dict, default `None`\n        Training time series for multi-series forecasters.\n    exog : pandas Series, pandas DataFrame, dict, default `None`\n        Exogenous variables.\n    interval : list, default `None`\n        Confidence of the prediction interval estimated. Sequence of percentiles\n        to compute, which must be between 0 and 100 inclusive.\n    alpha : float, default `None`\n        The confidence intervals used in ForecasterSarimax are (1 - alpha) %. \n    n_boot : int, default `250`\n        Number of bootstrapping iterations used to estimate prediction\n        intervals.\n    random_state : int, default `123`\n        Sets a seed to the random generator, so that boot intervals are always \n        deterministic.\n    use_in_sample_residuals : bool, default `True`\n        If `True`, residuals from the training data are used as proxy of prediction \n        error to create prediction intervals.  If `False`, out_sample_residuals \n        are used if they are already stored inside the forecaster.\n    use_binned_residuals : bool, default `False`\n        If `True`, residuals used in each bootstrapping iteration are selected\n        conditioning on the predicted values. If `False`, residuals are selected\n        randomly without conditioning on the predicted values.\n    n_jobs : int, 'auto', default `'auto'`\n        The number of jobs to run in parallel. If `-1`, then the number of jobs is \n        set to the number of cores. If 'auto', `n_jobs` is set using the fuction\n        skforecast.utils.select_n_jobs_fit_forecaster.\n        **New in version 0.9.0**\n    show_progress : bool, default `True`\n        Whether to show a progress bar.\n    suppress_warnings: bool, default `False`\n        If `True`, skforecast warnings will be suppressed during the backtesting \n        process. See skforecast.exceptions.warn_skforecast_categories for more\n        information.\n    suppress_warnings_fit : bool, default `False`\n        If `True`, warnings generated during fitting will be ignored. Only \n        `ForecasterSarimax`.\n\n    Returns\n    -------\n    None\n    \n    \"\"\"\n\n    forecaster_name = type(forecaster).__name__\n    cv_name = type(cv).__name__\n\n    if cv_name != \"TimeSeriesFold\":\n        raise TypeError(f\"`cv` must be a TimeSeriesFold object. Got {cv_name}.\")\n\n    steps = cv.steps\n    initial_train_size = cv.initial_train_size\n    gap = cv.gap\n    allow_incomplete_fold = cv.allow_incomplete_fold\n    refit = cv.refit\n\n    forecasters_uni = [\n        \"ForecasterRecursive\",\n        \"ForecasterDirect\",\n        \"ForecasterSarimax\",\n        \"ForecasterEquivalentDate\",\n    ]\n    forecasters_multi = [\n        \"ForecasterDirectMultiVariate\",\n        \"ForecasterRnn\",\n    ]\n    forecasters_multi_dict = [\n        \"ForecasterRecursiveMultiSeries\"\n    ]\n\n    if forecaster_name in forecasters_uni:\n        if not isinstance(y, pd.Series):\n            raise TypeError(\"`y` must be a pandas Series.\")\n        data_name = 'y'\n        data_length = len(y)\n\n    elif forecaster_name in forecasters_multi:\n        if not isinstance(series, pd.DataFrame):\n            raise TypeError(\"`series` must be a pandas DataFrame.\")\n        data_name = 'series'\n        data_length = len(series)\n    \n    elif forecaster_name in forecasters_multi_dict:\n        if not isinstance(series, (pd.DataFrame, dict)):\n            raise TypeError(\n                f\"`series` must be a pandas DataFrame or a dict of DataFrames or Series. \"\n                f\"Got {type(series)}.\"\n            )\n        \n        data_name = 'series'\n        if isinstance(series, dict):\n            not_valid_series = [\n                k \n                for k, v in series.items()\n                if not isinstance(v, (pd.Series, pd.DataFrame))\n            ]\n            if not_valid_series:\n                raise TypeError(\n                    f\"If `series` is a dictionary, all series must be a named \"\n                    f\"pandas Series or a pandas DataFrame with a single column. \"\n                    f\"Review series: {not_valid_series}\"\n                )\n            not_valid_index = [\n                k \n                for k, v in series.items()\n                if not isinstance(v.index, pd.DatetimeIndex)\n            ]\n            if not_valid_index:\n                raise ValueError(\n                    f\"If `series` is a dictionary, all series must have a Pandas \"\n                    f\"DatetimeIndex as index with the same frequency. \"\n                    f\"Review series: {not_valid_index}\"\n                )\n\n            indexes_freq = [f'{v.index.freq}' for v in series.values()]\n            indexes_freq = sorted(set(indexes_freq))\n            if not len(indexes_freq) == 1:\n                raise ValueError(\n                    f\"If `series` is a dictionary, all series must have a Pandas \"\n                    f\"DatetimeIndex as index with the same frequency. \"\n                    f\"Found frequencies: {indexes_freq}\"\n                )\n            data_length = max([len(series[serie]) for serie in series])\n        else:\n            data_length = len(series)\n\n    if exog is not None:\n        if forecaster_name in forecasters_multi_dict:\n            if not isinstance(exog, (pd.Series, pd.DataFrame, dict)):\n                raise TypeError(\n                    f\"`exog` must be a pandas Series, DataFrame, dictionary of pandas \"\n                    f\"Series/DataFrames or None. Got {type(exog)}.\"\n                )\n            if isinstance(exog, dict):\n                not_valid_exog = [\n                    k \n                    for k, v in exog.items()\n                    if not isinstance(v, (pd.Series, pd.DataFrame, type(None)))\n                ]\n                if not_valid_exog:\n                    raise TypeError(\n                        f\"If `exog` is a dictionary, All exog must be a named pandas \"\n                        f\"Series, a pandas DataFrame or None. Review exog: {not_valid_exog}\"\n                    )\n        else:\n            if not isinstance(exog, (pd.Series, pd.DataFrame)):\n                raise TypeError(\n                    f\"`exog` must be a pandas Series, DataFrame or None. Got {type(exog)}.\"\n                )\n\n    if hasattr(forecaster, 'differentiation'):\n        if forecaster.differentiation != cv.differentiation:\n            raise ValueError(\n                f\"The differentiation included in the forecaster \"\n                f\"({forecaster.differentiation}) differs from the differentiation \"\n                f\"included in the cv ({cv.differentiation}). Set the same value \"\n                f\"for both using the `differentiation` argument.\"\n            )\n\n    if not isinstance(metric, (str, Callable, list)):\n        raise TypeError(\n            f\"`metric` must be a string, a callable function, or a list containing \"\n            f\"multiple strings and/or callables. Got {type(metric)}.\"\n        )\n\n    if forecaster_name == \"ForecasterEquivalentDate\" and isinstance(\n        forecaster.offset, pd.tseries.offsets.DateOffset\n    ):\n        if initial_train_size is None:\n            raise ValueError(\n                f\"`initial_train_size` must be an integer greater than \"\n                f\"the `window_size` of the forecaster ({forecaster.window_size}) \"\n                f\"and smaller than the length of `{data_name}` ({data_length}).\"\n            )\n    elif initial_train_size is not None:\n        if initial_train_size < forecaster.window_size or initial_train_size >= data_length:\n            raise ValueError(\n                f\"If used, `initial_train_size` must be an integer greater than \"\n                f\"the `window_size` of the forecaster ({forecaster.window_size}) \"\n                f\"and smaller than the length of `{data_name}` ({data_length}).\"\n            )\n        if initial_train_size + gap >= data_length:\n            raise ValueError(\n                f\"The combination of initial_train_size {initial_train_size} and \"\n                f\"gap {gap} cannot be greater than the length of `{data_name}` \"\n                f\"({data_length}).\"\n            )\n    else:\n        if forecaster_name in ['ForecasterSarimax', 'ForecasterEquivalentDate']:\n            raise ValueError(\n                f\"`initial_train_size` must be an integer smaller than the \"\n                f\"length of `{data_name}` ({data_length}).\"\n            )\n        else:\n            if not forecaster.is_fitted:\n                raise NotFittedError(\n                    \"`forecaster` must be already trained if no `initial_train_size` \"\n                    \"is provided.\"\n                )\n            if refit:\n                raise ValueError(\n                    \"`refit` is only allowed when `initial_train_size` is not `None`.\"\n                )\n\n    if forecaster_name == 'ForecasterSarimax' and cv.skip_folds is not None:\n        raise ValueError(\n            \"`skip_folds` is not allowed for ForecasterSarimax. Set it to `None`.\"\n        )\n\n    if not isinstance(add_aggregated_metric, bool):\n        raise TypeError(\"`add_aggregated_metric` must be a boolean: `True`, `False`.\")\n    if not isinstance(n_boot, (int, np.integer)) or n_boot < 0:\n        raise TypeError(f\"`n_boot` must be an integer greater than 0. Got {n_boot}.\")\n    if not isinstance(random_state, (int, np.integer)) or random_state < 0:\n        raise TypeError(f\"`random_state` must be an integer greater than 0. Got {random_state}.\")\n    if not isinstance(use_in_sample_residuals, bool):\n        raise TypeError(\"`use_in_sample_residuals` must be a boolean: `True`, `False`.\")\n    if not isinstance(use_binned_residuals, bool):\n        raise TypeError(\"`use_binned_residuals` must be a boolean: `True`, `False`.\")\n    if not isinstance(n_jobs, int) and n_jobs != 'auto':\n        raise TypeError(f\"`n_jobs` must be an integer or `'auto'`. Got {n_jobs}.\")\n    if not isinstance(show_progress, bool):\n        raise TypeError(\"`show_progress` must be a boolean: `True`, `False`.\")\n    if not isinstance(suppress_warnings, bool):\n        raise TypeError(\"`suppress_warnings` must be a boolean: `True`, `False`.\")\n    if not isinstance(suppress_warnings_fit, bool):\n        raise TypeError(\"`suppress_warnings_fit` must be a boolean: `True`, `False`.\")\n\n    if interval is not None or alpha is not None:\n        check_interval(interval=interval, alpha=alpha)\n\n    if not allow_incomplete_fold and data_length - (initial_train_size + gap) < steps:\n        raise ValueError(\n            f\"There is not enough data to evaluate {steps} steps in a single \"\n            f\"fold. Set `allow_incomplete_fold` to `True` to allow incomplete folds.\\n\"\n            f\"    Data available for test : {data_length - (initial_train_size + gap)}\\n\"\n            f\"    Steps                   : {steps}\"\n        )\n\n\ndef select_n_jobs_backtesting(\n    forecaster: object,\n    refit: Union[bool, int]\n) -> int:\n    \"\"\"\n    Select the optimal number of jobs to use in the backtesting process. This\n    selection is based on heuristics and is not guaranteed to be optimal.\n\n    The number of jobs is chosen as follows:\n\n    - If `refit` is an integer, then `n_jobs = 1`. This is because parallelization doesn't \n    work with intermittent refit.\n    - If forecaster is 'ForecasterRecursive' and regressor is a linear regressor, \n    then `n_jobs = 1`.\n    - If forecaster is 'ForecasterRecursive' and regressor is not a linear \n    regressor then `n_jobs = cpu_count() - 1`.\n    - If forecaster is 'ForecasterDirect' or 'ForecasterDirectMultiVariate'\n    and `refit = True`, then `n_jobs = cpu_count() - 1`.\n    - If forecaster is 'ForecasterDirect' or 'ForecasterDirectMultiVariate'\n    and `refit = False`, then `n_jobs = 1`.\n    - If forecaster is 'ForecasterRecursiveMultiSeries', then `n_jobs = cpu_count() - 1`.\n    - If forecaster is 'ForecasterSarimax' or 'ForecasterEquivalentDate', \n    then `n_jobs = 1`.\n    - If regressor is a `LGBMRegressor(n_jobs=1)`, then `n_jobs = cpu_count() - 1`.\n    - If regressor is a `LGBMRegressor` with internal n_jobs != 1, then `n_jobs = 1`.\n    This is because `lightgbm` is highly optimized for gradient boosting and\n    parallelizes operations at a very fine-grained level, making additional\n    parallelization unnecessary and potentially harmful due to resource contention.\n\n    Parameters\n    ----------\n    forecaster : Forecaster\n        Forecaster model.\n    refit : bool, int\n        If the forecaster is refitted during the backtesting process.\n\n    Returns\n    -------\n    n_jobs : int\n        The number of jobs to run in parallel.\n    \n    \"\"\"\n\n    forecaster_name = type(forecaster).__name__\n\n    if isinstance(forecaster.regressor, Pipeline):\n        regressor = forecaster.regressor[-1]\n        regressor_name = type(regressor).__name__\n    else:\n        regressor = forecaster.regressor\n        regressor_name = type(regressor).__name__\n\n    linear_regressors = [\n        regressor_name\n        for regressor_name in dir(sklearn.linear_model)\n        if not regressor_name.startswith('_')\n    ]\n\n    refit = False if refit == 0 else refit\n    if not isinstance(refit, bool) and refit != 1:\n        n_jobs = 1\n    else:\n        if forecaster_name in ['ForecasterRecursive']:\n            if regressor_name in linear_regressors:\n                n_jobs = 1\n            elif regressor_name == 'LGBMRegressor':\n                n_jobs = cpu_count() - 1 if regressor.n_jobs == 1 else 1\n            else:\n                n_jobs = cpu_count() - 1\n        elif forecaster_name in ['ForecasterDirect', 'ForecasterDirectMultiVariate']:\n            # Parallelization is applied during the fitting process.\n            n_jobs = 1\n        elif forecaster_name in ['ForecasterRecursiveMultiSeries']:\n            if regressor_name == 'LGBMRegressor':\n                n_jobs = cpu_count() - 1 if regressor.n_jobs == 1 else 1\n            else:\n                n_jobs = cpu_count() - 1\n        elif forecaster_name in ['ForecasterSarimax', 'ForecasterEquivalentDate']:\n            n_jobs = 1\n        else:\n            n_jobs = 1\n\n    return n_jobs\n\n\ndef _calculate_metrics_one_step_ahead(\n    forecaster: object,\n    y: pd.Series,\n    metrics: list,\n    X_train: pd.DataFrame,\n    y_train: Union[pd.Series, dict],\n    X_test: pd.DataFrame,\n    y_test: Union[pd.Series, dict]\n) -> list:\n    \"\"\"\n    Calculate metrics when predictions are one-step-ahead. When forecaster is\n    of type ForecasterDirect only the regressor for step 1 is used.\n\n    Parameters\n    ----------\n    forecaster : object\n        Forecaster model.\n    y : pandas Series\n        Time series data used to train and test the model.\n    metrics : list\n        List of metrics.\n    X_train : pandas DataFrame\n        Predictor values used to train the model.\n    y_train : pandas Series\n        Target values related to each row of `X_train`.\n    X_test : pandas DataFrame\n        Predictor values used to test the model.\n    y_test : pandas Series\n        Target values related to each row of `X_test`.\n\n    Returns\n    -------\n    metric_values : list\n        List with metric values.\n    \n    \"\"\"\n\n    if type(forecaster).__name__ == 'ForecasterDirect':\n\n        step = 1  # Only the model for step 1 is optimized.\n        X_train, y_train = forecaster.filter_train_X_y_for_step(\n                               step    = step,\n                               X_train = X_train,\n                               y_train = y_train\n                           )\n        X_test, y_test = forecaster.filter_train_X_y_for_step(\n                             step    = step,  \n                             X_train = X_test,\n                             y_train = y_test\n                         )\n        forecaster.regressors_[step].fit(X_train, y_train)\n        y_pred = forecaster.regressors_[step].predict(X_test)\n\n    else:\n        forecaster.regressor.fit(X_train, y_train)\n        y_pred = forecaster.regressor.predict(X_test)\n\n    y_true = y_test.to_numpy()\n    y_pred = y_pred.ravel()\n    y_train = y_train.to_numpy()\n\n    if forecaster.differentiation is not None:\n        y_true = forecaster.differentiator.inverse_transform_next_window(y_true)\n        y_pred = forecaster.differentiator.inverse_transform_next_window(y_pred)\n        y_train = forecaster.differentiator.inverse_transform_training(y_train)\n\n    if forecaster.transformer_y is not None:\n        y_true = forecaster.transformer_y.inverse_transform(y_true.reshape(-1, 1))\n        y_pred = forecaster.transformer_y.inverse_transform(y_pred.reshape(-1, 1))\n        y_train = forecaster.transformer_y.inverse_transform(y_train.reshape(-1, 1))\n\n    metric_values = []\n    for m in metrics:\n        metric_values.append(\n            m(y_true=y_true.ravel(), y_pred=y_pred.ravel(), y_train=y_train.ravel())\n        )\n\n    return metric_values\n\n\ndef _initialize_levels_model_selection_multiseries(\n    forecaster: object, \n    series: Union[pd.DataFrame, dict],\n    levels: Optional[Union[str, list]] = None\n) -> list:\n    \"\"\"\n    Initialize levels for model_selection multi-series functions.\n\n    Parameters\n    ----------\n    forecaster : ForecasterRecursiveMultiSeries, ForecasterDirectMultiVariate, ForecasterRnn\n        Forecaster model.\n    series : pandas DataFrame, dict\n        Training time series.\n    levels : str, list, default `None`\n        level (`str`) or levels (`list`) at which the forecaster is optimized. \n        If `None`, all levels are taken into account. The resulting metric will be\n        the average of the optimization of all levels.\n\n    Returns\n    -------\n    levels : list\n        List of levels to be used in model_selection multi-series functions.\n    \n    \"\"\"\n\n    multi_series_forecasters_with_levels = [\n        'ForecasterRecursiveMultiSeries', \n        'ForecasterRnn'\n    ]\n\n    if type(forecaster).__name__ in multi_series_forecasters_with_levels  \\\n        and not isinstance(levels, (str, list, type(None))):\n        raise TypeError(\n            (f\"`levels` must be a `list` of column names, a `str` of a column \"\n             f\"name or `None` when using a forecaster of type \"\n             f\"{multi_series_forecasters_with_levels}. If the forecaster is of \"\n             f\"type `ForecasterDirectMultiVariate`, this argument is ignored.\")\n        )\n\n    if type(forecaster).__name__ == 'ForecasterDirectMultiVariate':\n        if levels and levels != forecaster.level and levels != [forecaster.level]:\n            warnings.warn(\n                (f\"`levels` argument have no use when the forecaster is of type \"\n                 f\"`ForecasterDirectMultiVariate`. The level of this forecaster \"\n                 f\"is '{forecaster.level}', to predict another level, change \"\n                 f\"the `level` argument when initializing the forecaster. \\n\"),\n                 IgnoredArgumentWarning\n            )\n        levels = [forecaster.level]\n    else:\n        if levels is None:\n            # Forecaster could be untrained, so self.series_col_names cannot be used.\n            if isinstance(series, pd.DataFrame):\n                levels = list(series.columns)\n            else:\n                levels = list(series.keys())\n        elif isinstance(levels, str):\n            levels = [levels]\n\n    return levels\n\n\ndef _extract_data_folds_multiseries(\n    series: Union[pd.Series, pd.DataFrame, dict],\n    folds: list,\n    span_index: Union[pd.DatetimeIndex, pd.RangeIndex],\n    window_size: int,\n    exog: Optional[Union[pd.Series, pd.DataFrame, dict]] = None,\n    dropna_last_window: bool = False,\n    externally_fitted: bool = False\n) -> Generator[\n        Tuple[\n            Union[pd.Series, pd.DataFrame, dict],\n            pd.DataFrame,\n            list,\n            Optional[Union[pd.Series, pd.DataFrame, dict]],\n            Optional[Union[pd.Series, pd.DataFrame, dict]],\n            list\n        ],\n        None,\n        None\n    ]:\n    \"\"\"\n    Select the data from series and exog that corresponds to each fold created using the\n    skforecast.model_selection._create_backtesting_folds function.\n\n    Parameters\n    ----------\n    series : pandas Series, pandas DataFrame, dict\n        Time series.\n    folds : list\n        Folds created using the skforecast.model_selection._create_backtesting_folds\n        function.\n    span_index : pandas DatetimeIndex, pandas RangeIndex\n        Full index from the minimum to the maximum index among all series.\n    window_size : int\n        Size of the window needed to create the predictors.\n    exog : pandas Series, pandas DataFrame, dict, default `None`\n        Exogenous variables.\n    dropna_last_window : bool, default `False`\n        If `True`, drop the columns of the last window that have NaN values.\n    externally_fitted : bool, default `False`\n        Flag indicating whether the forecaster is already trained. Only used when \n        `initial_train_size` is None and `refit` is False.\n\n    Yield\n    -----\n    series_train : pandas Series, pandas DataFrame, dict\n        Time series corresponding to the training set of the fold.\n    series_last_window: pandas DataFrame\n        Time series corresponding to the last window of the fold.\n    levels_last_window: list\n        Levels of the time series present in the last window of the fold.\n    exog_train: pandas Series, pandas DataFrame, dict, None\n        Exogenous variable corresponding to the training set of the fold.\n    exog_test: pandas Series, pandas DataFrame, dict, None\n        Exogenous variable corresponding to the test set of the fold.\n    fold: list\n        Fold created using the skforecast.model_selection._create_backtesting_folds\n\n    \"\"\"\n\n    for fold in folds:\n        train_iloc_start       = fold[0][0]\n        train_iloc_end         = fold[0][1]\n        last_window_iloc_start = fold[1][0]\n        last_window_iloc_end   = fold[1][1]\n        test_iloc_start        = fold[2][0]\n        test_iloc_end          = fold[2][1]\n\n        if isinstance(series, dict) or isinstance(exog, dict):\n            # Substract 1 to the iloc indexes to get the loc indexes\n            train_loc_start       = span_index[train_iloc_start]\n            train_loc_end         = span_index[train_iloc_end - 1]\n            last_window_loc_start = span_index[last_window_iloc_start]\n            last_window_loc_end   = span_index[last_window_iloc_end - 1]\n            test_loc_start        = span_index[test_iloc_start]\n            test_loc_end          = span_index[test_iloc_end - 1]\n\n        if isinstance(series, pd.DataFrame):\n            series_train = series.iloc[train_iloc_start:train_iloc_end, ]\n\n            series_to_drop = []\n            for col in series_train.columns:\n                if series_train[col].isna().all():\n                    series_to_drop.append(col)\n                else:\n                    first_valid_index = series_train[col].first_valid_index()\n                    last_valid_index = series_train[col].last_valid_index()\n                    if (\n                        len(series_train[col].loc[first_valid_index:last_valid_index])\n                        < window_size\n                    ):\n                        series_to_drop.append(col)\n\n            series_last_window = series.iloc[\n                last_window_iloc_start:last_window_iloc_end,\n            ]\n            \n            series_train = series_train.drop(columns=series_to_drop)\n            if not externally_fitted:\n                series_last_window = series_last_window.drop(columns=series_to_drop)\n        else:\n            series_train = {}\n            for k in series.keys():\n                v = series[k].loc[train_loc_start:train_loc_end]\n                if not v.isna().all():\n                    first_valid_index = v.first_valid_index()\n                    last_valid_index  = v.last_valid_index()\n                    if first_valid_index is not None and last_valid_index is not None:\n                        v = v.loc[first_valid_index : last_valid_index]\n                        if len(v) >= window_size:\n                            series_train[k] = v\n\n            series_last_window = {}\n            for k, v in series.items():\n                v = series[k].loc[last_window_loc_start:last_window_loc_end]\n                if ((externally_fitted or k in series_train) and len(v) >= window_size):\n                    series_last_window[k] = v\n\n            series_last_window = pd.DataFrame(series_last_window)\n\n        if dropna_last_window:\n            series_last_window = series_last_window.dropna(axis=1, how=\"any\")\n            # TODO: add the option to drop the series without minimum non NaN values.\n            # Similar to how pandas does in the rolling window function.\n        \n        levels_last_window = list(series_last_window.columns)\n\n        if exog is not None:\n            if isinstance(exog, (pd.Series, pd.DataFrame)):\n                exog_train = exog.iloc[train_iloc_start:train_iloc_end, ]\n                exog_test = exog.iloc[test_iloc_start:test_iloc_end, ]\n            else:\n                exog_train = {\n                    k: v.loc[train_loc_start:train_loc_end] \n                    for k, v in exog.items()\n                }\n                exog_train = {k: v for k, v in exog_train.items() if len(v) > 0}\n\n                exog_test = {\n                    k: v.loc[test_loc_start:test_loc_end]\n                    for k, v in exog.items()\n                    if externally_fitted or k in exog_train\n                }\n\n                exog_test = {k: v for k, v in exog_test.items() if len(v) > 0}\n        else:\n            exog_train = None\n            exog_test = None\n\n        yield series_train, series_last_window, levels_last_window, exog_train, exog_test, fold\n\n\ndef _calculate_metrics_backtesting_multiseries(\n    series: Union[pd.DataFrame, dict],\n    predictions: pd.DataFrame,\n    folds: Union[list, tqdm],\n    span_index: Union[pd.DatetimeIndex, pd.RangeIndex],\n    window_size: int,\n    metrics: list,\n    levels: list,\n    add_aggregated_metric: bool = True\n) -> pd.DataFrame:\n    \"\"\"   \n    Calculate metrics for each level and also for all levels aggregated using\n    average, weighted average or pooling.\n\n    - 'average': the average (arithmetic mean) of all levels.\n    - 'weighted_average': the average of the metrics weighted by the number of\n    predicted values of each level.\n    - 'pooling': the values of all levels are pooled and then the metric is\n    calculated.\n\n    Parameters\n    ----------\n    series : pandas DataFrame, dict\n        Series data used for backtesting.\n    predictions : pandas DataFrame\n        Predictions generated during the backtesting process.\n    folds : list, tqdm\n        Folds created during the backtesting process.\n    span_index : pandas DatetimeIndex, pandas RangeIndex\n        Full index from the minimum to the maximum index among all series.\n    window_size : int\n        Size of the window used by the forecaster to create the predictors.\n        This is used remove the first `window_size` (differentiation included) \n        values from y_train since they are not part of the training matrix.\n    metrics : list\n        List of metrics to calculate.\n    levels : list\n        Levels to calculate the metrics.\n    add_aggregated_metric : bool, default `True`\n        If `True`, and multiple series (`levels`) are predicted, the aggregated\n        metrics (average, weighted average and pooled) are also returned.\n\n        - 'average': the average (arithmetic mean) of all levels.\n        - 'weighted_average': the average of the metrics weighted by the number of\n        predicted values of each level.\n        - 'pooling': the values of all levels are pooled and then the metric is\n        calculated.\n\n    Returns\n    -------\n    metrics_levels : pandas DataFrame\n        Value(s) of the metric(s).\n    \n    \"\"\"\n\n    if not isinstance(series, (pd.DataFrame, dict)):\n        raise TypeError(\n            (\"`series` must be a pandas DataFrame or a dictionary of pandas \"\n             \"DataFrames.\")\n        )\n    if not isinstance(predictions, pd.DataFrame):\n        raise TypeError(\"`predictions` must be a pandas DataFrame.\")\n    if not isinstance(folds, (list, tqdm)):\n        raise TypeError(\"`folds` must be a list or a tqdm object.\")\n    if not isinstance(span_index, (pd.DatetimeIndex, pd.RangeIndex)):\n        raise TypeError(\"`span_index` must be a pandas DatetimeIndex or pandas RangeIndex.\")\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError(\"`window_size` must be an integer.\")\n    if not isinstance(metrics, list):\n        raise TypeError(\"`metrics` must be a list.\")\n    if not isinstance(levels, list):\n        raise TypeError(\"`levels` must be a list.\")\n    if not isinstance(add_aggregated_metric, bool):\n        raise TypeError(\"`add_aggregated_metric` must be a boolean.\")\n    \n    metric_names = [(m if isinstance(m, str) else m.__name__) for m in metrics]\n\n    y_true_pred_levels = []\n    y_train_levels = []\n    for level in levels:\n        y_true_pred_level = None\n        y_train = None\n        if level in predictions.columns:\n            # TODO: avoid merges inside the loop, instead merge outside and then filter\n            y_true_pred_level = pd.merge(\n                series[level],\n                predictions[level],\n                left_index  = True,\n                right_index = True,\n                how         = \"inner\",\n            ).dropna(axis=0, how=\"any\")\n            y_true_pred_level.columns = ['y_true', 'y_pred']\n\n            train_indexes = []\n            for i, fold in enumerate(folds):\n                fit_fold = fold[-1]\n                if i == 0 or fit_fold:\n                    train_iloc_start = fold[0][0]\n                    train_iloc_end = fold[0][1]\n                    train_indexes.append(np.arange(train_iloc_start, train_iloc_end))\n            train_indexes = np.unique(np.concatenate(train_indexes))\n            train_indexes = span_index[train_indexes]\n            y_train = series[level].loc[series[level].index.intersection(train_indexes)]\n\n        y_true_pred_levels.append(y_true_pred_level)\n        y_train_levels.append(y_train)\n            \n    metrics_levels = []\n    for i, level in enumerate(levels):\n        if y_true_pred_levels[i] is not None and not y_true_pred_levels[i].empty:\n            metrics_level = [\n                m(\n                    y_true = y_true_pred_levels[i].iloc[:, 0],\n                    y_pred = y_true_pred_levels[i].iloc[:, 1],\n                    y_train = y_train_levels[i].iloc[window_size:]  # Exclude observations used to create predictors\n                )\n                for m in metrics\n            ]\n            metrics_levels.append(metrics_level)\n        else:\n            metrics_levels.append([None for _ in metrics])\n\n    metrics_levels = pd.DataFrame(\n                         data    = metrics_levels,\n                         columns = [m if isinstance(m, str) else m.__name__\n                                    for m in metrics]\n                     )\n    metrics_levels.insert(0, 'levels', levels)\n\n    if len(levels) < 2:\n        add_aggregated_metric = False\n    \n    if add_aggregated_metric:\n\n        # aggragation: average\n        average = metrics_levels.drop(columns='levels').mean(skipna=True)\n        average = average.to_frame().transpose()\n        average['levels'] = 'average'\n\n        # aggregation: weighted_average\n        weighted_averages = {}\n        n_predictions_levels = (\n            predictions\n            .notna()\n            .sum()\n            .to_frame(name='n_predictions')\n            .reset_index(names='levels')\n        )\n        metrics_levels_no_missing = (\n            metrics_levels.merge(n_predictions_levels, on='levels', how='inner')\n        )\n        for col in metric_names:\n            weighted_averages[col] = np.average(\n                metrics_levels_no_missing[col],\n                weights=metrics_levels_no_missing['n_predictions']\n            )\n        weighted_average = pd.DataFrame(weighted_averages, index=[0])\n        weighted_average['levels'] = 'weighted_average'\n\n        # aggregation: pooling\n        y_true_pred_levels, y_train_levels = zip(\n            *[\n                (a, b.iloc[window_size:])  # Exclude observations used to create predictors\n                for a, b in zip(y_true_pred_levels, y_train_levels)\n                if a is not None\n            ]\n        )\n        y_train_levels = list(y_train_levels)\n        y_true_pred_levels = pd.concat(y_true_pred_levels)\n        y_train_levels_concat = pd.concat(y_train_levels)\n\n        pooled = []\n        for m, m_name in zip(metrics, metric_names):\n            if m_name in ['mean_absolute_scaled_error', 'root_mean_squared_scaled_error']:\n                pooled.append(\n                    m(\n                        y_true = y_true_pred_levels.loc[:, 'y_true'],\n                        y_pred = y_true_pred_levels.loc[:, 'y_pred'],\n                        y_train = y_train_levels\n                    )\n                )\n            else:\n                pooled.append(\n                    m(\n                        y_true = y_true_pred_levels.loc[:, 'y_true'],\n                        y_pred = y_true_pred_levels.loc[:, 'y_pred'],\n                        y_train = y_train_levels_concat\n                    )\n                )\n        pooled = pd.DataFrame([pooled], columns=metric_names)\n        pooled['levels'] = 'pooling'\n\n        metrics_levels = pd.concat(\n            [metrics_levels, average, weighted_average, pooled],\n            axis=0,\n            ignore_index=True\n        )\n\n    return metrics_levels\n\n\ndef _predict_and_calculate_metrics_one_step_ahead_multiseries(\n    forecaster: object,\n    series: Union[pd.DataFrame, dict],\n    X_train: pd.DataFrame,\n    y_train: Union[pd.Series, dict],\n    X_test: pd.DataFrame,\n    y_test: Union[pd.Series, dict],\n    X_train_encoding: pd.Series,\n    X_test_encoding: pd.Series,\n    levels: list,\n    metrics: list,\n    add_aggregated_metric: bool = True\n) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"   \n    One-step-ahead predictions and metrics for each level and also for all levels\n    aggregated using average, weighted average or pooling.\n    Input matrices (X_train, y_train, X_train_encoding, X_test, y_test, X_test_encoding)\n    should have been generated using the forecaster._train_test_split_one_step_ahead().\n\n    - 'average': the average (arithmetic mean) of all levels.\n    - 'weighted_average': the average of the metrics weighted by the number of\n    predicted values of each level.\n    - 'pooling': the values of all levels are pooled and then the metric is\n    calculated.\n\n    Parameters\n    ----------\n    forecaster : object\n        Forecaster model.\n    series : pandas DataFrame, dict\n        Series data used to train and test the forecaster.\n    X_train : pandas DataFrame\n        Training matrix.\n    y_train : pandas Series, dict\n        Target values of the training set.\n    X_test : pandas DataFrame\n        Test matrix.\n    y_test : pandas Series, dict\n        Target values of the test set.\n    X_train_encoding : pandas Series\n        Series identifiers for each row of `X_train`.\n    X_test_encoding : pandas Series\n        Series identifiers for each row of `X_test`.\n    levels : list\n        Levels to calculate the metrics.\n    metrics : list\n        List of metrics to calculate.\n    add_aggregated_metric : bool, default `True`\n        If `True`, and multiple series (`levels`) are predicted, the aggregated\n        metrics (average, weighted average and pooled) are also returned.\n\n        - 'average': the average (arithmetic mean) of all levels.\n        - 'weighted_average': the average of the metrics weighted by the number of\n        predicted values of each level.\n        - 'pooling': the values of all levels are pooled and then the metric is\n        calculated.\n\n    Returns\n    -------\n    metrics_levels : pandas DataFrame\n        Value(s) of the metric(s).\n    predictions : pandas DataFrame\n        Value of predictions for each level.\n    \n    \"\"\"\n\n    if not isinstance(series, (pd.DataFrame, dict)):\n        raise TypeError(\n            \"`series` must be a pandas DataFrame or a dictionary of pandas \"\n            \"DataFrames.\"\n        )\n    if not isinstance(X_train, pd.DataFrame):\n        raise TypeError(f\"`X_train` must be a pandas DataFrame. Got: {type(X_train)}\")\n    if not isinstance(y_train, (pd.Series, dict)):\n        raise TypeError(\n            f\"`y_train` must be a pandas Series or a dictionary of pandas Series. \"\n            f\"Got: {type(y_train)}\"\n        )        \n    if not isinstance(X_test, pd.DataFrame):\n        raise TypeError(f\"`X_test` must be a pandas DataFrame. Got: {type(X_test)}\")\n    if not isinstance(y_test, (pd.Series, dict)):\n        raise TypeError(\n            f\"`y_test` must be a pandas Series or a dictionary of pandas Series. \"\n            f\"Got: {type(y_test)}\"\n        )\n    if not isinstance(X_train_encoding, pd.Series):\n        raise TypeError(\n            f\"`X_train_encoding` must be a pandas Series. Got: {type(X_train_encoding)}\"\n        )\n    if not isinstance(X_test_encoding, pd.Series):\n        raise TypeError(\n            f\"`X_test_encoding` must be a pandas Series. Got: {type(X_test_encoding)}\"\n        )\n    if not isinstance(levels, list):\n        raise TypeError(f\"`levels` must be a list. Got: {type(levels)}\")\n    if not isinstance(metrics, list):\n        raise TypeError(f\"`metrics` must be a list. Got: {type(metrics)}\")\n    if not isinstance(add_aggregated_metric, bool):\n        raise TypeError(\n            f\"`add_aggregated_metric` must be a boolean. Got: {type(add_aggregated_metric)}\"\n        )\n    \n    metrics = [\n        _get_metric(metric=m)\n        if isinstance(m, str)\n        else add_y_train_argument(m) \n        for m in metrics\n    ]\n    metric_names = [(m if isinstance(m, str) else m.__name__) for m in metrics]\n\n    if isinstance(series[levels[0]].index, pd.DatetimeIndex):\n        freq = series[levels[0]].index.freq\n    else:\n        freq = series[levels[0]].index.step\n\n    if type(forecaster).__name__ == 'ForecasterDirectMultiVariate':\n        step = 1\n        X_train, y_train = forecaster.filter_train_X_y_for_step(\n                               step    = step,\n                               X_train = X_train,\n                               y_train = y_train\n                           )\n        X_test, y_test = forecaster.filter_train_X_y_for_step(\n                             step    = step,  \n                             X_train = X_test,\n                             y_train = y_test\n                         )                 \n        forecaster.regressors_[step].fit(X_train, y_train)\n        pred = forecaster.regressors_[step].predict(X_test)\n    else:\n        forecaster.regressor.fit(X_train, y_train)\n        pred = forecaster.regressor.predict(X_test)\n\n    predictions_per_level = pd.DataFrame(\n        {\n            'y_true': y_test,\n            'y_pred': pred,\n            '_level_skforecast': X_test_encoding,\n        },\n        index=y_test.index,\n    ).groupby('_level_skforecast')\n    predictions_per_level = {key: group for key, group in predictions_per_level}\n\n    y_train_per_level = pd.DataFrame(\n        {\"y_train\": y_train, \"_level_skforecast\": X_train_encoding},\n        index=y_train.index,\n    ).groupby(\"_level_skforecast\")\n    # Interleaved Nan values were excluded fom y_train. They are reestored\n    y_train_per_level = {key: group.asfreq(freq) for key, group in y_train_per_level}\n\n    if forecaster.differentiation is not None:\n        for level in predictions_per_level:\n            predictions_per_level[level][\"y_true\"] = (\n                forecaster.differentiator_[level].inverse_transform_next_window(\n                    predictions_per_level[level][\"y_true\"].to_numpy()\n                )\n            )\n            predictions_per_level[level][\"y_pred\"] = (\n                forecaster.differentiator_[level].inverse_transform_next_window(\n                    predictions_per_level[level][\"y_pred\"].to_numpy()\n                )   \n            )\n            y_train_per_level[level][\"y_train\"] = (\n                forecaster.differentiator_[level].inverse_transform_training(\n                    y_train_per_level[level][\"y_train\"].to_numpy()\n                )\n            )\n\n    if forecaster.transformer_series is not None:\n        for level in predictions_per_level:\n            transformer = forecaster.transformer_series_[level]\n            predictions_per_level[level][\"y_true\"] = transformer.inverse_transform(\n                predictions_per_level[level][[\"y_true\"]]\n            )\n            predictions_per_level[level][\"y_pred\"] = transformer.inverse_transform(\n                predictions_per_level[level][[\"y_pred\"]]\n            )\n            y_train_per_level[level][\"y_train\"] = transformer.inverse_transform(\n                y_train_per_level[level][[\"y_train\"]]\n            )\n    \n    metrics_levels = []\n    for level in levels:\n        if level in predictions_per_level:\n            metrics_level = [\n                m(\n                    y_true  = predictions_per_level[level].loc[:, 'y_true'],\n                    y_pred  = predictions_per_level[level].loc[:, 'y_pred'],\n                    y_train = y_train_per_level[level].loc[:, 'y_train']\n                )\n                for m in metrics\n            ]\n            metrics_levels.append(metrics_level)\n        else:\n            metrics_levels.append([None for _ in metrics])\n\n    metrics_levels = pd.DataFrame(\n                         data    = metrics_levels,\n                         columns = [m if isinstance(m, str) else m.__name__\n                                    for m in metrics]\n                     )\n    metrics_levels.insert(0, 'levels', levels)\n\n    if len(levels) < 2:\n        add_aggregated_metric = False\n\n    if add_aggregated_metric:\n\n        # aggragation: average\n        average = metrics_levels.drop(columns='levels').mean(skipna=True)\n        average = average.to_frame().transpose()\n        average['levels'] = 'average'\n\n        # aggregation: weighted_average\n        weighted_averages = {}\n        n_predictions_levels = {\n            k: v['y_pred'].notna().sum()\n            for k, v in predictions_per_level.items()\n        }\n        n_predictions_levels = pd.DataFrame(\n            n_predictions_levels.items(),\n            columns=['levels', 'n_predictions']\n        )\n        metrics_levels_no_missing = (\n            metrics_levels.merge(n_predictions_levels, on='levels', how='inner')\n        )\n        for col in metric_names:\n            weighted_averages[col] = np.average(\n                metrics_levels_no_missing[col],\n                weights=metrics_levels_no_missing['n_predictions']\n            )\n        weighted_average = pd.DataFrame(weighted_averages, index=[0])\n        weighted_average['levels'] = 'weighted_average'\n\n        # aggregation: pooling\n        list_y_train_by_level = [\n            v['y_train'].to_numpy()\n            for k, v in y_train_per_level.items()\n            if k in predictions_per_level\n        ]\n        predictions_pooled = pd.concat(predictions_per_level.values())\n        y_train_pooled = pd.concat(\n            [v for k, v in y_train_per_level.items() if k in predictions_per_level]\n        )\n        pooled = []\n        for m, m_name in zip(metrics, metric_names):\n            if m_name in ['mean_absolute_scaled_error', 'root_mean_squared_scaled_error']:\n                pooled.append(\n                    m(\n                        y_true  = predictions_pooled['y_true'],\n                        y_pred  = predictions_pooled['y_pred'],\n                        y_train = list_y_train_by_level\n                    )\n                )\n            else:\n                pooled.append(\n                    m(\n                        y_true  = predictions_pooled['y_true'],\n                        y_pred  = predictions_pooled['y_pred'],\n                        y_train = y_train_pooled['y_train']\n                    )\n                )\n        pooled = pd.DataFrame([pooled], columns=metric_names)\n        pooled['levels'] = 'pooling'\n\n        metrics_levels = pd.concat(\n            [metrics_levels, average, weighted_average, pooled],\n            axis=0,\n            ignore_index=True\n        )\n\n    predictions = (\n        pd.concat(predictions_per_level.values())\n        .loc[:, [\"y_pred\", \"_level_skforecast\"]]\n        .pivot(columns=\"_level_skforecast\", values=\"y_pred\")\n        .rename_axis(columns=None, index=None)\n    )\n    predictions = predictions.asfreq(X_test.index.freq)\n\n    return metrics_levels, predictions\n"
  },
  "GT_src_dict": {
    "skforecast/model_selection/_utils.py": {
      "_extract_data_folds_multiseries": {
        "code": "def _extract_data_folds_multiseries(series: Union[pd.Series, pd.DataFrame, dict], folds: list, span_index: Union[pd.DatetimeIndex, pd.RangeIndex], window_size: int, exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None, dropna_last_window: bool=False, externally_fitted: bool=False) -> Generator[Tuple[Union[pd.Series, pd.DataFrame, dict], pd.DataFrame, list, Optional[Union[pd.Series, pd.DataFrame, dict]], Optional[Union[pd.Series, pd.DataFrame, dict]], list], None, None]:\n    \"\"\"Selects the training and testing data corresponding to each fold created for multi-series backtesting. It extracts the relevant time series and exogenous variables based on a specified window size and the defined folds.\n\nParameters\n----------\nseries : Union[pd.Series, pd.DataFrame, dict]\n    The time series data, which can be in the form of a pandas Series, DataFrame, or a dictionary containing Series or DataFrames.\nfolds : list\n    A list of folds generated by the function `skforecast.model_selection._create_backtesting_folds`, indicating the indices for training and testing splits.\nspan_index : Union[pd.DatetimeIndex, pd.RangeIndex]\n    The complete index spanning from the minimum to the maximum index among all provided series.\nwindow_size : int\n    The size of the window needed for creating predictors.\nexog : Optional[Union[pd.Series, pd.DataFrame, dict]], default `None`\n    Exogenous variables used in the forecasting process.\ndropna_last_window : bool, default `False`\n    If `True`, columns with all NaN values in the last window are dropped.\nexternally_fitted : bool, default `False`\n    Indicates if the forecaster is already trained, relevant when `initial_train_size` is None and `refit` is False.\n\nReturns\n-------\nGenerator[Tuple[\n    Union[pd.Series, pd.DataFrame, dict],\n    pd.DataFrame,\n    list,\n    Optional[Union[pd.Series, pd.DataFrame, dict]],\n    Optional[Union[pd.Series, pd.DataFrame, dict]],\n    list\n], None, None]\n    A generator yielding tuples containing the training series, the last window series for each fold, the corresponding levels, and the associated exogenous training and testing variables.\n\nThe function interacts with the `span_index` to extract appropriate slices of time series based on indices defined by the folds. It also checks for missing values and adjusts the training sets accordingly, thus ensuring that the returned datasets are suitable for model training and evaluation.\"\"\"\n    '\\n    Select the data from series and exog that corresponds to each fold created using the\\n    skforecast.model_selection._create_backtesting_folds function.\\n\\n    Parameters\\n    ----------\\n    series : pandas Series, pandas DataFrame, dict\\n        Time series.\\n    folds : list\\n        Folds created using the skforecast.model_selection._create_backtesting_folds\\n        function.\\n    span_index : pandas DatetimeIndex, pandas RangeIndex\\n        Full index from the minimum to the maximum index among all series.\\n    window_size : int\\n        Size of the window needed to create the predictors.\\n    exog : pandas Series, pandas DataFrame, dict, default `None`\\n        Exogenous variables.\\n    dropna_last_window : bool, default `False`\\n        If `True`, drop the columns of the last window that have NaN values.\\n    externally_fitted : bool, default `False`\\n        Flag indicating whether the forecaster is already trained. Only used when \\n        `initial_train_size` is None and `refit` is False.\\n\\n    Yield\\n    -----\\n    series_train : pandas Series, pandas DataFrame, dict\\n        Time series corresponding to the training set of the fold.\\n    series_last_window: pandas DataFrame\\n        Time series corresponding to the last window of the fold.\\n    levels_last_window: list\\n        Levels of the time series present in the last window of the fold.\\n    exog_train: pandas Series, pandas DataFrame, dict, None\\n        Exogenous variable corresponding to the training set of the fold.\\n    exog_test: pandas Series, pandas DataFrame, dict, None\\n        Exogenous variable corresponding to the test set of the fold.\\n    fold: list\\n        Fold created using the skforecast.model_selection._create_backtesting_folds\\n\\n    '\n    for fold in folds:\n        train_iloc_start = fold[0][0]\n        train_iloc_end = fold[0][1]\n        last_window_iloc_start = fold[1][0]\n        last_window_iloc_end = fold[1][1]\n        test_iloc_start = fold[2][0]\n        test_iloc_end = fold[2][1]\n        if isinstance(series, dict) or isinstance(exog, dict):\n            train_loc_start = span_index[train_iloc_start]\n            train_loc_end = span_index[train_iloc_end - 1]\n            last_window_loc_start = span_index[last_window_iloc_start]\n            last_window_loc_end = span_index[last_window_iloc_end - 1]\n            test_loc_start = span_index[test_iloc_start]\n            test_loc_end = span_index[test_iloc_end - 1]\n        if isinstance(series, pd.DataFrame):\n            series_train = series.iloc[train_iloc_start:train_iloc_end,]\n            series_to_drop = []\n            for col in series_train.columns:\n                if series_train[col].isna().all():\n                    series_to_drop.append(col)\n                else:\n                    first_valid_index = series_train[col].first_valid_index()\n                    last_valid_index = series_train[col].last_valid_index()\n                    if len(series_train[col].loc[first_valid_index:last_valid_index]) < window_size:\n                        series_to_drop.append(col)\n            series_last_window = series.iloc[last_window_iloc_start:last_window_iloc_end,]\n            series_train = series_train.drop(columns=series_to_drop)\n            if not externally_fitted:\n                series_last_window = series_last_window.drop(columns=series_to_drop)\n        else:\n            series_train = {}\n            for k in series.keys():\n                v = series[k].loc[train_loc_start:train_loc_end]\n                if not v.isna().all():\n                    first_valid_index = v.first_valid_index()\n                    last_valid_index = v.last_valid_index()\n                    if first_valid_index is not None and last_valid_index is not None:\n                        v = v.loc[first_valid_index:last_valid_index]\n                        if len(v) >= window_size:\n                            series_train[k] = v\n            series_last_window = {}\n            for k, v in series.items():\n                v = series[k].loc[last_window_loc_start:last_window_loc_end]\n                if (externally_fitted or k in series_train) and len(v) >= window_size:\n                    series_last_window[k] = v\n            series_last_window = pd.DataFrame(series_last_window)\n        if dropna_last_window:\n            series_last_window = series_last_window.dropna(axis=1, how='any')\n        levels_last_window = list(series_last_window.columns)\n        if exog is not None:\n            if isinstance(exog, (pd.Series, pd.DataFrame)):\n                exog_train = exog.iloc[train_iloc_start:train_iloc_end,]\n                exog_test = exog.iloc[test_iloc_start:test_iloc_end,]\n            else:\n                exog_train = {k: v.loc[train_loc_start:train_loc_end] for k, v in exog.items()}\n                exog_train = {k: v for k, v in exog_train.items() if len(v) > 0}\n                exog_test = {k: v.loc[test_loc_start:test_loc_end] for k, v in exog.items() if externally_fitted or k in exog_train}\n                exog_test = {k: v for k, v in exog_test.items() if len(v) > 0}\n        else:\n            exog_train = None\n            exog_test = None\n        yield (series_train, series_last_window, levels_last_window, exog_train, exog_test, fold)",
        "docstring": "Selects the training and testing data corresponding to each fold created for multi-series backtesting. It extracts the relevant time series and exogenous variables based on a specified window size and the defined folds.\n\nParameters\n----------\nseries : Union[pd.Series, pd.DataFrame, dict]\n    The time series data, which can be in the form of a pandas Series, DataFrame, or a dictionary containing Series or DataFrames.\nfolds : list\n    A list of folds generated by the function `skforecast.model_selection._create_backtesting_folds`, indicating the indices for training and testing splits.\nspan_index : Union[pd.DatetimeIndex, pd.RangeIndex]\n    The complete index spanning from the minimum to the maximum index among all provided series.\nwindow_size : int\n    The size of the window needed for creating predictors.\nexog : Optional[Union[pd.Series, pd.DataFrame, dict]], default `None`\n    Exogenous variables used in the forecasting process.\ndropna_last_window : bool, default `False`\n    If `True`, columns with all NaN values in the last window are dropped.\nexternally_fitted : bool, default `False`\n    Indicates if the forecaster is already trained, relevant when `initial_train_size` is None and `refit` is False.\n\nReturns\n-------\nGenerator[Tuple[\n    Union[pd.Series, pd.DataFrame, dict],\n    pd.DataFrame,\n    list,\n    Optional[Union[pd.Series, pd.DataFrame, dict]],\n    Optional[Union[pd.Series, pd.DataFrame, dict]],\n    list\n], None, None]\n    A generator yielding tuples containing the training series, the last window series for each fold, the corresponding levels, and the associated exogenous training and testing variables.\n\nThe function interacts with the `span_index` to extract appropriate slices of time series based on indices defined by the folds. It also checks for missing values and adjusts the training sets accordingly, thus ensuring that the returned datasets are suitable for model training and evaluation.",
        "signature": "def _extract_data_folds_multiseries(series: Union[pd.Series, pd.DataFrame, dict], folds: list, span_index: Union[pd.DatetimeIndex, pd.RangeIndex], window_size: int, exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None, dropna_last_window: bool=False, externally_fitted: bool=False) -> Generator[Tuple[Union[pd.Series, pd.DataFrame, dict], pd.DataFrame, list, Optional[Union[pd.Series, pd.DataFrame, dict]], Optional[Union[pd.Series, pd.DataFrame, dict]], list], None, None]:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {},
  "PRD": "# PROJECT NAME: skforecast-test_extract_data_folds_multiseries\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 skforecast/\n    \u2514\u2500\u2500 model_selection/\n        \u2514\u2500\u2500 _utils.py\n            \u2514\u2500\u2500 _extract_data_folds_multiseries\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module is designed to handle the extraction of data subsets (folds) from multivariate time series datasets for model evaluation and validation purposes. It supports splitting time series data into train, test, and validation sets over specified ranges while accommodating optional exogenous variables that are aligned with the series. The module provides functionalities to process diverse index types (e.g., range-based or datetime-based) and manage scenarios involving missing values or gaps in the data, ensuring robust handling of incomplete datasets. By automating the creation of consistent and well-structured data folds, it simplifies the workflow for developers, enabling efficient backtesting and cross-validation of forecasting models on complex multiseries data.\n\n## FILE 1: skforecast/model_selection/_utils.py\n\n- FUNCTION NAME: _extract_data_folds_multiseries\n  - SIGNATURE: def _extract_data_folds_multiseries(series: Union[pd.Series, pd.DataFrame, dict], folds: list, span_index: Union[pd.DatetimeIndex, pd.RangeIndex], window_size: int, exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None, dropna_last_window: bool=False, externally_fitted: bool=False) -> Generator[Tuple[Union[pd.Series, pd.DataFrame, dict], pd.DataFrame, list, Optional[Union[pd.Series, pd.DataFrame, dict]], Optional[Union[pd.Series, pd.DataFrame, dict]], list], None, None]:\n  - DOCSTRING: \n```python\n\"\"\"\nSelects the training and testing data corresponding to each fold created for multi-series backtesting. It extracts the relevant time series and exogenous variables based on a specified window size and the defined folds.\n\nParameters\n----------\nseries : Union[pd.Series, pd.DataFrame, dict]\n    The time series data, which can be in the form of a pandas Series, DataFrame, or a dictionary containing Series or DataFrames.\nfolds : list\n    A list of folds generated by the function `skforecast.model_selection._create_backtesting_folds`, indicating the indices for training and testing splits.\nspan_index : Union[pd.DatetimeIndex, pd.RangeIndex]\n    The complete index spanning from the minimum to the maximum index among all provided series.\nwindow_size : int\n    The size of the window needed for creating predictors.\nexog : Optional[Union[pd.Series, pd.DataFrame, dict]], default `None`\n    Exogenous variables used in the forecasting process.\ndropna_last_window : bool, default `False`\n    If `True`, columns with all NaN values in the last window are dropped.\nexternally_fitted : bool, default `False`\n    Indicates if the forecaster is already trained, relevant when `initial_train_size` is None and `refit` is False.\n\nReturns\n-------\nGenerator[Tuple[\n    Union[pd.Series, pd.DataFrame, dict],\n    pd.DataFrame,\n    list,\n    Optional[Union[pd.Series, pd.DataFrame, dict]],\n    Optional[Union[pd.Series, pd.DataFrame, dict]],\n    list\n], None, None]\n    A generator yielding tuples containing the training series, the last window series for each fold, the corresponding levels, and the associated exogenous training and testing variables.\n\nThe function interacts with the `span_index` to extract appropriate slices of time series based on indices defined by the folds. It also checks for missing values and adjusts the training sets accordingly, thus ensuring that the returned datasets are suitable for model training and evaluation.\n\"\"\"\n```\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "skforecast/model_selection/_utils.py": "from typing import Union, Tuple, Optional, Callable, Generator\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom joblib import cpu_count\nfrom tqdm.auto import tqdm\nfrom sklearn.pipeline import Pipeline\nimport sklearn.linear_model\nfrom sklearn.exceptions import NotFittedError\nfrom ..exceptions import IgnoredArgumentWarning\nfrom ..metrics import add_y_train_argument, _get_metric\nfrom ..utils import check_interval\n\ndef initialize_lags_grid(forecaster: object, lags_grid: Optional[Union[list, dict]]=None) -> Tuple[dict, str]:\n    \"\"\"\n    Initialize lags grid and lags label for model selection. \n\n    Parameters\n    ----------\n    forecaster : Forecaster\n        Forecaster model. ForecasterRecursive, ForecasterDirect, \n        ForecasterRecursiveMultiSeries, ForecasterDirectMultiVariate.\n    lags_grid : list, dict, default `None`\n        Lists of lags to try, containing int, lists, numpy ndarray, or range \n        objects. If `dict`, the keys are used as labels in the `results` \n        DataFrame, and the values are used as the lists of lags to try.\n\n    Returns\n    -------\n    lags_grid : dict\n        Dictionary with lags configuration for each iteration.\n    lags_label : str\n        Label for lags representation in the results object.\n\n    \"\"\"\n    if not isinstance(lags_grid, (list, dict, type(None))):\n        raise TypeError(f'`lags_grid` argument must be a list, dict or None. Got {type(lags_grid)}.')\n    lags_label = 'values'\n    if isinstance(lags_grid, list):\n        lags_grid = {f'{lags}': lags for lags in lags_grid}\n    elif lags_grid is None:\n        lags = [int(lag) for lag in forecaster.lags]\n        lags_grid = {f'{lags}': lags}\n    else:\n        lags_label = 'keys'\n    return (lags_grid, lags_label)\n\ndef check_backtesting_input(forecaster: object, cv: object, metric: Union[str, Callable, list], add_aggregated_metric: bool=True, y: Optional[pd.Series]=None, series: Optional[Union[pd.DataFrame, dict]]=None, exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None, interval: Optional[list]=None, alpha: Optional[float]=None, n_boot: int=250, random_state: int=123, use_in_sample_residuals: bool=True, use_binned_residuals: bool=False, n_jobs: Union[int, str]='auto', show_progress: bool=True, suppress_warnings: bool=False, suppress_warnings_fit: bool=False) -> None:\n    \"\"\"\n    This is a helper function to check most inputs of backtesting functions in \n    modules `model_selection`.\n\n    Parameters\n    ----------\n    forecaster : Forecaster\n        Forecaster model.\n    cv : TimeSeriesFold\n        TimeSeriesFold object with the information needed to split the data into folds.\n    metric : str, Callable, list\n        Metric used to quantify the goodness of fit of the model.\n    add_aggregated_metric : bool, default `True`\n        If `True`, the aggregated metrics (average, weighted average and pooling)\n        over all levels are also returned (only multiseries).\n    y : pandas Series, default `None`\n        Training time series for uni-series forecasters.\n    series : pandas DataFrame, dict, default `None`\n        Training time series for multi-series forecasters.\n    exog : pandas Series, pandas DataFrame, dict, default `None`\n        Exogenous variables.\n    interval : list, default `None`\n        Confidence of the prediction interval estimated. Sequence of percentiles\n        to compute, which must be between 0 and 100 inclusive.\n    alpha : float, default `None`\n        The confidence intervals used in ForecasterSarimax are (1 - alpha) %. \n    n_boot : int, default `250`\n        Number of bootstrapping iterations used to estimate prediction\n        intervals.\n    random_state : int, default `123`\n        Sets a seed to the random generator, so that boot intervals are always \n        deterministic.\n    use_in_sample_residuals : bool, default `True`\n        If `True`, residuals from the training data are used as proxy of prediction \n        error to create prediction intervals.  If `False`, out_sample_residuals \n        are used if they are already stored inside the forecaster.\n    use_binned_residuals : bool, default `False`\n        If `True`, residuals used in each bootstrapping iteration are selected\n        conditioning on the predicted values. If `False`, residuals are selected\n        randomly without conditioning on the predicted values.\n    n_jobs : int, 'auto', default `'auto'`\n        The number of jobs to run in parallel. If `-1`, then the number of jobs is \n        set to the number of cores. If 'auto', `n_jobs` is set using the fuction\n        skforecast.utils.select_n_jobs_fit_forecaster.\n        **New in version 0.9.0**\n    show_progress : bool, default `True`\n        Whether to show a progress bar.\n    suppress_warnings: bool, default `False`\n        If `True`, skforecast warnings will be suppressed during the backtesting \n        process. See skforecast.exceptions.warn_skforecast_categories for more\n        information.\n    suppress_warnings_fit : bool, default `False`\n        If `True`, warnings generated during fitting will be ignored. Only \n        `ForecasterSarimax`.\n\n    Returns\n    -------\n    None\n    \n    \"\"\"\n    forecaster_name = type(forecaster).__name__\n    cv_name = type(cv).__name__\n    if cv_name != 'TimeSeriesFold':\n        raise TypeError(f'`cv` must be a TimeSeriesFold object. Got {cv_name}.')\n    steps = cv.steps\n    initial_train_size = cv.initial_train_size\n    gap = cv.gap\n    allow_incomplete_fold = cv.allow_incomplete_fold\n    refit = cv.refit\n    forecasters_uni = ['ForecasterRecursive', 'ForecasterDirect', 'ForecasterSarimax', 'ForecasterEquivalentDate']\n    forecasters_multi = ['ForecasterDirectMultiVariate', 'ForecasterRnn']\n    forecasters_multi_dict = ['ForecasterRecursiveMultiSeries']\n    if forecaster_name in forecasters_uni:\n        if not isinstance(y, pd.Series):\n            raise TypeError('`y` must be a pandas Series.')\n        data_name = 'y'\n        data_length = len(y)\n    elif forecaster_name in forecasters_multi:\n        if not isinstance(series, pd.DataFrame):\n            raise TypeError('`series` must be a pandas DataFrame.')\n        data_name = 'series'\n        data_length = len(series)\n    elif forecaster_name in forecasters_multi_dict:\n        if not isinstance(series, (pd.DataFrame, dict)):\n            raise TypeError(f'`series` must be a pandas DataFrame or a dict of DataFrames or Series. Got {type(series)}.')\n        data_name = 'series'\n        if isinstance(series, dict):\n            not_valid_series = [k for k, v in series.items() if not isinstance(v, (pd.Series, pd.DataFrame))]\n            if not_valid_series:\n                raise TypeError(f'If `series` is a dictionary, all series must be a named pandas Series or a pandas DataFrame with a single column. Review series: {not_valid_series}')\n            not_valid_index = [k for k, v in series.items() if not isinstance(v.index, pd.DatetimeIndex)]\n            if not_valid_index:\n                raise ValueError(f'If `series` is a dictionary, all series must have a Pandas DatetimeIndex as index with the same frequency. Review series: {not_valid_index}')\n            indexes_freq = [f'{v.index.freq}' for v in series.values()]\n            indexes_freq = sorted(set(indexes_freq))\n            if not len(indexes_freq) == 1:\n                raise ValueError(f'If `series` is a dictionary, all series must have a Pandas DatetimeIndex as index with the same frequency. Found frequencies: {indexes_freq}')\n            data_length = max([len(series[serie]) for serie in series])\n        else:\n            data_length = len(series)\n    if exog is not None:\n        if forecaster_name in forecasters_multi_dict:\n            if not isinstance(exog, (pd.Series, pd.DataFrame, dict)):\n                raise TypeError(f'`exog` must be a pandas Series, DataFrame, dictionary of pandas Series/DataFrames or None. Got {type(exog)}.')\n            if isinstance(exog, dict):\n                not_valid_exog = [k for k, v in exog.items() if not isinstance(v, (pd.Series, pd.DataFrame, type(None)))]\n                if not_valid_exog:\n                    raise TypeError(f'If `exog` is a dictionary, All exog must be a named pandas Series, a pandas DataFrame or None. Review exog: {not_valid_exog}')\n        elif not isinstance(exog, (pd.Series, pd.DataFrame)):\n            raise TypeError(f'`exog` must be a pandas Series, DataFrame or None. Got {type(exog)}.')\n    if hasattr(forecaster, 'differentiation'):\n        if forecaster.differentiation != cv.differentiation:\n            raise ValueError(f'The differentiation included in the forecaster ({forecaster.differentiation}) differs from the differentiation included in the cv ({cv.differentiation}). Set the same value for both using the `differentiation` argument.')\n    if not isinstance(metric, (str, Callable, list)):\n        raise TypeError(f'`metric` must be a string, a callable function, or a list containing multiple strings and/or callables. Got {type(metric)}.')\n    if forecaster_name == 'ForecasterEquivalentDate' and isinstance(forecaster.offset, pd.tseries.offsets.DateOffset):\n        if initial_train_size is None:\n            raise ValueError(f'`initial_train_size` must be an integer greater than the `window_size` of the forecaster ({forecaster.window_size}) and smaller than the length of `{data_name}` ({data_length}).')\n    elif initial_train_size is not None:\n        if initial_train_size < forecaster.window_size or initial_train_size >= data_length:\n            raise ValueError(f'If used, `initial_train_size` must be an integer greater than the `window_size` of the forecaster ({forecaster.window_size}) and smaller than the length of `{data_name}` ({data_length}).')\n        if initial_train_size + gap >= data_length:\n            raise ValueError(f'The combination of initial_train_size {initial_train_size} and gap {gap} cannot be greater than the length of `{data_name}` ({data_length}).')\n    elif forecaster_name in ['ForecasterSarimax', 'ForecasterEquivalentDate']:\n        raise ValueError(f'`initial_train_size` must be an integer smaller than the length of `{data_name}` ({data_length}).')\n    else:\n        if not forecaster.is_fitted:\n            raise NotFittedError('`forecaster` must be already trained if no `initial_train_size` is provided.')\n        if refit:\n            raise ValueError('`refit` is only allowed when `initial_train_size` is not `None`.')\n    if forecaster_name == 'ForecasterSarimax' and cv.skip_folds is not None:\n        raise ValueError('`skip_folds` is not allowed for ForecasterSarimax. Set it to `None`.')\n    if not isinstance(add_aggregated_metric, bool):\n        raise TypeError('`add_aggregated_metric` must be a boolean: `True`, `False`.')\n    if not isinstance(n_boot, (int, np.integer)) or n_boot < 0:\n        raise TypeError(f'`n_boot` must be an integer greater than 0. Got {n_boot}.')\n    if not isinstance(random_state, (int, np.integer)) or random_state < 0:\n        raise TypeError(f'`random_state` must be an integer greater than 0. Got {random_state}.')\n    if not isinstance(use_in_sample_residuals, bool):\n        raise TypeError('`use_in_sample_residuals` must be a boolean: `True`, `False`.')\n    if not isinstance(use_binned_residuals, bool):\n        raise TypeError('`use_binned_residuals` must be a boolean: `True`, `False`.')\n    if not isinstance(n_jobs, int) and n_jobs != 'auto':\n        raise TypeError(f\"`n_jobs` must be an integer or `'auto'`. Got {n_jobs}.\")\n    if not isinstance(show_progress, bool):\n        raise TypeError('`show_progress` must be a boolean: `True`, `False`.')\n    if not isinstance(suppress_warnings, bool):\n        raise TypeError('`suppress_warnings` must be a boolean: `True`, `False`.')\n    if not isinstance(suppress_warnings_fit, bool):\n        raise TypeError('`suppress_warnings_fit` must be a boolean: `True`, `False`.')\n    if interval is not None or alpha is not None:\n        check_interval(interval=interval, alpha=alpha)\n    if not allow_incomplete_fold and data_length - (initial_train_size + gap) < steps:\n        raise ValueError(f'There is not enough data to evaluate {steps} steps in a single fold. Set `allow_incomplete_fold` to `True` to allow incomplete folds.\\n    Data available for test : {data_length - (initial_train_size + gap)}\\n    Steps                   : {steps}')\n\ndef select_n_jobs_backtesting(forecaster: object, refit: Union[bool, int]) -> int:\n    \"\"\"\n    Select the optimal number of jobs to use in the backtesting process. This\n    selection is based on heuristics and is not guaranteed to be optimal.\n\n    The number of jobs is chosen as follows:\n\n    - If `refit` is an integer, then `n_jobs = 1`. This is because parallelization doesn't \n    work with intermittent refit.\n    - If forecaster is 'ForecasterRecursive' and regressor is a linear regressor, \n    then `n_jobs = 1`.\n    - If forecaster is 'ForecasterRecursive' and regressor is not a linear \n    regressor then `n_jobs = cpu_count() - 1`.\n    - If forecaster is 'ForecasterDirect' or 'ForecasterDirectMultiVariate'\n    and `refit = True`, then `n_jobs = cpu_count() - 1`.\n    - If forecaster is 'ForecasterDirect' or 'ForecasterDirectMultiVariate'\n    and `refit = False`, then `n_jobs = 1`.\n    - If forecaster is 'ForecasterRecursiveMultiSeries', then `n_jobs = cpu_count() - 1`.\n    - If forecaster is 'ForecasterSarimax' or 'ForecasterEquivalentDate', \n    then `n_jobs = 1`.\n    - If regressor is a `LGBMRegressor(n_jobs=1)`, then `n_jobs = cpu_count() - 1`.\n    - If regressor is a `LGBMRegressor` with internal n_jobs != 1, then `n_jobs = 1`.\n    This is because `lightgbm` is highly optimized for gradient boosting and\n    parallelizes operations at a very fine-grained level, making additional\n    parallelization unnecessary and potentially harmful due to resource contention.\n\n    Parameters\n    ----------\n    forecaster : Forecaster\n        Forecaster model.\n    refit : bool, int\n        If the forecaster is refitted during the backtesting process.\n\n    Returns\n    -------\n    n_jobs : int\n        The number of jobs to run in parallel.\n    \n    \"\"\"\n    forecaster_name = type(forecaster).__name__\n    if isinstance(forecaster.regressor, Pipeline):\n        regressor = forecaster.regressor[-1]\n        regressor_name = type(regressor).__name__\n    else:\n        regressor = forecaster.regressor\n        regressor_name = type(regressor).__name__\n    linear_regressors = [regressor_name for regressor_name in dir(sklearn.linear_model) if not regressor_name.startswith('_')]\n    refit = False if refit == 0 else refit\n    if not isinstance(refit, bool) and refit != 1:\n        n_jobs = 1\n    elif forecaster_name in ['ForecasterRecursive']:\n        if regressor_name in linear_regressors:\n            n_jobs = 1\n        elif regressor_name == 'LGBMRegressor':\n            n_jobs = cpu_count() - 1 if regressor.n_jobs == 1 else 1\n        else:\n            n_jobs = cpu_count() - 1\n    elif forecaster_name in ['ForecasterDirect', 'ForecasterDirectMultiVariate']:\n        n_jobs = 1\n    elif forecaster_name in ['ForecasterRecursiveMultiSeries']:\n        if regressor_name == 'LGBMRegressor':\n            n_jobs = cpu_count() - 1 if regressor.n_jobs == 1 else 1\n        else:\n            n_jobs = cpu_count() - 1\n    elif forecaster_name in ['ForecasterSarimax', 'ForecasterEquivalentDate']:\n        n_jobs = 1\n    else:\n        n_jobs = 1\n    return n_jobs\n\ndef _calculate_metrics_one_step_ahead(forecaster: object, y: pd.Series, metrics: list, X_train: pd.DataFrame, y_train: Union[pd.Series, dict], X_test: pd.DataFrame, y_test: Union[pd.Series, dict]) -> list:\n    \"\"\"\n    Calculate metrics when predictions are one-step-ahead. When forecaster is\n    of type ForecasterDirect only the regressor for step 1 is used.\n\n    Parameters\n    ----------\n    forecaster : object\n        Forecaster model.\n    y : pandas Series\n        Time series data used to train and test the model.\n    metrics : list\n        List of metrics.\n    X_train : pandas DataFrame\n        Predictor values used to train the model.\n    y_train : pandas Series\n        Target values related to each row of `X_train`.\n    X_test : pandas DataFrame\n        Predictor values used to test the model.\n    y_test : pandas Series\n        Target values related to each row of `X_test`.\n\n    Returns\n    -------\n    metric_values : list\n        List with metric values.\n    \n    \"\"\"\n    if type(forecaster).__name__ == 'ForecasterDirect':\n        step = 1\n        X_train, y_train = forecaster.filter_train_X_y_for_step(step=step, X_train=X_train, y_train=y_train)\n        X_test, y_test = forecaster.filter_train_X_y_for_step(step=step, X_train=X_test, y_train=y_test)\n        forecaster.regressors_[step].fit(X_train, y_train)\n        y_pred = forecaster.regressors_[step].predict(X_test)\n    else:\n        forecaster.regressor.fit(X_train, y_train)\n        y_pred = forecaster.regressor.predict(X_test)\n    y_true = y_test.to_numpy()\n    y_pred = y_pred.ravel()\n    y_train = y_train.to_numpy()\n    if forecaster.differentiation is not None:\n        y_true = forecaster.differentiator.inverse_transform_next_window(y_true)\n        y_pred = forecaster.differentiator.inverse_transform_next_window(y_pred)\n        y_train = forecaster.differentiator.inverse_transform_training(y_train)\n    if forecaster.transformer_y is not None:\n        y_true = forecaster.transformer_y.inverse_transform(y_true.reshape(-1, 1))\n        y_pred = forecaster.transformer_y.inverse_transform(y_pred.reshape(-1, 1))\n        y_train = forecaster.transformer_y.inverse_transform(y_train.reshape(-1, 1))\n    metric_values = []\n    for m in metrics:\n        metric_values.append(m(y_true=y_true.ravel(), y_pred=y_pred.ravel(), y_train=y_train.ravel()))\n    return metric_values\n\ndef _initialize_levels_model_selection_multiseries(forecaster: object, series: Union[pd.DataFrame, dict], levels: Optional[Union[str, list]]=None) -> list:\n    \"\"\"\n    Initialize levels for model_selection multi-series functions.\n\n    Parameters\n    ----------\n    forecaster : ForecasterRecursiveMultiSeries, ForecasterDirectMultiVariate, ForecasterRnn\n        Forecaster model.\n    series : pandas DataFrame, dict\n        Training time series.\n    levels : str, list, default `None`\n        level (`str`) or levels (`list`) at which the forecaster is optimized. \n        If `None`, all levels are taken into account. The resulting metric will be\n        the average of the optimization of all levels.\n\n    Returns\n    -------\n    levels : list\n        List of levels to be used in model_selection multi-series functions.\n    \n    \"\"\"\n    multi_series_forecasters_with_levels = ['ForecasterRecursiveMultiSeries', 'ForecasterRnn']\n    if type(forecaster).__name__ in multi_series_forecasters_with_levels and (not isinstance(levels, (str, list, type(None)))):\n        raise TypeError(f'`levels` must be a `list` of column names, a `str` of a column name or `None` when using a forecaster of type {multi_series_forecasters_with_levels}. If the forecaster is of type `ForecasterDirectMultiVariate`, this argument is ignored.')\n    if type(forecaster).__name__ == 'ForecasterDirectMultiVariate':\n        if levels and levels != forecaster.level and (levels != [forecaster.level]):\n            warnings.warn(f\"`levels` argument have no use when the forecaster is of type `ForecasterDirectMultiVariate`. The level of this forecaster is '{forecaster.level}', to predict another level, change the `level` argument when initializing the forecaster. \\n\", IgnoredArgumentWarning)\n        levels = [forecaster.level]\n    elif levels is None:\n        if isinstance(series, pd.DataFrame):\n            levels = list(series.columns)\n        else:\n            levels = list(series.keys())\n    elif isinstance(levels, str):\n        levels = [levels]\n    return levels\n\ndef _calculate_metrics_backtesting_multiseries(series: Union[pd.DataFrame, dict], predictions: pd.DataFrame, folds: Union[list, tqdm], span_index: Union[pd.DatetimeIndex, pd.RangeIndex], window_size: int, metrics: list, levels: list, add_aggregated_metric: bool=True) -> pd.DataFrame:\n    \"\"\"   \n    Calculate metrics for each level and also for all levels aggregated using\n    average, weighted average or pooling.\n\n    - 'average': the average (arithmetic mean) of all levels.\n    - 'weighted_average': the average of the metrics weighted by the number of\n    predicted values of each level.\n    - 'pooling': the values of all levels are pooled and then the metric is\n    calculated.\n\n    Parameters\n    ----------\n    series : pandas DataFrame, dict\n        Series data used for backtesting.\n    predictions : pandas DataFrame\n        Predictions generated during the backtesting process.\n    folds : list, tqdm\n        Folds created during the backtesting process.\n    span_index : pandas DatetimeIndex, pandas RangeIndex\n        Full index from the minimum to the maximum index among all series.\n    window_size : int\n        Size of the window used by the forecaster to create the predictors.\n        This is used remove the first `window_size` (differentiation included) \n        values from y_train since they are not part of the training matrix.\n    metrics : list\n        List of metrics to calculate.\n    levels : list\n        Levels to calculate the metrics.\n    add_aggregated_metric : bool, default `True`\n        If `True`, and multiple series (`levels`) are predicted, the aggregated\n        metrics (average, weighted average and pooled) are also returned.\n\n        - 'average': the average (arithmetic mean) of all levels.\n        - 'weighted_average': the average of the metrics weighted by the number of\n        predicted values of each level.\n        - 'pooling': the values of all levels are pooled and then the metric is\n        calculated.\n\n    Returns\n    -------\n    metrics_levels : pandas DataFrame\n        Value(s) of the metric(s).\n    \n    \"\"\"\n    if not isinstance(series, (pd.DataFrame, dict)):\n        raise TypeError('`series` must be a pandas DataFrame or a dictionary of pandas DataFrames.')\n    if not isinstance(predictions, pd.DataFrame):\n        raise TypeError('`predictions` must be a pandas DataFrame.')\n    if not isinstance(folds, (list, tqdm)):\n        raise TypeError('`folds` must be a list or a tqdm object.')\n    if not isinstance(span_index, (pd.DatetimeIndex, pd.RangeIndex)):\n        raise TypeError('`span_index` must be a pandas DatetimeIndex or pandas RangeIndex.')\n    if not isinstance(window_size, (int, np.integer)):\n        raise TypeError('`window_size` must be an integer.')\n    if not isinstance(metrics, list):\n        raise TypeError('`metrics` must be a list.')\n    if not isinstance(levels, list):\n        raise TypeError('`levels` must be a list.')\n    if not isinstance(add_aggregated_metric, bool):\n        raise TypeError('`add_aggregated_metric` must be a boolean.')\n    metric_names = [m if isinstance(m, str) else m.__name__ for m in metrics]\n    y_true_pred_levels = []\n    y_train_levels = []\n    for level in levels:\n        y_true_pred_level = None\n        y_train = None\n        if level in predictions.columns:\n            y_true_pred_level = pd.merge(series[level], predictions[level], left_index=True, right_index=True, how='inner').dropna(axis=0, how='any')\n            y_true_pred_level.columns = ['y_true', 'y_pred']\n            train_indexes = []\n            for i, fold in enumerate(folds):\n                fit_fold = fold[-1]\n                if i == 0 or fit_fold:\n                    train_iloc_start = fold[0][0]\n                    train_iloc_end = fold[0][1]\n                    train_indexes.append(np.arange(train_iloc_start, train_iloc_end))\n            train_indexes = np.unique(np.concatenate(train_indexes))\n            train_indexes = span_index[train_indexes]\n            y_train = series[level].loc[series[level].index.intersection(train_indexes)]\n        y_true_pred_levels.append(y_true_pred_level)\n        y_train_levels.append(y_train)\n    metrics_levels = []\n    for i, level in enumerate(levels):\n        if y_true_pred_levels[i] is not None and (not y_true_pred_levels[i].empty):\n            metrics_level = [m(y_true=y_true_pred_levels[i].iloc[:, 0], y_pred=y_true_pred_levels[i].iloc[:, 1], y_train=y_train_levels[i].iloc[window_size:]) for m in metrics]\n            metrics_levels.append(metrics_level)\n        else:\n            metrics_levels.append([None for _ in metrics])\n    metrics_levels = pd.DataFrame(data=metrics_levels, columns=[m if isinstance(m, str) else m.__name__ for m in metrics])\n    metrics_levels.insert(0, 'levels', levels)\n    if len(levels) < 2:\n        add_aggregated_metric = False\n    if add_aggregated_metric:\n        average = metrics_levels.drop(columns='levels').mean(skipna=True)\n        average = average.to_frame().transpose()\n        average['levels'] = 'average'\n        weighted_averages = {}\n        n_predictions_levels = predictions.notna().sum().to_frame(name='n_predictions').reset_index(names='levels')\n        metrics_levels_no_missing = metrics_levels.merge(n_predictions_levels, on='levels', how='inner')\n        for col in metric_names:\n            weighted_averages[col] = np.average(metrics_levels_no_missing[col], weights=metrics_levels_no_missing['n_predictions'])\n        weighted_average = pd.DataFrame(weighted_averages, index=[0])\n        weighted_average['levels'] = 'weighted_average'\n        y_true_pred_levels, y_train_levels = zip(*[(a, b.iloc[window_size:]) for a, b in zip(y_true_pred_levels, y_train_levels) if a is not None])\n        y_train_levels = list(y_train_levels)\n        y_true_pred_levels = pd.concat(y_true_pred_levels)\n        y_train_levels_concat = pd.concat(y_train_levels)\n        pooled = []\n        for m, m_name in zip(metrics, metric_names):\n            if m_name in ['mean_absolute_scaled_error', 'root_mean_squared_scaled_error']:\n                pooled.append(m(y_true=y_true_pred_levels.loc[:, 'y_true'], y_pred=y_true_pred_levels.loc[:, 'y_pred'], y_train=y_train_levels))\n            else:\n                pooled.append(m(y_true=y_true_pred_levels.loc[:, 'y_true'], y_pred=y_true_pred_levels.loc[:, 'y_pred'], y_train=y_train_levels_concat))\n        pooled = pd.DataFrame([pooled], columns=metric_names)\n        pooled['levels'] = 'pooling'\n        metrics_levels = pd.concat([metrics_levels, average, weighted_average, pooled], axis=0, ignore_index=True)\n    return metrics_levels\n\ndef _predict_and_calculate_metrics_one_step_ahead_multiseries(forecaster: object, series: Union[pd.DataFrame, dict], X_train: pd.DataFrame, y_train: Union[pd.Series, dict], X_test: pd.DataFrame, y_test: Union[pd.Series, dict], X_train_encoding: pd.Series, X_test_encoding: pd.Series, levels: list, metrics: list, add_aggregated_metric: bool=True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"   \n    One-step-ahead predictions and metrics for each level and also for all levels\n    aggregated using average, weighted average or pooling.\n    Input matrices (X_train, y_train, X_train_encoding, X_test, y_test, X_test_encoding)\n    should have been generated using the forecaster._train_test_split_one_step_ahead().\n\n    - 'average': the average (arithmetic mean) of all levels.\n    - 'weighted_average': the average of the metrics weighted by the number of\n    predicted values of each level.\n    - 'pooling': the values of all levels are pooled and then the metric is\n    calculated.\n\n    Parameters\n    ----------\n    forecaster : object\n        Forecaster model.\n    series : pandas DataFrame, dict\n        Series data used to train and test the forecaster.\n    X_train : pandas DataFrame\n        Training matrix.\n    y_train : pandas Series, dict\n        Target values of the training set.\n    X_test : pandas DataFrame\n        Test matrix.\n    y_test : pandas Series, dict\n        Target values of the test set.\n    X_train_encoding : pandas Series\n        Series identifiers for each row of `X_train`.\n    X_test_encoding : pandas Series\n        Series identifiers for each row of `X_test`.\n    levels : list\n        Levels to calculate the metrics.\n    metrics : list\n        List of metrics to calculate.\n    add_aggregated_metric : bool, default `True`\n        If `True`, and multiple series (`levels`) are predicted, the aggregated\n        metrics (average, weighted average and pooled) are also returned.\n\n        - 'average': the average (arithmetic mean) of all levels.\n        - 'weighted_average': the average of the metrics weighted by the number of\n        predicted values of each level.\n        - 'pooling': the values of all levels are pooled and then the metric is\n        calculated.\n\n    Returns\n    -------\n    metrics_levels : pandas DataFrame\n        Value(s) of the metric(s).\n    predictions : pandas DataFrame\n        Value of predictions for each level.\n    \n    \"\"\"\n    if not isinstance(series, (pd.DataFrame, dict)):\n        raise TypeError('`series` must be a pandas DataFrame or a dictionary of pandas DataFrames.')\n    if not isinstance(X_train, pd.DataFrame):\n        raise TypeError(f'`X_train` must be a pandas DataFrame. Got: {type(X_train)}')\n    if not isinstance(y_train, (pd.Series, dict)):\n        raise TypeError(f'`y_train` must be a pandas Series or a dictionary of pandas Series. Got: {type(y_train)}')\n    if not isinstance(X_test, pd.DataFrame):\n        raise TypeError(f'`X_test` must be a pandas DataFrame. Got: {type(X_test)}')\n    if not isinstance(y_test, (pd.Series, dict)):\n        raise TypeError(f'`y_test` must be a pandas Series or a dictionary of pandas Series. Got: {type(y_test)}')\n    if not isinstance(X_train_encoding, pd.Series):\n        raise TypeError(f'`X_train_encoding` must be a pandas Series. Got: {type(X_train_encoding)}')\n    if not isinstance(X_test_encoding, pd.Series):\n        raise TypeError(f'`X_test_encoding` must be a pandas Series. Got: {type(X_test_encoding)}')\n    if not isinstance(levels, list):\n        raise TypeError(f'`levels` must be a list. Got: {type(levels)}')\n    if not isinstance(metrics, list):\n        raise TypeError(f'`metrics` must be a list. Got: {type(metrics)}')\n    if not isinstance(add_aggregated_metric, bool):\n        raise TypeError(f'`add_aggregated_metric` must be a boolean. Got: {type(add_aggregated_metric)}')\n    metrics = [_get_metric(metric=m) if isinstance(m, str) else add_y_train_argument(m) for m in metrics]\n    metric_names = [m if isinstance(m, str) else m.__name__ for m in metrics]\n    if isinstance(series[levels[0]].index, pd.DatetimeIndex):\n        freq = series[levels[0]].index.freq\n    else:\n        freq = series[levels[0]].index.step\n    if type(forecaster).__name__ == 'ForecasterDirectMultiVariate':\n        step = 1\n        X_train, y_train = forecaster.filter_train_X_y_for_step(step=step, X_train=X_train, y_train=y_train)\n        X_test, y_test = forecaster.filter_train_X_y_for_step(step=step, X_train=X_test, y_train=y_test)\n        forecaster.regressors_[step].fit(X_train, y_train)\n        pred = forecaster.regressors_[step].predict(X_test)\n    else:\n        forecaster.regressor.fit(X_train, y_train)\n        pred = forecaster.regressor.predict(X_test)\n    predictions_per_level = pd.DataFrame({'y_true': y_test, 'y_pred': pred, '_level_skforecast': X_test_encoding}, index=y_test.index).groupby('_level_skforecast')\n    predictions_per_level = {key: group for key, group in predictions_per_level}\n    y_train_per_level = pd.DataFrame({'y_train': y_train, '_level_skforecast': X_train_encoding}, index=y_train.index).groupby('_level_skforecast')\n    y_train_per_level = {key: group.asfreq(freq) for key, group in y_train_per_level}\n    if forecaster.differentiation is not None:\n        for level in predictions_per_level:\n            predictions_per_level[level]['y_true'] = forecaster.differentiator_[level].inverse_transform_next_window(predictions_per_level[level]['y_true'].to_numpy())\n            predictions_per_level[level]['y_pred'] = forecaster.differentiator_[level].inverse_transform_next_window(predictions_per_level[level]['y_pred'].to_numpy())\n            y_train_per_level[level]['y_train'] = forecaster.differentiator_[level].inverse_transform_training(y_train_per_level[level]['y_train'].to_numpy())\n    if forecaster.transformer_series is not None:\n        for level in predictions_per_level:\n            transformer = forecaster.transformer_series_[level]\n            predictions_per_level[level]['y_true'] = transformer.inverse_transform(predictions_per_level[level][['y_true']])\n            predictions_per_level[level]['y_pred'] = transformer.inverse_transform(predictions_per_level[level][['y_pred']])\n            y_train_per_level[level]['y_train'] = transformer.inverse_transform(y_train_per_level[level][['y_train']])\n    metrics_levels = []\n    for level in levels:\n        if level in predictions_per_level:\n            metrics_level = [m(y_true=predictions_per_level[level].loc[:, 'y_true'], y_pred=predictions_per_level[level].loc[:, 'y_pred'], y_train=y_train_per_level[level].loc[:, 'y_train']) for m in metrics]\n            metrics_levels.append(metrics_level)\n        else:\n            metrics_levels.append([None for _ in metrics])\n    metrics_levels = pd.DataFrame(data=metrics_levels, columns=[m if isinstance(m, str) else m.__name__ for m in metrics])\n    metrics_levels.insert(0, 'levels', levels)\n    if len(levels) < 2:\n        add_aggregated_metric = False\n    if add_aggregated_metric:\n        average = metrics_levels.drop(columns='levels').mean(skipna=True)\n        average = average.to_frame().transpose()\n        average['levels'] = 'average'\n        weighted_averages = {}\n        n_predictions_levels = {k: v['y_pred'].notna().sum() for k, v in predictions_per_level.items()}\n        n_predictions_levels = pd.DataFrame(n_predictions_levels.items(), columns=['levels', 'n_predictions'])\n        metrics_levels_no_missing = metrics_levels.merge(n_predictions_levels, on='levels', how='inner')\n        for col in metric_names:\n            weighted_averages[col] = np.average(metrics_levels_no_missing[col], weights=metrics_levels_no_missing['n_predictions'])\n        weighted_average = pd.DataFrame(weighted_averages, index=[0])\n        weighted_average['levels'] = 'weighted_average'\n        list_y_train_by_level = [v['y_train'].to_numpy() for k, v in y_train_per_level.items() if k in predictions_per_level]\n        predictions_pooled = pd.concat(predictions_per_level.values())\n        y_train_pooled = pd.concat([v for k, v in y_train_per_level.items() if k in predictions_per_level])\n        pooled = []\n        for m, m_name in zip(metrics, metric_names):\n            if m_name in ['mean_absolute_scaled_error', 'root_mean_squared_scaled_error']:\n                pooled.append(m(y_true=predictions_pooled['y_true'], y_pred=predictions_pooled['y_pred'], y_train=list_y_train_by_level))\n            else:\n                pooled.append(m(y_true=predictions_pooled['y_true'], y_pred=predictions_pooled['y_pred'], y_train=y_train_pooled['y_train']))\n        pooled = pd.DataFrame([pooled], columns=metric_names)\n        pooled['levels'] = 'pooling'\n        metrics_levels = pd.concat([metrics_levels, average, weighted_average, pooled], axis=0, ignore_index=True)\n    predictions = pd.concat(predictions_per_level.values()).loc[:, ['y_pred', '_level_skforecast']].pivot(columns='_level_skforecast', values='y_pred').rename_axis(columns=None, index=None)\n    predictions = predictions.asfreq(X_test.index.freq)\n    return (metrics_levels, predictions)"
  },
  "call_tree": {
    "skforecast/model_selection/tests/tests_utils/test_extract_data_folds_multiseries.py:test_extract_data_folds_multiseries_series_DataFrame_exog_None_RangeIndex": {
      "skforecast/model_selection/_utils.py:_extract_data_folds_multiseries": {}
    },
    "skforecast/model_selection/tests/tests_utils/test_extract_data_folds_multiseries.py:test_extract_data_folds_multiseries_series_DataFrame_with_NaN_exog_RangeIndex": {
      "skforecast/model_selection/_utils.py:_extract_data_folds_multiseries": {}
    },
    "skforecast/model_selection/tests/tests_utils/test_extract_data_folds_multiseries.py:test_extract_data_folds_multiseries_series_DataFrame_with_NaN_exog_DatetimeIndex": {
      "skforecast/model_selection/_utils.py:_extract_data_folds_multiseries": {}
    },
    "skforecast/model_selection/tests/tests_utils/test_extract_data_folds_multiseries.py:test_extract_data_folds_multiseries_series_dict_exog_dict_DatetimeIndex": {
      "skforecast/model_selection/_utils.py:_extract_data_folds_multiseries": {}
    }
  }
}