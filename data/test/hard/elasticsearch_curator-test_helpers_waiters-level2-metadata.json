{
  "dir_path": "/app/elasticsearch_curator",
  "package_name": "elasticsearch_curator",
  "sample_name": "elasticsearch_curator-test_helpers_waiters",
  "src_dir": "curator/",
  "test_dir": "tests/",
  "test_file": "tests/unit/test_helpers_waiters.py",
  "test_code": "\"\"\"Unit tests for utils\"\"\"\n\nfrom unittest import TestCase\nfrom unittest.mock import Mock\nimport pytest\nfrom curator.exceptions import (\n    ActionTimeout,\n    ConfigurationError,\n    CuratorException,\n    MissingArgument,\n)\nfrom curator.helpers.waiters import (\n    health_check,\n    restore_check,\n    snapshot_check,\n    task_check,\n    wait_for_it,\n)\n\nFAKE_FAIL = Exception('Simulated Failure')\n\n\nclass TestHealthCheck(TestCase):\n    \"\"\"TestHealthCheck\n\n    Test helpers.waiters.health_check functionality\n    \"\"\"\n\n    # pylint: disable=line-too-long\n    CLUSTER_HEALTH = {\n        \"cluster_name\": \"unit_test\",\n        \"status\": \"green\",\n        \"timed_out\": False,\n        \"number_of_nodes\": 7,\n        \"number_of_data_nodes\": 3,\n        \"active_primary_shards\": 235,\n        \"active_shards\": 471,\n        \"relocating_shards\": 0,\n        \"initializing_shards\": 0,\n        \"unassigned_shards\": 0,\n        \"delayed_unassigned_shards\": 0,\n        \"number_of_pending_tasks\": 0,\n        \"task_max_waiting_in_queue_millis\": 0,\n        \"active_shards_percent_as_number\": 100,\n    }\n\n    def test_no_kwargs(self):\n        \"\"\"test_no_kwargs\n\n        Should raise a ``MissingArgument`` exception when no keyword args are passed.\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'Must provide at least one keyword argument'\n        ):\n            health_check(client)\n\n    def test_key_value_match(self):\n        \"\"\"test_key_value_match\n\n        Should return ``True`` when matching keyword args are passed.\n        \"\"\"\n        client = Mock()\n        client.cluster.health.return_value = self.CLUSTER_HEALTH\n        assert health_check(client, status='green')\n\n    def test_key_value_no_match(self):\n        \"\"\"test_key_value_no_match\n\n        Should return ``False`` when matching keyword args are passed, but no matches\n        are found.\n        \"\"\"\n        client = Mock()\n        client.cluster.health.return_value = self.CLUSTER_HEALTH\n        assert not health_check(client, status='red')\n\n    def test_key_not_found(self):\n        \"\"\"test_key_not_found\n\n        Should raise ``ConfigurationError`` when keyword args are passed, but keys\n        match.\n        \"\"\"\n        client = Mock()\n        client.cluster.health.return_value = self.CLUSTER_HEALTH\n        with pytest.raises(ConfigurationError, match=r'not in cluster health output'):\n            health_check(client, foo='bar')\n\n\nclass TestRestoreCheck(TestCase):\n    \"\"\"TestRestoreCheck\n\n    Test helpers.waiters.restore_check functionality\n    \"\"\"\n\n    SNAP_NAME = 'snap_name'\n    NAMED_INDICES = [\"index-2015.01.01\", \"index-2015.02.01\"]\n\n    def test_fail_to_get_recovery(self):\n        \"\"\"test_fail_to_get_recovery\n\n        Should raise ``CuratorException`` when an upstream Exception is encountered\n        \"\"\"\n        client = Mock()\n        client.indices.recovery.side_effect = FAKE_FAIL\n        with pytest.raises(\n            CuratorException, match=r'Unable to obtain recovery information'\n        ):\n            restore_check(client, [])\n\n    def test_incomplete_recovery(self):\n        \"\"\"test_incomplete_recovery\n\n        Should return ``False`` when recovery is incomplete\n        \"\"\"\n        client = Mock()\n        # :pylint disable=line-too-long\n        client.indices.recovery.return_value = {\n            'index-2015.01.01': {'shards': [{'stage': 'INDEX'}]},\n            'index-2015.02.01': {'shards': [{'stage': 'INDEX'}]},\n        }\n        assert not restore_check(client, self.NAMED_INDICES)\n\n    def test_completed_recovery(self):\n        \"\"\"test_completed_recovery\n\n        Should return ``True`` when recovery is complete\n        \"\"\"\n        client = Mock()\n        # :pylint disable=line-too-long\n        client.indices.recovery.return_value = {\n            'index-2015.01.01': {'shards': [{'stage': 'DONE'}]},\n            'index-2015.02.01': {'shards': [{'stage': 'DONE'}]},\n        }\n        assert restore_check(client, self.NAMED_INDICES)\n\n    def test_empty_recovery(self):\n        \"\"\"test_empty_recovery\n\n        Should return ``False`` when an empty response comes back\n        \"\"\"\n        client = Mock()\n        client.indices.recovery.return_value = {}\n        assert not restore_check(client, self.NAMED_INDICES)\n\n\nclass TestSnapshotCheck(TestCase):\n    \"\"\"TestSnapshotCheck\n\n    Test helpers.waiters.snapshot_check functionality\n    \"\"\"\n\n    # :pylint disable=line-too-long\n    SNAP_NAME = 'snap_name'\n    NAMED_INDICES = [\"index-2015.01.01\", \"index-2015.02.01\"]\n\n    def test_fail_to_get_snapshot(self):\n        \"\"\"test_fail_to_get_snapshot\n\n        Should raise ``CuratorException`` when another upstream Exception occurs.\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.side_effect = FAKE_FAIL\n        self.assertRaises(CuratorException, snapshot_check, client)\n\n    def test_in_progress(self):\n        \"\"\"test_in_progress\n\n        Should return ``False`` when state is ``IN_PROGRESS``.\n        \"\"\"\n        client = Mock()\n        test_val = {\n            'snapshots': [\n                {\n                    'state': 'IN_PROGRESS',\n                    'snapshot': self.SNAP_NAME,\n                    'indices': self.NAMED_INDICES,\n                }\n            ]\n        }\n        client.snapshot.get.return_value = test_val\n        assert not snapshot_check(client, repository='foo', snapshot=self.SNAP_NAME)\n\n    def test_success(self):\n        \"\"\"test_success\n\n        Should return ``True`` when state is ``SUCCESS``.\n        \"\"\"\n        client = Mock()\n        test_val = {\n            'snapshots': [\n                {\n                    'state': 'SUCCESS',\n                    'snapshot': self.SNAP_NAME,\n                    'indices': self.NAMED_INDICES,\n                }\n            ]\n        }\n        client.snapshot.get.return_value = test_val\n        assert snapshot_check(client, repository='foo', snapshot=self.SNAP_NAME)\n\n    def test_partial(self):\n        \"\"\"test_partial\n\n        Should return ``True`` when state is ``PARTIAL``.\n        \"\"\"\n        client = Mock()\n        test_val = {\n            'snapshots': [\n                {\n                    'state': 'PARTIAL',\n                    'snapshot': self.SNAP_NAME,\n                    'indices': self.NAMED_INDICES,\n                }\n            ]\n        }\n        client.snapshot.get.return_value = test_val\n        assert snapshot_check(client, repository='foo', snapshot=self.SNAP_NAME)\n\n    def test_failed(self):\n        \"\"\"test_failed\n\n        Should return ``True`` when state is ``FAILED``.\n        \"\"\"\n        client = Mock()\n        test_val = {\n            'snapshots': [\n                {\n                    'state': 'FAILED',\n                    'snapshot': self.SNAP_NAME,\n                    'indices': self.NAMED_INDICES,\n                }\n            ]\n        }\n        client.snapshot.get.return_value = test_val\n        assert snapshot_check(client, repository='foo', snapshot=self.SNAP_NAME)\n\n    def test_other(self):\n        \"\"\"test_other\n\n        Should return ``True`` when state is anything other than ``IN_PROGRESS`` or the\n        above.\n        \"\"\"\n        client = Mock()\n        test_val = {\n            'snapshots': [\n                {\n                    'state': 'SOMETHINGELSE',\n                    'snapshot': self.SNAP_NAME,\n                    'indices': self.NAMED_INDICES,\n                }\n            ]\n        }\n        client.snapshot.get.return_value = test_val\n        assert snapshot_check(client, repository='foo', snapshot=self.SNAP_NAME)\n\n\nclass TestTaskCheck(TestCase):\n    \"\"\"TestTaskCheck\n\n    Test helpers.waiters.task_check functionality\n    \"\"\"\n\n    # pylint: disable=line-too-long\n    PROTO_TASK = {\n        'node': 'I0ekFjMhSPCQz7FUs1zJOg',\n        'description': 'UNIT TEST',\n        'running_time_in_nanos': 1637039537721,\n        'action': 'indices:data/write/reindex',\n        'id': 54510686,\n        'start_time_in_millis': 1489695981997,\n    }\n    GENERIC_TASK = {'task': 'I0ekFjMhSPCQz7FUs1zJOg:54510686'}\n\n    def test_bad_task_id(self):\n        \"\"\"test_bad_task_id\n\n        Should raise ``CuratorException`` if a bad value for ``task_id`` is passed\n        \"\"\"\n        client = Mock()\n        client.tasks.get.side_effect = FAKE_FAIL\n        with pytest.raises(\n            CuratorException, match=r'Unable to obtain task information for task'\n        ):\n            task_check(client, 'foo')\n\n    def test_incomplete_task(self):\n        \"\"\"test_incomplete_task\n\n        Should return ``False`` if task is incomplete\n        \"\"\"\n        client = Mock()\n        test_task = {\n            'completed': False,\n            'task': self.PROTO_TASK,\n            'response': {'failures': []},\n        }\n        client.tasks.get.return_value = test_task\n        assert not task_check(client, task_id=self.GENERIC_TASK['task'])\n\n    def test_complete_task(self):\n        \"\"\"test_complete_task\n\n        Should return ``True`` if task is complete\n        \"\"\"\n        client = Mock()\n        test_task = {\n            'completed': True,\n            'task': self.PROTO_TASK,\n            'response': {'failures': []},\n        }\n        client.tasks.get.return_value = test_task\n        assert task_check(client, task_id=self.GENERIC_TASK['task'])\n\n\nclass TestWaitForIt(TestCase):\n    \"\"\"TestWaitForIt\n\n    Test helpers.waiters.wait_for_it functionality\n    \"\"\"\n\n    # pylint: disable=line-too-long\n    def test_bad_action(self):\n        \"\"\"test_bad_action\n\n        Should raise a ``ConfigurationError`` exception if ``action`` is invalid\n        \"\"\"\n        client = Mock()\n        # self.assertRaises(ConfigurationError, wait_for_it, client, 'foo')\n        with pytest.raises(ConfigurationError, match=r'\"action\" must be one of'):\n            wait_for_it(client, 'foo')\n\n    def test_reindex_action_no_task_id(self):\n        \"\"\"test_reindex_action_no_task_id\n\n        Should raise a ``MissingArgument`` exception if ``task_id`` is missing for\n        ``reindex``\n        \"\"\"\n        client = Mock()\n        # self.assertRaises(MissingArgument, wait_for_it, client, 'reindex')\n        with pytest.raises(MissingArgument, match=r'A task_id must accompany \"action\"'):\n            wait_for_it(client, 'reindex')\n\n    def test_snapshot_action_no_snapshot(self):\n        \"\"\"test_snapshot_action_no_snapshot\n\n        Should raise a ``MissingArgument`` exception if ``snapshot`` is missing for\n        ``snapshot``\n        \"\"\"\n        client = Mock()\n        # self.assertRaises(MissingArgument, wait_for_it, client,\n        #   'snapshot', repository='foo')\n        with pytest.raises(\n            MissingArgument, match=r'A snapshot and repository must accompany \"action\"'\n        ):\n            wait_for_it(client, 'snapshot', repository='foo')\n\n    def test_snapshot_action_no_repository(self):\n        \"\"\"test_snapshot_action_no_repository\n\n        Should raise a ``MissingArgument`` exception if ``repository`` is missing for\n        ``snapshot``\n        \"\"\"\n        client = Mock()\n        # self.assertRaises(MissingArgument, wait_for_it, client,\n        #   'snapshot', snapshot='foo')\n        with pytest.raises(\n            MissingArgument, match=r'A snapshot and repository must accompany \"action\"'\n        ):\n            wait_for_it(client, 'snapshot', snapshot='foo')\n\n    def test_restore_action_no_indexlist(self):\n        \"\"\"test_restore_action_no_indexlist\n\n        Should raise a ``MissingArgument`` exception if ``index_list`` is missing for\n        ``restore``\n        \"\"\"\n        client = Mock()\n        # self.assertRaises(MissingArgument, wait_for_it, client, 'restore')\n        with pytest.raises(\n            MissingArgument, match=r'An index_list must accompany \"action\"'\n        ):\n            wait_for_it(client, 'restore')\n\n    def test_reindex_action_bad_task_id(self):\n        \"\"\"test_reindex_action_bad_task_id\n\n        Should raise a ``CuratorException`` exception if there's a bad task_id\n\n        This is kind of a fake fail, even in the code.\n        \"\"\"\n        client = Mock()\n        client.tasks.get.return_value = {'a': 'b'}\n        client.tasks.get.side_effect = FAKE_FAIL\n        # self.assertRaises(CuratorException, wait_for_it,\n        #       client, 'reindex', task_id='foo')\n        with pytest.raises(CuratorException, match=r'Unable to find task_id'):\n            wait_for_it(client, 'reindex', task_id='foo')\n\n    def test_reached_max_wait(self):\n        \"\"\"test_reached_max_wait\n\n        Should raise a ``ActionTimeout`` exception if we've waited past the defined\n        timeout period\n        \"\"\"\n        client = Mock()\n        client.cluster.health.return_value = {'status': 'red'}\n        # self.assertRaises(ActionTimeout, wait_for_it, client, 'replicas',\n        # wait_interval=1, max_wait=1)\n        with pytest.raises(\n            ActionTimeout, match=r'failed to complete in the max_wait period'\n        ):\n            wait_for_it(client, 'replicas', wait_interval=1, max_wait=1)\n",
  "GT_file_code": {
    "curator/helpers/waiters.py": "\"\"\"The function that waits\n\n...and its helpers\n\"\"\"\nimport logging\nfrom time import localtime, sleep, strftime\nfrom datetime import datetime\nfrom curator.exceptions import (\n    ActionTimeout, ConfigurationError, CuratorException, FailedReindex, MissingArgument)\nfrom curator.helpers.utils import chunk_index_list\n\ndef health_check(client, **kwargs):\n    \"\"\"\n    This function calls `client.cluster.` :py:meth:`~.elasticsearch.client.ClusterClient.health`\n    and, based on the params provided, will return ``True`` or ``False`` depending on whether that\n    particular keyword appears in the output, and has the expected value.\n\n    If multiple keys are provided, all must match for a ``True`` response.\n\n    :param client: A client connection object\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :rtype: bool\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.debug('KWARGS= \"%s\"', kwargs)\n    klist = list(kwargs.keys())\n    if not klist:\n        raise MissingArgument('Must provide at least one keyword argument')\n    hc_data = client.cluster.health()\n    response = True\n\n    for k in klist:\n        # First, verify that all kwargs are in the list\n        if not k in list(hc_data.keys()):\n            raise ConfigurationError('Key \"{0}\" not in cluster health output')\n        if not hc_data[k] == kwargs[k]:\n            msg = f'NO MATCH: Value for key \"{kwargs[k]}\", health check data: {hc_data[k]}'\n            logger.debug(msg)\n            response = False\n        else:\n            msg = f'MATCH: Value for key \"{kwargs[k]}\", health check data: {hc_data[k]}'\n            logger.debug(msg)\n    if response:\n        logger.info('Health Check for all provided keys passed.')\n    return response\n\ndef relocate_check(client, index):\n    \"\"\"\n    This function calls `client.cluster.` :py:meth:`~.elasticsearch.client.ClusterClient.state`\n    with a given index to check if all of the shards for that index are in the ``STARTED`` state.\n    It will return ``True`` if all primary and replica shards are in the ``STARTED`` state, and it\n    will return ``False`` if any shard is in a different state.\n\n    :param client: A client connection object\n    :param index: The index name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type index: str\n\n    :rtype: bool\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    shard_state_data = (\n        client.cluster.state(index=index)['routing_table']['indices'][index]['shards']\n    )\n    finished_state = (\n        all(\n            all(\n                shard['state'] == \"STARTED\" for shard in shards\n            )\n            for shards in shard_state_data.values()\n        )\n    )\n    if finished_state:\n        logger.info('Relocate Check for index: \"%s\" has passed.', index)\n    return finished_state\n\ndef restore_check(client, index_list):\n    \"\"\"\n    This function calls `client.indices.` :py:meth:`~.elasticsearch.client.IndicesClient.recovery`\n    with the list of indices to check for complete recovery.  It will return ``True`` if recovery\n    of those indices is complete, and ``False`` otherwise.  It is designed to fail fast: if a\n    single shard is encountered that is still recovering (not in ``DONE`` stage), it will\n    immediately return ``False``, rather than complete iterating over the rest of the response.\n\n    :param client: A client connection object\n    :param index_list: The list of indices to verify having been restored.\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type index_list: list\n\n    :rtype: bool\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    response = {}\n    for chunk in chunk_index_list(index_list):\n        try:\n            chunk_response = client.indices.recovery(index=chunk, human=True)\n        except Exception as err:\n            msg = f'Unable to obtain recovery information for specified indices. Error: {err}'\n            raise CuratorException(msg) from err\n        if chunk_response == {}:\n            logger.info('_recovery returned an empty response. Trying again.')\n            return False\n        response.update(chunk_response)\n    logger.info('Provided indices: %s', index_list)\n    logger.info('Found indices: %s', list(response.keys()))\n    # pylint: disable=consider-using-dict-items\n    for index in response:\n        for shard in range(0, len(response[index]['shards'])):\n            stage = response[index]['shards'][shard]['stage']\n            if stage != 'DONE':\n                logger.info('Index \"%s\" is still in stage \"%s\"', index, stage)\n                return False\n\n    # If we've gotten here, all of the indices have recovered\n    return True\n\ndef snapshot_check(client, snapshot=None, repository=None):\n    \"\"\"\n    This function calls `client.snapshot.` :py:meth:`~.elasticsearch.client.SnapshotClient.get` and\n    tests to see whether the snapshot is complete, and if so, with what status.  It will log errors\n    according to the result. If the snapshot is still ``IN_PROGRESS``, it will return ``False``.\n    ``SUCCESS`` will be an ``INFO`` level message, ``PARTIAL`` nets a ``WARNING`` message,\n    ``FAILED`` is an ``ERROR``, message, and all others will be a ``WARNING`` level message.\n\n    :param client: A client connection object\n    :param snapshot: The snapshot name\n    :param repository: The repository name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type snapshot: str\n    :type repository: str\n\n    :rtype: bool\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.debug('SNAPSHOT: %s', snapshot)\n    logger.debug('REPOSITORY: %s', repository)\n    try:\n        result = client.snapshot.get(repository=repository, snapshot=snapshot)\n        logger.debug('RESULT: %s', result)\n    except Exception as err:\n        raise CuratorException(\n            f'Unable to obtain information for snapshot \"{snapshot}\" in repository '\n            f'\"{repository}\". Error: {err}'\n        ) from err\n    state = result['snapshots'][0]['state']\n    logger.debug('Snapshot state = %s', state)\n    retval = True\n    if state == 'IN_PROGRESS':\n        logger.info('Snapshot %s still in progress.', snapshot)\n        retval = False\n    elif state == 'SUCCESS':\n        logger.info('Snapshot %s successfully completed.', snapshot)\n    elif state == 'PARTIAL':\n        logger.warning('Snapshot %s completed with state PARTIAL.', snapshot)\n    elif state == 'FAILED':\n        logger.error('Snapshot %s completed with state FAILED.', snapshot)\n    else:\n        logger.warning('Snapshot %s completed with state: %s', snapshot, state)\n    return retval\n\ndef task_check(client, task_id=None):\n    \"\"\"\n    This function calls `client.tasks.` :py:meth:`~.elasticsearch.client.TasksClient.get` with the\n    provided ``task_id``.  If the task data contains ``'completed': True``, then it will return\n    ``True``. If the task is not completed, it will log some information about the task and return\n    ``False``\n\n    :param client: A client connection object\n    :param task_id: The task id\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type task_id: str\n\n    :rtype: bool\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    try:\n        task_data = client.tasks.get(task_id=task_id)\n    except Exception as err:\n        msg = f'Unable to obtain task information for task_id \"{task_id}\". Exception {err}'\n        raise CuratorException(msg) from err\n    task = task_data['task']\n    completed = task_data['completed']\n    if task['action'] == 'indices:data/write/reindex':\n        logger.debug('It\\'s a REINDEX TASK')\n        logger.debug('TASK_DATA: %s', task_data)\n        logger.debug('TASK_DATA keys: %s', list(task_data.keys()))\n        if 'response' in task_data:\n            response = task_data['response']\n            if response['failures']:\n                msg = f'Failures found in reindex response: {response[\"failures\"]}'\n                raise FailedReindex(msg)\n    running_time = 0.000000001 * task['running_time_in_nanos']\n    logger.debug('Running time: %s seconds', running_time)\n    descr = task['description']\n\n    if completed:\n        completion_time = (running_time * 1000) + task['start_time_in_millis']\n        time_string = strftime('%Y-%m-%dT%H:%M:%SZ', localtime(completion_time/1000))\n        logger.info('Task \"%s\" completed at %s.', descr, time_string)\n        retval = True\n    else:\n        # Log the task status here.\n        logger.debug('Full Task Data: %s', task_data)\n        msg = (\n            f'Task \"{descr}\" with task_id \"{task_id}\" has been running for {running_time} seconds'\n        )\n        logger.info(msg)\n        retval = False\n    return retval\n\n# pylint: disable=too-many-locals, too-many-arguments\ndef wait_for_it(\n        client, action, task_id=None, snapshot=None, repository=None, index=None, index_list=None,\n        wait_interval=9, max_wait=-1\n    ):\n    \"\"\"\n    This function becomes one place to do all ``wait_for_completion`` type behaviors\n\n    :param client: A client connection object\n    :param action: The action name that will identify how to wait\n    :param task_id: If the action provided a task_id, this is where it must be declared.\n    :param snapshot: The name of the snapshot.\n    :param repository: The Elasticsearch snapshot repository to use\n    :param wait_interval: Seconds to wait between completion checks.\n    :param max_wait: Maximum number of seconds to ``wait_for_completion``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type action: str\n    :type task_id: str\n    :type snapshot: str\n    :type repository: str\n    :type wait_interval: int\n    :type max_wait: int\n    :rtype: None\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    action_map = {\n        'allocation':{'function': health_check, 'args': {'relocating_shards':0}},\n        'replicas':{'function': health_check, 'args': {'status':'green'}},\n        'cluster_routing':{'function': health_check, 'args': {'relocating_shards':0}},\n        'snapshot':{\n            'function':snapshot_check, 'args':{'snapshot':snapshot, 'repository':repository}},\n        'restore':{'function':restore_check, 'args':{'index_list':index_list}},\n        'reindex':{'function':task_check, 'args':{'task_id':task_id}},\n        'shrink':{'function': health_check, 'args': {'status':'green'}},\n        'relocate':{'function': relocate_check, 'args': {'index':index}},\n    }\n    wait_actions = list(action_map.keys())\n\n    if action not in wait_actions:\n        raise ConfigurationError(f'\"action\" must be one of {wait_actions}')\n    if action == 'reindex' and task_id is None:\n        raise MissingArgument(f'A task_id must accompany \"action\" {action}')\n    if action == 'snapshot' and ((snapshot is None) or (repository is None)):\n        raise MissingArgument(\n            f'A snapshot and repository must accompany \"action\" {action}. snapshot: '\n            f'{snapshot}, repository: {repository}'\n        )\n    if action == 'restore' and index_list is None:\n        raise MissingArgument(f'An index_list must accompany \"action\" {action}')\n    if action == 'reindex':\n        try:\n            _ = client.tasks.get(task_id=task_id)\n        except Exception as err:\n            # This exception should only exist in API usage. It should never\n            # occur in regular Curator usage.\n            raise CuratorException(f'Unable to find task_id {task_id}. Exception: {err}') from err\n\n    # Now with this mapped, we can perform the wait as indicated.\n    start_time = datetime.now()\n    result = False\n    while True:\n        elapsed = int((datetime.now() - start_time).total_seconds())\n        logger.debug('Elapsed time: %s seconds', elapsed)\n        response = action_map[action]['function'](client, **action_map[action]['args'])\n        logger.debug('Response: %s', response)\n        # Success\n        if response:\n            logger.debug(\n                'Action \"%s\" finished executing (may or may not have been successful)', action)\n            result = True\n            break\n        # Not success, and reached maximum wait (if defined)\n        if (max_wait != -1) and (elapsed >= max_wait):\n            msg = f'Unable to complete action \"{action}\" within max_wait ({max_wait}) seconds.'\n            logger.error(msg)\n            break\n        # Not success, so we wait.\n        msg = (\n            f'Action \"{action}\" not yet complete, {elapsed} total seconds elapsed. '\n            f'Waiting {wait_interval} seconds before checking again.'\n        )\n        logger.debug(msg)\n        sleep(wait_interval)\n\n    logger.debug('Result: %s', result)\n    if not result:\n        raise ActionTimeout(\n            f'Action \"{action}\" failed to complete in the max_wait period of {max_wait} seconds'\n        )\n",
    "curator/helpers/utils.py": "\"\"\"Helper utilities\n\nThe kind that don't fit in testers, getters, date_ops, or converters\n\"\"\"\nimport logging\nfrom es_client.helpers.utils import ensure_list\nfrom curator.exceptions import FailedExecution\n\ndef chunk_index_list(indices):\n    \"\"\"\n    This utility chunks very large index lists into 3KB chunks.\n    It measures the size as a csv string, then converts back into a list for the return value.\n\n    :param indices: The list of indices\n\n    :type indices: list\n\n    :returns: A list of lists (each a piece of the original ``indices``)\n    :rtype: list\n    \"\"\"\n    chunks = []\n    chunk = \"\"\n    for index in indices:\n        if len(chunk) < 3072:\n            if not chunk:\n                chunk = index\n            else:\n                chunk += \",\" + index\n        else:\n            chunks.append(chunk.split(','))\n            chunk = index\n    chunks.append(chunk.split(','))\n    return chunks\n\ndef report_failure(exception):\n    \"\"\"\n    Raise a :py:exc:`~.curator.exceptions.FailedExecution` exception and include the original error\n    message.\n\n    :param exception: The upstream exception.\n\n    :type exception: :py:exc:Exception\n\n    :rtype: None\n    \"\"\"\n    raise FailedExecution(\n        f'Exception encountered.  Rerun with loglevel DEBUG and/or check Elasticsearch logs for'\n        f'more information. Exception: {exception}'\n    )\n\ndef show_dry_run(ilo, action, **kwargs):\n    \"\"\"\n    Log dry run output with the action which would have been executed.\n\n    :param ilo: An IndexList Object\n    :param action: The ``action`` to be performed.\n    :param kwargs: Any other args to show in the log output\n\n\n    :type ilo: :py:class:`~.curator.indexlist.IndexList`\n    :type action: str\n    :type kwargs: dict\n\n    :rtype: None\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.info('DRY-RUN MODE.  No changes will be made.')\n    msg = f'(CLOSED) indices may be shown that may not be acted on by action \"{action}\".'\n    logger.info(msg)\n    indices = sorted(ilo.indices)\n    for idx in indices:\n        # Dry runs need index state, so we collect it here if it's not present.\n        try:\n            index_closed = ilo.index_info[idx]['state'] == 'close'\n        except KeyError:\n            ilo.get_index_state()\n            index_closed = ilo.index_info[idx]['state'] == 'close'\n        var = ' (CLOSED)' if index_closed else ''\n        msg = f'DRY-RUN: {action}: {idx}{var} with arguments: {kwargs}'\n        logger.info(msg)\n\ndef to_csv(indices):\n    \"\"\"\n    :param indices: A list of indices to act on, or a single value, which could be\n        in the format of a csv string already.\n\n    :type indices: list\n\n    :returns: A csv string from a list of indices, or a single value if only one value is present\n    :rtype: str\n    \"\"\"\n    indices = ensure_list(indices) # in case of a single value passed\n    if indices:\n        return ','.join(sorted(indices))\n    return None\n",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\"\n"
  },
  "GT_src_dict": {
    "curator/helpers/waiters.py": {
      "health_check": {
        "code": "def health_check(client, **kwargs):\n    \"\"\"Checks the health of an Elasticsearch cluster by verifying the health status against provided keyword arguments.\n\nThis function interacts with the `client.cluster.health` API to retrieve the current health status of the cluster. It takes keyword arguments representing health properties (e.g., status, relocating_shards) and validates them against the actual health data from the cluster.\n\nParameters:\n- client (Elasticsearch): An Elasticsearch client connection object used to communicate with the cluster.\n- **kwargs: Keyword arguments corresponding to the expected health indicators and their values.\n\nReturns:\n- bool: Returns `True` if all provided health indicators match their expected values; otherwise, returns `False`.\n\nRaises:\n- MissingArgument: If no keyword arguments are provided.\n- ConfigurationError: If any provided key is not present in the cluster health output.\n\nLogs debugging information regarding the health check process and logs the result of the health check, providing insights into matching or mismatching values.\"\"\"\n    '\\n    This function calls `client.cluster.` :py:meth:`~.elasticsearch.client.ClusterClient.health`\\n    and, based on the params provided, will return ``True`` or ``False`` depending on whether that\\n    particular keyword appears in the output, and has the expected value.\\n\\n    If multiple keys are provided, all must match for a ``True`` response.\\n\\n    :param client: A client connection object\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n\\n    :rtype: bool\\n    '\n    logger = logging.getLogger(__name__)\n    logger.debug('KWARGS= \"%s\"', kwargs)\n    klist = list(kwargs.keys())\n    if not klist:\n        raise MissingArgument('Must provide at least one keyword argument')\n    hc_data = client.cluster.health()\n    response = True\n    for k in klist:\n        if not k in list(hc_data.keys()):\n            raise ConfigurationError('Key \"{0}\" not in cluster health output')\n        if not hc_data[k] == kwargs[k]:\n            msg = f'NO MATCH: Value for key \"{kwargs[k]}\", health check data: {hc_data[k]}'\n            logger.debug(msg)\n            response = False\n        else:\n            msg = f'MATCH: Value for key \"{kwargs[k]}\", health check data: {hc_data[k]}'\n            logger.debug(msg)\n    if response:\n        logger.info('Health Check for all provided keys passed.')\n    return response",
        "docstring": "Checks the health of an Elasticsearch cluster by verifying the health status against provided keyword arguments.\n\nThis function interacts with the `client.cluster.health` API to retrieve the current health status of the cluster. It takes keyword arguments representing health properties (e.g., status, relocating_shards) and validates them against the actual health data from the cluster.\n\nParameters:\n- client (Elasticsearch): An Elasticsearch client connection object used to communicate with the cluster.\n- **kwargs: Keyword arguments corresponding to the expected health indicators and their values.\n\nReturns:\n- bool: Returns `True` if all provided health indicators match their expected values; otherwise, returns `False`.\n\nRaises:\n- MissingArgument: If no keyword arguments are provided.\n- ConfigurationError: If any provided key is not present in the cluster health output.\n\nLogs debugging information regarding the health check process and logs the result of the health check, providing insights into matching or mismatching values.",
        "signature": "def health_check(client, **kwargs):",
        "type": "Function",
        "class_signature": null
      },
      "restore_check": {
        "code": "def restore_check(client, index_list):\n    \"\"\"This function checks the recovery status of a list of indices in Elasticsearch by calling the `client.indices.recovery` method. It returns `True` if all shards of the specified indices are in the \"DONE\" state, indicating complete recovery. If any shard is still recovering, it returns `False` immediately. \n\nParameters:\n- client (Elasticsearch): A client connection object to communicate with the Elasticsearch cluster.\n- index_list (list): A list of indices to verify having been restored.\n\nReturns:\n- bool: `True` if all indices are fully recovered; `False` otherwise.\n\nThe function leverages the `chunk_index_list` utility to handle large lists of indices efficiently. It logs the recovery process and results, including any errors encountered during the check. If no recovery information is returned, it logs a message and defaults to returning `False`.\"\"\"\n    '\\n    This function calls `client.indices.` :py:meth:`~.elasticsearch.client.IndicesClient.recovery`\\n    with the list of indices to check for complete recovery.  It will return ``True`` if recovery\\n    of those indices is complete, and ``False`` otherwise.  It is designed to fail fast: if a\\n    single shard is encountered that is still recovering (not in ``DONE`` stage), it will\\n    immediately return ``False``, rather than complete iterating over the rest of the response.\\n\\n    :param client: A client connection object\\n    :param index_list: The list of indices to verify having been restored.\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type index_list: list\\n\\n    :rtype: bool\\n    '\n    logger = logging.getLogger(__name__)\n    response = {}\n    for chunk in chunk_index_list(index_list):\n        try:\n            chunk_response = client.indices.recovery(index=chunk, human=True)\n        except Exception as err:\n            msg = f'Unable to obtain recovery information for specified indices. Error: {err}'\n            raise CuratorException(msg) from err\n        if chunk_response == {}:\n            logger.info('_recovery returned an empty response. Trying again.')\n            return False\n        response.update(chunk_response)\n    logger.info('Provided indices: %s', index_list)\n    logger.info('Found indices: %s', list(response.keys()))\n    for index in response:\n        for shard in range(0, len(response[index]['shards'])):\n            stage = response[index]['shards'][shard]['stage']\n            if stage != 'DONE':\n                logger.info('Index \"%s\" is still in stage \"%s\"', index, stage)\n                return False\n    return True",
        "docstring": "This function checks the recovery status of a list of indices in Elasticsearch by calling the `client.indices.recovery` method. It returns `True` if all shards of the specified indices are in the \"DONE\" state, indicating complete recovery. If any shard is still recovering, it returns `False` immediately. \n\nParameters:\n- client (Elasticsearch): A client connection object to communicate with the Elasticsearch cluster.\n- index_list (list): A list of indices to verify having been restored.\n\nReturns:\n- bool: `True` if all indices are fully recovered; `False` otherwise.\n\nThe function leverages the `chunk_index_list` utility to handle large lists of indices efficiently. It logs the recovery process and results, including any errors encountered during the check. If no recovery information is returned, it logs a message and defaults to returning `False`.",
        "signature": "def restore_check(client, index_list):",
        "type": "Function",
        "class_signature": null
      },
      "snapshot_check": {
        "code": "def snapshot_check(client, snapshot=None, repository=None):\n    \"\"\"This function checks the status of a specified snapshot in a given Elasticsearch repository. It queries the snapshot's state using the client's snapshot client, logs the status, and returns a boolean indicating whether the snapshot is complete. The function handles different snapshot states: returning `False` if the snapshot is still in progress (`IN_PROGRESS`), logging `INFO` for a successful completion (`SUCCESS`), logging a `WARNING` for a partial completion (`PARTIAL`), and logging an `ERROR` for a failed snapshot (`FAILED`).\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param snapshot: The name of the snapshot to check.\n:type snapshot: str\n:param repository: The name of the snapshot repository.\n:type repository: str\n\n:rtype: bool\n:return: `True` if the snapshot is complete, `False` if it is still in progress.\n\nExceptions raised include `CuratorException` if there is an issue obtaining snapshot information, indicating a dependency on the client's snapshot methods and appropriate handling of Elasticsearch responses.\"\"\"\n    '\\n    This function calls `client.snapshot.` :py:meth:`~.elasticsearch.client.SnapshotClient.get` and\\n    tests to see whether the snapshot is complete, and if so, with what status.  It will log errors\\n    according to the result. If the snapshot is still ``IN_PROGRESS``, it will return ``False``.\\n    ``SUCCESS`` will be an ``INFO`` level message, ``PARTIAL`` nets a ``WARNING`` message,\\n    ``FAILED`` is an ``ERROR``, message, and all others will be a ``WARNING`` level message.\\n\\n    :param client: A client connection object\\n    :param snapshot: The snapshot name\\n    :param repository: The repository name\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type snapshot: str\\n    :type repository: str\\n\\n    :rtype: bool\\n    '\n    logger = logging.getLogger(__name__)\n    logger.debug('SNAPSHOT: %s', snapshot)\n    logger.debug('REPOSITORY: %s', repository)\n    try:\n        result = client.snapshot.get(repository=repository, snapshot=snapshot)\n        logger.debug('RESULT: %s', result)\n    except Exception as err:\n        raise CuratorException(f'Unable to obtain information for snapshot \"{snapshot}\" in repository \"{repository}\". Error: {err}') from err\n    state = result['snapshots'][0]['state']\n    logger.debug('Snapshot state = %s', state)\n    retval = True\n    if state == 'IN_PROGRESS':\n        logger.info('Snapshot %s still in progress.', snapshot)\n        retval = False\n    elif state == 'SUCCESS':\n        logger.info('Snapshot %s successfully completed.', snapshot)\n    elif state == 'PARTIAL':\n        logger.warning('Snapshot %s completed with state PARTIAL.', snapshot)\n    elif state == 'FAILED':\n        logger.error('Snapshot %s completed with state FAILED.', snapshot)\n    else:\n        logger.warning('Snapshot %s completed with state: %s', snapshot, state)\n    return retval",
        "docstring": "This function checks the status of a specified snapshot in a given Elasticsearch repository. It queries the snapshot's state using the client's snapshot client, logs the status, and returns a boolean indicating whether the snapshot is complete. The function handles different snapshot states: returning `False` if the snapshot is still in progress (`IN_PROGRESS`), logging `INFO` for a successful completion (`SUCCESS`), logging a `WARNING` for a partial completion (`PARTIAL`), and logging an `ERROR` for a failed snapshot (`FAILED`).\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param snapshot: The name of the snapshot to check.\n:type snapshot: str\n:param repository: The name of the snapshot repository.\n:type repository: str\n\n:rtype: bool\n:return: `True` if the snapshot is complete, `False` if it is still in progress.\n\nExceptions raised include `CuratorException` if there is an issue obtaining snapshot information, indicating a dependency on the client's snapshot methods and appropriate handling of Elasticsearch responses.",
        "signature": "def snapshot_check(client, snapshot=None, repository=None):",
        "type": "Function",
        "class_signature": null
      },
      "task_check": {
        "code": "def task_check(client, task_id=None):\n    \"\"\"Checks the status of a task in Elasticsearch using its task ID. It retrieves the task data and determines if the task is complete. If the task is a reindex task and has any failures, it raises a `FailedReindex` exception. The function logs detailed information about the task's progress and duration, including completion time if completed.\n\n:param client: A client connection object for Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param task_id: The ID of the task to check.\n:type task_id: str\n\n:rtype: bool\n:return: Returns `True` if the task is completed; otherwise, `False`.\n\nSide Effects:\n- Logs detailed information about the task, such as its running time and completion status.\n- Raises a `CuratorException` if the task data cannot be retrieved or if the task fails during reindexing.\n\nThis function relies on the Elasticsearch client and retrieves data through `client.tasks.get()`.\"\"\"\n    \"\\n    This function calls `client.tasks.` :py:meth:`~.elasticsearch.client.TasksClient.get` with the\\n    provided ``task_id``.  If the task data contains ``'completed': True``, then it will return\\n    ``True``. If the task is not completed, it will log some information about the task and return\\n    ``False``\\n\\n    :param client: A client connection object\\n    :param task_id: The task id\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type task_id: str\\n\\n    :rtype: bool\\n    \"\n    logger = logging.getLogger(__name__)\n    try:\n        task_data = client.tasks.get(task_id=task_id)\n    except Exception as err:\n        msg = f'Unable to obtain task information for task_id \"{task_id}\". Exception {err}'\n        raise CuratorException(msg) from err\n    task = task_data['task']\n    completed = task_data['completed']\n    if task['action'] == 'indices:data/write/reindex':\n        logger.debug(\"It's a REINDEX TASK\")\n        logger.debug('TASK_DATA: %s', task_data)\n        logger.debug('TASK_DATA keys: %s', list(task_data.keys()))\n        if 'response' in task_data:\n            response = task_data['response']\n            if response['failures']:\n                msg = f'Failures found in reindex response: {response['failures']}'\n                raise FailedReindex(msg)\n    running_time = 1e-09 * task['running_time_in_nanos']\n    logger.debug('Running time: %s seconds', running_time)\n    descr = task['description']\n    if completed:\n        completion_time = running_time * 1000 + task['start_time_in_millis']\n        time_string = strftime('%Y-%m-%dT%H:%M:%SZ', localtime(completion_time / 1000))\n        logger.info('Task \"%s\" completed at %s.', descr, time_string)\n        retval = True\n    else:\n        logger.debug('Full Task Data: %s', task_data)\n        msg = f'Task \"{descr}\" with task_id \"{task_id}\" has been running for {running_time} seconds'\n        logger.info(msg)\n        retval = False\n    return retval",
        "docstring": "Checks the status of a task in Elasticsearch using its task ID. It retrieves the task data and determines if the task is complete. If the task is a reindex task and has any failures, it raises a `FailedReindex` exception. The function logs detailed information about the task's progress and duration, including completion time if completed.\n\n:param client: A client connection object for Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param task_id: The ID of the task to check.\n:type task_id: str\n\n:rtype: bool\n:return: Returns `True` if the task is completed; otherwise, `False`.\n\nSide Effects:\n- Logs detailed information about the task, such as its running time and completion status.\n- Raises a `CuratorException` if the task data cannot be retrieved or if the task fails during reindexing.\n\nThis function relies on the Elasticsearch client and retrieves data through `client.tasks.get()`.",
        "signature": "def task_check(client, task_id=None):",
        "type": "Function",
        "class_signature": null
      },
      "wait_for_it": {
        "code": "def wait_for_it(client, action, task_id=None, snapshot=None, repository=None, index=None, index_list=None, wait_interval=9, max_wait=-1):\n    \"\"\"The `wait_for_it` function provides a unified mechanism to wait for the completion of various actions related to Elasticsearch, such as health checks, snapshot status, recovery, and task completion. It checks the status of the specified action at regular intervals until the action completes or a maximum wait time is reached.\n\nParameters:\n- `client`: An Elasticsearch client connection object used to interact with the Elasticsearch cluster.\n- `action`: A string indicating the specific action to be awaited (e.g., 'snapshot', 'restore', 'reindex').\n- `task_id`: Optional string for actions that generate a task ID, like reindexing.\n- `snapshot`: Optional string for the name of the snapshot when checking snapshot status.\n- `repository`: Optional string specifying the Elasticsearch snapshot repository.\n- `index`: Optional string for the index associated with relocation checks.\n- `index_list`: Optional list of indices to check for restoration.\n- `wait_interval`: Optional integer (default is 9 seconds) specifying the wait time between checks.\n- `max_wait`: Optional integer (default is -1, meaning no limit) specifying the maximum wait time.\n\nReturns:\n- None: Raises `ActionTimeout` if the action does not complete within the specified max wait time.\n\nRaises:\n- `ConfigurationError`: If the provided action is invalid or required parameters are missing.\n- `MissingArgument`: If required arguments for certain actions are not provided.\n- `CuratorException`: If a task associated with the action cannot be found.\n\nThe function interacts with several other functions including `health_check`, `snapshot_check`, `restore_check`, `task_check`, and `relocate_check` to validate the status of ongoing processes in the Elasticsearch cluster based on the specified action.\"\"\"\n    '\\n    This function becomes one place to do all ``wait_for_completion`` type behaviors\\n\\n    :param client: A client connection object\\n    :param action: The action name that will identify how to wait\\n    :param task_id: If the action provided a task_id, this is where it must be declared.\\n    :param snapshot: The name of the snapshot.\\n    :param repository: The Elasticsearch snapshot repository to use\\n    :param wait_interval: Seconds to wait between completion checks.\\n    :param max_wait: Maximum number of seconds to ``wait_for_completion``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type action: str\\n    :type task_id: str\\n    :type snapshot: str\\n    :type repository: str\\n    :type wait_interval: int\\n    :type max_wait: int\\n    :rtype: None\\n    '\n    logger = logging.getLogger(__name__)\n    action_map = {'allocation': {'function': health_check, 'args': {'relocating_shards': 0}}, 'replicas': {'function': health_check, 'args': {'status': 'green'}}, 'cluster_routing': {'function': health_check, 'args': {'relocating_shards': 0}}, 'snapshot': {'function': snapshot_check, 'args': {'snapshot': snapshot, 'repository': repository}}, 'restore': {'function': restore_check, 'args': {'index_list': index_list}}, 'reindex': {'function': task_check, 'args': {'task_id': task_id}}, 'shrink': {'function': health_check, 'args': {'status': 'green'}}, 'relocate': {'function': relocate_check, 'args': {'index': index}}}\n    wait_actions = list(action_map.keys())\n    if action not in wait_actions:\n        raise ConfigurationError(f'\"action\" must be one of {wait_actions}')\n    if action == 'reindex' and task_id is None:\n        raise MissingArgument(f'A task_id must accompany \"action\" {action}')\n    if action == 'snapshot' and (snapshot is None or repository is None):\n        raise MissingArgument(f'A snapshot and repository must accompany \"action\" {action}. snapshot: {snapshot}, repository: {repository}')\n    if action == 'restore' and index_list is None:\n        raise MissingArgument(f'An index_list must accompany \"action\" {action}')\n    if action == 'reindex':\n        try:\n            _ = client.tasks.get(task_id=task_id)\n        except Exception as err:\n            raise CuratorException(f'Unable to find task_id {task_id}. Exception: {err}') from err\n    start_time = datetime.now()\n    result = False\n    while True:\n        elapsed = int((datetime.now() - start_time).total_seconds())\n        logger.debug('Elapsed time: %s seconds', elapsed)\n        response = action_map[action]['function'](client, **action_map[action]['args'])\n        logger.debug('Response: %s', response)\n        if response:\n            logger.debug('Action \"%s\" finished executing (may or may not have been successful)', action)\n            result = True\n            break\n        if max_wait != -1 and elapsed >= max_wait:\n            msg = f'Unable to complete action \"{action}\" within max_wait ({max_wait}) seconds.'\n            logger.error(msg)\n            break\n        msg = f'Action \"{action}\" not yet complete, {elapsed} total seconds elapsed. Waiting {wait_interval} seconds before checking again.'\n        logger.debug(msg)\n        sleep(wait_interval)\n    logger.debug('Result: %s', result)\n    if not result:\n        raise ActionTimeout(f'Action \"{action}\" failed to complete in the max_wait period of {max_wait} seconds')",
        "docstring": "The `wait_for_it` function provides a unified mechanism to wait for the completion of various actions related to Elasticsearch, such as health checks, snapshot status, recovery, and task completion. It checks the status of the specified action at regular intervals until the action completes or a maximum wait time is reached.\n\nParameters:\n- `client`: An Elasticsearch client connection object used to interact with the Elasticsearch cluster.\n- `action`: A string indicating the specific action to be awaited (e.g., 'snapshot', 'restore', 'reindex').\n- `task_id`: Optional string for actions that generate a task ID, like reindexing.\n- `snapshot`: Optional string for the name of the snapshot when checking snapshot status.\n- `repository`: Optional string specifying the Elasticsearch snapshot repository.\n- `index`: Optional string for the index associated with relocation checks.\n- `index_list`: Optional list of indices to check for restoration.\n- `wait_interval`: Optional integer (default is 9 seconds) specifying the wait time between checks.\n- `max_wait`: Optional integer (default is -1, meaning no limit) specifying the maximum wait time.\n\nReturns:\n- None: Raises `ActionTimeout` if the action does not complete within the specified max wait time.\n\nRaises:\n- `ConfigurationError`: If the provided action is invalid or required parameters are missing.\n- `MissingArgument`: If required arguments for certain actions are not provided.\n- `CuratorException`: If a task associated with the action cannot be found.\n\nThe function interacts with several other functions including `health_check`, `snapshot_check`, `restore_check`, `task_check`, and `relocate_check` to validate the status of ongoing processes in the Elasticsearch cluster based on the specified action.",
        "signature": "def wait_for_it(client, action, task_id=None, snapshot=None, repository=None, index=None, index_list=None, wait_interval=9, max_wait=-1):",
        "type": "Function",
        "class_signature": null
      }
    },
    "curator/helpers/utils.py": {
      "chunk_index_list": {
        "code": "def chunk_index_list(indices):\n    \"\"\"Chunk a list of indices into smaller sublists, each not exceeding 3KB when represented as a comma-separated string. This is useful for managing large index lists that may cause issues if processed in bulk.\n\n:param indices: A list of indices to be chunked.\n:type indices: list\n:returns: A list of lists, where each sublist contains indices that collectively do not exceed 3KB in size.\n:rtype: list\n\nThe function measures the length of the aggregated indices string (as if it were a CSV) and uses a constant size limit of 3072 bytes to determine when to split the list. The splitting ensures that the resultant sublists can be processed efficiently without exceeding size limitations.\"\"\"\n    '\\n    This utility chunks very large index lists into 3KB chunks.\\n    It measures the size as a csv string, then converts back into a list for the return value.\\n\\n    :param indices: The list of indices\\n\\n    :type indices: list\\n\\n    :returns: A list of lists (each a piece of the original ``indices``)\\n    :rtype: list\\n    '\n    chunks = []\n    chunk = ''\n    for index in indices:\n        if len(chunk) < 3072:\n            if not chunk:\n                chunk = index\n            else:\n                chunk += ',' + index\n        else:\n            chunks.append(chunk.split(','))\n            chunk = index\n    chunks.append(chunk.split(','))\n    return chunks",
        "docstring": "Chunk a list of indices into smaller sublists, each not exceeding 3KB when represented as a comma-separated string. This is useful for managing large index lists that may cause issues if processed in bulk.\n\n:param indices: A list of indices to be chunked.\n:type indices: list\n:returns: A list of lists, where each sublist contains indices that collectively do not exceed 3KB in size.\n:rtype: list\n\nThe function measures the length of the aggregated indices string (as if it were a CSV) and uses a constant size limit of 3072 bytes to determine when to split the list. The splitting ensures that the resultant sublists can be processed efficiently without exceeding size limitations.",
        "signature": "def chunk_index_list(indices):",
        "type": "Function",
        "class_signature": null
      }
    },
    "curator/exceptions.py": {}
  },
  "dependency_dict": {
    "curator/helpers/waiters.py:restore_check": {},
    "curator/helpers/utils.py:chunk_index_list": {},
    "curator/helpers/waiters.py:wait_for_it": {},
    "curator/helpers/waiters.py:health_check": {}
  },
  "call_tree": {
    "tests/unit/test_helpers_waiters.py:TestHealthCheck:test_key_not_found": {
      "curator/helpers/waiters.py:health_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestHealthCheck:test_key_value_match": {
      "curator/helpers/waiters.py:health_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestHealthCheck:test_key_value_no_match": {
      "curator/helpers/waiters.py:health_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestHealthCheck:test_no_kwargs": {
      "curator/helpers/waiters.py:health_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestRestoreCheck:test_completed_recovery": {
      "curator/helpers/waiters.py:restore_check": {
        "curator/helpers/utils.py:chunk_index_list": {}
      }
    },
    "tests/unit/test_helpers_waiters.py:TestRestoreCheck:test_empty_recovery": {
      "curator/helpers/waiters.py:restore_check": {
        "curator/helpers/utils.py:chunk_index_list": {}
      }
    },
    "tests/unit/test_helpers_waiters.py:TestRestoreCheck:test_fail_to_get_recovery": {
      "curator/helpers/waiters.py:restore_check": {
        "curator/helpers/utils.py:chunk_index_list": {}
      }
    },
    "tests/unit/test_helpers_waiters.py:TestRestoreCheck:test_incomplete_recovery": {
      "curator/helpers/waiters.py:restore_check": {
        "curator/helpers/utils.py:chunk_index_list": {}
      }
    },
    "tests/unit/test_helpers_waiters.py:TestSnapshotCheck:test_fail_to_get_snapshot": {
      "curator/helpers/waiters.py:snapshot_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestSnapshotCheck:test_failed": {
      "curator/helpers/waiters.py:snapshot_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestSnapshotCheck:test_in_progress": {
      "curator/helpers/waiters.py:snapshot_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestSnapshotCheck:test_other": {
      "curator/helpers/waiters.py:snapshot_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestSnapshotCheck:test_partial": {
      "curator/helpers/waiters.py:snapshot_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestSnapshotCheck:test_success": {
      "curator/helpers/waiters.py:snapshot_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestTaskCheck:test_bad_task_id": {
      "curator/helpers/waiters.py:task_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestTaskCheck:test_complete_task": {
      "curator/helpers/waiters.py:task_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestTaskCheck:test_incomplete_task": {
      "curator/helpers/waiters.py:task_check": {}
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_bad_action": {
      "curator/helpers/waiters.py:wait_for_it": {}
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_reached_max_wait": {
      "curator/helpers/waiters.py:wait_for_it": {
        "curator/helpers/waiters.py:health_check": {}
      }
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_reindex_action_bad_task_id": {
      "curator/helpers/waiters.py:wait_for_it": {}
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_reindex_action_no_task_id": {
      "curator/helpers/waiters.py:wait_for_it": {}
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_restore_action_no_indexlist": {
      "curator/helpers/waiters.py:wait_for_it": {}
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_snapshot_action_no_repository": {
      "curator/helpers/waiters.py:wait_for_it": {}
    },
    "tests/unit/test_helpers_waiters.py:TestWaitForIt:test_snapshot_action_no_snapshot": {
      "curator/helpers/waiters.py:wait_for_it": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_waiters/elasticsearch_curator-test_helpers_waiters/tests/integration/test_cli.py:TestCLIMethods:test_action_is_none": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_waiters/elasticsearch_curator-test_helpers_waiters/tests/integration/test_cli.py:TestCLIMethods:test_no_action": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_waiters/elasticsearch_curator-test_helpers_waiters/tests/integration/test_integrations.py:TestFilters:test_filter_by_alias_bad_aliases": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    }
  },
  "PRD": "# PROJECT NAME: elasticsearch_curator-test_helpers_waiters\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 curator/\n    \u251c\u2500\u2500 exceptions.py\n    \u2502   \u2514\u2500\u2500 ConfigurationError.ConfigurationError\n    \u2514\u2500\u2500 helpers/\n        \u251c\u2500\u2500 utils.py\n        \u2502   \u2514\u2500\u2500 chunk_index_list\n        \u2514\u2500\u2500 waiters.py\n            \u251c\u2500\u2500 health_check\n            \u251c\u2500\u2500 restore_check\n            \u251c\u2500\u2500 snapshot_check\n            \u251c\u2500\u2500 task_check\n            \u2514\u2500\u2500 wait_for_it\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module provides comprehensive testing for utility functions that facilitate monitoring and validation of Elasticsearch cluster operations, such as health checks, snapshot status, restore processes, and task completion. It ensures the reliability of key operational checks by verifying that functions correctly handle various scenarios, including successful, incomplete, and erroneous states, as well as edge cases like missing arguments or configuration issues. By validating these utilities, the module helps developers maintain robust and predictable automation workflows involving Elasticsearch operations, reducing the risk of misconfiguration, unhandled exceptions, or incomplete processes. This testing framework ultimately supports the consistent and accurate functioning of tools managing Elasticsearch clusters.\n\n## FILE 1: curator/helpers/waiters.py\n\n- FUNCTION NAME: wait_for_it\n  - SIGNATURE: def wait_for_it(client, action, task_id=None, snapshot=None, repository=None, index=None, index_list=None, wait_interval=9, max_wait=-1):\n  - DOCSTRING: \n```python\n\"\"\"\nThe `wait_for_it` function provides a unified mechanism to wait for the completion of various actions related to Elasticsearch, such as health checks, snapshot status, recovery, and task completion. It checks the status of the specified action at regular intervals until the action completes or a maximum wait time is reached.\n\nParameters:\n- `client`: An Elasticsearch client connection object used to interact with the Elasticsearch cluster.\n- `action`: A string indicating the specific action to be awaited (e.g., 'snapshot', 'restore', 'reindex').\n- `task_id`: Optional string for actions that generate a task ID, like reindexing.\n- `snapshot`: Optional string for the name of the snapshot when checking snapshot status.\n- `repository`: Optional string specifying the Elasticsearch snapshot repository.\n- `index`: Optional string for the index associated with relocation checks.\n- `index_list`: Optional list of indices to check for restoration.\n- `wait_interval`: Optional integer (default is 9 seconds) specifying the wait time between checks.\n- `max_wait`: Optional integer (default is -1, meaning no limit) specifying the maximum wait time.\n\nReturns:\n- None: Raises `ActionTimeout` if the action does not complete within the specified max wait time.\n\nRaises:\n- `ConfigurationError`: If the provided action is invalid or required parameters are missing.\n- `MissingArgument`: If required arguments for certain actions are not provided.\n- `CuratorException`: If a task associated with the action cannot be found.\n\nThe function interacts with several other functions including `health_check`, `snapshot_check`, `restore_check`, `task_check`, and `relocate_check` to validate the status of ongoing processes in the Elasticsearch cluster based on the specified action.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/waiters.py:health_check\n\n- FUNCTION NAME: task_check\n  - SIGNATURE: def task_check(client, task_id=None):\n  - DOCSTRING: \n```python\n\"\"\"\nChecks the status of a task in Elasticsearch using its task ID. It retrieves the task data and determines if the task is complete. If the task is a reindex task and has any failures, it raises a `FailedReindex` exception. The function logs detailed information about the task's progress and duration, including completion time if completed.\n\n:param client: A client connection object for Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param task_id: The ID of the task to check.\n:type task_id: str\n\n:rtype: bool\n:return: Returns `True` if the task is completed; otherwise, `False`.\n\nSide Effects:\n- Logs detailed information about the task, such as its running time and completion status.\n- Raises a `CuratorException` if the task data cannot be retrieved or if the task fails during reindexing.\n\nThis function relies on the Elasticsearch client and retrieves data through `client.tasks.get()`.\n\"\"\"\n```\n\n- FUNCTION NAME: restore_check\n  - SIGNATURE: def restore_check(client, index_list):\n  - DOCSTRING: \n```python\n\"\"\"\nThis function checks the recovery status of a list of indices in Elasticsearch by calling the `client.indices.recovery` method. It returns `True` if all shards of the specified indices are in the \"DONE\" state, indicating complete recovery. If any shard is still recovering, it returns `False` immediately. \n\nParameters:\n- client (Elasticsearch): A client connection object to communicate with the Elasticsearch cluster.\n- index_list (list): A list of indices to verify having been restored.\n\nReturns:\n- bool: `True` if all indices are fully recovered; `False` otherwise.\n\nThe function leverages the `chunk_index_list` utility to handle large lists of indices efficiently. It logs the recovery process and results, including any errors encountered during the check. If no recovery information is returned, it logs a message and defaults to returning `False`.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/utils.py:chunk_index_list\n\n- FUNCTION NAME: health_check\n  - SIGNATURE: def health_check(client, **kwargs):\n  - DOCSTRING: \n```python\n\"\"\"\nChecks the health of an Elasticsearch cluster by verifying the health status against provided keyword arguments.\n\nThis function interacts with the `client.cluster.health` API to retrieve the current health status of the cluster. It takes keyword arguments representing health properties (e.g., status, relocating_shards) and validates them against the actual health data from the cluster.\n\nParameters:\n- client (Elasticsearch): An Elasticsearch client connection object used to communicate with the cluster.\n- **kwargs: Keyword arguments corresponding to the expected health indicators and their values.\n\nReturns:\n- bool: Returns `True` if all provided health indicators match their expected values; otherwise, returns `False`.\n\nRaises:\n- MissingArgument: If no keyword arguments are provided.\n- ConfigurationError: If any provided key is not present in the cluster health output.\n\nLogs debugging information regarding the health check process and logs the result of the health check, providing insights into matching or mismatching values.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/waiters.py:wait_for_it\n\n- FUNCTION NAME: snapshot_check\n  - SIGNATURE: def snapshot_check(client, snapshot=None, repository=None):\n  - DOCSTRING: \n```python\n\"\"\"\nThis function checks the status of a specified snapshot in a given Elasticsearch repository. It queries the snapshot's state using the client's snapshot client, logs the status, and returns a boolean indicating whether the snapshot is complete. The function handles different snapshot states: returning `False` if the snapshot is still in progress (`IN_PROGRESS`), logging `INFO` for a successful completion (`SUCCESS`), logging a `WARNING` for a partial completion (`PARTIAL`), and logging an `ERROR` for a failed snapshot (`FAILED`).\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param snapshot: The name of the snapshot to check.\n:type snapshot: str\n:param repository: The name of the snapshot repository.\n:type repository: str\n\n:rtype: bool\n:return: `True` if the snapshot is complete, `False` if it is still in progress.\n\nExceptions raised include `CuratorException` if there is an issue obtaining snapshot information, indicating a dependency on the client's snapshot methods and appropriate handling of Elasticsearch responses.\n\"\"\"\n```\n\n## FILE 2: curator/helpers/utils.py\n\n- FUNCTION NAME: chunk_index_list\n  - SIGNATURE: def chunk_index_list(indices):\n  - DOCSTRING: \n```python\n\"\"\"\nChunk a list of indices into smaller sublists, each not exceeding 3KB when represented as a comma-separated string. This is useful for managing large index lists that may cause issues if processed in bulk.\n\n:param indices: A list of indices to be chunked.\n:type indices: list\n:returns: A list of lists, where each sublist contains indices that collectively do not exceed 3KB in size.\n:rtype: list\n\nThe function measures the length of the aggregated indices string (as if it were a CSV) and uses a constant size limit of 3072 bytes to determine when to split the list. The splitting ensures that the resultant sublists can be processed efficiently without exceeding size limitations.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/waiters.py:restore_check\n\n## FILE 3: curator/exceptions.py\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "curator/helpers/waiters.py": "\"\"\"The function that waits\n\n...and its helpers\n\"\"\"\nimport logging\nfrom time import localtime, sleep, strftime\nfrom datetime import datetime\nfrom curator.exceptions import ActionTimeout, ConfigurationError, CuratorException, FailedReindex, MissingArgument\nfrom curator.helpers.utils import chunk_index_list\n\ndef relocate_check(client, index):\n    \"\"\"\n    This function calls `client.cluster.` :py:meth:`~.elasticsearch.client.ClusterClient.state`\n    with a given index to check if all of the shards for that index are in the ``STARTED`` state.\n    It will return ``True`` if all primary and replica shards are in the ``STARTED`` state, and it\n    will return ``False`` if any shard is in a different state.\n\n    :param client: A client connection object\n    :param index: The index name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type index: str\n\n    :rtype: bool\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    shard_state_data = client.cluster.state(index=index)['routing_table']['indices'][index]['shards']\n    finished_state = all((all((shard['state'] == 'STARTED' for shard in shards)) for shards in shard_state_data.values()))\n    if finished_state:\n        logger.info('Relocate Check for index: \"%s\" has passed.', index)\n    return finished_state",
    "curator/helpers/utils.py": "\"\"\"Helper utilities\n\nThe kind that don't fit in testers, getters, date_ops, or converters\n\"\"\"\nimport logging\nfrom es_client.helpers.utils import ensure_list\nfrom curator.exceptions import FailedExecution\n\ndef report_failure(exception):\n    \"\"\"\n    Raise a :py:exc:`~.curator.exceptions.FailedExecution` exception and include the original error\n    message.\n\n    :param exception: The upstream exception.\n\n    :type exception: :py:exc:Exception\n\n    :rtype: None\n    \"\"\"\n    raise FailedExecution(f'Exception encountered.  Rerun with loglevel DEBUG and/or check Elasticsearch logs formore information. Exception: {exception}')\n\ndef show_dry_run(ilo, action, **kwargs):\n    \"\"\"\n    Log dry run output with the action which would have been executed.\n\n    :param ilo: An IndexList Object\n    :param action: The ``action`` to be performed.\n    :param kwargs: Any other args to show in the log output\n\n\n    :type ilo: :py:class:`~.curator.indexlist.IndexList`\n    :type action: str\n    :type kwargs: dict\n\n    :rtype: None\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.info('DRY-RUN MODE.  No changes will be made.')\n    msg = f'(CLOSED) indices may be shown that may not be acted on by action \"{action}\".'\n    logger.info(msg)\n    indices = sorted(ilo.indices)\n    for idx in indices:\n        try:\n            index_closed = ilo.index_info[idx]['state'] == 'close'\n        except KeyError:\n            ilo.get_index_state()\n            index_closed = ilo.index_info[idx]['state'] == 'close'\n        var = ' (CLOSED)' if index_closed else ''\n        msg = f'DRY-RUN: {action}: {idx}{var} with arguments: {kwargs}'\n        logger.info(msg)\n\ndef to_csv(indices):\n    \"\"\"\n    :param indices: A list of indices to act on, or a single value, which could be\n        in the format of a csv string already.\n\n    :type indices: list\n\n    :returns: A csv string from a list of indices, or a single value if only one value is present\n    :rtype: str\n    \"\"\"\n    indices = ensure_list(indices)\n    if indices:\n        return ','.join(sorted(indices))\n    return None",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\n\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\""
  }
}