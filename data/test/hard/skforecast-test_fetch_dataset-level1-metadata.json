{
  "dir_path": "/app/skforecast",
  "package_name": "skforecast",
  "sample_name": "skforecast-test_fetch_dataset",
  "src_dir": "skforecast/",
  "test_dir": "tests/",
  "test_file": "skforecast/datasets/tests/tests_datasets/test_fetch_dataset.py",
  "test_code": "# Unit test fetch_dataset\n# ==============================================================================\nimport re\nimport pytest\nimport pandas as pd\nfrom skforecast.datasets import fetch_dataset\n\ndatasets_keys = [\n    'h2o', 'h2o_exog', 'fuel_consumption', 'items_sales', \n    'air_quality_valencia', 'air_quality_valencia_no_missing', \n    'website_visits', 'bike_sharing', 'bike_sharing_extended_features', \n    'australia_tourism', 'uk_daily_flights', 'wikipedia_visits', \n    'vic_electricity', 'store_sales', 'bicimad', 'm4_daily', 'm4_hourly', \n    'ashrae_daily', 'bdg2_daily', 'bdg2_hourly'\n]\n\n\ndef test_fetch_dataset():\n    \"\"\"\n    Test function `fetch_dataset`.\n    \"\"\"\n    \n    # Test fetching the 'h2o' dataset\n    df = fetch_dataset('h2o', version='latest', raw=False, verbose=False)\n    assert isinstance(df, pd.DataFrame)\n    assert df.shape == (204, 1)\n    assert df.index.freq == 'MS'\n    assert df.index[0].strftime('%Y-%m-%d') == '1991-07-01'\n    assert df.index[-1].strftime('%Y-%m-%d') == '2008-06-01'\n\n    # Test fetching the 'items_sales' dataset\n    df = fetch_dataset('items_sales', version='latest', raw=False, verbose=True)\n    assert isinstance(df, pd.DataFrame)\n    assert df.shape == (1097, 3)\n    assert df.index.freq == 'D'\n    assert df.index[0] == pd.Timestamp('2012-01-01')\n    assert df.index[-1] == pd.Timestamp('2015-01-01')\n\n    # Test fetching a non-existent dataset\n\n    err_msg = re.escape(\n        (f\"Dataset 'non_existent_dataset' not found. \"\n         f\"Available datasets are: {datasets_keys}\")\n    )\n    with pytest.raises(ValueError, match = err_msg):\n        fetch_dataset('non_existent_dataset', version='latest', raw=False, verbose=False)\n\n    # Test fetching a dataset with a non-existent version\n    bad_url = (\n        'https://raw.githubusercontent.com/skforecast/'\n        'skforecast-datasets/non_existent_version/data/h2o.csv'\n    )\n    \n    err_msg = re.escape(\n        f\"Error reading dataset 'h2o' from {bad_url}. Try to version = 'latest'\"\n    )\n    with pytest.raises(ValueError, match = err_msg):\n        fetch_dataset('h2o', version='non_existent_version', raw=False, verbose=False)\n",
  "GT_file_code": {
    "skforecast/datasets/datasets.py": "\n################################################################################\n#                            skforecast.datsets                                #\n#                                                                              #\n# This work by skforecast team is licensed under the BSD 3-Clause License.     #\n################################################################################\n# coding=utf-8\n\nimport pandas as pd\nimport textwrap\n\n\ndef fetch_dataset(\n    name: str,\n    version: str = 'latest',\n    raw: bool = False,\n    kwargs_read_csv: dict = {},\n    verbose: bool = True\n) -> pd.DataFrame:\n    \"\"\"\n    Fetch a dataset from the skforecast-datasets repository.\n\n    Parameters\n    ----------\n    name: str\n        Name of the dataset to fetch.\n    version: str, int, default `'latest'`\n        Version of the dataset to fetch. If 'latest', the lastest version will be \n        fetched (the one in the main branch). For a list of available versions, \n        see the repository branches.\n    raw: bool, default `False`\n        If True, the raw dataset is fetched. If False, the preprocessed dataset \n        is fetched. The preprocessing consists of setting the column with the \n        date/time as index and converting the index to datetime. A frequency is \n        also set to the index.\n    kwargs_read_csv: dict, default `{}`\n        Kwargs to pass to pandas `read_csv` function.\n    verbose: bool, default `True`\n        If True, print information about the dataset.\n    \n    Returns\n    -------\n    df: pandas DataFrame\n        Dataset.\n    \n    \"\"\"\n\n    version = 'main' if version == 'latest' else f'{version}'\n\n    datasets = {\n        'h2o': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/h2o.csv'\n            ),\n            'sep': ',',\n            'index_col': 'fecha',\n            'date_format': '%Y-%m-%d',\n            'freq': 'MS',\n            'description': (\n                'Monthly expenditure ($AUD) on corticosteroid drugs that the '\n                'Australian health system had between 1991 and 2008. '\n            ),\n            'source': (\n                'Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice'\n                '(3rd Edition). http://pkg.robjhyndman.com/fpp3package/,'\n                'https://github.com/robjhyndman/fpp3package, http://OTexts.com/fpp3.'\n            )\n        },\n        'h2o_exog': {\n            'url': (\n                f\"https://raw.githubusercontent.com/skforecast/\"\n                f\"skforecast-datasets/{version}/data/h2o_exog.csv\"\n            ),\n            'sep': ',',\n            'index_col': 'fecha',\n            'date_format': '%Y-%m-%d',\n            'freq': 'MS',\n            'description': (\n                'Monthly expenditure ($AUD) on corticosteroid drugs that the '\n                'Australian health system had between 1991 and 2008. Two additional '\n                'variables (exog_1, exog_2) are simulated.'\n            ),\n            'source': (\n                \"Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice \"\n                \"(3rd Edition). http://pkg.robjhyndman.com/fpp3package/, \"\n                \"https://github.com/robjhyndman/fpp3package, http://OTexts.com/fpp3.\"\n            )\n        },\n        'fuel_consumption': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/consumos-combustibles-mensual.csv'\n            ),\n            'sep': ',',\n            'index_col': 'Fecha',\n            'date_format': '%Y-%m-%d',\n            'freq': 'MS',\n            'description': (\n                'Monthly fuel consumption in Spain from 1969-01-01 to 2022-08-01.'\n            ),\n            'source': (\n                'Obtained from Corporaci\u00f3n de Reservas Estrat\u00e9gicas de Productos '\n                'Petrol\u00edferos and Corporaci\u00f3n de Derecho P\u00fablico tutelada por el '\n                'Ministerio para la Transici\u00f3n Ecol\u00f3gica y el Reto Demogr\u00e1fico. '\n                'https://www.cores.es/es/estadisticas'\n            )\n        },\n        'items_sales': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/simulated_items_sales.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date',\n            'date_format': '%Y-%m-%d',\n            'freq': 'D',\n            'description': 'Simulated time series for the sales of 3 different items.',\n            'source': 'Simulated data.'\n        },\n        'air_quality_valencia': {\n            'url': (\n                f\"https://raw.githubusercontent.com/skforecast/\"\n                f\"skforecast-datasets/{version}/data/air_quality_valencia.csv\"\n            ),\n            'sep': ',',\n            'index_col': 'datetime',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'H',\n            'description': (\n                'Hourly measures of several air chemical pollutant at Valencia city '\n                '(Avd. Francia) from 2019-01-01 to 20213-12-31. Including the following '\n                'variables: pm2.5 (\u00b5g/m\u00b3), CO (mg/m\u00b3), NO (\u00b5g/m\u00b3), NO2 (\u00b5g/m\u00b3), '\n                'PM10 (\u00b5g/m\u00b3), NOx (\u00b5g/m\u00b3), O3 (\u00b5g/m\u00b3), Veloc. (m/s), Direc. (degrees), '\n                'SO2 (\u00b5g/m\u00b3).'\n            ),\n            'source': (\n                \"Red de Vigilancia y Control de la Contaminaci\u00f3n Atmosf\u00e9rica, \"\n                \"46250047-Val\u00e8ncia - Av. Fran\u00e7a, \"\n                \"https://mediambient.gva.es/es/web/calidad-ambiental/datos-historicos.\"\n            )\n        },\n        'air_quality_valencia_no_missing': {\n            'url': (\n                f\"https://raw.githubusercontent.com/skforecast/\"\n                f\"skforecast-datasets/{version}/data/air_quality_valencia_no_missing.csv\"\n            ),\n            'sep': ',',\n            'index_col': 'datetime',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'H',\n            'description': (\n                'Hourly measures of several air chemical pollutant at Valencia city '\n                '(Avd. Francia) from 2019-01-01 to 20213-12-31. Including the following '\n                'variables: pm2.5 (\u00b5g/m\u00b3), CO (mg/m\u00b3), NO (\u00b5g/m\u00b3), NO2 (\u00b5g/m\u00b3), '\n                'PM10 (\u00b5g/m\u00b3), NOx (\u00b5g/m\u00b3), O3 (\u00b5g/m\u00b3), Veloc. (m/s), Direc. (degrees), '\n                'SO2 (\u00b5g/m\u00b3). Missing values have been imputed using linear interpolation.'\n            ),\n            'source': (\n                \"Red de Vigilancia y Control de la Contaminaci\u00f3n Atmosf\u00e9rica, \"\n                \"46250047-Val\u00e8ncia - Av. Fran\u00e7a, \"\n                \"https://mediambient.gva.es/es/web/calidad-ambiental/datos-historicos.\"\n            )\n        },\n        'website_visits': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/visitas_por_dia_web_cienciadedatos.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date',\n            'date_format': '%Y-%m-%d',\n            'freq': '1D',\n            'description': (\n                'Daily visits to the cienciadedatos.net website registered with the '\n                'google analytics service.'\n            ),\n            'source': (\n                \"Amat Rodrigo, J. (2021). cienciadedatos.net (1.0.0). Zenodo. \"\n                \"https://doi.org/10.5281/zenodo.10006330\"\n            )\n        },\n        'bike_sharing': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/bike_sharing_dataset_clean.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date_time',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'H',\n            'description': (\n                'Hourly usage of the bike share system in the city of Washington D.C. '\n                'during the years 2011 and 2012. In addition to the number of users per '\n                'hour, information about weather conditions and holidays is available.'\n            ),\n            'source': (\n                \"Fanaee-T,Hadi. (2013). Bike Sharing Dataset. UCI Machine Learning \"\n                \"Repository. https://doi.org/10.24432/C5W894.\"\n            )\n        },\n        'bike_sharing_extended_features': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/bike_sharing_extended_features.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date_time',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'H',\n            'description': (\n                'Hourly usage of the bike share system in the city of Washington D.C. '\n                'during the years 2011 and 2012. In addition to the number of users per '\n                'hour, the dataset was enriched by introducing supplementary features. '\n                'Addition includes calendar-based variables (day of the week, hour of '\n                'the day, month, etc.), indicators for sunlight, incorporation of '\n                'rolling temperature averages, and the creation of polynomial features '\n                'generated from variable pairs. All cyclic variables are encoded using '\n                'sine and cosine functions to ensure accurate representation.'\n            ),\n            'source': (\n                \"Fanaee-T,Hadi. (2013). Bike Sharing Dataset. UCI Machine Learning \"\n                \"Repository. https://doi.org/10.24432/C5W894.\"\n            )\n        },\n        'australia_tourism': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/australia_tourism.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date_time',\n            'date_format': '%Y-%m-%d',\n            'freq': 'Q',\n            'description': (\n                \"Quarterly overnight trips (in thousands) from 1998 Q1 to 2016 Q4 \"\n                \"across Australia. The tourism regions are formed through the \"\n                \"aggregation of Statistical Local Areas (SLAs) which are defined by \"\n                \"the various State and Territory tourism authorities according to \"\n                \"their research and marketing needs.\"\n            ),\n            'source': (\n                \"Wang, E, D Cook, and RJ Hyndman (2020). A new tidy data structure to \"\n                \"support exploration and modeling of temporal data, Journal of \"\n                \"Computational and Graphical Statistics, 29:3, 466-478, \"\n                \"doi:10.1080/10618600.2019.1695624.\"\n            )\n        },\n        'uk_daily_flights': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/uk_daily_flights.csv'\n            ),\n            'sep': ',',\n            'index_col': 'Date',\n            'date_format': '%d/%m/%Y',\n            'freq': 'D',\n            'description': 'Daily number of flights in UK from 02/01/2019 to 23/01/2022.',\n            'source': (\n                'Experimental statistics published as part of the Economic activity and '\n                'social change in the UK, real-time indicators release, Published 27 '\n                'January 2022. Daily flight numbers are available in the dashboard '\n                'provided by the European Organisation for the Safety of Air Navigation '\n                '(EUROCONTROL). '\n                'https://www.ons.gov.uk/economy/economicoutputandproductivity/output/'\n                'bulletins/economicactivityandsocialchangeintheukrealtimeindicators/latest'\n            )\n        },\n        'wikipedia_visits': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/wikipedia_visits.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date',\n            'date_format': '%Y-%m-%d',\n            'freq': 'D',\n            'description': (\n                'Log daily page views for the Wikipedia page for Peyton Manning. '\n                'Scraped data using the Wikipediatrend package in R.'\n            ),\n            'source': (\n                'https://github.com/facebook/prophet/blob/main/examples/'\n                'example_wp_log_peyton_manning.csv'\n            )\n        },\n        'vic_electricity': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/vic_electricity.csv'\n            ),\n            'sep': ',',\n            'index_col': 'Time',\n            'date_format': '%Y-%m-%dT%H:%M:%SZ',\n            'freq': '30min',\n            'description': 'Half-hourly electricity demand for Victoria, Australia',\n            'source': (\n                \"O'Hara-Wild M, Hyndman R, Wang E, Godahewa R (2022).tsibbledata: Diverse \"\n                \"Datasets for 'tsibble'. https://tsibbledata.tidyverts.org/, \"\n                \"https://github.com/tidyverts/tsibbledata/. \"\n                \"https://tsibbledata.tidyverts.org/reference/vic_elec.html\"\n            )\n        },\n        'store_sales': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/store_sales.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date',\n            'date_format': '%Y-%m-%d',\n            'freq': 'D',\n            'description': (\n                'This dataset contains 913,000 sales transactions from 2013-01-01 to '\n                '2017-12-31 for 50 products (SKU) in 10 stores.'\n            ),\n            'source': (\n                'The original data was obtained from: inversion. (2018). Store Item '\n                'Demand Forecasting Challenge. Kaggle. '\n                'https://kaggle.com/competitions/demand-forecasting-kernels-only'\n            )\n        },\n        'bicimad': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/bicimad_users.csv'\n            ),\n            'sep': ',',\n            'index_col': 'date',\n            'date_format': '%Y-%m-%d',\n            'freq': 'D',\n            'description': (\n                'This dataset contains the daily users of the bicycle rental '\n                'service (BiciMad) in the city of Madrid (Spain) from 2014-06-23 '\n                'to 2022-09-30.'\n            ),\n            'source': (\n                'The original data was obtained from: Portal de datos abiertos '\n                'del Ayuntamiento de Madrid https://datos.madrid.es/portal/site/egob'\n            )\n        },\n        'm4_daily': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/m4_daily.parquet'\n            ),\n            'sep': None,\n            'index_col': 'timestamp',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'D',\n            'description': \"Time series with daily frequency from the M4 competition.\",\n            'source': (\n                \"Monash Time Series Forecasting Repository  \"\n                \"(https://zenodo.org/communities/forecasting) Godahewa, R., Bergmeir, \"\n                \"C., Webb, G. I., Hyndman, R. J., & Montero-Manso, P. (2021). Monash \"\n                \"Time Series Forecasting Archive. In Neural Information Processing \"\n                \"Systems Track on Datasets and Benchmarks. \\n\"\n                \"Raw data, available in .tsf format, has been converted to Pandas \"\n                \"format using the code provided by the authors in \"\n                \"https://github.com/rakshitha123/TSForecasting/blob/master/utils/data_loader.py \\n\"\n                \"The category of each time series has been included in the dataset. This \"\n                \"information has been obtainded from the Kaggle competition page: \"\n                \"https://www.kaggle.com/datasets/yogesh94/m4-forecasting-competition-dataset\"\n            )\n        },\n        'm4_hourly': {\n            'url': (\n                f'https://raw.githubusercontent.com/skforecast/'\n                f'skforecast-datasets/{version}/data/m4_hourly.parquet'\n            ),\n            'sep': None,\n            'index_col': 'timestamp',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'H',\n            'description': \"Time series with hourly frequency from the M4 competition.\",\n            'source': (\n                \"Monash Time Series Forecasting Repository  \"\n                \"(https://zenodo.org/communities/forecasting) Godahewa, R., Bergmeir, \"\n                \"C., Webb, G. I., Hyndman, R. J., & Montero-Manso, P. (2021). Monash \"\n                \"Time Series Forecasting Archive. In Neural Information Processing \"\n                \"Systems Track on Datasets and Benchmarks. \\n\"\n                \"Raw data, available in .tsf format, has been converted to Pandas \"\n                \"format using the code provided by the authors in \"\n                \"https://github.com/rakshitha123/TSForecasting/blob/master/utils/data_loader.py \\n\"\n                \"The category of each time series has been included in the dataset. This \"\n                \"information has been obtainded from the Kaggle competition page: \"\n                \"https://www.kaggle.com/datasets/yogesh94/m4-forecasting-competition-dataset\"\n            )\n        },\n        'ashrae_daily': {\n            'url': 'https://drive.google.com/file/d/1fMsYjfhrFLmeFjKG3jenXjDa5s984ThC/view?usp=sharing',\n            'sep': None,\n            'index_col': 'timestamp',\n            'date_format': '%Y-%m-%d',\n            'freq': 'D',\n            'description': (\n                \"Daily energy consumption data from the ASHRAE competition with \"\n                \"building metadata and weather data.\"\n            ),\n            'source': (\n                \"Kaggle competition Addison Howard, Chris Balbach, Clayton Miller, \"\n                \"Jeff Haberl, Krishnan Gowri, Sohier Dane. (2019). ASHRAE - Great Energy \"\n                \"Predictor III. Kaggle. https://www.kaggle.com/c/ashrae-energy-prediction/overview\"\n            )\n        },\n        'bdg2_daily': {\n            'url': 'https://drive.google.com/file/d/1KHYopzclKvS1F6Gt6GoJWKnxiuZ2aqen/view?usp=sharing',\n            'sep': None,\n            'index_col': 'timestamp',\n            'date_format': '%Y-%m-%d',\n            'freq': 'D',\n            'description': (\n                \"Daily energy consumption data from the The Building Data Genome Project 2 \"\n                \"with building metadata and weather data. \"\n                \"https://github.com/buds-lab/building-data-genome-project-2\"\n            ),\n            'source': (\n                \"Miller, C., Kathirgamanathan, A., Picchetti, B. et al. The Building Data \"\n                \"Genome Project 2, energy meter data from the ASHRAE Great Energy \"\n                \"Predictor III competition. Sci Data 7, 368 (2020). \"\n                \"https://doi.org/10.1038/s41597-020-00712-x\"\n            )\n        },\n        'bdg2_hourly': {\n            'url': 'https://drive.google.com/file/d/1I2i5mZJ82Cl_SHPTaWJmLoaXnntdCgh7/view?usp=sharing',\n            'sep': None,\n            'index_col': 'timestamp',\n            'date_format': '%Y-%m-%d %H:%M:%S',\n            'freq': 'H',\n            'description': (\n                \"Hourly energy consumption data from the The Building Data Genome Project 2 \"\n                \"with building metadata and weather data. \"\n                \"https://github.com/buds-lab/building-data-genome-project-2\"\n            ),\n            'source': (\n                \"Miller, C., Kathirgamanathan, A., Picchetti, B. et al. The Building Data \"\n                \"Genome Project 2, energy meter data from the ASHRAE Great Energy \"\n                \"Predictor III competition. Sci Data 7, 368 (2020). \"\n                \"https://doi.org/10.1038/s41597-020-00712-x\"\n            )\n        }\n    }\n    \n    if name not in datasets.keys():\n        raise ValueError(\n            f\"Dataset '{name}' not found. Available datasets are: {list(datasets.keys())}\"\n        )\n    \n    url = datasets[name]['url']\n\n    if url.endswith('.csv'):\n        try:\n            sep = datasets[name]['sep']\n            df = pd.read_csv(url, sep=sep, **kwargs_read_csv)\n        except:\n            raise ValueError(\n                f\"Error reading dataset '{name}' from {url}. Try to version = 'latest'\"\n            )\n\n    if url.endswith('.parquet'):\n        try:\n            df = pd.read_parquet(url)\n        except:\n            raise ValueError(\n                f\"Error reading dataset '{name}' from {url}. Try to version = 'latest'\"\n            )\n        \n    if url.startswith('https://drive.google.com'):\n        file_id = url.split('/')[-2]\n        url = 'https://drive.google.com/uc?id=' + file_id\n        df = pd.read_parquet(url)\n        \n    if not raw:\n        try:\n            index_col = datasets[name]['index_col']\n            freq = datasets[name]['freq']\n            if freq == 'H' and pd.__version__ >= '2.2.0':\n                freq = \"h\"\n            date_format = datasets[name]['date_format']\n            df = df.set_index(index_col)\n            df.index = pd.to_datetime(df.index, format=date_format)\n            df = df.asfreq(freq)\n            df = df.sort_index()\n        except:\n            pass\n    \n    if verbose:\n        print(name)\n        print('-' * len(name))\n        description = textwrap.fill(datasets[name]['description'], width=80)\n        source = textwrap.fill(datasets[name]['source'], width=80)\n        print(description)\n        print(source)\n        print(f\"Shape of the dataset: {df.shape}\")\n\n    return df\n\n\ndef load_demo_dataset(version: str = 'latest') -> pd.Series:\n    \"\"\"\n    Load demo data set with monthly expenditure ($AUD) on corticosteroid drugs that\n    the Australian health system had between 1991 and 2008. Obtained from the book:\n    Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos.\n    Index is set to datetime with monthly frequency and sorted.\n\n    Parameters\n    ----------\n    version: str, default `'latest'`\n        Version of the dataset to fetch. If 'latest', the lastest version will be\n        fetched (the one in the main branch). For a list of available versions,\n        see the repository branches.\n\n    Returns\n    -------\n    df: pandas Series\n        Dataset.\n    \n    \"\"\"\n\n    version = 'main' if version == 'latest' else f'{version}'\n\n    url = (\n        f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/'\n        'data/h2o.csv'\n    )\n\n    df = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d')\n    df = df.set_index('datetime')\n    df = df.asfreq('MS')\n    df = df['y']\n    df = df.sort_index()\n\n    return df\n"
  },
  "GT_src_dict": {
    "skforecast/datasets/datasets.py": {
      "fetch_dataset": {
        "code": "def fetch_dataset(name: str, version: str='latest', raw: bool=False, kwargs_read_csv: dict={}, verbose: bool=True) -> pd.DataFrame:\n    \"\"\"Fetch a dataset from the skforecast-datasets repository.\n\nParameters\n----------\nname: str\n    The name of the dataset to fetch. Available options are defined in the internal \n    `datasets` dictionary. \nversion: str, default 'latest'\n    The specific version of the dataset to fetch; if 'latest', retrieves \n    the most current version from the main branch.\nraw: bool, default False\n    If True, fetches the raw dataset; if False, retrieves the preprocessed version.\nkwargs_read_csv: dict, default {}\n    Additional keyword arguments to pass to pandas' `read_csv` function when \n    loading the dataset.\nverbose: bool, default True\n    If True, prints information about the dataset, including its description, source, \n    and shape.\n\nReturns\n-------\npd.DataFrame\n    A pandas DataFrame containing the dataset, potentially preprocessed based on the \n    `raw` parameter.\n\nRaises\n------\nValueError\n    If the specified dataset name is not found or if there are issues reading the data.\n\nThe function relies on pandas for data manipulation, specifically for reading CSV and \nParquet files. The function first checks the dataset name against a predefined \n`datasets` dictionary that contains relevant metadata for each dataset, including the \nURL, separator, index column, date format, frequency, description, and source. The \ndata is subsequently fetched from the specified URL, and if preprocessing is desired, \nthe DataFrame's index is set to a datetime column, converted to datetime type, and \nthe frequency is adjusted accordingly.\"\"\"\n    \"\\n    Fetch a dataset from the skforecast-datasets repository.\\n\\n    Parameters\\n    ----------\\n    name: str\\n        Name of the dataset to fetch.\\n    version: str, int, default `'latest'`\\n        Version of the dataset to fetch. If 'latest', the lastest version will be \\n        fetched (the one in the main branch). For a list of available versions, \\n        see the repository branches.\\n    raw: bool, default `False`\\n        If True, the raw dataset is fetched. If False, the preprocessed dataset \\n        is fetched. The preprocessing consists of setting the column with the \\n        date/time as index and converting the index to datetime. A frequency is \\n        also set to the index.\\n    kwargs_read_csv: dict, default `{}`\\n        Kwargs to pass to pandas `read_csv` function.\\n    verbose: bool, default `True`\\n        If True, print information about the dataset.\\n    \\n    Returns\\n    -------\\n    df: pandas DataFrame\\n        Dataset.\\n    \\n    \"\n    version = 'main' if version == 'latest' else f'{version}'\n    datasets = {'h2o': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/h2o.csv', 'sep': ',', 'index_col': 'fecha', 'date_format': '%Y-%m-%d', 'freq': 'MS', 'description': 'Monthly expenditure ($AUD) on corticosteroid drugs that the Australian health system had between 1991 and 2008. ', 'source': 'Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice(3rd Edition). http://pkg.robjhyndman.com/fpp3package/,https://github.com/robjhyndman/fpp3package, http://OTexts.com/fpp3.'}, 'h2o_exog': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/h2o_exog.csv', 'sep': ',', 'index_col': 'fecha', 'date_format': '%Y-%m-%d', 'freq': 'MS', 'description': 'Monthly expenditure ($AUD) on corticosteroid drugs that the Australian health system had between 1991 and 2008. Two additional variables (exog_1, exog_2) are simulated.', 'source': 'Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice (3rd Edition). http://pkg.robjhyndman.com/fpp3package/, https://github.com/robjhyndman/fpp3package, http://OTexts.com/fpp3.'}, 'fuel_consumption': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/consumos-combustibles-mensual.csv', 'sep': ',', 'index_col': 'Fecha', 'date_format': '%Y-%m-%d', 'freq': 'MS', 'description': 'Monthly fuel consumption in Spain from 1969-01-01 to 2022-08-01.', 'source': 'Obtained from Corporaci\u00f3n de Reservas Estrat\u00e9gicas de Productos Petrol\u00edferos and Corporaci\u00f3n de Derecho P\u00fablico tutelada por el Ministerio para la Transici\u00f3n Ecol\u00f3gica y el Reto Demogr\u00e1fico. https://www.cores.es/es/estadisticas'}, 'items_sales': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/simulated_items_sales.csv', 'sep': ',', 'index_col': 'date', 'date_format': '%Y-%m-%d', 'freq': 'D', 'description': 'Simulated time series for the sales of 3 different items.', 'source': 'Simulated data.'}, 'air_quality_valencia': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/air_quality_valencia.csv', 'sep': ',', 'index_col': 'datetime', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'H', 'description': 'Hourly measures of several air chemical pollutant at Valencia city (Avd. Francia) from 2019-01-01 to 20213-12-31. Including the following variables: pm2.5 (\u00b5g/m\u00b3), CO (mg/m\u00b3), NO (\u00b5g/m\u00b3), NO2 (\u00b5g/m\u00b3), PM10 (\u00b5g/m\u00b3), NOx (\u00b5g/m\u00b3), O3 (\u00b5g/m\u00b3), Veloc. (m/s), Direc. (degrees), SO2 (\u00b5g/m\u00b3).', 'source': 'Red de Vigilancia y Control de la Contaminaci\u00f3n Atmosf\u00e9rica, 46250047-Val\u00e8ncia - Av. Fran\u00e7a, https://mediambient.gva.es/es/web/calidad-ambiental/datos-historicos.'}, 'air_quality_valencia_no_missing': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/air_quality_valencia_no_missing.csv', 'sep': ',', 'index_col': 'datetime', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'H', 'description': 'Hourly measures of several air chemical pollutant at Valencia city (Avd. Francia) from 2019-01-01 to 20213-12-31. Including the following variables: pm2.5 (\u00b5g/m\u00b3), CO (mg/m\u00b3), NO (\u00b5g/m\u00b3), NO2 (\u00b5g/m\u00b3), PM10 (\u00b5g/m\u00b3), NOx (\u00b5g/m\u00b3), O3 (\u00b5g/m\u00b3), Veloc. (m/s), Direc. (degrees), SO2 (\u00b5g/m\u00b3). Missing values have been imputed using linear interpolation.', 'source': 'Red de Vigilancia y Control de la Contaminaci\u00f3n Atmosf\u00e9rica, 46250047-Val\u00e8ncia - Av. Fran\u00e7a, https://mediambient.gva.es/es/web/calidad-ambiental/datos-historicos.'}, 'website_visits': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/visitas_por_dia_web_cienciadedatos.csv', 'sep': ',', 'index_col': 'date', 'date_format': '%Y-%m-%d', 'freq': '1D', 'description': 'Daily visits to the cienciadedatos.net website registered with the google analytics service.', 'source': 'Amat Rodrigo, J. (2021). cienciadedatos.net (1.0.0). Zenodo. https://doi.org/10.5281/zenodo.10006330'}, 'bike_sharing': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/bike_sharing_dataset_clean.csv', 'sep': ',', 'index_col': 'date_time', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'H', 'description': 'Hourly usage of the bike share system in the city of Washington D.C. during the years 2011 and 2012. In addition to the number of users per hour, information about weather conditions and holidays is available.', 'source': 'Fanaee-T,Hadi. (2013). Bike Sharing Dataset. UCI Machine Learning Repository. https://doi.org/10.24432/C5W894.'}, 'bike_sharing_extended_features': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/bike_sharing_extended_features.csv', 'sep': ',', 'index_col': 'date_time', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'H', 'description': 'Hourly usage of the bike share system in the city of Washington D.C. during the years 2011 and 2012. In addition to the number of users per hour, the dataset was enriched by introducing supplementary features. Addition includes calendar-based variables (day of the week, hour of the day, month, etc.), indicators for sunlight, incorporation of rolling temperature averages, and the creation of polynomial features generated from variable pairs. All cyclic variables are encoded using sine and cosine functions to ensure accurate representation.', 'source': 'Fanaee-T,Hadi. (2013). Bike Sharing Dataset. UCI Machine Learning Repository. https://doi.org/10.24432/C5W894.'}, 'australia_tourism': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/australia_tourism.csv', 'sep': ',', 'index_col': 'date_time', 'date_format': '%Y-%m-%d', 'freq': 'Q', 'description': 'Quarterly overnight trips (in thousands) from 1998 Q1 to 2016 Q4 across Australia. The tourism regions are formed through the aggregation of Statistical Local Areas (SLAs) which are defined by the various State and Territory tourism authorities according to their research and marketing needs.', 'source': 'Wang, E, D Cook, and RJ Hyndman (2020). A new tidy data structure to support exploration and modeling of temporal data, Journal of Computational and Graphical Statistics, 29:3, 466-478, doi:10.1080/10618600.2019.1695624.'}, 'uk_daily_flights': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/uk_daily_flights.csv', 'sep': ',', 'index_col': 'Date', 'date_format': '%d/%m/%Y', 'freq': 'D', 'description': 'Daily number of flights in UK from 02/01/2019 to 23/01/2022.', 'source': 'Experimental statistics published as part of the Economic activity and social change in the UK, real-time indicators release, Published 27 January 2022. Daily flight numbers are available in the dashboard provided by the European Organisation for the Safety of Air Navigation (EUROCONTROL). https://www.ons.gov.uk/economy/economicoutputandproductivity/output/bulletins/economicactivityandsocialchangeintheukrealtimeindicators/latest'}, 'wikipedia_visits': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/wikipedia_visits.csv', 'sep': ',', 'index_col': 'date', 'date_format': '%Y-%m-%d', 'freq': 'D', 'description': 'Log daily page views for the Wikipedia page for Peyton Manning. Scraped data using the Wikipediatrend package in R.', 'source': 'https://github.com/facebook/prophet/blob/main/examples/example_wp_log_peyton_manning.csv'}, 'vic_electricity': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/vic_electricity.csv', 'sep': ',', 'index_col': 'Time', 'date_format': '%Y-%m-%dT%H:%M:%SZ', 'freq': '30min', 'description': 'Half-hourly electricity demand for Victoria, Australia', 'source': \"O'Hara-Wild M, Hyndman R, Wang E, Godahewa R (2022).tsibbledata: Diverse Datasets for 'tsibble'. https://tsibbledata.tidyverts.org/, https://github.com/tidyverts/tsibbledata/. https://tsibbledata.tidyverts.org/reference/vic_elec.html\"}, 'store_sales': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/store_sales.csv', 'sep': ',', 'index_col': 'date', 'date_format': '%Y-%m-%d', 'freq': 'D', 'description': 'This dataset contains 913,000 sales transactions from 2013-01-01 to 2017-12-31 for 50 products (SKU) in 10 stores.', 'source': 'The original data was obtained from: inversion. (2018). Store Item Demand Forecasting Challenge. Kaggle. https://kaggle.com/competitions/demand-forecasting-kernels-only'}, 'bicimad': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/bicimad_users.csv', 'sep': ',', 'index_col': 'date', 'date_format': '%Y-%m-%d', 'freq': 'D', 'description': 'This dataset contains the daily users of the bicycle rental service (BiciMad) in the city of Madrid (Spain) from 2014-06-23 to 2022-09-30.', 'source': 'The original data was obtained from: Portal de datos abiertos del Ayuntamiento de Madrid https://datos.madrid.es/portal/site/egob'}, 'm4_daily': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/m4_daily.parquet', 'sep': None, 'index_col': 'timestamp', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'D', 'description': 'Time series with daily frequency from the M4 competition.', 'source': 'Monash Time Series Forecasting Repository  (https://zenodo.org/communities/forecasting) Godahewa, R., Bergmeir, C., Webb, G. I., Hyndman, R. J., & Montero-Manso, P. (2021). Monash Time Series Forecasting Archive. In Neural Information Processing Systems Track on Datasets and Benchmarks. \\nRaw data, available in .tsf format, has been converted to Pandas format using the code provided by the authors in https://github.com/rakshitha123/TSForecasting/blob/master/utils/data_loader.py \\nThe category of each time series has been included in the dataset. This information has been obtainded from the Kaggle competition page: https://www.kaggle.com/datasets/yogesh94/m4-forecasting-competition-dataset'}, 'm4_hourly': {'url': f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/m4_hourly.parquet', 'sep': None, 'index_col': 'timestamp', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'H', 'description': 'Time series with hourly frequency from the M4 competition.', 'source': 'Monash Time Series Forecasting Repository  (https://zenodo.org/communities/forecasting) Godahewa, R., Bergmeir, C., Webb, G. I., Hyndman, R. J., & Montero-Manso, P. (2021). Monash Time Series Forecasting Archive. In Neural Information Processing Systems Track on Datasets and Benchmarks. \\nRaw data, available in .tsf format, has been converted to Pandas format using the code provided by the authors in https://github.com/rakshitha123/TSForecasting/blob/master/utils/data_loader.py \\nThe category of each time series has been included in the dataset. This information has been obtainded from the Kaggle competition page: https://www.kaggle.com/datasets/yogesh94/m4-forecasting-competition-dataset'}, 'ashrae_daily': {'url': 'https://drive.google.com/file/d/1fMsYjfhrFLmeFjKG3jenXjDa5s984ThC/view?usp=sharing', 'sep': None, 'index_col': 'timestamp', 'date_format': '%Y-%m-%d', 'freq': 'D', 'description': 'Daily energy consumption data from the ASHRAE competition with building metadata and weather data.', 'source': 'Kaggle competition Addison Howard, Chris Balbach, Clayton Miller, Jeff Haberl, Krishnan Gowri, Sohier Dane. (2019). ASHRAE - Great Energy Predictor III. Kaggle. https://www.kaggle.com/c/ashrae-energy-prediction/overview'}, 'bdg2_daily': {'url': 'https://drive.google.com/file/d/1KHYopzclKvS1F6Gt6GoJWKnxiuZ2aqen/view?usp=sharing', 'sep': None, 'index_col': 'timestamp', 'date_format': '%Y-%m-%d', 'freq': 'D', 'description': 'Daily energy consumption data from the The Building Data Genome Project 2 with building metadata and weather data. https://github.com/buds-lab/building-data-genome-project-2', 'source': 'Miller, C., Kathirgamanathan, A., Picchetti, B. et al. The Building Data Genome Project 2, energy meter data from the ASHRAE Great Energy Predictor III competition. Sci Data 7, 368 (2020). https://doi.org/10.1038/s41597-020-00712-x'}, 'bdg2_hourly': {'url': 'https://drive.google.com/file/d/1I2i5mZJ82Cl_SHPTaWJmLoaXnntdCgh7/view?usp=sharing', 'sep': None, 'index_col': 'timestamp', 'date_format': '%Y-%m-%d %H:%M:%S', 'freq': 'H', 'description': 'Hourly energy consumption data from the The Building Data Genome Project 2 with building metadata and weather data. https://github.com/buds-lab/building-data-genome-project-2', 'source': 'Miller, C., Kathirgamanathan, A., Picchetti, B. et al. The Building Data Genome Project 2, energy meter data from the ASHRAE Great Energy Predictor III competition. Sci Data 7, 368 (2020). https://doi.org/10.1038/s41597-020-00712-x'}}\n    if name not in datasets.keys():\n        raise ValueError(f\"Dataset '{name}' not found. Available datasets are: {list(datasets.keys())}\")\n    url = datasets[name]['url']\n    if url.endswith('.csv'):\n        try:\n            sep = datasets[name]['sep']\n            df = pd.read_csv(url, sep=sep, **kwargs_read_csv)\n        except:\n            raise ValueError(f\"Error reading dataset '{name}' from {url}. Try to version = 'latest'\")\n    if url.endswith('.parquet'):\n        try:\n            df = pd.read_parquet(url)\n        except:\n            raise ValueError(f\"Error reading dataset '{name}' from {url}. Try to version = 'latest'\")\n    if url.startswith('https://drive.google.com'):\n        file_id = url.split('/')[-2]\n        url = 'https://drive.google.com/uc?id=' + file_id\n        df = pd.read_parquet(url)\n    if not raw:\n        try:\n            index_col = datasets[name]['index_col']\n            freq = datasets[name]['freq']\n            if freq == 'H' and pd.__version__ >= '2.2.0':\n                freq = 'h'\n            date_format = datasets[name]['date_format']\n            df = df.set_index(index_col)\n            df.index = pd.to_datetime(df.index, format=date_format)\n            df = df.asfreq(freq)\n            df = df.sort_index()\n        except:\n            pass\n    if verbose:\n        print(name)\n        print('-' * len(name))\n        description = textwrap.fill(datasets[name]['description'], width=80)\n        source = textwrap.fill(datasets[name]['source'], width=80)\n        print(description)\n        print(source)\n        print(f'Shape of the dataset: {df.shape}')\n    return df",
        "docstring": "Fetch a dataset from the skforecast-datasets repository.\n\nParameters\n----------\nname: str\n    The name of the dataset to fetch. Available options are defined in the internal \n    `datasets` dictionary. \nversion: str, default 'latest'\n    The specific version of the dataset to fetch; if 'latest', retrieves \n    the most current version from the main branch.\nraw: bool, default False\n    If True, fetches the raw dataset; if False, retrieves the preprocessed version.\nkwargs_read_csv: dict, default {}\n    Additional keyword arguments to pass to pandas' `read_csv` function when \n    loading the dataset.\nverbose: bool, default True\n    If True, prints information about the dataset, including its description, source, \n    and shape.\n\nReturns\n-------\npd.DataFrame\n    A pandas DataFrame containing the dataset, potentially preprocessed based on the \n    `raw` parameter.\n\nRaises\n------\nValueError\n    If the specified dataset name is not found or if there are issues reading the data.\n\nThe function relies on pandas for data manipulation, specifically for reading CSV and \nParquet files. The function first checks the dataset name against a predefined \n`datasets` dictionary that contains relevant metadata for each dataset, including the \nURL, separator, index column, date format, frequency, description, and source. The \ndata is subsequently fetched from the specified URL, and if preprocessing is desired, \nthe DataFrame's index is set to a datetime column, converted to datetime type, and \nthe frequency is adjusted accordingly.",
        "signature": "def fetch_dataset(name: str, version: str='latest', raw: bool=False, kwargs_read_csv: dict={}, verbose: bool=True) -> pd.DataFrame:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {},
  "PRD": "# PROJECT NAME: skforecast-test_fetch_dataset\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 skforecast/\n    \u2514\u2500\u2500 datasets/\n        \u2514\u2500\u2500 datasets.py\n            \u2514\u2500\u2500 fetch_dataset\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module is designed to validate and ensure the reliable functionality of the `fetch_dataset` function, a utility for retrieving predefined time series datasets from the Skforecast repository. It provides capabilities to fetch datasets in a structured, standardized format (as pandas DataFrames) while verifying key attributes such as shape, index frequency, and temporal range consistency. Additionally, it handles error scenarios gracefully by checking for non-existent datasets or invalid versions, providing clear feedback to users. This module addresses the need for a robust mechanism to access and test time series datasets, streamlining data retrieval processes for developers and researchers working on forecasting and related applications.\n\n## FILE 1: skforecast/datasets/datasets.py\n\n- FUNCTION NAME: fetch_dataset\n  - SIGNATURE: def fetch_dataset(name: str, version: str='latest', raw: bool=False, kwargs_read_csv: dict={}, verbose: bool=True) -> pd.DataFrame:\n  - DOCSTRING: \n```python\n\"\"\"\nFetch a dataset from the skforecast-datasets repository.\n\nParameters\n----------\nname: str\n    The name of the dataset to fetch. Available options are defined in the internal \n    `datasets` dictionary. \nversion: str, default 'latest'\n    The specific version of the dataset to fetch; if 'latest', retrieves \n    the most current version from the main branch.\nraw: bool, default False\n    If True, fetches the raw dataset; if False, retrieves the preprocessed version.\nkwargs_read_csv: dict, default {}\n    Additional keyword arguments to pass to pandas' `read_csv` function when \n    loading the dataset.\nverbose: bool, default True\n    If True, prints information about the dataset, including its description, source, \n    and shape.\n\nReturns\n-------\npd.DataFrame\n    A pandas DataFrame containing the dataset, potentially preprocessed based on the \n    `raw` parameter.\n\nRaises\n------\nValueError\n    If the specified dataset name is not found or if there are issues reading the data.\n\nThe function relies on pandas for data manipulation, specifically for reading CSV and \nParquet files. The function first checks the dataset name against a predefined \n`datasets` dictionary that contains relevant metadata for each dataset, including the \nURL, separator, index column, date format, frequency, description, and source. The \ndata is subsequently fetched from the specified URL, and if preprocessing is desired, \nthe DataFrame's index is set to a datetime column, converted to datetime type, and \nthe frequency is adjusted accordingly.\n\"\"\"\n```\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "skforecast/datasets/datasets.py": "import pandas as pd\nimport textwrap\n\ndef load_demo_dataset(version: str='latest') -> pd.Series:\n    \"\"\"\n    Load demo data set with monthly expenditure ($AUD) on corticosteroid drugs that\n    the Australian health system had between 1991 and 2008. Obtained from the book:\n    Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos.\n    Index is set to datetime with monthly frequency and sorted.\n\n    Parameters\n    ----------\n    version: str, default `'latest'`\n        Version of the dataset to fetch. If 'latest', the lastest version will be\n        fetched (the one in the main branch). For a list of available versions,\n        see the repository branches.\n\n    Returns\n    -------\n    df: pandas Series\n        Dataset.\n    \n    \"\"\"\n    version = 'main' if version == 'latest' else f'{version}'\n    url = f'https://raw.githubusercontent.com/skforecast/skforecast-datasets/{version}/data/h2o.csv'\n    df = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d')\n    df = df.set_index('datetime')\n    df = df.asfreq('MS')\n    df = df['y']\n    df = df.sort_index()\n    return df"
  },
  "call_tree": {
    "skforecast/datasets/tests/tests_datasets/test_fetch_dataset.py:test_fetch_dataset": {
      "skforecast/datasets/datasets.py:fetch_dataset": {}
    }
  }
}