{
  "dir_path": "/app/datashader",
  "package_name": "datashader",
  "sample_name": "datashader-test_glyphs",
  "src_dir": "datashader/",
  "test_dir": "datashader/tests/",
  "test_file": "datashader/tests/test_glyphs.py",
  "test_code": "from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport pytest\n\nfrom datashader.datashape import dshape\nfrom datashader.glyphs import Point, LinesAxis1, Glyph\nfrom datashader.glyphs.area import _build_draw_trapezoid_y\nfrom datashader.glyphs.line import (\n    _build_map_onto_pixel_for_line,\n    _build_draw_segment,\n    _build_extend_line_axis0,\n)\nfrom datashader.glyphs.trimesh import(\n    _build_map_onto_pixel_for_triangle,\n    _build_draw_triangle,\n    _build_extend_triangles\n)\nfrom datashader.utils import ngjit\n\n\ndef test_point_bounds_check():\n    df = pd.DataFrame({'x': [1, 2, 3], 'y': [5, 6, 7]})\n    p = Point('x', 'y')\n    assert p._compute_bounds(df['x'].values) == (1, 3)\n    assert p._compute_bounds(df['y'].values) == (5, 7)\n\n\ndef test_point_validate():\n    p = Point('x', 'y')\n    p.validate(dshape(\"{x: int32, y: float32}\"))\n    with pytest.raises(ValueError):\n        p.validate(dshape(\"{x: string, y: float32}\"))\n\n\n@ngjit\ndef append(i, x, y, agg):\n    agg[y, x] += 1\n\n@ngjit\ndef tri_append(x, y, agg, n):\n    agg[y, x] += n\n\n\ndef new_agg():\n    return np.zeros((5, 5), dtype='i4')\n\n\nmapper = ngjit(lambda x: x)\nmap_onto_pixel_for_line = _build_map_onto_pixel_for_line(mapper, mapper)\nmap_onto_pixel_for_triangle = _build_map_onto_pixel_for_triangle(mapper, mapper)\n\n# Line rasterization\nexpand_aggs_and_cols = Glyph._expand_aggs_and_cols(append, 1, False)\n_draw_segment = _build_draw_segment(append, map_onto_pixel_for_line,\n                                    expand_aggs_and_cols, 0, False)\nextend_line, _ = _build_extend_line_axis0(_draw_segment, expand_aggs_and_cols, None)\n\n# Triangles rasterization\ndraw_triangle, draw_triangle_interp = _build_draw_triangle(tri_append)\nextend_triangles = _build_extend_triangles(draw_triangle, draw_triangle_interp,\n                                           map_onto_pixel_for_triangle)\n\n# Trapezoid y rasterization\n_draw_trapezoid = _build_draw_trapezoid_y(\n    append, map_onto_pixel_for_line, expand_aggs_and_cols\n)\n\nbounds = (-3, 1, -3, 1)\nvt = (1., 3., 1., 3.)\n\n\ndef draw_segment(x0, y0, x1, y1, i, segment_start, agg):\n    \"\"\"\n    Helper to draw line with fixed bounds and scale values.\n    \"\"\"\n    sx, tx, sy, ty = 1, 0, 1, 0\n    xmin, xmax, ymin, ymax = 0, 5, 0, 5\n    buffer = np.empty(0)\n    _draw_segment(\n        i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n        segment_start, False, x0, x1, y0, y1, 0.0, 0.0, buffer, agg)\n\n\ndef draw_trapezoid(x0, x1, y0, y1, y2, y3, i, trapezoid_start, stacked, agg):\n    \"\"\"\n    Helper to draw line with fixed bounds and scale values.\n    \"\"\"\n    sx, tx, sy, ty = 1, 0, 1, 0\n    xmin, xmax, ymin, ymax = 0, 5, 0, 5\n    _draw_trapezoid(\n        i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n        x0, x1, y0, y1, y2, y3, trapezoid_start, stacked, agg)\n\n\ndef test_draw_line():\n    x0, y0 = (0, 0)\n    x1, y1 = (3, 3)\n    out = np.array([[1, 0, 0, 0, 0],\n                    [0, 1, 0, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 0, 1, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_segment(x1, y1, x0, y0, 0, True, agg)\n    np.testing.assert_equal(agg, out)\n    # plot_start = False\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, False, agg)\n    out[0, 0] = 0\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_segment(x1, y1, x0, y0, 0, False, agg)\n    out[0, 0] = 1\n    out[3, 3] = 0\n    np.testing.assert_equal(agg, out)\n    # Flip coords\n    x0, y0 = (0, 4)\n    x1, y1 = (3, 1)\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 0, 1, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 1, 0, 0, 0],\n                    [1, 0, 0, 0, 0]])\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_segment(x1, y1, x0, y0, 0, True, agg)\n    np.testing.assert_equal(agg, out)\n    # plot_start = False\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, False, agg)\n    out[4, 0] = 0\n    np.testing.assert_equal(agg, out)\n    agg = new_agg()\n    draw_segment(x1, y1, x0, y0, 0, False, agg)\n    out[4, 0] = 1\n    out[1, 3] = 0\n\n\ndef test_draw_line_same_point():\n    x0, y0 = (4, 4)\n    x1, y1 = (4, 4)\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    assert agg.sum() == 1\n    assert agg[4, 4] == 1\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, False, agg)\n    assert agg.sum() == 1\n    assert agg[4, 4] == 1\n\n    x0, y0 = (4, 4)\n    x1, y1 = (10, 10)\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    assert agg.sum() == 1\n    assert agg[4, 4] == 1\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, False, agg)\n    assert agg.sum() == 0\n    assert agg[4, 4] == 0\n\n\ndef test_draw_line_vertical_horizontal():\n    # Vertical\n    x0, y0 = (3, 3)\n    x1, y1 = (3, 0)\n    agg = new_agg()\n    draw_segment(x0, y0, x1, y1, 0, True, agg)\n    out = new_agg()\n    out[:4, 3] = 1\n    np.testing.assert_equal(agg, out)\n    # Horizontal\n    agg = new_agg()\n    draw_segment(y0, x0, y1, x1, 0, True, agg)\n    out = new_agg()\n    out[3, :4] = 1\n    np.testing.assert_equal(agg, out)\n\n\ndef test_extend_lines():\n    xs = np.array([0, -2, -2, 0, 0])\n    ys = np.array([-1, -1, 1.1, 1.1, -1])\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 1, 1, 1, 0],\n                    [0, 1, 0, 1, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    sx, tx, sy, ty = vt\n    xmin, xmax, ymin, ymax = bounds\n    buffer = np.empty(0)\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, False, buffer, agg)\n    np.testing.assert_equal(agg, out)\n    # plot_start = True\n    out[2, 3] += 1\n    agg = new_agg()\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, True, buffer, agg)\n    np.testing.assert_equal(agg, out)\n\n    xs = np.array([2, 1, 0, -1, -4, -1, -100, -1, 2])\n    ys = np.array([-1, -2, -3, -4, -1, 2, 100, 2, -1])\n    out = np.array([[0, 1, 0, 1, 0],\n                    [1, 0, 0, 1, 0],\n                    [0, 0, 0, 0, 0],\n                    [1, 1, 0, 1, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = new_agg()\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, True, buffer, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_extend_lines_all_out_of_bounds():\n    xs = np.array([-100, -200, -100])\n    ys = np.array([0, 0, 1])\n    agg = new_agg()\n    sx, tx, sy, ty = vt\n    xmin, xmax, ymin, ymax = bounds\n    buffer = np.empty(0)\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, True, buffer, agg)\n    assert agg.sum() == 0\n\n\ndef test_extend_lines_nan():\n    xs = np.array([-3, -2, np.nan, 0, 1])\n    ys = np.array([-3, -2, np.nan, 0, 1])\n    agg = new_agg()\n    sx, tx, sy, ty = vt\n    xmin, xmax, ymin, ymax = bounds\n    buffer = np.empty(0)\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, True, buffer, agg)\n    out = np.diag([1, 1, 0, 1, 0])\n    np.testing.assert_equal(agg, out)\n\n\ndef test_extend_lines_exact_bounds():\n    xs = np.array([-3, 1, 1, -3, -3])\n    ys = np.array([-3, -3, 1, 1, -3])\n\n    agg = np.zeros((4, 4), dtype='i4')\n    sx, tx, sy, ty = vt\n    xmin, xmax, ymin, ymax = bounds\n    buffer = np.empty(0)\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, True, buffer, agg)\n    out = np.array([[2, 1, 1, 1],\n                    [1, 0, 0, 1],\n                    [1, 0, 0, 1],\n                    [1, 1, 1, 1]])\n    np.testing.assert_equal(agg, out)\n\n    agg = np.zeros((4, 4), dtype='i4')\n    extend_line(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, False, buffer, agg)\n    out = np.array([[1, 1, 1, 1],\n                    [1, 0, 0, 1],\n                    [1, 0, 0, 1],\n                    [1, 1, 1, 1]])\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_acute():\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (1, 3, 4, 0)\n\n    out = np.array([[0, 0, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [0, 0, 1, 1, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from left to right\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_acute_not_stacked():\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (1, 3, 4, 0)\n\n    out = np.array([[0, 0, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [0, 0, 1, 1, 0]])\n\n    # Specify vertices from left to right\n    trapezoid_start = True\n    stacked = False\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_right():\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (1, 3, 4, 1)\n\n    out = np.array([[0, 0, 0, 0, 0],\n                    [1, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [0, 0, 1, 1, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from left to right\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_obtuse():\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (0, 3, 5, 1)\n\n    out = np.array([[1, 1, 0, 0, 0],\n                    [1, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [0, 0, 1, 1, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from left to right\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_intersecting():\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (0, 5, 1, 4)\n\n    out = np.array([[1, 0, 0, 0, 0],\n                    [1, 1, 0, 0, 0],\n                    [1, 1, 0, 1, 0],\n                    [1, 0, 1, 1, 0],\n                    [0, 0, 0, 1, 0]])\n\n    # Specify vertices from left to right\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_vertical_line_start_and_not_clipped():\n    x0, x1 = (2, 2)\n    y0, y1, y2, y3 = (1, 3, 4, 0)\n\n    out = np.array([[0, 0, 1, 0, 0],\n                    [0, 0, 2, 0, 0],\n                    [0, 0, 2, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from inner to outer\n    trapezoid_start = True\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from outer to inner which should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_vertical_line_not_start_and_not_clipped():\n    x0, x1 = (2, 2)\n    y0, y1, y2, y3 = (1, 3, 4, 0)\n    trapezoid_start = False\n    stacked = True\n\n    # trapezoid_start=False, clipped=False\n    out = np.array([[0, 0, 1, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from inner to outer\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 1, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from outer to inner\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_clipped():\n    x0, x1 = (4, 6)\n    y0, y1, y2, y3 = (1, 3, 5, 0)\n    trapezoid_start = True\n    stacked = True\n\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 1],\n                    [0, 0, 0, 0, 1],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from inner to outer\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    out = np.array([[0, 0, 0, 0, 1],\n                    [0, 0, 0, 0, 1],\n                    [0, 0, 0, 0, 1],\n                    [0, 0, 0, 0, 1],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from outer to inner\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_vertical_line_not_start_and_clipped():\n    x0, x1 = (4, 6)\n    y0, y1, y2, y3 = (1, 3, 4, 0)\n    trapezoid_start = False\n    stacked = True\n\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from inner to outer\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_trapezoid_horizontal_line():\n    # Obtuse trapezoid\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (2, 2, 2, 2)\n    trapezoid_start = True\n    stacked = False\n\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [1, 1, 1, 1, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from left to right\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # with stacked = True, the zero width line is not rendered\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg.sum(), 0)\n\n\ndef test_draw_trapezoid_diagonal_line():\n    # Obtuse trapezoid\n    x0, x1 = (0, 3)\n    y0, y1, y2, y3 = (0, 0, 2, 2)\n    trapezoid_start = True\n    stacked = False\n\n    out = np.array([[1, 0, 0, 0, 0],\n                    [0, 1, 1, 0, 0],\n                    [0, 0, 0, 1, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from left to right\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # Specify vertices from right to left should give same result\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # with stacked = True, the zero width line is not rendered\n    stacked = True\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg.sum(), 0)\n\n\ndef test_draw_trapezoid_point():\n    # Obtuse trapezoid\n    x0, x1 = (3, 3)\n    y0, y1, y2, y3 = (2, 2, 2, 2)\n    trapezoid_start = True\n    stacked = False\n\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 2, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n\n    # Specify vertices from left to right\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # trapezoid_start=False and clipped=False causes only a single aggregation in\n    # the point bin\n    trapezoid_start = False\n    out[2, 3] = 1\n    agg = new_agg()\n    draw_trapezoid(x0, x1, y0, y1, y2, y3, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n    # with stacked = True, the zero width line is not rendered\n    trapezoid_start = True\n    stacked = True\n    out[2, 3] = 0\n    agg = new_agg()\n    draw_trapezoid(x1, x0, y3, y2, y1, y0, 0,\n                   trapezoid_start, stacked, agg)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_draw_triangle_nointerp():\n    \"\"\"Assert that we draw triangles properly, without interpolation enabled.\n    \"\"\"\n    # Isosceles triangle\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5))\n    out = np.array([[0, 0, 1, 0, 0],\n                    [0, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 1],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri, (0, 4, 0, 3), (0, 0, 0), (agg,), 1)\n    np.testing.assert_equal(agg, out)\n\n    # Right triangle\n    tri = ((2.4, -0.5), (-0.5, 2.4), (2.4, 2.4))\n    out = np.array([[0, 0, 2, 0, 0],\n                    [0, 2, 2, 0, 0],\n                    [2, 2, 2, 0, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri, (0, 4, 0, 3), (0, 0, 0), (agg,), 2)\n    np.testing.assert_equal(agg, out)\n\n    # Two right trimesh\n    tri = ((2.4, -0.5), (-0.5, 2.4), (2.4, 2.4),\n           (2.4, -0.5), (2.4, 3.5), (4.5, -0.5))\n    out = np.array([[0, 0, 3, 4, 4],\n                    [0, 3, 3, 4, 0],\n                    [3, 3, 3, 4, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri[:3], (0, 4, 0, 3), (0, 0, 0), (agg,), 3)\n    draw_triangle(tri[3:], (0, 4, 0, 3), (0, 0, 0), (agg,), 4)\n    np.testing.assert_equal(agg, out)\n\n    # Draw isoc triangle with clipping\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5))\n    out = np.array([[0, 0, 1, 0, 0],\n                    [0, 1, 1, 1, 0],\n                    [1, 1, 1, 1, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri, (0, 3, 0, 2), (0, 0, 0), (agg,), 1)\n    np.testing.assert_equal(agg, out)\n\n    # clip from right and left\n    out = np.array([[0, 0, 1, 0, 0],\n                    [0, 1, 1, 1, 0],\n                    [0, 1, 1, 1, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri, (1, 3, 0, 2), (0, 0, 0), (agg,), 1)\n    np.testing.assert_equal(agg, out)\n\n    # clip from right, left, top\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 1, 1, 1, 0],\n                    [0, 1, 1, 1, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri, (1, 3, 1, 2), (0, 0, 0), (agg,), 1)\n    np.testing.assert_equal(agg, out)\n\n    # clip from right, left, top, bottom\n    out = np.array([[0, 0, 0, 0, 0],\n                    [0, 1, 1, 1, 0],\n                    [0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri, (1, 3, 1, 1), (0, 0, 0), (agg,), 1)\n    np.testing.assert_equal(agg, out)\n\ndef test_draw_triangle_interp():\n    \"\"\"Assert that we draw triangles properly, with interpolation enabled.\n    \"\"\"\n    # Isosceles triangle\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5))\n    out = np.array([[0, 0, 3, 0, 0],\n                    [0, 3, 3, 3, 0],\n                    [3, 3, 3, 3, 3],\n                    [0, 0, 0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle_interp(tri, (0, 4, 0, 3), (0, 0, 0), (agg,), (3, 3, 3))\n    np.testing.assert_equal(agg, out)\n\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5))\n    out = np.array([[0,    0,    1.25, 0,    0   ],\n                    [0,    1.55, 1.75, 1.95, 0   ],\n                    [1.85, 2.05, 2.25, 2.45, 2.65],\n                    [0,    0,    0, 0, 0]])\n    agg = np.zeros((4, 5), dtype='f4')\n    draw_triangle_interp(tri, (0, 4, 0, 2), (0, 0, 0), (agg,), (1, 2, 3))\n    np.testing.assert_allclose(agg, out)\n\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5))\n    out = np.array([[0,    0,    3.75, 0,    0   ],\n                    [0,    4.65, 5.25, 5.85, 0   ],\n                    [5.55, 6.15, 6.75, 7.35, 7.95],\n                    [0,    0,    0,    0,    0   ]])\n    agg = np.zeros((4, 5), dtype='f4')\n    draw_triangle_interp(tri, (0, 4, 0, 2), (0, 0, 0), (agg,), (3, 6, 9))\n    np.testing.assert_allclose(agg, out)\n\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5))\n    out = np.array([[0,   0,   5.5, 0,   0  ],\n                    [0,   4.9, 4.5, 4.1, 0  ],\n                    [4.3, 3.9, 3.5, 3.1, 2.7],\n                    [0,   0,   0,   0,   0  ]])\n    agg = np.zeros((4, 5), dtype='f4')\n    draw_triangle_interp(tri, (0, 4, 0, 2), (0, 0, 0), (agg,), (6, 4, 2))\n    np.testing.assert_allclose(agg, out)\n\ndef test_draw_triangle_subpixel():\n    \"\"\"Assert that we draw subpixel triangles properly, both with and without\n    interpolation.\n    \"\"\"\n    # With interpolation\n    tri = ((2, -0.5), (-0.5, 2.5), (4.5, 2.5),\n           (2, 3), (2, 3), (2, 3),\n           (2, 3), (2, 3), (2, 3))\n    out = np.array([[0,   0,   5.5, 0,   0  ],\n                    [0,   4.9, 4.5, 4.1, 0  ],\n                    [4.3, 3.9, 3.5, 3.1, 2.7],\n                    [0,   0,   8,   0,   0  ]])\n    agg = np.zeros((4, 5), dtype='f4')\n    draw_triangle_interp(tri[:3], (0, 4, 0, 5), (0, 0, 0), (agg,), (6, 4, 2))\n    draw_triangle_interp(tri[3:6], (2, 2, 3, 3), (0, 0, 0), (agg,), (6, 4, 2))\n    draw_triangle_interp(tri[6:], (2, 2, 3, 3), (0, 0, 0), (agg,), (6, 4, 2))\n    np.testing.assert_allclose(agg, out)\n\n    # Without interpolation\n    out = np.array([[0, 0, 2, 0, 0],\n                    [0, 2, 2, 2, 0],\n                    [2, 2, 2, 2, 2],\n                    [0, 0, 4, 0, 0]])\n    agg = np.zeros((4, 5), dtype='i4')\n    draw_triangle(tri[:3], (0, 4, 0, 5), (0, 0, 0), (agg,), 2)\n    draw_triangle(tri[3:6], (2, 2, 3, 3), (0, 0, 0), (agg,), 2)\n    draw_triangle(tri[6:], (2, 2, 3, 3), (0, 0, 0), (agg,), 2)\n    np.testing.assert_equal(agg, out)\n\n\ndef test_line_awkward_point_on_upper_bound_maps_to_last_pixel():\n    \"\"\"Check that point deliberately chosen to be on the upper bound but\n    with a similar-magnitudes subtraction error like that which could\n    occur in extend line does indeed get mapped to last pixel.\n    \"\"\"\n    num_y_pixels = 2\n    ymax = 0.1\n    bigy = 10e9\n\n    sy = num_y_pixels/ymax\n    y = bigy-(bigy-ymax) # simulates clipped line\n\n    # check that test is set up ok\n    assert y!=ymax\n    np.testing.assert_almost_equal(y,ymax,decimal=6)\n\n    _,pymax = map_onto_pixel_for_line(1.0, 0.0, sy, 0.0,\n                                      0.0, 1.0, 0.0, ymax,\n                                      1.0, y)\n\n    assert pymax==num_y_pixels-1\n\n\ndef test_lines_xy_validate():\n    g = LinesAxis1(['x0', 'x1'], ['y11', 'y12'])\n    g.validate(\n        dshape(\"{x0: int32, x1: int32, y11: float32, y12: float32}\"))\n\n    with pytest.raises(ValueError):\n        g.validate(\n            dshape(\"{x0: int32, x1: float32, y11: string, y12: float32}\"))\n",
  "GT_file_code": {
    "datashader/glyphs/points.py": "from __future__ import annotations\nfrom packaging.version import Version\nimport numpy as np\nfrom toolz import memoize\n\nfrom datashader.glyphs.glyph import Glyph\nfrom datashader.utils import isreal, ngjit\n\nfrom numba import cuda\n\ntry:\n    import cudf\n    from ..transfer_functions._cuda_utils import cuda_args\nexcept Exception:\n    cudf = None\n    cuda_args = None\n\ntry:\n    from geopandas.array import GeometryDtype as gpd_GeometryDtype\nexcept ImportError:\n    gpd_GeometryDtype = type(None)\n\ntry:\n    import spatialpandas\nexcept Exception:\n    spatialpandas = None\n\n\ndef values(s):\n    if isinstance(s, cudf.Series):\n        if Version(cudf.__version__) >= Version(\"22.02\"):\n            return s.to_cupy(na_value=np.nan)\n        else:\n            return s.to_gpu_array(fillna=np.nan)\n\n    else:\n        return s.values\n\n\nclass _GeometryLike(Glyph):\n    def __init__(self, geometry):\n        self.geometry = geometry\n        self._cached_bounds = None\n\n    @property\n    def ndims(self):\n        return 1\n\n    @property\n    def inputs(self):\n        return (self.geometry,)\n\n    @property\n    def geom_dtypes(self):\n        if spatialpandas:\n            from spatialpandas.geometry import GeometryDtype\n            return (GeometryDtype,)\n        else:\n            return ()  # Empty tuple\n\n    def validate(self, in_dshape):\n        if not isinstance(in_dshape[str(self.geometry)], self.geom_dtypes):\n            raise ValueError(\n                '{col} must be an array with one of the following types: {typs}'.format(\n                    col=self.geometry,\n                    typs=', '.join(typ.__name__ for typ in self.geom_dtypes)\n                ))\n\n    @property\n    def x_label(self):\n        return 'x'\n\n    @property\n    def y_label(self):\n        return 'y'\n\n    def required_columns(self):\n        return [self.geometry]\n\n    def compute_x_bounds(self, df):\n        col = df[self.geometry]\n        if isinstance(col.dtype, gpd_GeometryDtype):\n            # geopandas\n            if self._cached_bounds is None:\n                self._cached_bounds = col.total_bounds\n            bounds = self._cached_bounds[::2]\n        else:\n            # spatialpandas\n            bounds = col.array.total_bounds_x\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, df):\n        col = df[self.geometry]\n        if isinstance(col.dtype, gpd_GeometryDtype):\n            # geopandas\n            if self._cached_bounds is None:\n                self._cached_bounds = col.total_bounds\n            bounds = self._cached_bounds[1::2]\n        else:\n            # spatialpandas\n            bounds = col.array.total_bounds_y\n        return self.maybe_expand_bounds(bounds)\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        total_bounds = ddf[self.geometry].total_bounds\n        x_extents = (total_bounds[0], total_bounds[2])\n        y_extents = (total_bounds[1], total_bounds[3])\n\n        return (self.maybe_expand_bounds(x_extents),\n                self.maybe_expand_bounds(y_extents))\n\n\nclass _PointLike(Glyph):\n    \"\"\"Shared methods between Point and Line\"\"\"\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    @property\n    def ndims(self):\n        return 1\n\n    @property\n    def inputs(self):\n        return (self.x, self.y)\n\n    def validate(self, in_dshape):\n        if not isreal(in_dshape.measure[str(self.x)]):\n            raise ValueError('x must be real')\n        elif not isreal(in_dshape.measure[str(self.y)]):\n            raise ValueError('y must be real')\n\n    @property\n    def x_label(self):\n        return self.x\n\n    @property\n    def y_label(self):\n        return self.y\n\n    def required_columns(self):\n        return [self.x, self.y]\n\n    def compute_x_bounds(self, df):\n        bounds = self._compute_bounds(df[self.x])\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, df):\n        bounds = self._compute_bounds(df[self.y])\n        return self.maybe_expand_bounds(bounds)\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n\n        r = ddf.map_partitions(lambda df: np.array([[\n            np.nanmin(df[self.x].values).item(),\n            np.nanmax(df[self.x].values).item(),\n            np.nanmin(df[self.y].values).item(),\n            np.nanmax(df[self.y].values).item()]]\n        )).compute()\n\n        x_extents = np.nanmin(r[:, 0]), np.nanmax(r[:, 1])\n        y_extents = np.nanmin(r[:, 2]), np.nanmax(r[:, 3])\n\n        return (self.maybe_expand_bounds(x_extents),\n                self.maybe_expand_bounds(y_extents))\n\n\nclass Point(_PointLike):\n    \"\"\"A point, with center at ``x`` and ``y``.\n\n    Points map each record to a single bin.\n    Points falling exactly on the upper bounds are treated as a special case,\n    mapping into the previous bin rather than being cropped off.\n\n    Parameters\n    ----------\n    x, y : str\n        Column names for the x and y coordinates of each point.\n    \"\"\"\n    @memoize\n    def _build_extend(self, x_mapper, y_mapper, info, append, _antialias_stage_2,\n                      _antialias_stage_2_funcs):\n        x_name = self.x\n        y_name = self.y\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def _perform_extend_points(i, sx, tx, sy, ty, xmin, xmax,\n                                   ymin, ymax, xs, ys, xxmax, yymax,\n                                   *aggs_and_cols):\n            x = xs[i]\n            y = ys[i]\n\n            # points outside bounds are dropped; remainder\n            # are mapped onto pixels\n            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n                xx = int(x_mapper(x) * sx + tx)\n                yy = int(y_mapper(y) * sy + ty)\n\n                xi, yi = (xxmax-1 if xx >= xxmax else xx,\n                          yymax-1 if yy >= yymax else yy)\n                append(i, xi, yi, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                       xxmax, yymax, *aggs_and_cols):\n            for i in range(xs.shape[0]):\n                _perform_extend_points(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                       xs, ys, xxmax, yymax, *aggs_and_cols)\n\n        @cuda.jit\n        @self.expand_aggs_and_cols(append)\n        def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                        xxmax, yymax, *aggs_and_cols):\n            i = cuda.grid(1)\n            if i < xs.shape[0]:\n                _perform_extend_points(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                       xs, ys, xxmax, yymax, *aggs_and_cols)\n\n        def extend(aggs, df, vt, bounds):\n            yymax, xxmax = aggs[0].shape[:2]\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = values(df[x_name])\n                ys = values(df[y_name])\n                do_extend = extend_cuda[cuda_args(xs.shape[0])]\n            else:\n                xs = df[x_name].values\n                ys = df[y_name].values\n                do_extend = extend_cpu\n\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass MultiPointGeoPandas(_GeometryLike):\n    # geopandas must be available if a GeoPandasPointGeometry object is created.\n    @property\n    def geom_dtypes(self):\n        from geopandas.array import GeometryDtype\n        return (GeometryDtype,)\n\n    @memoize\n    def _build_extend(\n        self, x_mapper, y_mapper, info, append, _antialias_stage_2, _antialias_stage_2_funcs,\n    ):\n        # Lazy import shapely. Cannot get here if geopandas and shapely are not available.\n        import shapely\n\n        geometry_name = self.geometry\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def _perform_extend_points(\n            i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols\n        ):\n            x = values[j]\n            y = values[j + 1]\n            # points outside bounds are dropped; remainder\n            # are mapped onto pixels\n            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n                xx = int(x_mapper(x) * sx + tx)\n                yy = int(y_mapper(y) * sy + ty)\n                xi, yi = (xx - 1 if x == xmax else xx,\n                          yy - 1 if y == ymax else yy)\n\n                append(i, xi, yi, *aggs_and_cols)\n\n        def extend(aggs, df, vt, bounds):\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            geometry = df[geometry_name].array\n\n            ragged = shapely.to_ragged_array(geometry)\n            geometry_type = ragged[0]\n\n            if geometry_type not in (shapely.GeometryType.MULTIPOINT, shapely.GeometryType.POINT):\n                raise ValueError(\n                    \"Canvas.points supports GeoPandas geometry types of POINT and MULTIPOINT, \"\n                    f\"not {repr(geometry_type)}\")\n\n            coords = ragged[1].ravel()  # No offsets required if POINT not MULTIPOINT\n            if geometry_type == shapely.GeometryType.POINT:\n                extend_point_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, *aggs_and_cols)\n            else:\n                offsets = ragged[2][0]\n                extend_multipoint_cpu(\n                    sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, offsets, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_multipoint_cpu(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, offsets, *aggs_and_cols,\n        ):\n            for i in range(len(offsets) - 1):\n                start = offsets[i]\n                stop = offsets[i+1]\n                for j in range(start, stop):\n                    _perform_extend_points(\n                        i, 2*j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols,\n                    )\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_point_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols):\n            n = len(values) // 2\n            for i in range(n):\n                _perform_extend_points(\n                    i, 2*i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols,\n                )\n\n        return extend\n\n\nclass MultiPointGeometry(_GeometryLike):\n    # spatialpandas must be available if a MultiPointGeometry object is created.\n\n    @property\n    def geom_dtypes(self):\n        from spatialpandas.geometry import PointDtype, MultiPointDtype\n        return PointDtype, MultiPointDtype\n\n    @memoize\n    def _build_extend(self, x_mapper, y_mapper, info, append, _antialias_stage_2,\n                      _antialias_stage_2_funcs):\n        geometry_name = self.geometry\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def _perform_extend_points(\n                i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols\n        ):\n            x = values[j]\n            y = values[j + 1]\n            # points outside bounds are dropped; remainder\n            # are mapped onto pixels\n            if (xmin <= x <= xmax) and (ymin <= y <= ymax):\n                xx = int(x_mapper(x) * sx + tx)\n                yy = int(y_mapper(y) * sy + ty)\n                xi, yi = (xx - 1 if x == xmax else xx,\n                          yy - 1 if y == ymax else yy)\n\n                append(i, xi, yi, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_point_cpu(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                values, missing, eligible_inds, *aggs_and_cols\n        ):\n            for i in eligible_inds:\n                if missing[i] is True:\n                    continue\n                _perform_extend_points(\n                    i, 2 * i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    values, *aggs_and_cols\n                )\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_multipoint_cpu(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                values, missing, offsets, eligible_inds, *aggs_and_cols\n        ):\n            for i in eligible_inds:\n                if missing[i] is True:\n                    continue\n                start = offsets[i]\n                stop = offsets[i + 1]\n                for j in range(start, stop, 2):\n                    _perform_extend_points(\n                        i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                        values, *aggs_and_cols\n                    )\n\n        def extend(aggs, df, vt, bounds):\n            from spatialpandas.geometry import PointArray\n\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n\n            geometry = df[geometry_name].array\n\n            if geometry._sindex is not None:\n                # Compute indices of potentially intersecting polygons using\n                # geometry's R-tree if there is one\n                eligible_inds = geometry.sindex.intersects((xmin, ymin, xmax, ymax))\n            else:\n                # Otherwise, process all indices\n                eligible_inds = np.arange(0, len(geometry), dtype='uint32')\n\n            missing = geometry.isna()\n\n            if isinstance(geometry, PointArray):\n                values = geometry.flat_values\n                extend_point_cpu(\n                    sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    values, missing, eligible_inds, *aggs_and_cols\n                )\n            else:\n                values = geometry.buffer_values\n                offsets = geometry.buffer_offsets[0]\n\n                extend_multipoint_cpu(\n                    sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    values, missing, offsets, eligible_inds, *aggs_and_cols\n                )\n\n        return extend\n",
    "datashader/glyphs/glyph.py": "from __future__ import annotations\nfrom packaging.version import Version\nimport inspect\nimport warnings\nimport os\nfrom math import isnan\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n\nfrom datashader.utils import Expr, ngjit\nfrom datashader.macros import expand_varargs\n\ntry:\n    import cudf\n    import cupy as cp\nexcept Exception:\n    cudf = None\n    cp = None\n\n\nclass Glyph(Expr):\n    \"\"\"Base class for glyphs.\"\"\"\n\n    antialiased = False\n\n    @property\n    def ndims(self):\n        \"\"\"\n        The number of dimensions required in the data structure this Glyph is\n        constructed from. Or None if input data structure is irregular\n\n        For example\n         * ndims is 1 if glyph is constructed from a DataFrame\n         * ndims is 2 if glyph is constructed from a 2D xarray DataArray\n         * ndims is None if glyph is constructed from multiple DataFrames of\n           different lengths\n        \"\"\"\n        raise NotImplementedError()\n\n    @staticmethod\n    def maybe_expand_bounds(bounds):\n        minval, maxval = bounds\n        if not (np.isfinite(minval) and np.isfinite(maxval)):\n            minval, maxval = -1.0, 1.0\n        elif minval == maxval:\n            minval, maxval = minval-1, minval+1\n        return minval, maxval\n\n    @staticmethod\n    def _compute_bounds(s):\n        if cudf and isinstance(s, cudf.Series):\n            s = s.nans_to_nulls()\n            return (s.min(), s.max())\n        elif isinstance(s, pd.Series):\n            return Glyph._compute_bounds_numba(s.values)\n        elif isinstance(s, xr.DataArray):\n            if cp and isinstance(s.data, cp.ndarray):\n                return (s.min().item(), s.max().item())\n            else:\n                return Glyph._compute_bounds_numba(s.values.ravel())\n        else:\n            return Glyph._compute_bounds_numba(s)\n\n    @staticmethod\n    @ngjit\n    def _compute_bounds_numba(arr):\n        minval = np.inf\n        maxval = -np.inf\n        for x in arr:\n            if not isnan(x):\n                if x < minval:\n                    minval = x\n                if x > maxval:\n                    maxval = x\n\n        return minval, maxval\n\n    @staticmethod\n    @ngjit\n    def _compute_bounds_2d(vals):\n        minval = np.inf\n        maxval = -np.inf\n        for i in range(vals.shape[0]):\n            for j in range(vals.shape[1]):\n                v = vals[i][j]\n                if not np.isnan(v):\n                    if v < minval:\n                        minval = v\n                    if v > maxval:\n                        maxval = v\n\n        return minval, maxval\n\n    @staticmethod\n    def to_cupy_array(df, columns):\n        if isinstance(columns, tuple):\n            columns = list(columns)\n\n        # Pandas extracts the column name multiple times, but\n        # cuDF only extracts each name a single time. For details, see:\n        # https://github.com/holoviz/datashader/pull/1050\n        if isinstance(columns, list) and (len(columns) != len(set(columns))):\n            return cp.stack([cp.array(df[c]) for c in columns], axis=1)\n\n        if Version(cudf.__version__) >= Version(\"22.02\"):\n            return df[columns].to_cupy()\n        else:\n            if not isinstance(columns, list):\n                return df[columns].to_gpu_array()\n            return df[columns].as_gpu_matrix()\n\n    def expand_aggs_and_cols(self, append):\n        \"\"\"\n        Create a decorator that can be used on functions that accept\n        *aggs_and_cols as a variable length argument. The decorator will\n        replace *aggs_and_cols with a fixed number of arguments.\n\n        The appropriate fixed number of arguments is calculated from the input\n        append function.\n\n        Rationale: When we know the fixed length of a variable length\n        argument, replacing it with fixed arguments can help numba better\n        optimize the the function.\n\n        If this ever causes problems in the future, this decorator can be\n        safely removed without changing the functionality of the decorated\n        function.\n\n        Parameters\n        ----------\n        append: function\n            The append function for the current aggregator\n\n        Returns\n        -------\n        function\n            Decorator function\n        \"\"\"\n        return self._expand_aggs_and_cols(append, self.ndims, self.antialiased)\n\n    @staticmethod\n    def _expand_aggs_and_cols(append, ndims, antialiased):\n        if os.environ.get('NUMBA_DISABLE_JIT', None):\n            # If the NUMBA_DISABLE_JIT environment is set, then we return an\n            # identity decorator (one that return function unchanged).\n            #\n            # Doing this makes it possible to debug functions that are\n            # decorated with @jit and @expand_varargs decorators\n            return lambda fn: fn\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            try:\n                # Numba keeps original function around as append.py_func\n                append_args = inspect.getfullargspec(append.py_func).args\n            except (TypeError, AttributeError):\n                # Treat append as a normal python function\n                append_args = inspect.getfullargspec(append).args\n\n        # Get number of arguments accepted by append\n        append_arglen = len(append_args)\n\n        # We will subtract 2 because we always pass in the x and y position\n        xy_arglen = 2\n\n        # We will also subtract the number of dimensions in this glyph,\n        # because that's how many data index arguments are passed to append\n        dim_arglen = (ndims or 0)\n\n        # The remaining arguments are for aggregates and columns\n        aggs_and_cols_len = append_arglen - xy_arglen - dim_arglen\n\n        # Antialiased append() calls also take aa_factor argument\n        if antialiased:\n            aggs_and_cols_len -= 2\n\n        return expand_varargs(aggs_and_cols_len)\n",
    "datashader/datashape/util/__init__.py": "\nfrom itertools import chain\nimport operator\n\nfrom .. import parser\nfrom .. import type_symbol_table\nfrom ..validation import validate\nfrom .. import coretypes\n\n\n__all__ = 'dshape', 'dshapes', 'has_var_dim', 'has_ellipsis', 'cat_dshapes'\n\nsubclasses = operator.methodcaller('__subclasses__')\n\n#------------------------------------------------------------------------\n# Utility Functions for DataShapes\n#------------------------------------------------------------------------\n\ndef dshapes(*args):\n    \"\"\"\n    Parse a bunch of datashapes all at once.\n\n    >>> a, b = dshapes('3 * int32', '2 * var * float64')\n    \"\"\"\n    return [dshape(arg) for arg in args]\n\n\ndef dshape(o):\n    \"\"\"\n    Parse a datashape. For a thorough description see\n    https://datashape.readthedocs.io/en/latest/\n\n    >>> ds = dshape('2 * int32')\n    >>> ds[1]\n    ctype(\"int32\")\n    \"\"\"\n    if isinstance(o, coretypes.DataShape):\n        return o\n    if isinstance(o, str):\n        ds = parser.parse(o, type_symbol_table.sym)\n    elif isinstance(o, (coretypes.CType, coretypes.String,\n                        coretypes.Record, coretypes.JSON,\n                        coretypes.Date, coretypes.Time, coretypes.DateTime,\n                        coretypes.Unit)):\n        ds = coretypes.DataShape(o)\n    elif isinstance(o, coretypes.Mono):\n        ds = o\n    elif isinstance(o, (list, tuple)):\n        ds = coretypes.DataShape(*o)\n    else:\n        raise TypeError('Cannot create dshape from object of type %s' % type(o))\n    validate(ds)\n    return ds\n\n\ndef cat_dshapes(dslist):\n    \"\"\"\n    Concatenates a list of dshapes together along\n    the first axis. Raises an error if there is\n    a mismatch along another axis or the measures\n    are different.\n\n    Requires that the leading dimension be a known\n    size for all data shapes.\n    TODO: Relax this restriction to support\n          streaming dimensions.\n\n    >>> cat_dshapes(dshapes('10 * int32', '5 * int32'))\n    dshape(\"15 * int32\")\n    \"\"\"\n    if len(dslist) == 0:\n        raise ValueError('Cannot concatenate an empty list of dshapes')\n    elif len(dslist) == 1:\n        return dslist[0]\n\n    outer_dim_size = operator.index(dslist[0][0])\n    inner_ds = dslist[0][1:]\n    for ds in dslist[1:]:\n        outer_dim_size += operator.index(ds[0])\n        if ds[1:] != inner_ds:\n            raise ValueError(('The datashapes to concatenate much'\n                              ' all match after'\n                              ' the first dimension (%s vs %s)') %\n                              (inner_ds, ds[1:]))\n    return coretypes.DataShape(*[coretypes.Fixed(outer_dim_size)] + list(inner_ds))\n\n\ndef collect(pred, expr):\n    \"\"\" Collect terms in expression that match predicate\n\n    >>> from datashader.datashape import Unit, dshape\n    >>> predicate = lambda term: isinstance(term, Unit)\n    >>> dshape = dshape('var * {value: int64, loc: 2 * int32}')\n    >>> sorted(set(collect(predicate, dshape)), key=str)\n    [Fixed(val=2), ctype(\"int32\"), ctype(\"int64\"), Var()]\n    >>> from datashader.datashape import var, int64\n    >>> sorted(set(collect(predicate, [var, int64])), key=str)\n    [ctype(\"int64\"), Var()]\n    \"\"\"\n    if pred(expr):\n        return [expr]\n    if isinstance(expr, coretypes.Record):\n        return chain.from_iterable(collect(pred, typ) for typ in expr.types)\n    if isinstance(expr, coretypes.Mono):\n        return chain.from_iterable(collect(pred, typ) for typ in expr.parameters)\n    if isinstance(expr, (list, tuple)):\n        return chain.from_iterable(collect(pred, item) for item in expr)\n\n\ndef has_var_dim(ds):\n    \"\"\"Returns True if datashape has a variable dimension\n\n    Note currently treats variable length string as scalars.\n\n    >>> has_var_dim(dshape('2 * int32'))\n    False\n    >>> has_var_dim(dshape('var * 2 * int32'))\n    True\n    \"\"\"\n    return has((coretypes.Ellipsis, coretypes.Var), ds)\n\n\ndef has(typ, ds):\n    if isinstance(ds, typ):\n        return True\n    if isinstance(ds, coretypes.Record):\n        return any(has(typ, t) for t in ds.types)\n    if isinstance(ds, coretypes.Mono):\n        return any(has(typ, p) for p in ds.parameters)\n    if isinstance(ds, (list, tuple)):\n        return any(has(typ, item) for item in ds)\n    return False\n\n\ndef has_ellipsis(ds):\n    \"\"\"Returns True if the datashape has an ellipsis\n\n    >>> has_ellipsis(dshape('2 * int'))\n    False\n    >>> has_ellipsis(dshape('... * int'))\n    True\n    \"\"\"\n    return has(coretypes.Ellipsis, ds)\n",
    "datashader/glyphs/line.py": "from __future__ import annotations\nimport math\nimport numpy as np\nfrom toolz import memoize\n\nfrom datashader.antialias import two_stage_agg\nfrom datashader.glyphs.points import _PointLike, _GeometryLike\nfrom datashader.utils import isnull, isreal, ngjit\nfrom numba import cuda\nimport numba.types as nb_types\n\n\ntry:\n    import cudf\n    import cupy as cp\n    from ..transfer_functions._cuda_utils import cuda_args\nexcept ImportError:\n    cudf = None\n    cp = None\n    cuda_args = None\n\ntry:\n    import spatialpandas\nexcept Exception:\n    spatialpandas = None\n\n\nclass _AntiAliasedLine:\n    \"\"\" Methods common to all lines. \"\"\"\n    _line_width = 0  # Use antialiasing if > 0.\n\n    def set_line_width(self, line_width):\n        self._line_width = line_width\n        if hasattr(self, \"antialiased\"):\n            self.antialiased = (line_width > 0)\n\n    def _build_extend(self, x_mapper, y_mapper, info, append, antialias_stage_2,\n                      antialias_stage_2_funcs):\n        return self._internal_build_extend(\n                x_mapper, y_mapper, info, append, self._line_width, antialias_stage_2,\n                antialias_stage_2_funcs)\n\n\ndef _line_internal_build_extend(\n    x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n    expand_aggs_and_cols,\n):\n    antialias = line_width > 0\n    map_onto_pixel = _build_map_onto_pixel_for_line(x_mapper, y_mapper, antialias)\n    overwrite, use_2_stage_agg = two_stage_agg(antialias_stage_2)\n    if not use_2_stage_agg:\n        antialias_stage_2_funcs = None\n    draw_segment = _build_draw_segment(\n        append, map_onto_pixel, expand_aggs_and_cols, line_width, overwrite,\n    )\n    return draw_segment, antialias_stage_2_funcs\n\n\nclass LineAxis0(_PointLike, _AntiAliasedLine):\n    \"\"\"A line, with vertices defined by ``x`` and ``y``.\n\n    Parameters\n    ----------\n    x, y : str\n        Column names for the x and y coordinates of each vertex.\n    \"\"\"\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        extend_cpu, extend_cuda = _build_extend_line_axis0(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n\n        x_name = self.x\n        y_name = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_name)\n                ys = self.to_cupy_array(df, y_name)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, x_name].to_numpy()\n                ys = df.loc[:, y_name].to_numpy()\n                do_extend = extend_cpu\n\n            # line may be clipped, then mapped to pixels\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                xs, ys, plot_start, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass LineAxis0Multi(_PointLike, _AntiAliasedLine):\n    \"\"\"\n    \"\"\"\n\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(xcol)]) for xcol in self.x]):\n            raise ValueError('x columns must be real')\n        elif not all([isreal(in_dshape.measure[str(ycol)]) for ycol in self.y]):\n            raise ValueError('y columns must be real')\n\n        if len(self.x) != len(self.y):\n            raise ValueError(\n                f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    @property\n    def x_label(self):\n        return 'x'\n\n    @property\n    def y_label(self):\n        return 'y'\n\n    def required_columns(self):\n        return self.x + self.y\n\n    def compute_x_bounds(self, df):\n        bounds_list = [self._compute_bounds(df[x])\n                       for x in self.x]\n        mins, maxes = zip(*bounds_list)\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    def compute_y_bounds(self, df):\n        bounds_list = [self._compute_bounds(df[y])\n                       for y in self.y]\n        mins, maxes = zip(*bounds_list)\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n\n        r = ddf.map_partitions(lambda df: np.array([[\n            np.nanmin([np.nanmin(df[c].values).item() for c in self.x]),\n            np.nanmax([np.nanmax(df[c].values).item() for c in self.x]),\n            np.nanmin([np.nanmin(df[c].values).item() for c in self.y]),\n            np.nanmax([np.nanmax(df[c].values).item() for c in self.y])]]\n        )).compute()\n\n        x_extents = np.nanmin(r[:, 0]), np.nanmax(r[:, 1])\n        y_extents = np.nanmin(r[:, 2]), np.nanmax(r[:, 3])\n\n        return (self.maybe_expand_bounds(x_extents),\n                self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        extend_cpu, extend_cuda = _build_extend_line_axis0_multi(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n\n        x_names = self.x\n        y_names = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_names)\n                ys = self.to_cupy_array(df, y_names)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, list(x_names)].to_numpy()\n                ys = df.loc[:, list(y_names)].to_numpy()\n                do_extend = extend_cpu\n\n            # line may be clipped, then mapped to pixels\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                xs, ys, plot_start, antialias_stage_2, *aggs_and_cols,\n            )\n\n        return extend\n\n\nclass LinesAxis1(_PointLike, _AntiAliasedLine):\n    \"\"\"A collection of lines (on line per row) with vertices defined\n    by the lists of columns in ``x`` and ``y``\n\n    Parameters\n    ----------\n    x, y : list\n        Lists of column names for the x and y coordinates\n    \"\"\"\n\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(xcol)])\n                    for xcol in self.x]):\n            raise ValueError('x columns must be real')\n        elif not all([isreal(in_dshape.measure[str(ycol)])\n                      for ycol in self.y]):\n            raise ValueError('y columns must be real')\n\n        unique_x_measures = set(in_dshape.measure[str(xcol)]\n                                for xcol in self.x)\n        if len(unique_x_measures) > 1:\n            raise ValueError('x columns must have the same data type')\n\n        unique_y_measures = set(in_dshape.measure[str(ycol)]\n                                for ycol in self.y)\n        if len(unique_y_measures) > 1:\n            raise ValueError('y columns must have the same data type')\n\n        if len(self.x) != len(self.y):\n            raise ValueError(\n                f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    def required_columns(self):\n        return self.x + self.y\n\n    @property\n    def x_label(self):\n        return 'x'\n\n    @property\n    def y_label(self):\n        return 'y'\n\n    def compute_x_bounds(self, df):\n        xs = tuple(df[xlabel] for xlabel in self.x)\n\n        bounds_list = [self._compute_bounds(xcol) for xcol in xs]\n        mins, maxes = zip(*bounds_list)\n\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    def compute_y_bounds(self, df):\n        ys = tuple(df[ylabel] for ylabel in self.y)\n\n        bounds_list = [self._compute_bounds(ycol) for ycol in ys]\n        mins, maxes = zip(*bounds_list)\n\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n\n        r = ddf.map_partitions(lambda df: np.array([[\n            np.nanmin([np.nanmin(df[c].values).item() for c in self.x]),\n            np.nanmax([np.nanmax(df[c].values).item() for c in self.x]),\n            np.nanmin([np.nanmin(df[c].values).item() for c in self.y]),\n            np.nanmax([np.nanmax(df[c].values).item() for c in self.y])]]\n        )).compute()\n\n        x_extents = np.nanmin(r[:, 0]), np.nanmax(r[:, 1])\n        y_extents = np.nanmin(r[:, 2]), np.nanmax(r[:, 3])\n\n        return (self.maybe_expand_bounds(x_extents),\n                self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        extend_cpu, extend_cuda = _build_extend_line_axis1_none_constant(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n        x_names = self.x\n        y_names = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_names)\n                ys = self.to_cupy_array(df, y_names)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, list(x_names)].to_numpy()\n                ys = df.loc[:, list(y_names)].to_numpy()\n                do_extend = extend_cpu\n\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass LinesAxis1XConstant(LinesAxis1):\n    \"\"\"\n    \"\"\"\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(ycol)]) for ycol in self.y]):\n            raise ValueError('y columns must be real')\n\n        unique_y_measures = set(in_dshape.measure[str(ycol)]\n                                for ycol in self.y)\n        if len(unique_y_measures) > 1:\n            raise ValueError('y columns must have the same data type')\n\n        if len(self.x) != len(self.y):\n            raise ValueError(\n                f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    def required_columns(self):\n        return self.y\n\n    def compute_x_bounds(self, *args):\n        x_min = np.nanmin(self.x)\n        x_max = np.nanmax(self.x)\n        return self.maybe_expand_bounds((x_min, x_max))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n\n        r = ddf.map_partitions(lambda df: np.array([[\n            np.nanmin([np.nanmin(df[c].values).item() for c in self.y]),\n            np.nanmax([np.nanmax(df[c].values).item() for c in self.y])]]\n        )).compute()\n\n        y_extents = np.nanmin(r[:, 0]), np.nanmax(r[:, 1])\n\n        return (self.compute_x_bounds(),\n                self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        extend_cpu, extend_cuda = _build_extend_line_axis1_x_constant(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n\n        x_values = self.x\n        y_names = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = cp.asarray(x_values)\n                ys = self.to_cupy_array(df, y_names)\n                do_extend = extend_cuda[cuda_args(ys.shape)]\n            else:\n                xs = x_values\n                ys = df.loc[:, list(y_names)].to_numpy()\n                do_extend = extend_cpu\n\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass LinesAxis1YConstant(LinesAxis1):\n    \"\"\"\n    \"\"\"\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(xcol)]) for xcol in self.x]):\n            raise ValueError('x columns must be real')\n\n        unique_x_measures = set(in_dshape.measure[str(xcol)]\n                                for xcol in self.x)\n        if len(unique_x_measures) > 1:\n            raise ValueError('x columns must have the same data type')\n\n        if len(self.x) != len(self.y):\n            raise ValueError(\n                f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    def required_columns(self):\n        return self.x\n\n    def compute_y_bounds(self, *args):\n        y_min = np.nanmin(self.y)\n        y_max = np.nanmax(self.y)\n        return self.maybe_expand_bounds((y_min, y_max))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n\n        r = ddf.map_partitions(lambda df: np.array([[\n            np.nanmin([np.nanmin(df[c].values).item() for c in self.x]),\n            np.nanmax([np.nanmax(df[c].values).item() for c in self.x])]]\n        )).compute()\n\n        x_extents = np.nanmin(r[:, 0]), np.nanmax(r[:, 1])\n\n        return (self.maybe_expand_bounds(x_extents),\n                self.compute_y_bounds())\n\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        extend_cpu, extend_cuda = _build_extend_line_axis1_y_constant(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n\n        x_names = self.x\n        y_values = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_names)\n                ys = cp.asarray(y_values)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, list(x_names)].to_numpy()\n                ys = y_values\n                do_extend = extend_cpu\n\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass LinesAxis1Ragged(_PointLike, _AntiAliasedLine):\n    def validate(self, in_dshape):\n        try:\n            from datashader.datatypes import RaggedDtype\n        except ImportError:\n            RaggedDtype = type(None)\n\n        if not isinstance(in_dshape[str(self.x)], RaggedDtype):\n            raise ValueError('x must be a RaggedArray')\n        elif not isinstance(in_dshape[str(self.y)], RaggedDtype):\n            raise ValueError('y must be a RaggedArray')\n\n    def required_columns(self):\n        return (self.x,) + (self.y,)\n\n    def compute_x_bounds(self, df):\n        bounds = self._compute_bounds(df[self.x].array.flat_array)\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, df):\n        bounds = self._compute_bounds(df[self.y].array.flat_array)\n        return self.maybe_expand_bounds(bounds)\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n\n        r = ddf.map_partitions(lambda df: np.array([[\n            np.nanmin(df[self.x].array.flat_array).item(),\n            np.nanmax(df[self.x].array.flat_array).item(),\n            np.nanmin(df[self.y].array.flat_array).item(),\n            np.nanmax(df[self.y].array.flat_array).item()]]\n        )).compute()\n\n        x_extents = np.nanmin(r[:, 0]), np.nanmax(r[:, 1])\n        y_extents = np.nanmin(r[:, 2]), np.nanmax(r[:, 3])\n\n        return (self.maybe_expand_bounds(x_extents),\n                self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        extend_cpu = _build_extend_line_axis1_ragged(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n        x_name = self.x\n        y_name = self.y\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n\n            xs = df[x_name].array\n            ys = df[y_name].array\n\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            # line may be clipped, then mapped to pixels\n            extend_cpu(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass LineAxis1Geometry(_GeometryLike, _AntiAliasedLine):\n    # spatialpandas must be available if a LineAxis1Geometry object is created.\n\n    @property\n    def geom_dtypes(self):\n        from spatialpandas.geometry import (\n            LineDtype, MultiLineDtype, RingDtype, PolygonDtype,\n            MultiPolygonDtype\n        )\n        return (LineDtype, MultiLineDtype, RingDtype,\n                PolygonDtype, MultiPolygonDtype)\n\n    @memoize\n    def _internal_build_extend(\n            self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n            antialias_stage_2_funcs):\n        from spatialpandas.geometry import (\n            PolygonArray, MultiPolygonArray, RingArray\n        )\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        perform_extend_cpu = _build_extend_line_axis1_geometry(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n        geometry_name = self.geometry\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            geom_array = df[geometry_name].array\n\n            # Use type to decide whether geometry represents a closed .\n            # We skip for closed geometries so as not to double count the first/last\n            # pixel\n            if isinstance(geom_array, (PolygonArray, MultiPolygonArray)):\n                # Convert polygon array to multi line of boundary\n                geom_array = geom_array.boundary\n                closed_rings = True\n            elif isinstance(geom_array, RingArray):\n                closed_rings = True\n            else:\n                closed_rings = False\n\n            perform_extend_cpu(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                geom_array, closed_rings, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\nclass LineAxis1GeoPandas(_GeometryLike, _AntiAliasedLine):\n    # geopandas must be available for a GeoPandasLine to be created.\n    @property\n    def geom_dtypes(self):\n        from geopandas.array import GeometryDtype\n        return (GeometryDtype,)\n\n    @memoize\n    def _internal_build_extend(\n        self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n        antialias_stage_2_funcs,\n    ):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        perform_extend_cpu = _build_extend_line_axis1_geopandas(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs,\n        )\n        geometry_name = self.geometry\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            geom_array = df[geometry_name].array\n\n            perform_extend_cpu(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                geom_array, antialias_stage_2, *aggs_and_cols,\n            )\n\n        return extend\n\n\nclass LinesXarrayCommonX(LinesAxis1):\n    def __init__(self, x, y, x_dim_index: int):\n        super().__init__(x, y)\n        self.x_dim_index = x_dim_index\n\n    def __hash__(self):\n        # This ensures that @memoize below caches different functions for different x_dim_index.\n        return hash((type(self), self.x_dim_index))\n\n    def compute_x_bounds(self, dataset):\n        bounds = self._compute_bounds(dataset[self.x])\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, dataset):\n        bounds = self._compute_bounds(dataset[self.y])\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_bounds_dask(self, xr_ds):\n        return self.compute_x_bounds(xr_ds), self.compute_y_bounds(xr_ds)\n\n    def validate(self, in_dshape):\n        if not isreal(in_dshape.measure[str(self.x)]):\n            raise ValueError('x column must be real')\n\n        if not isreal(in_dshape.measure[str(self.y)]):\n            raise ValueError('y column must be real')\n\n    @memoize\n    def _internal_build_extend(\n        self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2,\n        antialias_stage_2_funcs,\n    ):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(\n            x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs,\n            expand_aggs_and_cols,\n        )\n        swap_dims = self.x_dim_index == 0\n        extend_cpu, extend_cuda = _build_extend_line_axis1_x_constant(\n            draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs, swap_dims,\n        )\n\n        x_name = self.x\n        y_name = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = cp.asarray(df[x_name])\n                ys = cp.asarray(df[y_name])\n                do_extend = extend_cuda[cuda_args(ys.shape)]\n            elif cp and isinstance(df[y_name].data, cp.ndarray):\n                xs = cp.asarray(df[x_name])\n                ys = df[y_name].data\n                shape = ys.shape[::-1] if swap_dims else ys.shape\n                do_extend = extend_cuda[cuda_args(shape)]\n            else:\n                xs = df[x_name].to_numpy()\n                ys = df[y_name].to_numpy()\n                do_extend = extend_cpu\n\n            do_extend(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n            )\n\n        return extend\n\n\ndef _build_map_onto_pixel_for_line(x_mapper, y_mapper, want_antialias=False):\n    @ngjit\n    def map_onto_pixel_snap(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x, y):\n        \"\"\"Map points onto pixel grid.\n\n        Points falling on upper bound are mapped into previous bin.\n\n        If the line has been clipped, x and y will have been\n        computed to lie on the bounds; we compare point and bounds\n        in integer space to avoid fp error. In contrast, with\n        auto-ranging, a point on the bounds will be the same\n        floating point number as the bound, so comparison in fp\n        representation of continuous space or in integer space\n        doesn't change anything.\n        \"\"\"\n        xx = int(x_mapper(x) * sx + tx)\n        yy = int(y_mapper(y) * sy + ty)\n\n        # Note that sx and tx were designed so that\n        # x_mapper(xmax) * sx + tx equals the width of the canvas in pixels\n        #\n        # Likewise, sy and ty were designed so that\n        # y_mapper(ymax) * sy + ty equals the height of the canvas in pixels\n        #\n        # We round these results to integers (rather than casting to integers\n        # with the int constructor) to handle cases where floating-point\n        # precision errors results in a value just under the integer number\n        # of pixels.\n        xxmax = round(x_mapper(xmax) * sx + tx)\n        yymax = round(y_mapper(ymax) * sy + ty)\n\n        return (xx - 1 if xx == xxmax else xx,\n                yy - 1 if yy == yymax else yy)\n\n    @ngjit\n    def map_onto_pixel_no_snap(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x, y):\n        xx = x_mapper(x)*sx + tx - 0.5\n        yy = y_mapper(y)*sy + ty - 0.5\n        return xx, yy\n\n    if want_antialias:\n        return map_onto_pixel_no_snap\n    else:\n        return map_onto_pixel_snap\n\n\n@ngjit\ndef _liang_barsky(xmin, xmax, ymin, ymax, x0, x1, y0, y1, skip):\n    \"\"\" An implementation of the Liang-Barsky line clipping algorithm.\n\n    https://en.wikipedia.org/wiki/Liang%E2%80%93Barsky_algorithm\n\n    \"\"\"\n    # Check if line is fully outside viewport\n    if x0 < xmin and x1 < xmin:\n        skip = True\n    elif x0 > xmax and x1 > xmax:\n        skip = True\n    elif y0 < ymin and y1 < ymin:\n        skip = True\n    elif y0 > ymax and y1 > ymax:\n        skip = True\n\n    t0, t1 = 0, 1\n    dx1 = x1 - x0\n    t0, t1, accept = _clipt(-dx1, x0 - xmin, t0, t1)\n    if not accept:\n        skip = True\n    t0, t1, accept = _clipt(dx1, xmax - x0, t0, t1)\n    if not accept:\n        skip = True\n    dy1 = y1 - y0\n    t0, t1, accept = _clipt(-dy1, y0 - ymin, t0, t1)\n    if not accept:\n        skip = True\n    t0, t1, accept = _clipt(dy1, ymax - y0, t0, t1)\n    if not accept:\n        skip = True\n    if t1 < 1:\n        clipped_end = True\n        x1 = x0 + t1 * dx1\n        y1 = y0 + t1 * dy1\n    else:\n        clipped_end = False\n    if t0 > 0:\n        # If x0 is clipped, we need to plot the new start\n        clipped_start = True\n        x0 = x0 + t0 * dx1\n        y0 = y0 + t0 * dy1\n    else:\n        clipped_start = False\n\n    return x0, x1, y0, y1, skip, clipped_start, clipped_end\n\n\n@ngjit\ndef _clipt(p, q, t0, t1):\n    accept = True\n    if p < 0 and q < 0:\n        r = q / p\n        if r > t1:\n            accept = False\n        elif r > t0:\n            t0 = r\n    elif p > 0 and q < p:\n        r = q / p\n        if r < t0:\n            accept = False\n        elif r < t1:\n            t1 = r\n    elif q < 0:\n        accept = False\n    return t0, t1, accept\n\n\n@ngjit\ndef _clamp(x, low, high):\n    # Clamp ``x`` in the range ``low`` to ``high``.\n    return max(low, min(x, high))\n\n\n@ngjit\ndef _linearstep(edge0, edge1, x):\n    t = _clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0)\n    return t\n\n\n@ngjit\ndef _x_intercept(y, cx0, cy0, cx1, cy1):\n    # Return x value of intercept between line at constant y and line\n    # between corner points.\n    if cy0 == cy1:\n        # Line is horizontal, return the \"upper\", i.e. right-hand, end of it.\n        return cx1\n    frac = (y - cy0) / (cy1 - cy0)  # In range 0..1\n    return cx0 + frac*(cx1 - cx0)\n\n\ndef _build_full_antialias(expand_aggs_and_cols):\n    \"\"\"Specialize antialiased line drawing algorithm for a given append/axis combination\"\"\"\n    @ngjit\n    @expand_aggs_and_cols\n    def _full_antialias(line_width, overwrite, i, x0, x1, y0, y1,\n                        segment_start, segment_end, xm, ym, append,\n                        nx, ny, buffer, *aggs_and_cols):\n        \"\"\"Draw an antialiased line segment.\n\n        If overwrite=True can overwrite each pixel multiple times because\n        using max for the overwriting.  If False can only write each pixel\n        once per segment and its previous segment.\n        Argument xm, ym are only valid if overwrite and segment_start are False.\n        \"\"\"\n        if x0 == x1 and y0 == y1:\n            return\n\n        # Scan occurs in y-direction. But wish to scan in the shortest direction,\n        # so if |x0-x1| < |y0-y1| then flip (x,y) coords for maths and flip back\n        # again before setting pixels.\n        flip_xy = abs(x0-x1) < abs(y0-y1)\n        if flip_xy:\n            x0, y0 = y0, x0\n            x1, y1 = y1, x1\n            xm, ym = ym, xm\n\n        scale = 1.0\n\n        # line_width less than 1 is rendered as 1 but with lower intensity.\n        if line_width < 1.0:\n            scale *= line_width\n            line_width = 1.0\n\n        aa = 1.0\n        halfwidth = 0.5*(line_width + aa)\n\n        # Want y0 <= y1, so switch vertical direction if this is not so.\n        flip_order = y1 < y0 or (y1 == y0 and x1 < x0)\n\n        # Start (x0, y0), end (y0, y1)\n        #       c1 +-------------+ c2          along    | right\n        # (x0, y0) | o         o | (x1, y1)    vector   | vector\n        #       c0 +-------------+ c3          ---->    v\n\n        alongx = float(x1 - x0)\n        alongy = float(y1 - y0)  # Always +ve\n        length = math.sqrt(alongx**2 + alongy**2)\n        alongx /= length\n        alongy /= length\n\n        rightx = alongy\n        righty = -alongx\n\n        # 4 corners, x and y.  Uses buffer, which must have length 8.  Order of coords is\n        # (x0, x1, x2, x3, y0, y1, y2, y3).  Each CPU/GPU thread has its own local buffer\n        # so there is no cross-talk.  Contents of buffer are written and read within the\n        # lifetime of this function, so it doesn't matter what they are before this\n        # function is called or after it returns.\n        if flip_order:\n            buffer[0] = x1 - halfwidth*( rightx - alongx)\n            buffer[1] = x1 - halfwidth*(-rightx - alongx)\n            buffer[2] = x0 - halfwidth*(-rightx + alongx)\n            buffer[3] = x0 - halfwidth*( rightx + alongx)\n            buffer[4] = y1 - halfwidth*( righty - alongy)\n            buffer[5] = y1 - halfwidth*(-righty - alongy)\n            buffer[6] = y0 - halfwidth*(-righty + alongy)\n            buffer[7] = y0 - halfwidth*( righty + alongy)\n        else:\n            buffer[0] = x0 + halfwidth*( rightx - alongx)\n            buffer[1] = x0 + halfwidth*(-rightx - alongx)\n            buffer[2] = x1 + halfwidth*(-rightx + alongx)\n            buffer[3] = x1 + halfwidth*( rightx + alongx)\n            buffer[4] = y0 + halfwidth*( righty - alongy)\n            buffer[5] = y0 + halfwidth*(-righty - alongy)\n            buffer[6] = y1 + halfwidth*(-righty + alongy)\n            buffer[7] = y1 + halfwidth*( righty + alongy)\n\n        xmax = nx-1\n        ymax = ny-1\n        if flip_xy:\n            xmax, ymax = ymax, xmax\n\n        # Index of lowest-y point.\n        if flip_order:\n            lowindex = 0 if x0 > x1 else 1\n        else:\n            lowindex = 0 if x1 > x0 else 1\n\n        if not overwrite and not segment_start:\n            prev_alongx = x0 - xm\n            prev_alongy = y0 - ym\n            prev_length = math.sqrt(prev_alongx**2 + prev_alongy**2)\n            if prev_length > 0.0:\n                prev_alongx /= prev_length\n                prev_alongy /= prev_length\n                prev_rightx = prev_alongy\n                prev_righty = -prev_alongx\n            else:\n                overwrite = True\n\n        # y limits of scan.\n        ystart = _clamp(math.ceil(buffer[4 + lowindex]), 0, ymax)\n        yend = _clamp(math.floor(buffer[4 + (lowindex+2) % 4]), 0, ymax)\n        # Need to know which edges are to left and right; both will change.\n        ll = lowindex  # Index of lower point of left edge.\n        lu = (ll + 1) % 4  # Index of upper point of left edge.\n        rl = lowindex  # Index of lower point of right edge.\n        ru = (rl + 3) % 4  # Index of upper point of right edge.\n        for y in range(ystart, yend+1):\n            if ll == lowindex and y > buffer[4 + lu]:\n                ll = lu\n                lu = (ll + 1) % 4\n            if rl == lowindex and y > buffer[4 + ru]:\n                rl = ru\n                ru = (rl + 3) % 4\n            # Find x limits of scan at this y.\n            xleft = _clamp(math.ceil(_x_intercept(\n                y, buffer[ll], buffer[4+ll], buffer[lu], buffer[4+lu])), 0, xmax)\n            xright = _clamp(math.floor(_x_intercept(\n                y, buffer[rl], buffer[4+rl], buffer[ru], buffer[4+ru])), 0, xmax)\n            for x in range(xleft, xright+1):\n                along = (x-x0)*alongx + (y-y0)*alongy  # dot product\n                prev_correction = False\n                if along < 0.0:\n                    # Before start of segment\n                    if overwrite or segment_start or (x-x0)*prev_alongx + (y-y0)*prev_alongy > 0.0:\n                        distance = math.sqrt((x-x0)**2 + (y-y0)**2)  # round join/end cap\n                    else:\n                        continue\n                elif along > length:\n                    # After end of segment\n                    if overwrite or segment_end:\n                        distance = math.sqrt((x-x1)**2 + (y-y1)**2)  # round join/end cap\n                    else:\n                        continue\n                else:\n                    # Within segment\n                    distance = abs((x-x0)*rightx + (y-y0)*righty)\n                    if not overwrite and not segment_start and \\\n                            -prev_length <= (x-x0)*prev_alongx + (y-y0)*prev_alongy <= 0.0 and \\\n                            abs((x-x0)*prev_rightx + (y-y0)*prev_righty) <= halfwidth:\n                        prev_correction = True\n                value = 1.0 - _linearstep(0.5*(line_width - aa), halfwidth, distance)\n                value *= scale\n                prev_value = 0.0\n                if prev_correction:\n                    # Already set pixel from previous segment, need to correct it\n                    prev_distance = abs((x-x0)*prev_rightx + (y-y0)*prev_righty)\n                    prev_value = 1.0 - _linearstep(0.5*(line_width - aa), halfwidth, prev_distance)\n                    prev_value *= scale\n                    if value <= prev_value:\n                        # Have already used a larger value (alpha) for this pixel.\n                        value = 0.0\n                if value > 0.0:\n                    xx, yy = (y, x) if flip_xy else (x, y)\n                    append(i, xx, yy, value, prev_value, *aggs_and_cols)\n\n    return _full_antialias\n\n\ndef _build_bresenham(expand_aggs_and_cols):\n    \"\"\"Specialize a bresenham kernel for a given append/axis combination\"\"\"\n    @ngjit\n    @expand_aggs_and_cols\n    def _bresenham(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start,\n                   x0, x1, y0, y1, clipped, append, *aggs_and_cols):\n        \"\"\"Draw a line segment using Bresenham's algorithm\n        This method plots a line segment with integer coordinates onto a pixel\n        grid.\n        \"\"\"\n        dx = x1 - x0\n        ix = (dx > 0) - (dx < 0)\n        dx = abs(dx) * 2\n\n        dy = y1 - y0\n        iy = (dy > 0) - (dy < 0)\n        dy = abs(dy) * 2\n\n        # If vertices weren't clipped and are concurrent in integer space,\n        # call append and return, so that the second vertex won't be hit below.\n        if not clipped and not (dx | dy):\n            append(i, x0, y0, *aggs_and_cols)\n            return\n\n        if segment_start:\n            append(i, x0, y0, *aggs_and_cols)\n\n        if dx >= dy:\n            error = 2 * dy - dx\n            while x0 != x1:\n                if error >= 0 and (error or ix > 0):\n                    error -= 2 * dx\n                    y0 += iy\n                error += 2 * dy\n                x0 += ix\n                append(i, x0, y0, *aggs_and_cols)\n        else:\n            error = 2 * dx - dy\n            while y0 != y1:\n                if error >= 0 and (error or iy > 0):\n                    error -= 2 * dy\n                    x0 += ix\n                error += 2 * dx\n                y0 += iy\n                append(i, x0, y0, *aggs_and_cols)\n    return _bresenham\n\ndef _build_draw_segment(append, map_onto_pixel, expand_aggs_and_cols, line_width, overwrite):\n    \"\"\"Specialize a line plotting kernel for a given append/axis combination\"\"\"\n\n    if line_width > 0.0:\n        _bresenham = None\n        _full_antialias = _build_full_antialias(expand_aggs_and_cols)\n    else:\n        _bresenham = _build_bresenham(expand_aggs_and_cols)\n        _full_antialias = None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def draw_segment(\n            i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end,\n            x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols\n    ):\n        # xm, ym are only valid if segment_start is True.\n\n        # buffer is a length-8 float64 array if antialiasing is to be used,\n        # or None otherwise. It is allocated in the appropriate extend_cpu or\n        # extend_cuda function so that it is of the correct type (numpy or\n        # cupy) and that there is one per CPU/GPU thread.\n\n        # NOTE: The slightly bizarre variable versioning herein for variables\n        # x0, y0, y0, y1 is to deal with Numba not having SSA form prior to\n        # version 0.49.0. The result of lack of SSA is that the type inference\n        # algorithms would widen types that are multiply defined as would be the\n        # case in code such as `x, y = function(x, y)` if the function returned\n        # a wider type for x, y then the input x, y.\n        skip = False\n\n        # If any of the coordinates are NaN, there's a discontinuity.\n        # Skip the entire segment.\n        if isnull(x0) or isnull(y0) or isnull(x1) or isnull(y1):\n            skip = True\n        # Use Liang-Barsky to clip the segment to a bounding box\n        x0_1, x1_1, y0_1, y1_1, skip, clipped_start, clipped_end = \\\n            _liang_barsky(xmin, xmax, ymin, ymax, x0, x1, y0, y1, skip)\n\n        if not skip:\n            clipped = clipped_start or clipped_end\n            segment_start = segment_start or clipped_start\n            x0_2, y0_2 = map_onto_pixel(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, x0_1, y0_1\n            )\n            x1_2, y1_2 = map_onto_pixel(\n                sx, tx, sy, ty, xmin, xmax, ymin, ymax, x1_1, y1_1\n            )\n            if line_width > 0.0:\n                if segment_start:\n                    xm_2 = ym_2 = 0.0\n                else:\n                    xm_2, ym_2 = map_onto_pixel(\n                        sx, tx, sy, ty, xmin, xmax, ymin, ymax, xm, ym)\n                nx = round((xmax - xmin)*sx)\n                ny = round((ymax - ymin)*sy)\n                _full_antialias(line_width, overwrite, i, x0_2, x1_2, y0_2, y1_2,\n                                segment_start, segment_end, xm_2, ym_2, append,\n                                nx, ny, buffer, *aggs_and_cols)\n            else:\n                _bresenham(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                           segment_start, x0_2, x1_2, y0_2, y1_2,\n                           clipped, append, *aggs_and_cols)\n\n    return draw_segment\n\ndef _build_extend_line_axis0(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                            plot_start, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[i]\n        y0 = ys[i]\n        x1 = xs[i + 1]\n        y1 = ys[i + 1]\n        segment_start = (plot_start if i == 0 else\n                         (isnull(xs[i - 1]) or isnull(ys[i - 1])))\n\n        segment_end = (i == len(xs)-2) or isnull(xs[i+2]) or isnull(ys[i+2])\n\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i-1]\n            ym = ys[i-1]\n\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                     segment_start, segment_end, x0, x1, y0, y1,\n                     xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                   xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        \"\"\"Aggregate along a line formed by ``xs`` and ``ys``\"\"\"\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows = xs.shape[0]\n        for i in range(nrows - 1):\n            perform_extend_line(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                plot_start, xs, ys, buffer, *aggs_and_cols)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i = cuda.grid(1)\n        if i < xs.shape[0] - 1:\n            perform_extend_line(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                plot_start, xs, ys, buffer, *aggs_and_cols)\n\n    return extend_cpu, extend_cuda\n\n\ndef _build_extend_line_axis0_multi(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                            plot_start, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[i, j]\n        y0 = ys[i, j]\n        x1 = xs[i + 1, j]\n        y1 = ys[i + 1, j]\n        segment_start = (plot_start if i == 0 else\n                         (isnull(xs[i - 1, j]) or isnull(ys[i - 1, j])))\n\n        segment_end = (i == len(xs)-2) or isnull(xs[i+2, j]) or isnull(ys[i+2, j])\n\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i-1, j]\n            ym = ys[i-1, j]\n\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                     segment_start, segment_end, x0, x1, y0, y1,\n                     xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                   plot_start, antialias_stage_2, *aggs_and_cols):\n        \"\"\"Aggregate along a line formed by ``xs`` and ``ys``\"\"\"\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows, ncols = xs.shape\n\n        for j in range(ncols):\n            for i in range(nrows - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                    plot_start, xs, ys, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                  plot_start, antialias_stage_2, *aggs_and_cols):\n        \"\"\"Aggregate along a line formed by ``xs`` and ``ys``\"\"\"\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                plot_start, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                plot_start, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n\n        nrows, ncols = xs.shape\n        for j in range(ncols):\n            for i in range(nrows - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                    plot_start, xs, ys, buffer, *aggs_and_cols)\n\n            if ncols == 1:\n                return\n\n            aa_stage_2_accumulate(aggs_and_accums, j==0)\n\n            if j < ncols - 1:\n                aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                    plot_start, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        if i < xs.shape[0] - 1 and j < xs.shape[1]:\n            perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                plot_start, xs, ys, buffer, *aggs_and_cols)\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg, extend_cuda\n    else:\n        return extend_cpu, extend_cuda\n\n\ndef _build_extend_line_axis1_none_constant(draw_segment, expand_aggs_and_cols,\n                                           antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(\n            i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            xs, ys, buffer, *aggs_and_cols\n    ):\n        x0 = xs[i, j]\n        y0 = ys[i, j]\n        x1 = xs[i, j + 1]\n        y1 = ys[i, j + 1]\n        segment_start = (\n                (j == 0) or isnull(xs[i, j - 1]) or isnull(ys[i, j - 1])\n        )\n\n        segment_end = (j == xs.shape[1]-2) or isnull(xs[i, j+2]) or isnull(ys[i, j+2])\n\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i, j-1]\n            ym = ys[i, j-1]\n\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                     segment_start, segment_end, x0, x1, y0, y1,\n                     xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2,\n                   *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(\n                    i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    xs, ys, buffer, *aggs_and_cols\n                )\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                  antialias_stage_2, *aggs_and_cols):\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                    xs, ys, buffer, *aggs_and_cols)\n\n            if xs.shape[0] == 1:\n                return\n\n            aa_stage_2_accumulate(aggs_and_accums, i==0)\n\n            if i < xs.shape[0] - 1:\n                aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2,\n                    *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        if i < xs.shape[0] and j < xs.shape[1] - 1:\n            perform_extend_line(\n                i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                buffer, *aggs_and_cols\n            )\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg, extend_cuda\n    else:\n        return extend_cpu, extend_cuda\n\n\ndef _build_extend_line_axis1_x_constant(draw_segment, expand_aggs_and_cols,\n                                        antialias_stage_2_funcs, swap_dims: bool = False):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(\n            i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols\n    ):\n        x0 = xs[j]\n        x1 = xs[j + 1]\n        if swap_dims:\n            y0 = ys[j, i]\n            y1 = ys[j + 1, i]\n            segment_start = (j == 0) or isnull(xs[j - 1]) or isnull(ys[j - 1, i])\n            segment_end = (j == len(xs)-2) or isnull(xs[j+2]) or isnull(ys[j+2, i])\n        else:\n            y0 = ys[i, j]\n            y1 = ys[i, j + 1]\n            segment_start = (j == 0) or isnull(xs[j - 1]) or isnull(ys[i, j - 1])\n            segment_end = (j == len(xs)-2) or isnull(xs[j+2]) or isnull(ys[i, j+2])\n\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[j-1]\n            ym = ys[j-1, i] if swap_dims else ys[i, j-1]\n\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                     segment_start, segment_end, x0, x1, y0, y1,\n                     xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2,\n                   *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols, nrows = ys.shape if swap_dims else ys.shape[::-1]\n        for i in range(nrows):\n            for j in range(ncols - 1):\n                perform_extend_line(\n                    i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols\n                )\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                  antialias_stage_2, *aggs_and_cols):\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n\n        ncols = ys.shape[1]\n        for i in range(ys.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(\n                    i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                    buffer, *aggs_and_cols\n                )\n\n            if ys.shape[0] == 1:\n                return\n\n            aa_stage_2_accumulate(aggs_and_accums, i==0)\n\n            if i < ys.shape[0] - 1:\n                aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2,\n                    *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        ncols, nrows = ys.shape if swap_dims else ys.shape[::-1]\n        if i < nrows and j < ncols - 1:\n            perform_extend_line(\n                i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols\n            )\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg, extend_cuda\n    else:\n        return extend_cpu, extend_cuda\n\n\ndef _build_extend_line_axis1_y_constant(draw_segment, expand_aggs_and_cols,\n                                        antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(\n            i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols\n    ):\n        x0 = xs[i, j]\n        y0 = ys[j]\n        x1 = xs[i, j + 1]\n        y1 = ys[j + 1]\n\n        segment_start = (\n                (j == 0) or isnull(xs[i, j - 1]) or isnull(ys[j - 1])\n        )\n\n        segment_end = (j == len(ys)-2) or isnull(xs[i, j+2]) or isnull(ys[j+2])\n\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i, j-1]\n            ym = ys[j-1]\n\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                     segment_start, segment_end, x0, x1, y0, y1,\n                     xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2,\n                   *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(\n                    i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    xs, ys, buffer, *aggs_and_cols\n                )\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                  antialias_stage_2, *aggs_and_cols):\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys,\n                                antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n\n            for j in range(ncols - 1):\n                perform_extend_line(\n                    i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                    xs, ys, buffer, *aggs_and_cols\n                )\n\n            if xs.shape[0] == 1:\n                return\n\n            aa_stage_2_accumulate(aggs_and_accums, i==0)\n\n            if i < xs.shape[0] - 1:\n                aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2,\n                    *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        if i < xs.shape[0] and j < xs.shape[1] - 1:\n            perform_extend_line(\n                i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                xs, ys, buffer, *aggs_and_cols\n            )\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg, extend_cuda\n    else:\n        return extend_cpu, extend_cuda\n\n\ndef _build_extend_line_axis1_ragged(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    def extend_cpu(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n    ):\n        x_start_i = xs.start_indices\n        x_flat = xs.flat_array\n\n        y_start_i = ys.start_indices\n        y_flat = ys.flat_array\n\n        extend_cpu_numba(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            x_start_i, x_flat, y_start_i, y_flat, antialias_stage_2, *aggs_and_cols\n        )\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            x_start_i, x_flat, y_start_i, y_flat, antialias_stage_2, *aggs_and_cols\n    ):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows = len(x_start_i)\n        x_flat_len = len(x_flat)\n        y_flat_len = len(y_flat)\n\n        for i in range(nrows):\n            # Get x index range\n            x_start_index = x_start_i[i]\n            x_stop_index = (x_start_i[i + 1]\n                            if i < nrows - 1\n                            else x_flat_len)\n\n            # Get y index range\n            y_start_index = y_start_i[i]\n            y_stop_index = (y_start_i[i + 1]\n                            if i < nrows - 1\n                            else y_flat_len)\n\n            # Find line segment length as shorter of the two segments\n            segment_len = min(x_stop_index - x_start_index,\n                              y_stop_index - y_start_index)\n\n            for j in range(segment_len - 1):\n\n                x0 = x_flat[x_start_index + j]\n                y0 = y_flat[y_start_index + j]\n                x1 = x_flat[x_start_index + j + 1]\n                y1 = y_flat[y_start_index + j + 1]\n\n                segment_start = (\n                        (j == 0) or\n                        isnull(x_flat[x_start_index + j - 1]) or\n                        isnull(y_flat[y_start_index + j - 1])\n                )\n\n                segment_end = (\n                        (j == segment_len-2) or\n                        isnull(x_flat[x_start_index + j + 2]) or\n                        isnull(y_flat[y_start_index + j + 2])\n                )\n\n                if segment_start or use_2_stage_agg:\n                    xm = 0.0\n                    ym = 0.0\n                else:\n                    xm = x_flat[x_start_index + j - 1]\n                    ym = y_flat[y_start_index + j - 1]\n\n                draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                             segment_start, segment_end, x0, x1, y0, y1,\n                             xm, ym, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols\n    ):\n        x_start_i = xs.start_indices\n        x_flat = xs.flat_array\n\n        y_start_i = ys.start_indices\n        y_flat = ys.flat_array\n\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n\n        extend_cpu_numba_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, x_start_i, x_flat,\n            y_start_i, y_flat, antialias_stage_2, aggs_and_accums, *aggs_and_cols\n        )\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, x_start_i, x_flat,\n            y_start_i, y_flat, antialias_stage_2, aggs_and_accums, *aggs_and_cols\n    ):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n\n        nrows = len(x_start_i)\n        x_flat_len = len(x_flat)\n        y_flat_len = len(y_flat)\n\n        for i in range(nrows):\n            # Get x index range\n            x_start_index = x_start_i[i]\n            x_stop_index = (x_start_i[i + 1]\n                            if i < nrows - 1\n                            else x_flat_len)\n\n            # Get y index range\n            y_start_index = y_start_i[i]\n            y_stop_index = (y_start_i[i + 1]\n                            if i < nrows - 1\n                            else y_flat_len)\n\n            # Find line segment length as shorter of the two segments\n            segment_len = min(x_stop_index - x_start_index,\n                              y_stop_index - y_start_index)\n\n            for j in range(segment_len - 1):\n\n                x0 = x_flat[x_start_index + j]\n                y0 = y_flat[y_start_index + j]\n                x1 = x_flat[x_start_index + j + 1]\n                y1 = y_flat[y_start_index + j + 1]\n\n                segment_start = (\n                        (j == 0) or\n                        isnull(x_flat[x_start_index + j - 1]) or\n                        isnull(y_flat[y_start_index + j - 1])\n                )\n\n                segment_end = (\n                        (j == segment_len-2) or\n                        isnull(x_flat[x_start_index + j + 2]) or\n                        isnull(y_flat[y_start_index + j + 2])\n                )\n\n                draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                             segment_start, segment_end, x0, x1, y0, y1,\n                             0.0, 0.0, buffer, *aggs_and_cols)\n\n            if nrows == 1:\n                return\n\n            aa_stage_2_accumulate(aggs_and_accums, i==0)\n\n            if i < nrows - 1:\n                aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg\n    else:\n        return extend_cpu\n\n\ndef _build_extend_line_axis1_geometry(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    def extend_cpu(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            geometry, closed_rings, antialias_stage_2, *aggs_and_cols\n    ):\n        values = geometry.buffer_values\n        missing = geometry.isna()\n        offsets = geometry.buffer_offsets\n\n        if len(offsets) == 2:\n            # MultiLineArray\n            offsets0, offsets1 = offsets\n        else:\n            # LineArray\n            offsets1 = offsets[0]\n            offsets0 = np.arange(len(offsets1))\n\n        if geometry._sindex is not None:\n            # Compute indices of potentially intersecting polygons using\n            # geometry's R-tree if there is one\n            eligible_inds = geometry.sindex.intersects((xmin, ymin, xmax, ymax))\n        else:\n            # Otherwise, process all indices\n            eligible_inds = np.arange(0, len(geometry), dtype='uint32')\n\n        extend_cpu_numba(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            values, missing, offsets0, offsets1, eligible_inds,\n            closed_rings, antialias_stage_2, *aggs_and_cols\n        )\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            values, missing, offsets0, offsets1, eligible_inds,\n            closed_rings, antialias_stage_2, *aggs_and_cols\n    ):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        for i in eligible_inds:\n            if missing[i]:\n                continue\n\n            start0 = offsets0[i]\n            stop0 = offsets0[i + 1]\n\n            for j in range(start0, stop0):\n                start1 = offsets1[j]\n                stop1 = offsets1[j + 1]\n\n                for k in range(start1, stop1 - 2, 2):\n                    x0 = values[k]\n                    if not np.isfinite(x0):\n                        continue\n\n                    y0 = values[k + 1]\n                    if not np.isfinite(y0):\n                        continue\n\n                    x1 = values[k + 2]\n                    if not np.isfinite(x1):\n                        continue\n\n                    y1 = values[k + 3]\n                    if not np.isfinite(y1):\n                        continue\n\n                    segment_start = (\n                            (k == start1 and not closed_rings) or\n                            (k > start1 and\n                             (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    )\n\n                    segment_end = (\n                            (not closed_rings and k == stop1-4) or\n                            (k < stop1-4 and\n                             (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    )\n\n                    if segment_start or use_2_stage_agg:\n                        xm = 0.0\n                        ym = 0.0\n                    elif k == start1 and closed_rings:\n                        xm = values[stop1-4]\n                        ym = values[stop1-3]\n                    else:\n                        xm = values[k-2]\n                        ym = values[k-1]\n\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                 segment_start, segment_end, x0, x1, y0, y1,\n                                 xm, ym, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            geometry, closed_rings, antialias_stage_2, *aggs_and_cols\n    ):\n        values = geometry.buffer_values\n        missing = geometry.isna()\n        offsets = geometry.buffer_offsets\n\n        if len(offsets) == 2:\n            # MultiLineArray\n            offsets0, offsets1 = offsets\n        else:\n            # LineArray\n            offsets1 = offsets[0]\n            offsets0 = np.arange(len(offsets1))\n\n        if geometry._sindex is not None:\n            # Compute indices of potentially intersecting polygons using\n            # geometry's R-tree if there is one\n            eligible_inds = geometry.sindex.intersects((xmin, ymin, xmax, ymax))\n        else:\n            # Otherwise, process all indices\n            eligible_inds = np.arange(0, len(geometry), dtype='uint32')\n\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n\n        extend_cpu_numba_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            values, missing, offsets0, offsets1, eligible_inds,\n            closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols\n        )\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n            values, missing, offsets0, offsets1, eligible_inds,\n            closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols\n    ):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n\n        first_pass = True\n        for i in eligible_inds:\n            if missing[i]:\n                continue\n\n            start0 = offsets0[i]\n            stop0 = offsets0[i + 1]\n\n            for j in range(start0, stop0):\n                start1 = offsets1[j]\n                stop1 = offsets1[j + 1]\n\n                for k in range(start1, stop1 - 2, 2):\n                    x0 = values[k]\n                    if not np.isfinite(x0):\n                        continue\n\n                    y0 = values[k + 1]\n                    if not np.isfinite(y0):\n                        continue\n\n                    x1 = values[k + 2]\n                    if not np.isfinite(x1):\n                        continue\n\n                    y1 = values[k + 3]\n                    if not np.isfinite(y1):\n                        continue\n\n                    segment_start = (\n                            (k == start1 and not closed_rings) or\n                            (k > start1 and\n                             (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    )\n\n                    segment_end = (\n                            (not closed_rings and k == stop1-4) or\n                            (k < stop1-4 and\n                             (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    )\n\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                 segment_start, segment_end, x0, x1, y0, y1,\n                                 0.0, 0.0, buffer, *aggs_and_cols)\n\n            aa_stage_2_accumulate(aggs_and_accums, first_pass)\n            first_pass = False\n            aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg\n    else:\n        return extend_cpu\n\n\ndef _build_extend_line_axis1_geopandas(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    # Lazy import shapely. Cannot get here if geopandas and shapely are not available.\n    import shapely\n\n    def _process_geometry(geometry):\n        ragged = shapely.to_ragged_array(geometry)\n        geometry_type = ragged[0]\n\n        if geometry_type not in (\n            shapely.GeometryType.LINESTRING, shapely.GeometryType.MULTILINESTRING,\n            shapely.GeometryType.MULTIPOLYGON, shapely.GeometryType.POLYGON,\n        ):\n            raise ValueError(\n                \"Canvas.line supports GeoPandas geometry types of LINESTRING, MULTILINESTRING, \"\n                f\"MULTIPOLYGON and POLYGON, not {repr(geometry_type)}\")\n\n        coords = ragged[1].ravel()\n\n        # Use type to decide whether geometry represents closed line loops or open list strips.\n        # Skip the last point for closed geometries so as not to double count the first/last point.\n        if geometry_type == shapely.GeometryType.LINESTRING:\n            offsets = ragged[2][0]\n            outer_offsets = np.arange(len(offsets))\n            closed_rings = False\n        elif geometry_type == shapely.GeometryType.MULTILINESTRING:\n            offsets, outer_offsets = ragged[2]\n            closed_rings = False\n        elif geometry_type == shapely.GeometryType.MULTIPOLYGON:\n            offsets, temp_offsets, outer_offsets = ragged[2]\n            outer_offsets = temp_offsets[outer_offsets]\n            closed_rings = True\n        else:  # geometry_type == shapely.GeometryType.POLYGON:\n            offsets, outer_offsets = ragged[2]\n            closed_rings = True\n\n        return coords, offsets, outer_offsets, closed_rings\n\n    def extend_cpu(\n        sx, tx, sy, ty, xmin, xmax, ymin, ymax, geometry, antialias_stage_2, *aggs_and_cols\n    ):\n        coords, offsets, outer_offsets, closed_rings = _process_geometry(geometry)\n        extend_cpu_numba(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, offsets, outer_offsets, closed_rings,\n            antialias_stage_2, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, offsets, outer_offsets,\n            closed_rings, antialias_stage_2, *aggs_and_cols\n    ):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        n_multilines = len(outer_offsets) - 1\n        for i in range(n_multilines):\n            start0 = outer_offsets[i]\n            stop0 = outer_offsets[i + 1]\n\n            for j in range(start0, stop0):\n                start1 = offsets[j]\n                stop1 = offsets[j + 1]\n\n                for k in range(2*start1, 2*stop1 - 2, 2):\n                    x0 = values[k]\n                    y0 = values[k + 1]\n                    x1 = values[k + 2]\n                    y1 = values[k + 3]\n                    if not (np.isfinite(x0) and np.isfinite(y0) and\n                            np.isfinite(x1) and np.isfinite(y1)):\n                        continue\n\n                    segment_start = (\n                            (k == start1 and not closed_rings) or\n                            (k > start1 and\n                             (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    )\n\n                    segment_end = (\n                            (not closed_rings and k == stop1-4) or\n                            (k < stop1-4 and\n                             (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    )\n\n                    if segment_start or use_2_stage_agg:\n                        xm = 0.0\n                        ym = 0.0\n                    elif k == start1 and closed_rings:\n                        xm = values[stop1-4]\n                        ym = values[stop1-3]\n                    else:\n                        xm = values[k-2]\n                        ym = values[k-1]\n\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                 segment_start, segment_end, x0, x1, y0, y1,\n                                 xm, ym, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(\n        sx, tx, sy, ty, xmin, xmax, ymin, ymax, geometry, antialias_stage_2, *aggs_and_cols\n    ):\n        coords, offsets, outer_offsets, closed_rings = _process_geometry(geometry)\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs])\n\n        extend_cpu_numba_antialias_2agg(\n            sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, offsets, outer_offsets, closed_rings,\n            antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba_antialias_2agg(\n        sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, offsets, outer_offsets,\n        closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols\n    ):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        n_multilines = len(outer_offsets) - 1\n        first_pass = True\n        for i in range(n_multilines):\n            start0 = outer_offsets[i]\n            stop0 = outer_offsets[i + 1]\n\n            for j in range(start0, stop0):\n                start1 = offsets[j]\n                stop1 = offsets[j + 1]\n\n                for k in range(2*start1, 2*stop1 - 2, 2):\n                    x0 = values[k]\n                    y0 = values[k + 1]\n                    x1 = values[k + 2]\n                    y1 = values[k + 3]\n                    if not (np.isfinite(x0) and np.isfinite(y0) and\n                            np.isfinite(x1) and np.isfinite(y1)):\n                        continue\n\n                    segment_start = (\n                            (k == start1 and not closed_rings) or\n                            (k > start1 and\n                             (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    )\n\n                    segment_end = (\n                            (not closed_rings and k == stop1-4) or\n                            (k < stop1-4 and\n                             (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    )\n\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax,\n                                 segment_start, segment_end, x0, x1, y0, y1,\n                                 #xm, ym, buffer, *aggs_and_cols)\n                                 0.0, 0.0, buffer, *aggs_and_cols)\n\n            aa_stage_2_accumulate(aggs_and_accums, first_pass)\n            first_pass = False\n            aa_stage_2_clear(aggs_and_accums)\n\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg\n    else:\n        return extend_cpu\n"
  },
  "GT_src_dict": {
    "datashader/glyphs/points.py": {
      "_PointLike.__init__": {
        "code": "    def __init__(self, x, y):\n        \"\"\"Initializes a _PointLike object which serves as a base class for managing point-like graphical objects.\n\nParameters\n----------\nx : str\n    The column name representing the x-coordinates of each point.\ny : str\n    The column name representing the y-coordinates of each point.\n\nAttributes\n----------\nself.x : str\n    Stores the column name for the x-coordinates.\nself.y : str\n    Stores the column name for the y-coordinates.\n\nThis class is part of a graphical framework that utilizes points as the primary data representation, often used for rendering and calculating boundaries of graphical objects on a plot. The x and y attributes are essential for further computations within methods that handle validation, boundary calculation, and extending point data onto a graphical canvas.\"\"\"\n        self.x = x\n        self.y = y",
        "docstring": "Initializes a _PointLike object which serves as a base class for managing point-like graphical objects.\n\nParameters\n----------\nx : str\n    The column name representing the x-coordinates of each point.\ny : str\n    The column name representing the y-coordinates of each point.\n\nAttributes\n----------\nself.x : str\n    Stores the column name for the x-coordinates.\nself.y : str\n    Stores the column name for the y-coordinates.\n\nThis class is part of a graphical framework that utilizes points as the primary data representation, often used for rendering and calculating boundaries of graphical objects on a plot. The x and y attributes are essential for further computations within methods that handle validation, boundary calculation, and extending point data onto a graphical canvas.",
        "signature": "def __init__(self, x, y):",
        "type": "Method",
        "class_signature": "class _PointLike(Glyph):"
      },
      "_PointLike.validate": {
        "code": "    def validate(self, in_dshape):\n        \"\"\"Validates the input shape of the Point-like glyphs to ensure that the x and y coordinates are real numbers.\n\nParameters\n----------\nin_dshape : Dshape\n    The input data shape, which includes information about the measure used. This is expected to provide dimensions and types of input data.\n\nRaises\n------\nValueError\n    If the x or y coordinates, specified as attributes of the class, are not real numbers as determined by the 'isreal' utility function.\n\nNotes\n-----\nThe `isreal` function, imported from `datashader.utils`, is used to perform the validation check. It ensures that the data types of the x and y coordinates conform to the expected numeric types, preventing issues during computations.\"\"\"\n        if not isreal(in_dshape.measure[str(self.x)]):\n            raise ValueError('x must be real')\n        elif not isreal(in_dshape.measure[str(self.y)]):\n            raise ValueError('y must be real')",
        "docstring": "Validates the input shape of the Point-like glyphs to ensure that the x and y coordinates are real numbers.\n\nParameters\n----------\nin_dshape : Dshape\n    The input data shape, which includes information about the measure used. This is expected to provide dimensions and types of input data.\n\nRaises\n------\nValueError\n    If the x or y coordinates, specified as attributes of the class, are not real numbers as determined by the 'isreal' utility function.\n\nNotes\n-----\nThe `isreal` function, imported from `datashader.utils`, is used to perform the validation check. It ensures that the data types of the x and y coordinates conform to the expected numeric types, preventing issues during computations.",
        "signature": "def validate(self, in_dshape):",
        "type": "Method",
        "class_signature": "class _PointLike(Glyph):"
      }
    },
    "datashader/glyphs/glyph.py": {
      "Glyph._compute_bounds": {
        "code": "    def _compute_bounds(s):\n        \"\"\"Compute the minimum and maximum bounds of the provided data structure.\n\nParameters\n----------\ns : Union[cudf.Series, pd.Series, xr.DataArray, ndarray]\n    The input data structure for which the bounds will be computed. \n    It can be a cuDF Series, a pandas Series, or an xarray DataArray. \n\nReturns\n-------\ntuple\n    A tuple containing the minimum and maximum values in the input, \n    handling NaN values appropriately. If the input is of unsupported \n    types, the method will attempt to compute bounds using the \n    `_compute_bounds_numba` method.\n\nDependencies\n------------\nThis method interacts with the `cudf` and `cupy` libraries if available. \nIf `s` is a cuDF Series, it first converts NaN values to nulls. For \npandas Series and xarray DataArrays, it leverages the `_compute_bounds_numba` \nmethod for efficient computation of bounds using Numba's JIT compilation.\"\"\"\n        if cudf and isinstance(s, cudf.Series):\n            s = s.nans_to_nulls()\n            return (s.min(), s.max())\n        elif isinstance(s, pd.Series):\n            return Glyph._compute_bounds_numba(s.values)\n        elif isinstance(s, xr.DataArray):\n            if cp and isinstance(s.data, cp.ndarray):\n                return (s.min().item(), s.max().item())\n            else:\n                return Glyph._compute_bounds_numba(s.values.ravel())\n        else:\n            return Glyph._compute_bounds_numba(s)",
        "docstring": "Compute the minimum and maximum bounds of the provided data structure.\n\nParameters\n----------\ns : Union[cudf.Series, pd.Series, xr.DataArray, ndarray]\n    The input data structure for which the bounds will be computed. \n    It can be a cuDF Series, a pandas Series, or an xarray DataArray. \n\nReturns\n-------\ntuple\n    A tuple containing the minimum and maximum values in the input, \n    handling NaN values appropriately. If the input is of unsupported \n    types, the method will attempt to compute bounds using the \n    `_compute_bounds_numba` method.\n\nDependencies\n------------\nThis method interacts with the `cudf` and `cupy` libraries if available. \nIf `s` is a cuDF Series, it first converts NaN values to nulls. For \npandas Series and xarray DataArrays, it leverages the `_compute_bounds_numba` \nmethod for efficient computation of bounds using Numba's JIT compilation.",
        "signature": "def _compute_bounds(s):",
        "type": "Method",
        "class_signature": "class Glyph(Expr):"
      }
    },
    "datashader/datashape/util/__init__.py": {
      "dshape": {
        "code": "def dshape(o):\n    \"\"\"Parse and create a DataShape object from various input formats.\n\nParameters:\n- o: An input that can be in the form of a string representing a datashape, an instance of coretypes.DataShape, coretypes.CType, coretypes.String, coretypes.Record, coretypes.JSON, coretypes.Date, coretypes.Time, coretypes.DateTime, coretypes.Unit, coretypes.Mono, or a list/tuple of shapes.\n\nReturns:\n- An instance of coretypes.DataShape that represents the parsed datashape.\n\nRaises:\n- TypeError if the input is of an unsupported type.\n- Validation errors through the `validate(ds)` function if the resulting DataShape does not conform to expected standards.\n\nDependencies:\n- Utilizes `parser` to parse string representations of datashapes and `validate` from the validation module to ensure the integrity of the created DataShape. The `type_symbol_table.sym` is used in parsing.\"\"\"\n    '\\n    Parse a datashape. For a thorough description see\\n    https://datashape.readthedocs.io/en/latest/\\n\\n    >>> ds = dshape(\\'2 * int32\\')\\n    >>> ds[1]\\n    ctype(\"int32\")\\n    '\n    if isinstance(o, coretypes.DataShape):\n        return o\n    if isinstance(o, str):\n        ds = parser.parse(o, type_symbol_table.sym)\n    elif isinstance(o, (coretypes.CType, coretypes.String, coretypes.Record, coretypes.JSON, coretypes.Date, coretypes.Time, coretypes.DateTime, coretypes.Unit)):\n        ds = coretypes.DataShape(o)\n    elif isinstance(o, coretypes.Mono):\n        ds = o\n    elif isinstance(o, (list, tuple)):\n        ds = coretypes.DataShape(*o)\n    else:\n        raise TypeError('Cannot create dshape from object of type %s' % type(o))\n    validate(ds)\n    return ds",
        "docstring": "Parse and create a DataShape object from various input formats.\n\nParameters:\n- o: An input that can be in the form of a string representing a datashape, an instance of coretypes.DataShape, coretypes.CType, coretypes.String, coretypes.Record, coretypes.JSON, coretypes.Date, coretypes.Time, coretypes.DateTime, coretypes.Unit, coretypes.Mono, or a list/tuple of shapes.\n\nReturns:\n- An instance of coretypes.DataShape that represents the parsed datashape.\n\nRaises:\n- TypeError if the input is of an unsupported type.\n- Validation errors through the `validate(ds)` function if the resulting DataShape does not conform to expected standards.\n\nDependencies:\n- Utilizes `parser` to parse string representations of datashapes and `validate` from the validation module to ensure the integrity of the created DataShape. The `type_symbol_table.sym` is used in parsing.",
        "signature": "def dshape(o):",
        "type": "Function",
        "class_signature": null
      }
    },
    "datashader/glyphs/line.py": {
      "LinesAxis1.validate": {
        "code": "    def validate(self, in_dshape):\n        \"\"\"Validate the integrity of the x and y coordinate columns for a LinesAxis1 instance.\n\nParameters\n----------\nin_dshape : object\n    An object representing the input data shape, which must include measures for both x and y coordinates.\n\nRaises\n------\nValueError\n    If any of the following conditions are met:\n        - Any x column is not of a real number type.\n        - Any y column is not of a real number type.\n        - The x columns do not have the same data type.\n        - The y columns do not have the same data type.\n        - The lengths of x and y coordinate lists do not match.\n\nThe method interacts with the attributes `self.x` and `self.y`, which are expected to be lists of column names. The `isreal` function, imported from `datashader.utils`, is used to verify that the columns contain real numbers. The measures for each column are retrieved from `in_dshape.measure`, ensuring that the inputs conform to expected data types and shapes for processing graphical lines.\"\"\"\n        if not all([isreal(in_dshape.measure[str(xcol)]) for xcol in self.x]):\n            raise ValueError('x columns must be real')\n        elif not all([isreal(in_dshape.measure[str(ycol)]) for ycol in self.y]):\n            raise ValueError('y columns must be real')\n        unique_x_measures = set((in_dshape.measure[str(xcol)] for xcol in self.x))\n        if len(unique_x_measures) > 1:\n            raise ValueError('x columns must have the same data type')\n        unique_y_measures = set((in_dshape.measure[str(ycol)] for ycol in self.y))\n        if len(unique_y_measures) > 1:\n            raise ValueError('y columns must have the same data type')\n        if len(self.x) != len(self.y):\n            raise ValueError(f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')",
        "docstring": "Validate the integrity of the x and y coordinate columns for a LinesAxis1 instance.\n\nParameters\n----------\nin_dshape : object\n    An object representing the input data shape, which must include measures for both x and y coordinates.\n\nRaises\n------\nValueError\n    If any of the following conditions are met:\n        - Any x column is not of a real number type.\n        - Any y column is not of a real number type.\n        - The x columns do not have the same data type.\n        - The y columns do not have the same data type.\n        - The lengths of x and y coordinate lists do not match.\n\nThe method interacts with the attributes `self.x` and `self.y`, which are expected to be lists of column names. The `isreal` function, imported from `datashader.utils`, is used to verify that the columns contain real numbers. The measures for each column are retrieved from `in_dshape.measure`, ensuring that the inputs conform to expected data types and shapes for processing graphical lines.",
        "signature": "def validate(self, in_dshape):",
        "type": "Method",
        "class_signature": "class LinesAxis1(_PointLike, _AntiAliasedLine):"
      }
    }
  },
  "dependency_dict": {
    "datashader/datashape/util/__init__.py:dshape": {
      "datashader/datashape/validation.py": {
        "validate": {
          "code": "def validate(ds):\n    \"\"\"\n    Validate a datashape to see whether it is well-formed.\n\n    Parameters\n    ----------\n    ds : DataShape\n\n    Examples\n    --------\n    >>> from datashader.datashape import dshape\n    >>> dshape('10 * int32')\n    dshape(\"10 * int32\")\n    >>> dshape('... * int32')\n    dshape(\"... * int32\")\n    >>> dshape('... * ... * int32') # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    TypeError: Can only use a single wildcard\n    >>> dshape('T * ... * X * ... * X') # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    TypeError: Can only use a single wildcard\n    >>> dshape('T * ...') # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    DataShapeSyntaxError: Expected a dtype\n    \"\"\"\n    traverse(_validate, ds)",
          "docstring": "Validate a datashape to see whether it is well-formed.\n\nParameters\n----------\nds : DataShape\n\nExamples\n--------\n>>> from datashader.datashape import dshape\n>>> dshape('10 * int32')\ndshape(\"10 * int32\")\n>>> dshape('... * int32')\ndshape(\"... * int32\")\n>>> dshape('... * ... * int32') # doctest: +IGNORE_EXCEPTION_DETAIL\nTraceback (most recent call last):\n    ...\nTypeError: Can only use a single wildcard\n>>> dshape('T * ... * X * ... * X') # doctest: +IGNORE_EXCEPTION_DETAIL\nTraceback (most recent call last):\n    ...\nTypeError: Can only use a single wildcard\n>>> dshape('T * ...') # doctest: +IGNORE_EXCEPTION_DETAIL\nTraceback (most recent call last):\n    ...\nDataShapeSyntaxError: Expected a dtype",
          "signature": "def validate(ds):",
          "type": "Function",
          "class_signature": null
        }
      },
      "datashader/datashape/parser.py": {
        "parse": {
          "code": "def parse(ds_str, sym):\n    \"\"\"Parses a single datashape from a string.\n\n    Parameters\n    ----------\n    ds_str : string\n        The datashape string to parse.\n    sym : TypeSymbolTable\n        The symbol tables of dimensions, dtypes, and type constructors for each.\n\n    \"\"\"\n    dsp = DataShapeParser(ds_str, sym)\n    ds = dsp.parse_datashape()\n    # If no datashape could be found\n    if ds is None:\n        dsp.raise_error('Invalid datashape')\n\n    # Make sure there's no garbage at the end\n    if dsp.pos != dsp.end_pos:\n        dsp.raise_error('Unexpected token in datashape')\n    return ds",
          "docstring": "Parses a single datashape from a string.\n\nParameters\n----------\nds_str : string\n    The datashape string to parse.\nsym : TypeSymbolTable\n    The symbol tables of dimensions, dtypes, and type constructors for each.",
          "signature": "def parse(ds_str, sym):",
          "type": "Function",
          "class_signature": null
        }
      }
    },
    "datashader/glyphs/points.py:_PointLike:validate": {
      "datashader/datashape/coretypes.py": {
        "DataShape.measure": {
          "code": "    def measure(self):\n        return self.parameters[-1]",
          "docstring": "",
          "signature": "def measure(self):",
          "type": "Method",
          "class_signature": "class DataShape(Mono):"
        },
        "Record.__getitem__": {
          "code": "    def __getitem__(self, key):\n        return self.dict[key]",
          "docstring": "",
          "signature": "def __getitem__(self, key):",
          "type": "Method",
          "class_signature": "class Record(CollectionPrinter, Mono, metaclass=RecordMeta):"
        }
      },
      "datashader/utils.py": {
        "isreal": {
          "code": "def isreal(dt):\n    \"\"\"Check if a datashape is numeric and real.\n\n    Example\n    -------\n    >>> isreal('int32')\n    True\n    >>> isreal('float64')\n    True\n    >>> isreal('string')\n    False\n    >>> isreal('complex64')\n    False\n    \"\"\"\n    dt = datashape.predicates.launder(dt)\n    return isinstance(dt, datashape.Unit) and dt in datashape.typesets.real",
          "docstring": "Check if a datashape is numeric and real.\n\nExample\n-------\n>>> isreal('int32')\nTrue\n>>> isreal('float64')\nTrue\n>>> isreal('string')\nFalse\n>>> isreal('complex64')\nFalse",
          "signature": "def isreal(dt):",
          "type": "Function",
          "class_signature": null
        }
      }
    },
    "datashader/glyphs/line.py:LinesAxis1:validate": {
      "datashader/datashape/coretypes.py": {
        "Mono.__hash__": {
          "code": "    def __hash__(self):\n        try:\n            h = self._hash\n        except AttributeError:\n            h = self._hash = hash(self.shape) ^ hash(self.measure.info())\n        return h",
          "docstring": "",
          "signature": "def __hash__(self):",
          "type": "Method",
          "class_signature": "class Mono(metaclass=Type):"
        },
        "DataShape.measure": {
          "code": "    def measure(self):\n        return self.parameters[-1]",
          "docstring": "",
          "signature": "def measure(self):",
          "type": "Method",
          "class_signature": "class DataShape(Mono):"
        },
        "Record.__getitem__": {
          "code": "    def __getitem__(self, key):\n        return self.dict[key]",
          "docstring": "",
          "signature": "def __getitem__(self, key):",
          "type": "Method",
          "class_signature": "class Record(CollectionPrinter, Mono, metaclass=RecordMeta):"
        }
      },
      "datashader/utils.py": {
        "isreal": {
          "code": "def isreal(dt):\n    \"\"\"Check if a datashape is numeric and real.\n\n    Example\n    -------\n    >>> isreal('int32')\n    True\n    >>> isreal('float64')\n    True\n    >>> isreal('string')\n    False\n    >>> isreal('complex64')\n    False\n    \"\"\"\n    dt = datashape.predicates.launder(dt)\n    return isinstance(dt, datashape.Unit) and dt in datashape.typesets.real",
          "docstring": "Check if a datashape is numeric and real.\n\nExample\n-------\n>>> isreal('int32')\nTrue\n>>> isreal('float64')\nTrue\n>>> isreal('string')\nFalse\n>>> isreal('complex64')\nFalse",
          "signature": "def isreal(dt):",
          "type": "Function",
          "class_signature": null
        }
      }
    }
  },
  "call_tree": {
    "datashader/tests/test_glyphs.py:test_point_bounds_check": {
      "datashader/glyphs/points.py:_PointLike:__init__": {},
      "datashader/glyphs/glyph.py:Glyph:_compute_bounds": {}
    },
    "datashader/tests/test_glyphs.py:test_point_validate": {
      "datashader/glyphs/points.py:_PointLike:__init__": {},
      "datashader/datashape/util/__init__.py:dshape": {
        "datashader/datashape/parser.py:parse": {
          "datashader/datashape/parser.py:DataShapeParser:__init__": {
            "datashader/datashape/parser.py:DataShapeParser:advance_tok": {
              "datashader/datashape/lexer.py:lex": {}
            }
          },
          "datashader/datashape/parser.py:DataShapeParser:parse_datashape": {
            "datashader/datashape/parser.py:DataShapeParser:tok": {},
            "datashader/datashape/parser.py:DataShapeParser:parse_datashape_nooption": {
              "datashader/datashape/parser.py:DataShapeParser:parse_dim": {
                "datashader/datashape/parser.py:DataShapeParser:tok": {}
              },
              "datashader/datashape/parser.py:DataShapeParser:parse_dtype": {
                "datashader/datashape/parser.py:DataShapeParser:tok": {},
                "datashader/datashape/parser.py:DataShapeParser:parse_struct_type": {
                  "datashader/datashape/parser.py:DataShapeParser:tok": {},
                  "datashader/datashape/parser.py:DataShapeParser:advance_tok": {
                    "datashader/datashape/lexer.py:lex": {}
                  },
                  "datashader/datashape/parser.py:DataShapeParser:parse_homogeneous_list": {
                    "datashader/datashape/parser.py:DataShapeParser:parse_struct_field": {
                      "datashader/datashape/parser.py:DataShapeParser:tok": {},
                      "datashader/datashape/parser.py:DataShapeParser:advance_tok": {},
                      "datashader/datashape/parser.py:DataShapeParser:parse_datashape": {
                        "[ignored_or_cut_off]": "..."
                      }
                    },
                    "datashader/datashape/parser.py:DataShapeParser:tok": {},
                    "datashader/datashape/parser.py:DataShapeParser:advance_tok": {
                      "datashader/datashape/lexer.py:lex": {}
                    }
                  },
                  "datashader/datashape/parser.py:DataShapeParser:syntactic_sugar": {},
                  "datashader/datashape/type_symbol_table.py:_struct": {
                    "datashader/datashape/coretypes.py:Record:__init__": {
                      "datashader/datashape/coretypes.py:_launder": {}
                    }
                  }
                }
              },
              "datashader/datashape/coretypes.py:Mono:__len__": {},
              "datashader/datashape/coretypes.py:DataShape:__init__": {
                "datashader/datashape/coretypes.py:_launder": {}
              }
            }
          }
        },
        "datashader/datashape/validation.py:validate": {
          "datashader/datashape/validation.py:traverse": {
            "datashader/datashape/coretypes.py:Mono:parameters": {
              "datashader/datashape/coretypes.py:Mono:_slotted": {}
            },
            "datashader/datashape/validation.py:traverse": {
              "[ignored_or_cut_off]": "..."
            },
            "datashader/datashape/validation.py:_validate": {
              "datashader/datashape/coretypes.py:Mono:parameters": {
                "datashader/datashape/coretypes.py:Mono:_slotted": {}
              }
            }
          }
        }
      },
      "datashader/glyphs/points.py:_PointLike:validate": {
        "datashader/datashape/coretypes.py:DataShape:measure": {
          "datashader/datashape/coretypes.py:Mono:parameters": {
            "datashader/datashape/coretypes.py:Mono:_slotted": {}
          }
        },
        "datashader/datashape/coretypes.py:Record:__getitem__": {
          "datashader/datashape/coretypes.py:Record:dict": {
            "datashader/datashape/coretypes.py:Record:fields": {}
          }
        },
        "datashader/utils.py:isreal": {
          "datashader/datashape/predicates.py:launder": {},
          "datashader/datashape/typesets.py:TypeSet:__contains__": {
            "datashader/datashape/typesets.py:TypeSet:_set": {
              "datashader/datashape/coretypes.py:Mono:__hash__": {}
            },
            "datashader/datashape/coretypes.py:Mono:__hash__": {}
          }
        }
      }
    },
    "datashader/tests/test_glyphs.py:test_draw_line": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_segment": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_line_same_point": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_segment": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_line_vertical_horizontal": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_segment": {}
    },
    "datashader/tests/test_glyphs.py:test_extend_lines": {
      "datashader/tests/test_glyphs.py:new_agg": {}
    },
    "datashader/tests/test_glyphs.py:test_extend_lines_all_out_of_bounds": {
      "datashader/tests/test_glyphs.py:new_agg": {}
    },
    "datashader/tests/test_glyphs.py:test_extend_lines_nan": {
      "datashader/tests/test_glyphs.py:new_agg": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_acute": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_acute_not_stacked": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_right": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_obtuse": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_intersecting": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_vertical_line_start_and_not_clipped": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_vertical_line_not_start_and_not_clipped": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_clipped": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_vertical_line_not_start_and_clipped": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_horizontal_line": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_diagonal_line": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_draw_trapezoid_point": {
      "datashader/tests/test_glyphs.py:new_agg": {},
      "datashader/tests/test_glyphs.py:draw_trapezoid": {}
    },
    "datashader/tests/test_glyphs.py:test_lines_xy_validate": {
      "datashader/glyphs/points.py:_PointLike:__init__": {},
      "datashader/datashape/util/__init__.py:dshape": {
        "datashader/datashape/parser.py:parse": {
          "datashader/datashape/parser.py:DataShapeParser:__init__": {
            "datashader/datashape/parser.py:DataShapeParser:advance_tok": {
              "datashader/datashape/lexer.py:lex": {}
            }
          },
          "datashader/datashape/parser.py:DataShapeParser:parse_datashape": {
            "datashader/datashape/parser.py:DataShapeParser:tok": {},
            "datashader/datashape/parser.py:DataShapeParser:parse_datashape_nooption": {
              "datashader/datashape/parser.py:DataShapeParser:parse_dim": {
                "datashader/datashape/parser.py:DataShapeParser:tok": {}
              },
              "datashader/datashape/parser.py:DataShapeParser:parse_dtype": {
                "datashader/datashape/parser.py:DataShapeParser:tok": {},
                "datashader/datashape/parser.py:DataShapeParser:parse_struct_type": {
                  "datashader/datashape/parser.py:DataShapeParser:tok": {},
                  "datashader/datashape/parser.py:DataShapeParser:advance_tok": {
                    "datashader/datashape/lexer.py:lex": {}
                  },
                  "datashader/datashape/parser.py:DataShapeParser:parse_homogeneous_list": {
                    "datashader/datashape/parser.py:DataShapeParser:parse_struct_field": {
                      "datashader/datashape/parser.py:DataShapeParser:tok": {},
                      "datashader/datashape/parser.py:DataShapeParser:advance_tok": {},
                      "datashader/datashape/parser.py:DataShapeParser:parse_datashape": {
                        "[ignored_or_cut_off]": "..."
                      }
                    },
                    "datashader/datashape/parser.py:DataShapeParser:tok": {},
                    "datashader/datashape/parser.py:DataShapeParser:advance_tok": {
                      "datashader/datashape/lexer.py:lex": {}
                    }
                  },
                  "datashader/datashape/parser.py:DataShapeParser:syntactic_sugar": {},
                  "datashader/datashape/type_symbol_table.py:_struct": {
                    "datashader/datashape/coretypes.py:Record:__init__": {
                      "datashader/datashape/coretypes.py:_launder": {}
                    }
                  }
                }
              },
              "datashader/datashape/coretypes.py:Mono:__len__": {},
              "datashader/datashape/coretypes.py:DataShape:__init__": {
                "datashader/datashape/coretypes.py:_launder": {}
              }
            }
          }
        },
        "datashader/datashape/validation.py:validate": {
          "datashader/datashape/validation.py:traverse": {
            "datashader/datashape/coretypes.py:Mono:parameters": {
              "datashader/datashape/coretypes.py:Mono:_slotted": {}
            },
            "datashader/datashape/validation.py:traverse": {
              "[ignored_or_cut_off]": "..."
            },
            "datashader/datashape/validation.py:_validate": {
              "datashader/datashape/coretypes.py:Mono:parameters": {
                "datashader/datashape/coretypes.py:Mono:_slotted": {}
              }
            }
          }
        }
      },
      "datashader/glyphs/line.py:LinesAxis1:validate": {
        "datashader/datashape/coretypes.py:DataShape:measure": {
          "datashader/datashape/coretypes.py:Mono:parameters": {
            "datashader/datashape/coretypes.py:Mono:_slotted": {}
          }
        },
        "datashader/datashape/coretypes.py:Record:__getitem__": {
          "datashader/datashape/coretypes.py:Record:dict": {
            "datashader/datashape/coretypes.py:Record:fields": {}
          }
        },
        "datashader/utils.py:isreal": {
          "datashader/datashape/predicates.py:launder": {},
          "datashader/datashape/typesets.py:TypeSet:__contains__": {
            "datashader/datashape/typesets.py:TypeSet:_set": {
              "datashader/datashape/coretypes.py:Mono:__hash__": {}
            },
            "datashader/datashape/coretypes.py:Mono:__hash__": {}
          }
        },
        "datashader/datashape/coretypes.py:Mono:__hash__": {}
      }
    }
  },
  "PRD": "# PROJECT NAME: datashader-test_glyphs\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 datashader/\n    \u251c\u2500\u2500 datashape/\n    \u2502   \u2514\u2500\u2500 util/\n    \u2502       \u2514\u2500\u2500 __init__.py\n    \u2502           \u2514\u2500\u2500 dshape\n    \u2514\u2500\u2500 glyphs/\n        \u251c\u2500\u2500 glyph.py\n        \u2502   \u2514\u2500\u2500 Glyph._compute_bounds\n        \u251c\u2500\u2500 line.py\n        \u2502   \u2514\u2500\u2500 LinesAxis1.validate\n        \u2514\u2500\u2500 points.py\n            \u251c\u2500\u2500 _PointLike.__init__\n            \u2514\u2500\u2500 _PointLike.validate\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module is designed to facilitate high-performance, raster-based rendering of geometric shapes such as points, lines, triangles, and trapezoids onto numerical aggregation arrays. It provides capabilities for geometric validation, bounds determination, and efficient aggregation operations using specialized functions and utilities, including support for transformations and clipping within defined coordinate and pixel spaces. By enabling accurate rasterization of complex shapes with interpolation and stacking options, the module addresses the challenges of efficiently visualizing and processing large volumes of geometric data, making it ideal for use in data visualization tools and numerical analysis workflows. Its robust functionality ensures reliable rendering and aggregation, critical for developers handling large-scale spatial or tabular datasets.\n\n## FILE 1: datashader/glyphs/points.py\n\n- CLASS METHOD: _PointLike.validate\n  - CLASS SIGNATURE: class _PointLike(Glyph):\n  - SIGNATURE: def validate(self, in_dshape):\n  - DOCSTRING: \n```python\n\"\"\"\nValidates the input shape of the Point-like glyphs to ensure that the x and y coordinates are real numbers.\n\nParameters\n----------\nin_dshape : Dshape\n    The input data shape, which includes information about the measure used. This is expected to provide dimensions and types of input data.\n\nRaises\n------\nValueError\n    If the x or y coordinates, specified as attributes of the class, are not real numbers as determined by the 'isreal' utility function.\n\nNotes\n-----\nThe `isreal` function, imported from `datashader.utils`, is used to perform the validation check. It ensures that the data types of the x and y coordinates conform to the expected numeric types, preventing issues during computations.\n\"\"\"\n```\n\n- CLASS METHOD: _PointLike.__init__\n  - CLASS SIGNATURE: class _PointLike(Glyph):\n  - SIGNATURE: def __init__(self, x, y):\n  - DOCSTRING: \n```python\n\"\"\"\nInitializes a _PointLike object which serves as a base class for managing point-like graphical objects.\n\nParameters\n----------\nx : str\n    The column name representing the x-coordinates of each point.\ny : str\n    The column name representing the y-coordinates of each point.\n\nAttributes\n----------\nself.x : str\n    Stores the column name for the x-coordinates.\nself.y : str\n    Stores the column name for the y-coordinates.\n\nThis class is part of a graphical framework that utilizes points as the primary data representation, often used for rendering and calculating boundaries of graphical objects on a plot. The x and y attributes are essential for further computations within methods that handle validation, boundary calculation, and extending point data onto a graphical canvas.\n\"\"\"\n```\n\n## FILE 2: datashader/glyphs/glyph.py\n\n- CLASS METHOD: Glyph._compute_bounds\n  - CLASS SIGNATURE: class Glyph(Expr):\n  - SIGNATURE: def _compute_bounds(s):\n  - DOCSTRING: \n```python\n\"\"\"\nCompute the minimum and maximum bounds of the provided data structure.\n\nParameters\n----------\ns : Union[cudf.Series, pd.Series, xr.DataArray, ndarray]\n    The input data structure for which the bounds will be computed. \n    It can be a cuDF Series, a pandas Series, or an xarray DataArray. \n\nReturns\n-------\ntuple\n    A tuple containing the minimum and maximum values in the input, \n    handling NaN values appropriately. If the input is of unsupported \n    types, the method will attempt to compute bounds using the \n    `_compute_bounds_numba` method.\n\nDependencies\n------------\nThis method interacts with the `cudf` and `cupy` libraries if available. \nIf `s` is a cuDF Series, it first converts NaN values to nulls. For \npandas Series and xarray DataArrays, it leverages the `_compute_bounds_numba` \nmethod for efficient computation of bounds using Numba's JIT compilation.\n\"\"\"\n```\n\n## FILE 3: datashader/datashape/util/__init__.py\n\n- FUNCTION NAME: dshape\n  - SIGNATURE: def dshape(o):\n  - DOCSTRING: \n```python\n\"\"\"\nParse and create a DataShape object from various input formats.\n\nParameters:\n- o: An input that can be in the form of a string representing a datashape, an instance of coretypes.DataShape, coretypes.CType, coretypes.String, coretypes.Record, coretypes.JSON, coretypes.Date, coretypes.Time, coretypes.DateTime, coretypes.Unit, coretypes.Mono, or a list/tuple of shapes.\n\nReturns:\n- An instance of coretypes.DataShape that represents the parsed datashape.\n\nRaises:\n- TypeError if the input is of an unsupported type.\n- Validation errors through the `validate(ds)` function if the resulting DataShape does not conform to expected standards.\n\nDependencies:\n- Utilizes `parser` to parse string representations of datashapes and `validate` from the validation module to ensure the integrity of the created DataShape. The `type_symbol_table.sym` is used in parsing.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - datashader/datashape/validation.py:validate\n    - datashader/datashape/parser.py:parse\n\n## FILE 4: datashader/glyphs/line.py\n\n- CLASS METHOD: LinesAxis1.validate\n  - CLASS SIGNATURE: class LinesAxis1(_PointLike, _AntiAliasedLine):\n  - SIGNATURE: def validate(self, in_dshape):\n  - DOCSTRING: \n```python\n\"\"\"\nValidate the integrity of the x and y coordinate columns for a LinesAxis1 instance.\n\nParameters\n----------\nin_dshape : object\n    An object representing the input data shape, which must include measures for both x and y coordinates.\n\nRaises\n------\nValueError\n    If any of the following conditions are met:\n        - Any x column is not of a real number type.\n        - Any y column is not of a real number type.\n        - The x columns do not have the same data type.\n        - The y columns do not have the same data type.\n        - The lengths of x and y coordinate lists do not match.\n\nThe method interacts with the attributes `self.x` and `self.y`, which are expected to be lists of column names. The `isreal` function, imported from `datashader.utils`, is used to verify that the columns contain real numbers. The measures for each column are retrieved from `in_dshape.measure`, ensuring that the inputs conform to expected data types and shapes for processing graphical lines.\n\"\"\"\n```\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "datashader/glyphs/points.py": "from __future__ import annotations\nfrom packaging.version import Version\nimport numpy as np\nfrom toolz import memoize\nfrom datashader.glyphs.glyph import Glyph\nfrom datashader.utils import isreal, ngjit\nfrom numba import cuda\ntry:\n    import cudf\n    from ..transfer_functions._cuda_utils import cuda_args\nexcept Exception:\n    cudf = None\n    cuda_args = None\ntry:\n    from geopandas.array import GeometryDtype as gpd_GeometryDtype\nexcept ImportError:\n    gpd_GeometryDtype = type(None)\ntry:\n    import spatialpandas\nexcept Exception:\n    spatialpandas = None\n\ndef values(s):\n    if isinstance(s, cudf.Series):\n        if Version(cudf.__version__) >= Version('22.02'):\n            return s.to_cupy(na_value=np.nan)\n        else:\n            return s.to_gpu_array(fillna=np.nan)\n    else:\n        return s.values\n\nclass _GeometryLike(Glyph):\n\n    def __init__(self, geometry):\n        self.geometry = geometry\n        self._cached_bounds = None\n\n    @property\n    def ndims(self):\n        return 1\n\n    @property\n    def inputs(self):\n        return (self.geometry,)\n\n    @property\n    def geom_dtypes(self):\n        if spatialpandas:\n            from spatialpandas.geometry import GeometryDtype\n            return (GeometryDtype,)\n        else:\n            return ()\n\n    def validate(self, in_dshape):\n        if not isinstance(in_dshape[str(self.geometry)], self.geom_dtypes):\n            raise ValueError('{col} must be an array with one of the following types: {typs}'.format(col=self.geometry, typs=', '.join((typ.__name__ for typ in self.geom_dtypes))))\n\n    @property\n    def x_label(self):\n        return 'x'\n\n    @property\n    def y_label(self):\n        return 'y'\n\n    def required_columns(self):\n        return [self.geometry]\n\n    def compute_x_bounds(self, df):\n        col = df[self.geometry]\n        if isinstance(col.dtype, gpd_GeometryDtype):\n            if self._cached_bounds is None:\n                self._cached_bounds = col.total_bounds\n            bounds = self._cached_bounds[::2]\n        else:\n            bounds = col.array.total_bounds_x\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, df):\n        col = df[self.geometry]\n        if isinstance(col.dtype, gpd_GeometryDtype):\n            if self._cached_bounds is None:\n                self._cached_bounds = col.total_bounds\n            bounds = self._cached_bounds[1::2]\n        else:\n            bounds = col.array.total_bounds_y\n        return self.maybe_expand_bounds(bounds)\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        total_bounds = ddf[self.geometry].total_bounds\n        x_extents = (total_bounds[0], total_bounds[2])\n        y_extents = (total_bounds[1], total_bounds[3])\n        return (self.maybe_expand_bounds(x_extents), self.maybe_expand_bounds(y_extents))\n\nclass _PointLike(Glyph):\n    \"\"\"Shared methods between Point and Line\"\"\"\n\n    @property\n    def ndims(self):\n        return 1\n\n    @property\n    def inputs(self):\n        return (self.x, self.y)\n\n    @property\n    def x_label(self):\n        return self.x\n\n    @property\n    def y_label(self):\n        return self.y\n\n    def required_columns(self):\n        return [self.x, self.y]\n\n    def compute_x_bounds(self, df):\n        bounds = self._compute_bounds(df[self.x])\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, df):\n        bounds = self._compute_bounds(df[self.y])\n        return self.maybe_expand_bounds(bounds)\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        r = ddf.map_partitions(lambda df: np.array([[np.nanmin(df[self.x].values).item(), np.nanmax(df[self.x].values).item(), np.nanmin(df[self.y].values).item(), np.nanmax(df[self.y].values).item()]])).compute()\n        x_extents = (np.nanmin(r[:, 0]), np.nanmax(r[:, 1]))\n        y_extents = (np.nanmin(r[:, 2]), np.nanmax(r[:, 3]))\n        return (self.maybe_expand_bounds(x_extents), self.maybe_expand_bounds(y_extents))\n\nclass Point(_PointLike):\n    \"\"\"A point, with center at ``x`` and ``y``.\n\n    Points map each record to a single bin.\n    Points falling exactly on the upper bounds are treated as a special case,\n    mapping into the previous bin rather than being cropped off.\n\n    Parameters\n    ----------\n    x, y : str\n        Column names for the x and y coordinates of each point.\n    \"\"\"\n\n    @memoize\n    def _build_extend(self, x_mapper, y_mapper, info, append, _antialias_stage_2, _antialias_stage_2_funcs):\n        x_name = self.x\n        y_name = self.y\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def _perform_extend_points(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols):\n            x = xs[i]\n            y = ys[i]\n            if xmin <= x <= xmax and ymin <= y <= ymax:\n                xx = int(x_mapper(x) * sx + tx)\n                yy = int(y_mapper(y) * sy + ty)\n                xi, yi = (xxmax - 1 if xx >= xxmax else xx, yymax - 1 if yy >= yymax else yy)\n                append(i, xi, yi, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols):\n            for i in range(xs.shape[0]):\n                _perform_extend_points(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols)\n\n        @cuda.jit\n        @self.expand_aggs_and_cols(append)\n        def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols):\n            i = cuda.grid(1)\n            if i < xs.shape[0]:\n                _perform_extend_points(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols)\n\n        def extend(aggs, df, vt, bounds):\n            yymax, xxmax = aggs[0].shape[:2]\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = values(df[x_name])\n                ys = values(df[y_name])\n                do_extend = extend_cuda[cuda_args(xs.shape[0])]\n            else:\n                xs = df[x_name].values\n                ys = df[y_name].values\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, xxmax, yymax, *aggs_and_cols)\n        return extend\n\nclass MultiPointGeoPandas(_GeometryLike):\n\n    @property\n    def geom_dtypes(self):\n        from geopandas.array import GeometryDtype\n        return (GeometryDtype,)\n\n    @memoize\n    def _build_extend(self, x_mapper, y_mapper, info, append, _antialias_stage_2, _antialias_stage_2_funcs):\n        import shapely\n        geometry_name = self.geometry\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def _perform_extend_points(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols):\n            x = values[j]\n            y = values[j + 1]\n            if xmin <= x <= xmax and ymin <= y <= ymax:\n                xx = int(x_mapper(x) * sx + tx)\n                yy = int(y_mapper(y) * sy + ty)\n                xi, yi = (xx - 1 if x == xmax else xx, yy - 1 if y == ymax else yy)\n                append(i, xi, yi, *aggs_and_cols)\n\n        def extend(aggs, df, vt, bounds):\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            geometry = df[geometry_name].array\n            ragged = shapely.to_ragged_array(geometry)\n            geometry_type = ragged[0]\n            if geometry_type not in (shapely.GeometryType.MULTIPOINT, shapely.GeometryType.POINT):\n                raise ValueError(f'Canvas.points supports GeoPandas geometry types of POINT and MULTIPOINT, not {repr(geometry_type)}')\n            coords = ragged[1].ravel()\n            if geometry_type == shapely.GeometryType.POINT:\n                extend_point_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, *aggs_and_cols)\n            else:\n                offsets = ragged[2][0]\n                extend_multipoint_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, offsets, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_multipoint_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, offsets, *aggs_and_cols):\n            for i in range(len(offsets) - 1):\n                start = offsets[i]\n                stop = offsets[i + 1]\n                for j in range(start, stop):\n                    _perform_extend_points(i, 2 * j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_point_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols):\n            n = len(values) // 2\n            for i in range(n):\n                _perform_extend_points(i, 2 * i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols)\n        return extend\n\nclass MultiPointGeometry(_GeometryLike):\n\n    @property\n    def geom_dtypes(self):\n        from spatialpandas.geometry import PointDtype, MultiPointDtype\n        return (PointDtype, MultiPointDtype)\n\n    @memoize\n    def _build_extend(self, x_mapper, y_mapper, info, append, _antialias_stage_2, _antialias_stage_2_funcs):\n        geometry_name = self.geometry\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def _perform_extend_points(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols):\n            x = values[j]\n            y = values[j + 1]\n            if xmin <= x <= xmax and ymin <= y <= ymax:\n                xx = int(x_mapper(x) * sx + tx)\n                yy = int(y_mapper(y) * sy + ty)\n                xi, yi = (xx - 1 if x == xmax else xx, yy - 1 if y == ymax else yy)\n                append(i, xi, yi, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_point_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, eligible_inds, *aggs_and_cols):\n            for i in eligible_inds:\n                if missing[i] is True:\n                    continue\n                _perform_extend_points(i, 2 * i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols)\n\n        @ngjit\n        @self.expand_aggs_and_cols(append)\n        def extend_multipoint_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, offsets, eligible_inds, *aggs_and_cols):\n            for i in eligible_inds:\n                if missing[i] is True:\n                    continue\n                start = offsets[i]\n                stop = offsets[i + 1]\n                for j in range(start, stop, 2):\n                    _perform_extend_points(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, *aggs_and_cols)\n\n        def extend(aggs, df, vt, bounds):\n            from spatialpandas.geometry import PointArray\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            geometry = df[geometry_name].array\n            if geometry._sindex is not None:\n                eligible_inds = geometry.sindex.intersects((xmin, ymin, xmax, ymax))\n            else:\n                eligible_inds = np.arange(0, len(geometry), dtype='uint32')\n            missing = geometry.isna()\n            if isinstance(geometry, PointArray):\n                values = geometry.flat_values\n                extend_point_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, eligible_inds, *aggs_and_cols)\n            else:\n                values = geometry.buffer_values\n                offsets = geometry.buffer_offsets[0]\n                extend_multipoint_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, offsets, eligible_inds, *aggs_and_cols)\n        return extend",
    "datashader/glyphs/glyph.py": "from __future__ import annotations\nfrom packaging.version import Version\nimport inspect\nimport warnings\nimport os\nfrom math import isnan\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom datashader.utils import Expr, ngjit\nfrom datashader.macros import expand_varargs\ntry:\n    import cudf\n    import cupy as cp\nexcept Exception:\n    cudf = None\n    cp = None\n\nclass Glyph(Expr):\n    \"\"\"Base class for glyphs.\"\"\"\n    antialiased = False\n\n    @property\n    def ndims(self):\n        \"\"\"\n        The number of dimensions required in the data structure this Glyph is\n        constructed from. Or None if input data structure is irregular\n\n        For example\n         * ndims is 1 if glyph is constructed from a DataFrame\n         * ndims is 2 if glyph is constructed from a 2D xarray DataArray\n         * ndims is None if glyph is constructed from multiple DataFrames of\n           different lengths\n        \"\"\"\n        raise NotImplementedError()\n\n    @staticmethod\n    def maybe_expand_bounds(bounds):\n        minval, maxval = bounds\n        if not (np.isfinite(minval) and np.isfinite(maxval)):\n            minval, maxval = (-1.0, 1.0)\n        elif minval == maxval:\n            minval, maxval = (minval - 1, minval + 1)\n        return (minval, maxval)\n\n    @staticmethod\n    @ngjit\n    def _compute_bounds_numba(arr):\n        minval = np.inf\n        maxval = -np.inf\n        for x in arr:\n            if not isnan(x):\n                if x < minval:\n                    minval = x\n                if x > maxval:\n                    maxval = x\n        return (minval, maxval)\n\n    @staticmethod\n    @ngjit\n    def _compute_bounds_2d(vals):\n        minval = np.inf\n        maxval = -np.inf\n        for i in range(vals.shape[0]):\n            for j in range(vals.shape[1]):\n                v = vals[i][j]\n                if not np.isnan(v):\n                    if v < minval:\n                        minval = v\n                    if v > maxval:\n                        maxval = v\n        return (minval, maxval)\n\n    @staticmethod\n    def to_cupy_array(df, columns):\n        if isinstance(columns, tuple):\n            columns = list(columns)\n        if isinstance(columns, list) and len(columns) != len(set(columns)):\n            return cp.stack([cp.array(df[c]) for c in columns], axis=1)\n        if Version(cudf.__version__) >= Version('22.02'):\n            return df[columns].to_cupy()\n        else:\n            if not isinstance(columns, list):\n                return df[columns].to_gpu_array()\n            return df[columns].as_gpu_matrix()\n\n    def expand_aggs_and_cols(self, append):\n        \"\"\"\n        Create a decorator that can be used on functions that accept\n        *aggs_and_cols as a variable length argument. The decorator will\n        replace *aggs_and_cols with a fixed number of arguments.\n\n        The appropriate fixed number of arguments is calculated from the input\n        append function.\n\n        Rationale: When we know the fixed length of a variable length\n        argument, replacing it with fixed arguments can help numba better\n        optimize the the function.\n\n        If this ever causes problems in the future, this decorator can be\n        safely removed without changing the functionality of the decorated\n        function.\n\n        Parameters\n        ----------\n        append: function\n            The append function for the current aggregator\n\n        Returns\n        -------\n        function\n            Decorator function\n        \"\"\"\n        return self._expand_aggs_and_cols(append, self.ndims, self.antialiased)\n\n    @staticmethod\n    def _expand_aggs_and_cols(append, ndims, antialiased):\n        if os.environ.get('NUMBA_DISABLE_JIT', None):\n            return lambda fn: fn\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore')\n            try:\n                append_args = inspect.getfullargspec(append.py_func).args\n            except (TypeError, AttributeError):\n                append_args = inspect.getfullargspec(append).args\n        append_arglen = len(append_args)\n        xy_arglen = 2\n        dim_arglen = ndims or 0\n        aggs_and_cols_len = append_arglen - xy_arglen - dim_arglen\n        if antialiased:\n            aggs_and_cols_len -= 2\n        return expand_varargs(aggs_and_cols_len)",
    "datashader/datashape/util/__init__.py": "from itertools import chain\nimport operator\nfrom .. import parser\nfrom .. import type_symbol_table\nfrom ..validation import validate\nfrom .. import coretypes\n__all__ = ('dshape', 'dshapes', 'has_var_dim', 'has_ellipsis', 'cat_dshapes')\nsubclasses = operator.methodcaller('__subclasses__')\n\ndef dshapes(*args):\n    \"\"\"\n    Parse a bunch of datashapes all at once.\n\n    >>> a, b = dshapes('3 * int32', '2 * var * float64')\n    \"\"\"\n    return [dshape(arg) for arg in args]\n\ndef cat_dshapes(dslist):\n    \"\"\"\n    Concatenates a list of dshapes together along\n    the first axis. Raises an error if there is\n    a mismatch along another axis or the measures\n    are different.\n\n    Requires that the leading dimension be a known\n    size for all data shapes.\n    TODO: Relax this restriction to support\n          streaming dimensions.\n\n    >>> cat_dshapes(dshapes('10 * int32', '5 * int32'))\n    dshape(\"15 * int32\")\n    \"\"\"\n    if len(dslist) == 0:\n        raise ValueError('Cannot concatenate an empty list of dshapes')\n    elif len(dslist) == 1:\n        return dslist[0]\n    outer_dim_size = operator.index(dslist[0][0])\n    inner_ds = dslist[0][1:]\n    for ds in dslist[1:]:\n        outer_dim_size += operator.index(ds[0])\n        if ds[1:] != inner_ds:\n            raise ValueError('The datashapes to concatenate much all match after the first dimension (%s vs %s)' % (inner_ds, ds[1:]))\n    return coretypes.DataShape(*[coretypes.Fixed(outer_dim_size)] + list(inner_ds))\n\ndef collect(pred, expr):\n    \"\"\" Collect terms in expression that match predicate\n\n    >>> from datashader.datashape import Unit, dshape\n    >>> predicate = lambda term: isinstance(term, Unit)\n    >>> dshape = dshape('var * {value: int64, loc: 2 * int32}')\n    >>> sorted(set(collect(predicate, dshape)), key=str)\n    [Fixed(val=2), ctype(\"int32\"), ctype(\"int64\"), Var()]\n    >>> from datashader.datashape import var, int64\n    >>> sorted(set(collect(predicate, [var, int64])), key=str)\n    [ctype(\"int64\"), Var()]\n    \"\"\"\n    if pred(expr):\n        return [expr]\n    if isinstance(expr, coretypes.Record):\n        return chain.from_iterable((collect(pred, typ) for typ in expr.types))\n    if isinstance(expr, coretypes.Mono):\n        return chain.from_iterable((collect(pred, typ) for typ in expr.parameters))\n    if isinstance(expr, (list, tuple)):\n        return chain.from_iterable((collect(pred, item) for item in expr))\n\ndef has_var_dim(ds):\n    \"\"\"Returns True if datashape has a variable dimension\n\n    Note currently treats variable length string as scalars.\n\n    >>> has_var_dim(dshape('2 * int32'))\n    False\n    >>> has_var_dim(dshape('var * 2 * int32'))\n    True\n    \"\"\"\n    return has((coretypes.Ellipsis, coretypes.Var), ds)\n\ndef has(typ, ds):\n    if isinstance(ds, typ):\n        return True\n    if isinstance(ds, coretypes.Record):\n        return any((has(typ, t) for t in ds.types))\n    if isinstance(ds, coretypes.Mono):\n        return any((has(typ, p) for p in ds.parameters))\n    if isinstance(ds, (list, tuple)):\n        return any((has(typ, item) for item in ds))\n    return False\n\ndef has_ellipsis(ds):\n    \"\"\"Returns True if the datashape has an ellipsis\n\n    >>> has_ellipsis(dshape('2 * int'))\n    False\n    >>> has_ellipsis(dshape('... * int'))\n    True\n    \"\"\"\n    return has(coretypes.Ellipsis, ds)",
    "datashader/glyphs/line.py": "from __future__ import annotations\nimport math\nimport numpy as np\nfrom toolz import memoize\nfrom datashader.antialias import two_stage_agg\nfrom datashader.glyphs.points import _PointLike, _GeometryLike\nfrom datashader.utils import isnull, isreal, ngjit\nfrom numba import cuda\nimport numba.types as nb_types\ntry:\n    import cudf\n    import cupy as cp\n    from ..transfer_functions._cuda_utils import cuda_args\nexcept ImportError:\n    cudf = None\n    cp = None\n    cuda_args = None\ntry:\n    import spatialpandas\nexcept Exception:\n    spatialpandas = None\n\nclass _AntiAliasedLine:\n    \"\"\" Methods common to all lines. \"\"\"\n    _line_width = 0\n\n    def set_line_width(self, line_width):\n        self._line_width = line_width\n        if hasattr(self, 'antialiased'):\n            self.antialiased = line_width > 0\n\n    def _build_extend(self, x_mapper, y_mapper, info, append, antialias_stage_2, antialias_stage_2_funcs):\n        return self._internal_build_extend(x_mapper, y_mapper, info, append, self._line_width, antialias_stage_2, antialias_stage_2_funcs)\n\ndef _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols):\n    antialias = line_width > 0\n    map_onto_pixel = _build_map_onto_pixel_for_line(x_mapper, y_mapper, antialias)\n    overwrite, use_2_stage_agg = two_stage_agg(antialias_stage_2)\n    if not use_2_stage_agg:\n        antialias_stage_2_funcs = None\n    draw_segment = _build_draw_segment(append, map_onto_pixel, expand_aggs_and_cols, line_width, overwrite)\n    return (draw_segment, antialias_stage_2_funcs)\n\nclass LineAxis0(_PointLike, _AntiAliasedLine):\n    \"\"\"A line, with vertices defined by ``x`` and ``y``.\n\n    Parameters\n    ----------\n    x, y : str\n        Column names for the x and y coordinates of each vertex.\n    \"\"\"\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        extend_cpu, extend_cuda = _build_extend_line_axis0(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        x_name = self.x\n        y_name = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_name)\n                ys = self.to_cupy_array(df, y_name)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, x_name].to_numpy()\n                ys = df.loc[:, y_name].to_numpy()\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LineAxis0Multi(_PointLike, _AntiAliasedLine):\n    \"\"\"\n    \"\"\"\n\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(xcol)]) for xcol in self.x]):\n            raise ValueError('x columns must be real')\n        elif not all([isreal(in_dshape.measure[str(ycol)]) for ycol in self.y]):\n            raise ValueError('y columns must be real')\n        if len(self.x) != len(self.y):\n            raise ValueError(f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    @property\n    def x_label(self):\n        return 'x'\n\n    @property\n    def y_label(self):\n        return 'y'\n\n    def required_columns(self):\n        return self.x + self.y\n\n    def compute_x_bounds(self, df):\n        bounds_list = [self._compute_bounds(df[x]) for x in self.x]\n        mins, maxes = zip(*bounds_list)\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    def compute_y_bounds(self, df):\n        bounds_list = [self._compute_bounds(df[y]) for y in self.y]\n        mins, maxes = zip(*bounds_list)\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        r = ddf.map_partitions(lambda df: np.array([[np.nanmin([np.nanmin(df[c].values).item() for c in self.x]), np.nanmax([np.nanmax(df[c].values).item() for c in self.x]), np.nanmin([np.nanmin(df[c].values).item() for c in self.y]), np.nanmax([np.nanmax(df[c].values).item() for c in self.y])]])).compute()\n        x_extents = (np.nanmin(r[:, 0]), np.nanmax(r[:, 1]))\n        y_extents = (np.nanmin(r[:, 2]), np.nanmax(r[:, 3]))\n        return (self.maybe_expand_bounds(x_extents), self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        extend_cpu, extend_cuda = _build_extend_line_axis0_multi(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        x_names = self.x\n        y_names = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_names)\n                ys = self.to_cupy_array(df, y_names)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, list(x_names)].to_numpy()\n                ys = df.loc[:, list(y_names)].to_numpy()\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LinesAxis1(_PointLike, _AntiAliasedLine):\n    \"\"\"A collection of lines (on line per row) with vertices defined\n    by the lists of columns in ``x`` and ``y``\n\n    Parameters\n    ----------\n    x, y : list\n        Lists of column names for the x and y coordinates\n    \"\"\"\n\n    def required_columns(self):\n        return self.x + self.y\n\n    @property\n    def x_label(self):\n        return 'x'\n\n    @property\n    def y_label(self):\n        return 'y'\n\n    def compute_x_bounds(self, df):\n        xs = tuple((df[xlabel] for xlabel in self.x))\n        bounds_list = [self._compute_bounds(xcol) for xcol in xs]\n        mins, maxes = zip(*bounds_list)\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    def compute_y_bounds(self, df):\n        ys = tuple((df[ylabel] for ylabel in self.y))\n        bounds_list = [self._compute_bounds(ycol) for ycol in ys]\n        mins, maxes = zip(*bounds_list)\n        return self.maybe_expand_bounds((min(mins), max(maxes)))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        r = ddf.map_partitions(lambda df: np.array([[np.nanmin([np.nanmin(df[c].values).item() for c in self.x]), np.nanmax([np.nanmax(df[c].values).item() for c in self.x]), np.nanmin([np.nanmin(df[c].values).item() for c in self.y]), np.nanmax([np.nanmax(df[c].values).item() for c in self.y])]])).compute()\n        x_extents = (np.nanmin(r[:, 0]), np.nanmax(r[:, 1]))\n        y_extents = (np.nanmin(r[:, 2]), np.nanmax(r[:, 3]))\n        return (self.maybe_expand_bounds(x_extents), self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        extend_cpu, extend_cuda = _build_extend_line_axis1_none_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        x_names = self.x\n        y_names = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_names)\n                ys = self.to_cupy_array(df, y_names)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, list(x_names)].to_numpy()\n                ys = df.loc[:, list(y_names)].to_numpy()\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LinesAxis1XConstant(LinesAxis1):\n    \"\"\"\n    \"\"\"\n\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(ycol)]) for ycol in self.y]):\n            raise ValueError('y columns must be real')\n        unique_y_measures = set((in_dshape.measure[str(ycol)] for ycol in self.y))\n        if len(unique_y_measures) > 1:\n            raise ValueError('y columns must have the same data type')\n        if len(self.x) != len(self.y):\n            raise ValueError(f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    def required_columns(self):\n        return self.y\n\n    def compute_x_bounds(self, *args):\n        x_min = np.nanmin(self.x)\n        x_max = np.nanmax(self.x)\n        return self.maybe_expand_bounds((x_min, x_max))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        r = ddf.map_partitions(lambda df: np.array([[np.nanmin([np.nanmin(df[c].values).item() for c in self.y]), np.nanmax([np.nanmax(df[c].values).item() for c in self.y])]])).compute()\n        y_extents = (np.nanmin(r[:, 0]), np.nanmax(r[:, 1]))\n        return (self.compute_x_bounds(), self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        extend_cpu, extend_cuda = _build_extend_line_axis1_x_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        x_values = self.x\n        y_names = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = cp.asarray(x_values)\n                ys = self.to_cupy_array(df, y_names)\n                do_extend = extend_cuda[cuda_args(ys.shape)]\n            else:\n                xs = x_values\n                ys = df.loc[:, list(y_names)].to_numpy()\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LinesAxis1YConstant(LinesAxis1):\n    \"\"\"\n    \"\"\"\n\n    def validate(self, in_dshape):\n        if not all([isreal(in_dshape.measure[str(xcol)]) for xcol in self.x]):\n            raise ValueError('x columns must be real')\n        unique_x_measures = set((in_dshape.measure[str(xcol)] for xcol in self.x))\n        if len(unique_x_measures) > 1:\n            raise ValueError('x columns must have the same data type')\n        if len(self.x) != len(self.y):\n            raise ValueError(f'x and y coordinate lengths do not match: {len(self.x)} != {len(self.y)}')\n\n    def required_columns(self):\n        return self.x\n\n    def compute_y_bounds(self, *args):\n        y_min = np.nanmin(self.y)\n        y_max = np.nanmax(self.y)\n        return self.maybe_expand_bounds((y_min, y_max))\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        r = ddf.map_partitions(lambda df: np.array([[np.nanmin([np.nanmin(df[c].values).item() for c in self.x]), np.nanmax([np.nanmax(df[c].values).item() for c in self.x])]])).compute()\n        x_extents = (np.nanmin(r[:, 0]), np.nanmax(r[:, 1]))\n        return (self.maybe_expand_bounds(x_extents), self.compute_y_bounds())\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        extend_cpu, extend_cuda = _build_extend_line_axis1_y_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        x_names = self.x\n        y_values = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = self.to_cupy_array(df, x_names)\n                ys = cp.asarray(y_values)\n                do_extend = extend_cuda[cuda_args(xs.shape)]\n            else:\n                xs = df.loc[:, list(x_names)].to_numpy()\n                ys = y_values\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LinesAxis1Ragged(_PointLike, _AntiAliasedLine):\n\n    def validate(self, in_dshape):\n        try:\n            from datashader.datatypes import RaggedDtype\n        except ImportError:\n            RaggedDtype = type(None)\n        if not isinstance(in_dshape[str(self.x)], RaggedDtype):\n            raise ValueError('x must be a RaggedArray')\n        elif not isinstance(in_dshape[str(self.y)], RaggedDtype):\n            raise ValueError('y must be a RaggedArray')\n\n    def required_columns(self):\n        return (self.x,) + (self.y,)\n\n    def compute_x_bounds(self, df):\n        bounds = self._compute_bounds(df[self.x].array.flat_array)\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, df):\n        bounds = self._compute_bounds(df[self.y].array.flat_array)\n        return self.maybe_expand_bounds(bounds)\n\n    @memoize\n    def compute_bounds_dask(self, ddf):\n        r = ddf.map_partitions(lambda df: np.array([[np.nanmin(df[self.x].array.flat_array).item(), np.nanmax(df[self.x].array.flat_array).item(), np.nanmin(df[self.y].array.flat_array).item(), np.nanmax(df[self.y].array.flat_array).item()]])).compute()\n        x_extents = (np.nanmin(r[:, 0]), np.nanmax(r[:, 1]))\n        y_extents = (np.nanmin(r[:, 2]), np.nanmax(r[:, 3]))\n        return (self.maybe_expand_bounds(x_extents), self.maybe_expand_bounds(y_extents))\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        extend_cpu = _build_extend_line_axis1_ragged(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        x_name = self.x\n        y_name = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            xs = df[x_name].array\n            ys = df[y_name].array\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LineAxis1Geometry(_GeometryLike, _AntiAliasedLine):\n\n    @property\n    def geom_dtypes(self):\n        from spatialpandas.geometry import LineDtype, MultiLineDtype, RingDtype, PolygonDtype, MultiPolygonDtype\n        return (LineDtype, MultiLineDtype, RingDtype, PolygonDtype, MultiPolygonDtype)\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        from spatialpandas.geometry import PolygonArray, MultiPolygonArray, RingArray\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        perform_extend_cpu = _build_extend_line_axis1_geometry(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        geometry_name = self.geometry\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            geom_array = df[geometry_name].array\n            if isinstance(geom_array, (PolygonArray, MultiPolygonArray)):\n                geom_array = geom_array.boundary\n                closed_rings = True\n            elif isinstance(geom_array, RingArray):\n                closed_rings = True\n            else:\n                closed_rings = False\n            perform_extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, geom_array, closed_rings, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LineAxis1GeoPandas(_GeometryLike, _AntiAliasedLine):\n\n    @property\n    def geom_dtypes(self):\n        from geopandas.array import GeometryDtype\n        return (GeometryDtype,)\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        perform_extend_cpu = _build_extend_line_axis1_geopandas(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs)\n        geometry_name = self.geometry\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            geom_array = df[geometry_name].array\n            perform_extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, geom_array, antialias_stage_2, *aggs_and_cols)\n        return extend\n\nclass LinesXarrayCommonX(LinesAxis1):\n\n    def __init__(self, x, y, x_dim_index: int):\n        super().__init__(x, y)\n        self.x_dim_index = x_dim_index\n\n    def __hash__(self):\n        return hash((type(self), self.x_dim_index))\n\n    def compute_x_bounds(self, dataset):\n        bounds = self._compute_bounds(dataset[self.x])\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_y_bounds(self, dataset):\n        bounds = self._compute_bounds(dataset[self.y])\n        return self.maybe_expand_bounds(bounds)\n\n    def compute_bounds_dask(self, xr_ds):\n        return (self.compute_x_bounds(xr_ds), self.compute_y_bounds(xr_ds))\n\n    def validate(self, in_dshape):\n        if not isreal(in_dshape.measure[str(self.x)]):\n            raise ValueError('x column must be real')\n        if not isreal(in_dshape.measure[str(self.y)]):\n            raise ValueError('y column must be real')\n\n    @memoize\n    def _internal_build_extend(self, x_mapper, y_mapper, info, append, line_width, antialias_stage_2, antialias_stage_2_funcs):\n        expand_aggs_and_cols = self.expand_aggs_and_cols(append)\n        draw_segment, antialias_stage_2_funcs = _line_internal_build_extend(x_mapper, y_mapper, append, line_width, antialias_stage_2, antialias_stage_2_funcs, expand_aggs_and_cols)\n        swap_dims = self.x_dim_index == 0\n        extend_cpu, extend_cuda = _build_extend_line_axis1_x_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs, swap_dims)\n        x_name = self.x\n        y_name = self.y\n\n        def extend(aggs, df, vt, bounds, plot_start=True):\n            sx, tx, sy, ty = vt\n            xmin, xmax, ymin, ymax = bounds\n            aggs_and_cols = aggs + info(df, aggs[0].shape[:2])\n            if cudf and isinstance(df, cudf.DataFrame):\n                xs = cp.asarray(df[x_name])\n                ys = cp.asarray(df[y_name])\n                do_extend = extend_cuda[cuda_args(ys.shape)]\n            elif cp and isinstance(df[y_name].data, cp.ndarray):\n                xs = cp.asarray(df[x_name])\n                ys = df[y_name].data\n                shape = ys.shape[::-1] if swap_dims else ys.shape\n                do_extend = extend_cuda[cuda_args(shape)]\n            else:\n                xs = df[x_name].to_numpy()\n                ys = df[y_name].to_numpy()\n                do_extend = extend_cpu\n            do_extend(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols)\n        return extend\n\ndef _build_map_onto_pixel_for_line(x_mapper, y_mapper, want_antialias=False):\n\n    @ngjit\n    def map_onto_pixel_snap(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x, y):\n        \"\"\"Map points onto pixel grid.\n\n        Points falling on upper bound are mapped into previous bin.\n\n        If the line has been clipped, x and y will have been\n        computed to lie on the bounds; we compare point and bounds\n        in integer space to avoid fp error. In contrast, with\n        auto-ranging, a point on the bounds will be the same\n        floating point number as the bound, so comparison in fp\n        representation of continuous space or in integer space\n        doesn't change anything.\n        \"\"\"\n        xx = int(x_mapper(x) * sx + tx)\n        yy = int(y_mapper(y) * sy + ty)\n        xxmax = round(x_mapper(xmax) * sx + tx)\n        yymax = round(y_mapper(ymax) * sy + ty)\n        return (xx - 1 if xx == xxmax else xx, yy - 1 if yy == yymax else yy)\n\n    @ngjit\n    def map_onto_pixel_no_snap(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x, y):\n        xx = x_mapper(x) * sx + tx - 0.5\n        yy = y_mapper(y) * sy + ty - 0.5\n        return (xx, yy)\n    if want_antialias:\n        return map_onto_pixel_no_snap\n    else:\n        return map_onto_pixel_snap\n\n@ngjit\ndef _liang_barsky(xmin, xmax, ymin, ymax, x0, x1, y0, y1, skip):\n    \"\"\" An implementation of the Liang-Barsky line clipping algorithm.\n\n    https://en.wikipedia.org/wiki/Liang%E2%80%93Barsky_algorithm\n\n    \"\"\"\n    if x0 < xmin and x1 < xmin:\n        skip = True\n    elif x0 > xmax and x1 > xmax:\n        skip = True\n    elif y0 < ymin and y1 < ymin:\n        skip = True\n    elif y0 > ymax and y1 > ymax:\n        skip = True\n    t0, t1 = (0, 1)\n    dx1 = x1 - x0\n    t0, t1, accept = _clipt(-dx1, x0 - xmin, t0, t1)\n    if not accept:\n        skip = True\n    t0, t1, accept = _clipt(dx1, xmax - x0, t0, t1)\n    if not accept:\n        skip = True\n    dy1 = y1 - y0\n    t0, t1, accept = _clipt(-dy1, y0 - ymin, t0, t1)\n    if not accept:\n        skip = True\n    t0, t1, accept = _clipt(dy1, ymax - y0, t0, t1)\n    if not accept:\n        skip = True\n    if t1 < 1:\n        clipped_end = True\n        x1 = x0 + t1 * dx1\n        y1 = y0 + t1 * dy1\n    else:\n        clipped_end = False\n    if t0 > 0:\n        clipped_start = True\n        x0 = x0 + t0 * dx1\n        y0 = y0 + t0 * dy1\n    else:\n        clipped_start = False\n    return (x0, x1, y0, y1, skip, clipped_start, clipped_end)\n\n@ngjit\ndef _clipt(p, q, t0, t1):\n    accept = True\n    if p < 0 and q < 0:\n        r = q / p\n        if r > t1:\n            accept = False\n        elif r > t0:\n            t0 = r\n    elif p > 0 and q < p:\n        r = q / p\n        if r < t0:\n            accept = False\n        elif r < t1:\n            t1 = r\n    elif q < 0:\n        accept = False\n    return (t0, t1, accept)\n\n@ngjit\ndef _clamp(x, low, high):\n    return max(low, min(x, high))\n\n@ngjit\ndef _linearstep(edge0, edge1, x):\n    t = _clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0)\n    return t\n\n@ngjit\ndef _x_intercept(y, cx0, cy0, cx1, cy1):\n    if cy0 == cy1:\n        return cx1\n    frac = (y - cy0) / (cy1 - cy0)\n    return cx0 + frac * (cx1 - cx0)\n\ndef _build_full_antialias(expand_aggs_and_cols):\n    \"\"\"Specialize antialiased line drawing algorithm for a given append/axis combination\"\"\"\n\n    @ngjit\n    @expand_aggs_and_cols\n    def _full_antialias(line_width, overwrite, i, x0, x1, y0, y1, segment_start, segment_end, xm, ym, append, nx, ny, buffer, *aggs_and_cols):\n        \"\"\"Draw an antialiased line segment.\n\n        If overwrite=True can overwrite each pixel multiple times because\n        using max for the overwriting.  If False can only write each pixel\n        once per segment and its previous segment.\n        Argument xm, ym are only valid if overwrite and segment_start are False.\n        \"\"\"\n        if x0 == x1 and y0 == y1:\n            return\n        flip_xy = abs(x0 - x1) < abs(y0 - y1)\n        if flip_xy:\n            x0, y0 = (y0, x0)\n            x1, y1 = (y1, x1)\n            xm, ym = (ym, xm)\n        scale = 1.0\n        if line_width < 1.0:\n            scale *= line_width\n            line_width = 1.0\n        aa = 1.0\n        halfwidth = 0.5 * (line_width + aa)\n        flip_order = y1 < y0 or (y1 == y0 and x1 < x0)\n        alongx = float(x1 - x0)\n        alongy = float(y1 - y0)\n        length = math.sqrt(alongx ** 2 + alongy ** 2)\n        alongx /= length\n        alongy /= length\n        rightx = alongy\n        righty = -alongx\n        if flip_order:\n            buffer[0] = x1 - halfwidth * (rightx - alongx)\n            buffer[1] = x1 - halfwidth * (-rightx - alongx)\n            buffer[2] = x0 - halfwidth * (-rightx + alongx)\n            buffer[3] = x0 - halfwidth * (rightx + alongx)\n            buffer[4] = y1 - halfwidth * (righty - alongy)\n            buffer[5] = y1 - halfwidth * (-righty - alongy)\n            buffer[6] = y0 - halfwidth * (-righty + alongy)\n            buffer[7] = y0 - halfwidth * (righty + alongy)\n        else:\n            buffer[0] = x0 + halfwidth * (rightx - alongx)\n            buffer[1] = x0 + halfwidth * (-rightx - alongx)\n            buffer[2] = x1 + halfwidth * (-rightx + alongx)\n            buffer[3] = x1 + halfwidth * (rightx + alongx)\n            buffer[4] = y0 + halfwidth * (righty - alongy)\n            buffer[5] = y0 + halfwidth * (-righty - alongy)\n            buffer[6] = y1 + halfwidth * (-righty + alongy)\n            buffer[7] = y1 + halfwidth * (righty + alongy)\n        xmax = nx - 1\n        ymax = ny - 1\n        if flip_xy:\n            xmax, ymax = (ymax, xmax)\n        if flip_order:\n            lowindex = 0 if x0 > x1 else 1\n        else:\n            lowindex = 0 if x1 > x0 else 1\n        if not overwrite and (not segment_start):\n            prev_alongx = x0 - xm\n            prev_alongy = y0 - ym\n            prev_length = math.sqrt(prev_alongx ** 2 + prev_alongy ** 2)\n            if prev_length > 0.0:\n                prev_alongx /= prev_length\n                prev_alongy /= prev_length\n                prev_rightx = prev_alongy\n                prev_righty = -prev_alongx\n            else:\n                overwrite = True\n        ystart = _clamp(math.ceil(buffer[4 + lowindex]), 0, ymax)\n        yend = _clamp(math.floor(buffer[4 + (lowindex + 2) % 4]), 0, ymax)\n        ll = lowindex\n        lu = (ll + 1) % 4\n        rl = lowindex\n        ru = (rl + 3) % 4\n        for y in range(ystart, yend + 1):\n            if ll == lowindex and y > buffer[4 + lu]:\n                ll = lu\n                lu = (ll + 1) % 4\n            if rl == lowindex and y > buffer[4 + ru]:\n                rl = ru\n                ru = (rl + 3) % 4\n            xleft = _clamp(math.ceil(_x_intercept(y, buffer[ll], buffer[4 + ll], buffer[lu], buffer[4 + lu])), 0, xmax)\n            xright = _clamp(math.floor(_x_intercept(y, buffer[rl], buffer[4 + rl], buffer[ru], buffer[4 + ru])), 0, xmax)\n            for x in range(xleft, xright + 1):\n                along = (x - x0) * alongx + (y - y0) * alongy\n                prev_correction = False\n                if along < 0.0:\n                    if overwrite or segment_start or (x - x0) * prev_alongx + (y - y0) * prev_alongy > 0.0:\n                        distance = math.sqrt((x - x0) ** 2 + (y - y0) ** 2)\n                    else:\n                        continue\n                elif along > length:\n                    if overwrite or segment_end:\n                        distance = math.sqrt((x - x1) ** 2 + (y - y1) ** 2)\n                    else:\n                        continue\n                else:\n                    distance = abs((x - x0) * rightx + (y - y0) * righty)\n                    if not overwrite and (not segment_start) and (-prev_length <= (x - x0) * prev_alongx + (y - y0) * prev_alongy <= 0.0) and (abs((x - x0) * prev_rightx + (y - y0) * prev_righty) <= halfwidth):\n                        prev_correction = True\n                value = 1.0 - _linearstep(0.5 * (line_width - aa), halfwidth, distance)\n                value *= scale\n                prev_value = 0.0\n                if prev_correction:\n                    prev_distance = abs((x - x0) * prev_rightx + (y - y0) * prev_righty)\n                    prev_value = 1.0 - _linearstep(0.5 * (line_width - aa), halfwidth, prev_distance)\n                    prev_value *= scale\n                    if value <= prev_value:\n                        value = 0.0\n                if value > 0.0:\n                    xx, yy = (y, x) if flip_xy else (x, y)\n                    append(i, xx, yy, value, prev_value, *aggs_and_cols)\n    return _full_antialias\n\ndef _build_bresenham(expand_aggs_and_cols):\n    \"\"\"Specialize a bresenham kernel for a given append/axis combination\"\"\"\n\n    @ngjit\n    @expand_aggs_and_cols\n    def _bresenham(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, x0, x1, y0, y1, clipped, append, *aggs_and_cols):\n        \"\"\"Draw a line segment using Bresenham's algorithm\n        This method plots a line segment with integer coordinates onto a pixel\n        grid.\n        \"\"\"\n        dx = x1 - x0\n        ix = (dx > 0) - (dx < 0)\n        dx = abs(dx) * 2\n        dy = y1 - y0\n        iy = (dy > 0) - (dy < 0)\n        dy = abs(dy) * 2\n        if not clipped and (not dx | dy):\n            append(i, x0, y0, *aggs_and_cols)\n            return\n        if segment_start:\n            append(i, x0, y0, *aggs_and_cols)\n        if dx >= dy:\n            error = 2 * dy - dx\n            while x0 != x1:\n                if error >= 0 and (error or ix > 0):\n                    error -= 2 * dx\n                    y0 += iy\n                error += 2 * dy\n                x0 += ix\n                append(i, x0, y0, *aggs_and_cols)\n        else:\n            error = 2 * dx - dy\n            while y0 != y1:\n                if error >= 0 and (error or iy > 0):\n                    error -= 2 * dy\n                    x0 += ix\n                error += 2 * dx\n                y0 += iy\n                append(i, x0, y0, *aggs_and_cols)\n    return _bresenham\n\ndef _build_draw_segment(append, map_onto_pixel, expand_aggs_and_cols, line_width, overwrite):\n    \"\"\"Specialize a line plotting kernel for a given append/axis combination\"\"\"\n    if line_width > 0.0:\n        _bresenham = None\n        _full_antialias = _build_full_antialias(expand_aggs_and_cols)\n    else:\n        _bresenham = _build_bresenham(expand_aggs_and_cols)\n        _full_antialias = None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols):\n        skip = False\n        if isnull(x0) or isnull(y0) or isnull(x1) or isnull(y1):\n            skip = True\n        x0_1, x1_1, y0_1, y1_1, skip, clipped_start, clipped_end = _liang_barsky(xmin, xmax, ymin, ymax, x0, x1, y0, y1, skip)\n        if not skip:\n            clipped = clipped_start or clipped_end\n            segment_start = segment_start or clipped_start\n            x0_2, y0_2 = map_onto_pixel(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x0_1, y0_1)\n            x1_2, y1_2 = map_onto_pixel(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x1_1, y1_1)\n            if line_width > 0.0:\n                if segment_start:\n                    xm_2 = ym_2 = 0.0\n                else:\n                    xm_2, ym_2 = map_onto_pixel(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xm, ym)\n                nx = round((xmax - xmin) * sx)\n                ny = round((ymax - ymin) * sy)\n                _full_antialias(line_width, overwrite, i, x0_2, x1_2, y0_2, y1_2, segment_start, segment_end, xm_2, ym_2, append, nx, ny, buffer, *aggs_and_cols)\n            else:\n                _bresenham(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, x0_2, x1_2, y0_2, y1_2, clipped, append, *aggs_and_cols)\n    return draw_segment\n\ndef _build_extend_line_axis0(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[i]\n        y0 = ys[i]\n        x1 = xs[i + 1]\n        y1 = ys[i + 1]\n        segment_start = plot_start if i == 0 else isnull(xs[i - 1]) or isnull(ys[i - 1])\n        segment_end = i == len(xs) - 2 or isnull(xs[i + 2]) or isnull(ys[i + 2])\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i - 1]\n            ym = ys[i - 1]\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        \"\"\"Aggregate along a line formed by ``xs`` and ``ys``\"\"\"\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows = xs.shape[0]\n        for i in range(nrows - 1):\n            perform_extend_line(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i = cuda.grid(1)\n        if i < xs.shape[0] - 1:\n            perform_extend_line(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols)\n    return (extend_cpu, extend_cuda)\n\ndef _build_extend_line_axis0_multi(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[i, j]\n        y0 = ys[i, j]\n        x1 = xs[i + 1, j]\n        y1 = ys[i + 1, j]\n        segment_start = plot_start if i == 0 else isnull(xs[i - 1, j]) or isnull(ys[i - 1, j])\n        segment_end = i == len(xs) - 2 or isnull(xs[i + 2, j]) or isnull(ys[i + 2, j])\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i - 1, j]\n            ym = ys[i - 1, j]\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        \"\"\"Aggregate along a line formed by ``xs`` and ``ys``\"\"\"\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows, ncols = xs.shape\n        for j in range(ncols):\n            for i in range(nrows - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        \"\"\"Aggregate along a line formed by ``xs`` and ``ys``\"\"\"\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows, ncols = xs.shape\n        for j in range(ncols):\n            for i in range(nrows - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols)\n            if ncols == 1:\n                return\n            aa_stage_2_accumulate(aggs_and_accums, j == 0)\n            if j < ncols - 1:\n                aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, plot_start, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        if i < xs.shape[0] - 1 and j < xs.shape[1]:\n            perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, plot_start, xs, ys, buffer, *aggs_and_cols)\n    if use_2_stage_agg:\n        return (extend_cpu_antialias_2agg, extend_cuda)\n    else:\n        return (extend_cpu, extend_cuda)\n\ndef _build_extend_line_axis1_none_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[i, j]\n        y0 = ys[i, j]\n        x1 = xs[i, j + 1]\n        y1 = ys[i, j + 1]\n        segment_start = j == 0 or isnull(xs[i, j - 1]) or isnull(ys[i, j - 1])\n        segment_end = j == xs.shape[1] - 2 or isnull(xs[i, j + 2]) or isnull(ys[i, j + 2])\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i, j - 1]\n            ym = ys[i, j - 1]\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n            if xs.shape[0] == 1:\n                return\n            aa_stage_2_accumulate(aggs_and_accums, i == 0)\n            if i < xs.shape[0] - 1:\n                aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        if i < xs.shape[0] and j < xs.shape[1] - 1:\n            perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n    if use_2_stage_agg:\n        return (extend_cpu_antialias_2agg, extend_cuda)\n    else:\n        return (extend_cpu, extend_cuda)\n\ndef _build_extend_line_axis1_x_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs, swap_dims: bool=False):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[j]\n        x1 = xs[j + 1]\n        if swap_dims:\n            y0 = ys[j, i]\n            y1 = ys[j + 1, i]\n            segment_start = j == 0 or isnull(xs[j - 1]) or isnull(ys[j - 1, i])\n            segment_end = j == len(xs) - 2 or isnull(xs[j + 2]) or isnull(ys[j + 2, i])\n        else:\n            y0 = ys[i, j]\n            y1 = ys[i, j + 1]\n            segment_start = j == 0 or isnull(xs[j - 1]) or isnull(ys[i, j - 1])\n            segment_end = j == len(xs) - 2 or isnull(xs[j + 2]) or isnull(ys[i, j + 2])\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[j - 1]\n            ym = ys[j - 1, i] if swap_dims else ys[i, j - 1]\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols, nrows = ys.shape if swap_dims else ys.shape[::-1]\n        for i in range(nrows):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = ys.shape[1]\n        for i in range(ys.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n            if ys.shape[0] == 1:\n                return\n            aa_stage_2_accumulate(aggs_and_accums, i == 0)\n            if i < ys.shape[0] - 1:\n                aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        ncols, nrows = ys.shape if swap_dims else ys.shape[::-1]\n        if i < nrows and j < ncols - 1:\n            perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n    if use_2_stage_agg:\n        return (extend_cpu_antialias_2agg, extend_cuda)\n    else:\n        return (extend_cpu, extend_cuda)\n\ndef _build_extend_line_axis1_y_constant(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    @ngjit\n    @expand_aggs_and_cols\n    def perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols):\n        x0 = xs[i, j]\n        y0 = ys[j]\n        x1 = xs[i, j + 1]\n        y1 = ys[j + 1]\n        segment_start = j == 0 or isnull(xs[i, j - 1]) or isnull(ys[j - 1])\n        segment_end = j == len(ys) - 2 or isnull(xs[i, j + 2]) or isnull(ys[j + 2])\n        if segment_start or use_2_stage_agg:\n            xm = 0.0\n            ym = 0.0\n        else:\n            xm = xs[i, j - 1]\n            ym = ys[j - 1]\n        draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def cpu_antialias_2agg_impl(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        ncols = xs.shape[1]\n        for i in range(xs.shape[0]):\n            for j in range(ncols - 1):\n                perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n            if xs.shape[0] == 1:\n                return\n            aa_stage_2_accumulate(aggs_and_accums, i == 0)\n            if i < xs.shape[0] - 1:\n                aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n\n    @cuda.jit\n    @expand_aggs_and_cols\n    def extend_cuda(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = cuda.local.array(8, nb_types.float64) if antialias else None\n        i, j = cuda.grid(2)\n        if i < xs.shape[0] and j < xs.shape[1] - 1:\n            perform_extend_line(i, j, sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, buffer, *aggs_and_cols)\n    if use_2_stage_agg:\n        return (extend_cpu_antialias_2agg, extend_cuda)\n    else:\n        return (extend_cpu, extend_cuda)\n\ndef _build_extend_line_axis1_ragged(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        x_start_i = xs.start_indices\n        x_flat = xs.flat_array\n        y_start_i = ys.start_indices\n        y_flat = ys.flat_array\n        extend_cpu_numba(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x_start_i, x_flat, y_start_i, y_flat, antialias_stage_2, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x_start_i, x_flat, y_start_i, y_flat, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows = len(x_start_i)\n        x_flat_len = len(x_flat)\n        y_flat_len = len(y_flat)\n        for i in range(nrows):\n            x_start_index = x_start_i[i]\n            x_stop_index = x_start_i[i + 1] if i < nrows - 1 else x_flat_len\n            y_start_index = y_start_i[i]\n            y_stop_index = y_start_i[i + 1] if i < nrows - 1 else y_flat_len\n            segment_len = min(x_stop_index - x_start_index, y_stop_index - y_start_index)\n            for j in range(segment_len - 1):\n                x0 = x_flat[x_start_index + j]\n                y0 = y_flat[y_start_index + j]\n                x1 = x_flat[x_start_index + j + 1]\n                y1 = y_flat[y_start_index + j + 1]\n                segment_start = j == 0 or isnull(x_flat[x_start_index + j - 1]) or isnull(y_flat[y_start_index + j - 1])\n                segment_end = j == segment_len - 2 or isnull(x_flat[x_start_index + j + 2]) or isnull(y_flat[y_start_index + j + 2])\n                if segment_start or use_2_stage_agg:\n                    xm = 0.0\n                    ym = 0.0\n                else:\n                    xm = x_flat[x_start_index + j - 1]\n                    ym = y_flat[y_start_index + j - 1]\n                draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, xs, ys, antialias_stage_2, *aggs_and_cols):\n        x_start_i = xs.start_indices\n        x_flat = xs.flat_array\n        y_start_i = ys.start_indices\n        y_flat = ys.flat_array\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        extend_cpu_numba_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x_start_i, x_flat, y_start_i, y_flat, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, x_start_i, x_flat, y_start_i, y_flat, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        nrows = len(x_start_i)\n        x_flat_len = len(x_flat)\n        y_flat_len = len(y_flat)\n        for i in range(nrows):\n            x_start_index = x_start_i[i]\n            x_stop_index = x_start_i[i + 1] if i < nrows - 1 else x_flat_len\n            y_start_index = y_start_i[i]\n            y_stop_index = y_start_i[i + 1] if i < nrows - 1 else y_flat_len\n            segment_len = min(x_stop_index - x_start_index, y_stop_index - y_start_index)\n            for j in range(segment_len - 1):\n                x0 = x_flat[x_start_index + j]\n                y0 = y_flat[y_start_index + j]\n                x1 = x_flat[x_start_index + j + 1]\n                y1 = y_flat[y_start_index + j + 1]\n                segment_start = j == 0 or isnull(x_flat[x_start_index + j - 1]) or isnull(y_flat[y_start_index + j - 1])\n                segment_end = j == segment_len - 2 or isnull(x_flat[x_start_index + j + 2]) or isnull(y_flat[y_start_index + j + 2])\n                draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, 0.0, 0.0, buffer, *aggs_and_cols)\n            if nrows == 1:\n                return\n            aa_stage_2_accumulate(aggs_and_accums, i == 0)\n            if i < nrows - 1:\n                aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg\n    else:\n        return extend_cpu\n\ndef _build_extend_line_axis1_geometry(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, geometry, closed_rings, antialias_stage_2, *aggs_and_cols):\n        values = geometry.buffer_values\n        missing = geometry.isna()\n        offsets = geometry.buffer_offsets\n        if len(offsets) == 2:\n            offsets0, offsets1 = offsets\n        else:\n            offsets1 = offsets[0]\n            offsets0 = np.arange(len(offsets1))\n        if geometry._sindex is not None:\n            eligible_inds = geometry.sindex.intersects((xmin, ymin, xmax, ymax))\n        else:\n            eligible_inds = np.arange(0, len(geometry), dtype='uint32')\n        extend_cpu_numba(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, offsets0, offsets1, eligible_inds, closed_rings, antialias_stage_2, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, offsets0, offsets1, eligible_inds, closed_rings, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        for i in eligible_inds:\n            if missing[i]:\n                continue\n            start0 = offsets0[i]\n            stop0 = offsets0[i + 1]\n            for j in range(start0, stop0):\n                start1 = offsets1[j]\n                stop1 = offsets1[j + 1]\n                for k in range(start1, stop1 - 2, 2):\n                    x0 = values[k]\n                    if not np.isfinite(x0):\n                        continue\n                    y0 = values[k + 1]\n                    if not np.isfinite(y0):\n                        continue\n                    x1 = values[k + 2]\n                    if not np.isfinite(x1):\n                        continue\n                    y1 = values[k + 3]\n                    if not np.isfinite(y1):\n                        continue\n                    segment_start = k == start1 and (not closed_rings) or (k > start1 and (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    segment_end = not closed_rings and k == stop1 - 4 or (k < stop1 - 4 and (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    if segment_start or use_2_stage_agg:\n                        xm = 0.0\n                        ym = 0.0\n                    elif k == start1 and closed_rings:\n                        xm = values[stop1 - 4]\n                        ym = values[stop1 - 3]\n                    else:\n                        xm = values[k - 2]\n                        ym = values[k - 1]\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, geometry, closed_rings, antialias_stage_2, *aggs_and_cols):\n        values = geometry.buffer_values\n        missing = geometry.isna()\n        offsets = geometry.buffer_offsets\n        if len(offsets) == 2:\n            offsets0, offsets1 = offsets\n        else:\n            offsets1 = offsets[0]\n            offsets0 = np.arange(len(offsets1))\n        if geometry._sindex is not None:\n            eligible_inds = geometry.sindex.intersects((xmin, ymin, xmax, ymax))\n        else:\n            eligible_inds = np.arange(0, len(geometry), dtype='uint32')\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        extend_cpu_numba_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, offsets0, offsets1, eligible_inds, closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, missing, offsets0, offsets1, eligible_inds, closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        first_pass = True\n        for i in eligible_inds:\n            if missing[i]:\n                continue\n            start0 = offsets0[i]\n            stop0 = offsets0[i + 1]\n            for j in range(start0, stop0):\n                start1 = offsets1[j]\n                stop1 = offsets1[j + 1]\n                for k in range(start1, stop1 - 2, 2):\n                    x0 = values[k]\n                    if not np.isfinite(x0):\n                        continue\n                    y0 = values[k + 1]\n                    if not np.isfinite(y0):\n                        continue\n                    x1 = values[k + 2]\n                    if not np.isfinite(x1):\n                        continue\n                    y1 = values[k + 3]\n                    if not np.isfinite(y1):\n                        continue\n                    segment_start = k == start1 and (not closed_rings) or (k > start1 and (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    segment_end = not closed_rings and k == stop1 - 4 or (k < stop1 - 4 and (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, 0.0, 0.0, buffer, *aggs_and_cols)\n            aa_stage_2_accumulate(aggs_and_accums, first_pass)\n            first_pass = False\n            aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg\n    else:\n        return extend_cpu\n\ndef _build_extend_line_axis1_geopandas(draw_segment, expand_aggs_and_cols, antialias_stage_2_funcs):\n    if antialias_stage_2_funcs is not None:\n        aa_stage_2_accumulate, aa_stage_2_clear, aa_stage_2_copy_back = antialias_stage_2_funcs\n    use_2_stage_agg = antialias_stage_2_funcs is not None\n    import shapely\n\n    def _process_geometry(geometry):\n        ragged = shapely.to_ragged_array(geometry)\n        geometry_type = ragged[0]\n        if geometry_type not in (shapely.GeometryType.LINESTRING, shapely.GeometryType.MULTILINESTRING, shapely.GeometryType.MULTIPOLYGON, shapely.GeometryType.POLYGON):\n            raise ValueError(f'Canvas.line supports GeoPandas geometry types of LINESTRING, MULTILINESTRING, MULTIPOLYGON and POLYGON, not {repr(geometry_type)}')\n        coords = ragged[1].ravel()\n        if geometry_type == shapely.GeometryType.LINESTRING:\n            offsets = ragged[2][0]\n            outer_offsets = np.arange(len(offsets))\n            closed_rings = False\n        elif geometry_type == shapely.GeometryType.MULTILINESTRING:\n            offsets, outer_offsets = ragged[2]\n            closed_rings = False\n        elif geometry_type == shapely.GeometryType.MULTIPOLYGON:\n            offsets, temp_offsets, outer_offsets = ragged[2]\n            outer_offsets = temp_offsets[outer_offsets]\n            closed_rings = True\n        else:\n            offsets, outer_offsets = ragged[2]\n            closed_rings = True\n        return (coords, offsets, outer_offsets, closed_rings)\n\n    def extend_cpu(sx, tx, sy, ty, xmin, xmax, ymin, ymax, geometry, antialias_stage_2, *aggs_and_cols):\n        coords, offsets, outer_offsets, closed_rings = _process_geometry(geometry)\n        extend_cpu_numba(sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, offsets, outer_offsets, closed_rings, antialias_stage_2, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, offsets, outer_offsets, closed_rings, antialias_stage_2, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        n_multilines = len(outer_offsets) - 1\n        for i in range(n_multilines):\n            start0 = outer_offsets[i]\n            stop0 = outer_offsets[i + 1]\n            for j in range(start0, stop0):\n                start1 = offsets[j]\n                stop1 = offsets[j + 1]\n                for k in range(2 * start1, 2 * stop1 - 2, 2):\n                    x0 = values[k]\n                    y0 = values[k + 1]\n                    x1 = values[k + 2]\n                    y1 = values[k + 3]\n                    if not (np.isfinite(x0) and np.isfinite(y0) and np.isfinite(x1) and np.isfinite(y1)):\n                        continue\n                    segment_start = k == start1 and (not closed_rings) or (k > start1 and (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    segment_end = not closed_rings and k == stop1 - 4 or (k < stop1 - 4 and (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    if segment_start or use_2_stage_agg:\n                        xm = 0.0\n                        ym = 0.0\n                    elif k == start1 and closed_rings:\n                        xm = values[stop1 - 4]\n                        ym = values[stop1 - 3]\n                    else:\n                        xm = values[k - 2]\n                        ym = values[k - 1]\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, xm, ym, buffer, *aggs_and_cols)\n\n    def extend_cpu_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, geometry, antialias_stage_2, *aggs_and_cols):\n        coords, offsets, outer_offsets, closed_rings = _process_geometry(geometry)\n        n_aggs = len(antialias_stage_2[0])\n        aggs_and_accums = tuple(((agg, agg.copy()) for agg in aggs_and_cols[:n_aggs]))\n        extend_cpu_numba_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, coords, offsets, outer_offsets, closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols)\n\n    @ngjit\n    @expand_aggs_and_cols\n    def extend_cpu_numba_antialias_2agg(sx, tx, sy, ty, xmin, xmax, ymin, ymax, values, offsets, outer_offsets, closed_rings, antialias_stage_2, aggs_and_accums, *aggs_and_cols):\n        antialias = antialias_stage_2 is not None\n        buffer = np.empty(8) if antialias else None\n        n_multilines = len(outer_offsets) - 1\n        first_pass = True\n        for i in range(n_multilines):\n            start0 = outer_offsets[i]\n            stop0 = outer_offsets[i + 1]\n            for j in range(start0, stop0):\n                start1 = offsets[j]\n                stop1 = offsets[j + 1]\n                for k in range(2 * start1, 2 * stop1 - 2, 2):\n                    x0 = values[k]\n                    y0 = values[k + 1]\n                    x1 = values[k + 2]\n                    y1 = values[k + 3]\n                    if not (np.isfinite(x0) and np.isfinite(y0) and np.isfinite(x1) and np.isfinite(y1)):\n                        continue\n                    segment_start = k == start1 and (not closed_rings) or (k > start1 and (not np.isfinite(values[k - 2]) or not np.isfinite(values[k - 1])))\n                    segment_end = not closed_rings and k == stop1 - 4 or (k < stop1 - 4 and (not np.isfinite(values[k + 4]) or not np.isfinite(values[k + 5])))\n                    draw_segment(i, sx, tx, sy, ty, xmin, xmax, ymin, ymax, segment_start, segment_end, x0, x1, y0, y1, 0.0, 0.0, buffer, *aggs_and_cols)\n            aa_stage_2_accumulate(aggs_and_accums, first_pass)\n            first_pass = False\n            aa_stage_2_clear(aggs_and_accums)\n        aa_stage_2_copy_back(aggs_and_accums)\n    if use_2_stage_agg:\n        return extend_cpu_antialias_2agg\n    else:\n        return extend_cpu"
  }
}