{
  "dir_path": "/app/pydicom",
  "package_name": "pydicom",
  "sample_name": "pydicom-test_dataset",
  "src_dir": "pydicom/src/pydicom/",
  "test_dir": "tests/",
  "test_file": "modified_testcases/test_dataset.py",
  "test_code": "# Copyright 2008-2023 pydicom authors. See LICENSE file for details.\n\"\"\"Unit tests for the pydicom.dataset module.\"\"\"\n\nimport copy\nimport io\nimport math\nfrom pathlib import Path\nimport pickle\nfrom platform import python_implementation\nimport sys\nimport weakref\nimport tempfile\n\nimport pytest\n\nfrom pydicom.datadict import add_private_dict_entry\nfrom .test_helpers import assert_no_warning\n\ntry:\n    import numpy\n\n    HAVE_NP = True\nexcept ImportError:\n    HAVE_NP = False\n\nimport pydicom\nfrom pydicom import config\nfrom pydicom import dcmread\nfrom pydicom.data import get_testdata_file\nfrom pydicom.dataelem import DataElement, RawDataElement\nfrom pydicom.dataset import Dataset, FileDataset, validate_file_meta, FileMetaDataset\nfrom pydicom.encaps import encapsulate\nfrom pydicom.filebase import DicomBytesIO\nfrom pydicom.pixels.utils import get_image_pixel_ids\nfrom pydicom.sequence import Sequence\nfrom pydicom.tag import Tag\nfrom pydicom.uid import (\n    ImplicitVRLittleEndian,\n    ExplicitVRLittleEndian,\n    ExplicitVRBigEndian,\n    JPEGBaseline8Bit,\n    PYDICOM_IMPLEMENTATION_UID,\n    CTImageStorage,\n)\nfrom pydicom.valuerep import DS, VR\n\n\nclass BadRepr:\n    def __repr__(self):\n        raise ValueError(\"bad repr\")\n\n\n@pytest.fixture()\ndef clear_pixel_data_handlers():\n    orig_handlers = pydicom.config.pixel_data_handlers\n    pydicom.config.pixel_data_handlers = []\n    yield\n    pydicom.config.pixel_data_handlers = orig_handlers\n\n\nclass TestDataset:\n    \"\"\"Tests for dataset.Dataset.\"\"\"\n\n    def setup_method(self):\n        self.ds = Dataset()\n        self.ds.TreatmentMachineName = \"unit001\"\n\n    def test_attribute_error_in_property(self):\n        \"\"\"Dataset: AttributeError in property raises actual error message.\"\"\"\n        # This comes from bug fix for issue 42\n        # First, fake enough to try the pixel_array property\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.PixelData = \"xyzlmnop\"\n        msg = (\n            \"Unable to decode the pixel data as the dataset's 'file_meta' has \"\n            r\"no \\(0002,0010\\) 'Transfer Syntax UID' element\"\n        )\n        with pytest.raises(AttributeError, match=msg):\n            ds.pixel_array\n\n    def test_for_stray_raw_data_element(self):\n        dataset = Dataset()\n        dataset.PatientName = \"MacDonald^George\"\n        sub_ds = Dataset()\n        sub_ds.BeamNumber = \"1\"\n        dataset.BeamSequence = Sequence([sub_ds])\n        fp = DicomBytesIO()\n        dataset.save_as(fp, implicit_vr=True)\n\n        def _reset():\n            fp.seek(0)\n            ds1 = pydicom.dcmread(fp, force=True)\n            fp.seek(0)\n            ds2 = pydicom.dcmread(fp, force=True)\n            return ds1, ds2\n\n        ds1, ds2 = _reset()\n        assert ds1 == ds2\n\n        ds1, ds2 = _reset()\n        ds1.PatientName  # convert from raw\n        assert ds1 == ds2\n\n        ds1, ds2 = _reset()\n        ds2.PatientName\n        assert ds1 == ds2\n\n        ds1, ds2 = _reset()\n        ds2.PatientName\n        assert ds2 == ds1  # compare in other order\n\n        ds1, ds2 = _reset()\n        ds2.BeamSequence[0].BeamNumber\n        assert ds1 == ds2\n\n        # add a new element to one ds sequence item\n        ds1, ds2 = _reset()\n        ds2.BeamSequence[0].BeamName = \"1\"\n        assert ds1 != ds2\n\n        # change a value in a sequence item\n        ds1, ds2 = _reset()\n        ds2.BeamSequence[0].BeamNumber = \"2\"\n        assert ds2 != ds1\n\n    def test_attribute_error_in_property_correct_debug(self):\n        \"\"\"Test AttributeError in property raises correctly.\"\"\"\n\n        class Foo(Dataset):\n            @property\n            def bar(self):\n                return self._barr()\n\n            def _bar(self):\n                return \"OK\"\n\n        def test():\n            ds = Foo()\n            ds.bar\n\n        msg = r\"'Foo' object has no attribute '_barr'\"\n        with pytest.raises(AttributeError, match=msg):\n            test()\n\n    def test_tag_exception_print(self):\n        \"\"\"Test that tag appears in exception messages.\"\"\"\n        ds = Dataset()\n        ds.PatientID = \"123456\"  # Valid value\n        ds.SmallestImagePixelValue = BadRepr()  # Invalid value\n\n        msg = r\"With tag \\(0028,0106\\) got exception: bad repr\"\n        with pytest.raises(ValueError, match=msg):\n            str(ds)\n\n    def test_tag_exception_walk(self):\n        \"\"\"Test that tag appears in exceptions raised during recursion.\"\"\"\n        ds = Dataset()\n        ds.PatientID = \"123456\"  # Valid value\n        ds.SmallestImagePixelValue = BadRepr()  # Invalid value\n\n        def callback(dataset, data_element):\n            return str(data_element)\n\n        def func(dataset=ds):\n            return dataset.walk(callback)\n\n        msg = r\"With tag \\(0028,0106\\) got exception: bad repr\"\n        with pytest.raises(ValueError, match=msg):\n            func()\n\n    def test_set_new_data_element_by_name(self):\n        \"\"\"Dataset: set new data_element by name.\"\"\"\n        ds = Dataset()\n        ds.TreatmentMachineName = \"unit #1\"\n        data_element = ds[0x300A, 0x00B2]\n        assert \"unit #1\" == data_element.value\n        assert \"SH\" == data_element.VR\n\n    def test_set_existing_data_element_by_name(self):\n        \"\"\"Dataset: set existing data_element by name.\"\"\"\n        self.ds.TreatmentMachineName = \"unit999\"  # change existing value\n        assert \"unit999\" == self.ds[0x300A, 0x00B2].value\n\n    def test_set_non_dicom(self, setattr_warn):\n        \"\"\"Dataset: can set class instance property (non-dicom).\"\"\"\n        ds = Dataset()\n        msg = (\n            r\"Camel case attribute 'SomeVariableName' used which is not in \"\n            r\"the element keyword data dictionary\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            ds.SomeVariableName = 42\n        assert hasattr(ds, \"SomeVariableName\")\n        assert 42 == ds.SomeVariableName\n\n    def test_membership(self, contains_warn):\n        \"\"\"Dataset: can test if item present by 'if <name> in dataset'.\"\"\"\n        assert \"TreatmentMachineName\" in self.ds\n        msg = (\n            r\"Invalid value 'Dummyname' used with the 'in' operator: must be \"\n            r\"an element tag as a 2-tuple or int, or an element keyword\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            assert \"Dummyname\" not in self.ds\n\n    def test_contains(self, contains_warn):\n        \"\"\"Dataset: can test if item present by 'if <tag> in dataset'.\"\"\"\n        self.ds.CommandGroupLength = 100  # (0000,0000)\n        assert (0x300A, 0xB2) in self.ds\n        assert [0x300A, 0xB2] in self.ds\n        assert 0x300A00B2 in self.ds\n        assert (0x10, 0x5F) not in self.ds\n        assert \"CommandGroupLength\" in self.ds\n        # Use a negative tag to cause an exception\n        msg = (\n            r\"Invalid value '\\(-16, 16\\)' used with the 'in' operator: must \"\n            r\"be an element tag as a 2-tuple or int, or an element keyword\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            assert (-0x0010, 0x0010) not in self.ds\n\n        def foo():\n            pass\n\n        # Try a function\n        msg = r\"Invalid value '<function TestDataset\"\n        with pytest.warns(UserWarning, match=msg):\n            assert foo not in self.ds\n\n        # Random non-existent property\n        msg = (\n            r\"Invalid value 'random name' used with the 'in' operator: must \"\n            r\"be an element tag as a 2-tuple or int, or an element keyword\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            assert \"random name\" not in self.ds\n\n        # Overflowing tag\n        msg = (\n            r\"Invalid element tag value used with the 'in' operator: \"\n            r\"tags have a maximum value of \\(0xFFFF, 0xFFFF\\)\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            assert 0x100100010 not in self.ds\n\n    def test_contains_raises(self, contains_raise):\n        \"\"\"Test raising exception for invalid key.\"\"\"\n        msg = (\n            r\"Invalid value 'invalid' used with the 'in' operator: must \"\n            r\"be an element tag as a 2-tuple or int, or an element keyword\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            \"invalid\" in self.ds\n\n    def test_contains_ignore(self, contains_ignore):\n        \"\"\"Test ignoring invalid keys.\"\"\"\n        with assert_no_warning():\n            assert \"invalid\" not in self.ds\n\n    def test_clear(self):\n        assert 1 == len(self.ds)\n        self.ds.clear()\n        assert 0 == len(self.ds)\n\n    def test_pop(self):\n        with pytest.raises(KeyError):\n            self.ds.pop(0x300A00B244)\n        assert \"default\" == self.ds.pop(\"dummy\", \"default\")\n        elem = self.ds.pop(0x300A00B2)\n        assert \"unit001\" == elem.value\n        with pytest.raises(KeyError):\n            self.ds.pop(0x300A00B2)\n\n    def test_pop_using_tuple(self):\n        elem = self.ds.pop((0x300A, 0x00B2))\n        assert \"unit001\" == elem.value\n        with pytest.raises(KeyError):\n            self.ds.pop((0x300A, 0x00B2))\n\n    def test_pop_using_keyword(self):\n        with pytest.raises(KeyError):\n            self.ds.pop(\"InvalidName\")\n        elem = self.ds.pop(\"TreatmentMachineName\")\n        assert \"unit001\" == elem.value\n        with pytest.raises(KeyError):\n            self.ds.pop(\"TreatmentMachineName\")\n\n    def test_popitem(self):\n        elem = self.ds.popitem()\n        assert 0x300A00B2 == elem[0]\n        assert \"unit001\" == elem[1].value\n        with pytest.raises(KeyError):\n            self.ds.popitem()\n\n    def test_setdefault(self):\n        elem = self.ds.setdefault(0x300A00B2, \"foo\")\n        assert \"unit001\" == elem.value\n        elem = self.ds.setdefault(0x00100010, DataElement(0x00100010, \"PN\", \"Test\"))\n        assert \"Test\" == elem.value\n        assert 2 == len(self.ds)\n\n    def test_setdefault_unknown_tag(self, dont_raise_on_writing_invalid_value):\n        with pytest.warns(UserWarning, match=r\"\\(8888,0002\\)\"):\n            elem = self.ds.setdefault(0x88880002, \"foo\")\n        assert \"foo\" == elem.value\n        assert \"UN\" == elem.VR\n        assert 2 == len(self.ds)\n\n    def test_setdefault_unknown_tag_strict(self, raise_on_writing_invalid_value):\n        with pytest.raises(KeyError, match=r\"\\(8888,0004\\)\"):\n            self.ds.setdefault(0x88880004, \"foo\")\n\n    def test_setdefault_tuple(self):\n        elem = self.ds.setdefault((0x300A, 0x00B2), \"foo\")\n        assert \"unit001\" == elem.value\n        elem = self.ds.setdefault(\n            (0x0010, 0x0010), DataElement(0x00100010, \"PN\", \"Test\")\n        )\n        assert \"Test\" == elem.value\n        assert 2 == len(self.ds)\n\n    def test_setdefault_unknown_tuple(self, dont_raise_on_writing_invalid_value):\n        with pytest.warns(UserWarning, match=r\"\\(8888,0002\\)\"):\n            elem = self.ds.setdefault((0x8888, 0x0002), \"foo\")\n        assert \"foo\" == elem.value\n        assert \"UN\" == elem.VR\n        assert 2 == len(self.ds)\n\n    def test_setdefault_unknown_tuple_strict(self, raise_on_writing_invalid_value):\n        with pytest.raises(KeyError, match=r\"\\(8888,0004\\)\"):\n            self.ds.setdefault((0x8888, 0x0004), \"foo\")\n\n    def test_setdefault_use_value(self, dont_raise_on_writing_invalid_value):\n        elem = self.ds.setdefault((0x0010, 0x0010), \"Test\")\n        assert \"Test\" == elem.value\n        assert 2 == len(self.ds)\n\n    def test_setdefault_keyword(self):\n        \"\"\"Test setdefault().\"\"\"\n        assert \"WindowWidth\" not in self.ds\n        elem = self.ds.setdefault(\"WindowWidth\", None)\n        assert elem.value is None\n        assert self.ds.WindowWidth is None\n        elem = self.ds.setdefault(\"WindowWidth\", 1024)\n        assert elem.value is None\n        assert self.ds.WindowWidth is None\n\n        assert \"TreatmentMachineName\" in self.ds\n        assert \"unit001\" == self.ds.TreatmentMachineName\n        elem = self.ds.setdefault(\"TreatmentMachineName\", \"foo\")\n        assert \"unit001\" == elem.value\n\n        elem = self.ds.setdefault(\"PatientName\", DataElement(0x00100010, \"PN\", \"Test\"))\n        assert \"Test\" == elem.value\n        assert 3 == len(self.ds)\n\n    def test_setdefault_invalid_keyword(self):\n        \"\"\"Test setdefault() with an invalid keyword raises.\"\"\"\n        msg = (\n            r\"Unable to create an element tag from 'FooBar': unknown \"\n            r\"DICOM element keyword\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            self.ds.setdefault(\"FooBar\", \"foo\")\n\n    def test_setdefault_private(self):\n        \"\"\"Test setdefault() with a private tag.\"\"\"\n        elem = self.ds.setdefault(0x00090020, None)\n        assert elem.is_private\n        assert elem.value is None\n        assert \"UN\" == elem.VR\n        assert 0x00090020 in self.ds\n        elem.VR = \"PN\"\n        elem = self.ds.setdefault(0x00090020, \"test\")\n        assert elem.is_private\n        assert elem.value is None\n        assert \"PN\" == elem.VR\n\n    def test_get_exists1(self):\n        \"\"\"Dataset: dataset.get() returns an existing item by name.\"\"\"\n        assert \"unit001\" == self.ds.get(\"TreatmentMachineName\", None)\n\n    def test_get_exists2(self):\n        \"\"\"Dataset: dataset.get() returns an existing item by long tag.\"\"\"\n        assert \"unit001\" == self.ds.get(0x300A00B2, None).value\n\n    def test_get_exists3(self):\n        \"\"\"Dataset: dataset.get() returns an existing item by tuple tag.\"\"\"\n        assert \"unit001\" == self.ds.get((0x300A, 0x00B2), None).value\n\n    def test_get_exists4(self):\n        \"\"\"Dataset: dataset.get() returns an existing item by Tag.\"\"\"\n        assert \"unit001\" == self.ds.get(Tag(0x300A00B2), None).value\n\n    def test_get_default1(self):\n        \"\"\"Dataset: dataset.get() returns default for non-existing name.\"\"\"\n        assert \"not-there\" == self.ds.get(\"NotAMember\", \"not-there\")\n\n    def test_get_default2(self):\n        \"\"\"Dataset: dataset.get() returns default for non-existing tuple tag\"\"\"\n        assert \"not-there\" == self.ds.get((0x9999, 0x9999), \"not-there\")\n\n    def test_get_default3(self):\n        \"\"\"Dataset: dataset.get() returns default for non-existing long tag.\"\"\"\n        assert \"not-there\" == self.ds.get(0x99999999, \"not-there\")\n\n    def test_get_default4(self):\n        \"\"\"Dataset: dataset.get() returns default for non-existing Tag.\"\"\"\n        assert \"not-there\" == self.ds.get(Tag(0x99999999), \"not-there\")\n\n    def test_get_raises(self):\n        \"\"\"Test Dataset.get() raises exception when invalid Tag\"\"\"\n        with pytest.raises(TypeError, match=r\"Dataset.get key must be a string or tag\"):\n            self.ds.get(-0x0010, 0x0010)\n\n    def test_get_from_raw(self):\n        \"\"\"Dataset: get(tag) returns same object as ds[tag] for raw element.\"\"\"\n        # This came from issue 88, where get(tag#) returned a RawDataElement,\n        #     while get(name) converted to a true DataElement\n        test_tag = 0x100010\n        test_elem = RawDataElement(Tag(test_tag), \"PN\", 4, b\"test\", 0, True, True)\n        ds = Dataset({Tag(test_tag): test_elem})\n        assert ds[test_tag] == ds.get(test_tag)\n\n    def test__setitem__(self):\n        \"\"\"Dataset: if set an item, it must be a DataElement instance.\"\"\"\n        ds = Dataset()\n        with pytest.raises(TypeError):\n            ds[0x300A, 0xB2] = \"unit1\"\n\n    def test_matching_tags(self):\n        \"\"\"Dataset: key and data_element.tag mismatch raises ValueError.\"\"\"\n        ds = Dataset()\n        data_element = DataElement((0x300A, 0x00B2), \"SH\", \"unit001\")\n        with pytest.raises(ValueError):\n            ds[0x10, 0x10] = data_element\n\n    def test_named_member_updated(self):\n        \"\"\"Dataset: if set data_element by tag, name also reflects change.\"\"\"\n        self.ds[0x300A, 0xB2].value = \"moon_unit\"\n        assert \"moon_unit\" == self.ds.TreatmentMachineName\n\n    def test_update(self):\n        \"\"\"Dataset: update() method works with tag or name.\"\"\"\n        pat_data_element = DataElement((0x10, 0x12), \"PN\", \"Johnny\")\n        self.ds.update({\"PatientName\": \"John\", (0x10, 0x12): pat_data_element})\n        assert \"John\" == self.ds[0x10, 0x10].value\n        assert \"Johnny\" == self.ds[0x10, 0x12].value\n\n    def test_dir_attr(self):\n        \"\"\"Dataset.__dir__ returns class attributes\"\"\"\n        ds = Dataset()\n        assert hasattr(ds, \"is_implicit_VR\")\n        assert \"is_implicit_VR\" in dir(ds)\n\n    def test_dir_subclass(self):\n        \"\"\"Dataset.__dir__ returns class specific dir\"\"\"\n\n        class DSP(Dataset):\n            def test_func(self):\n                pass\n\n        ds = DSP()\n        assert hasattr(ds, \"test_func\")\n        assert callable(ds.test_func)\n        assert \"test_func\" in dir(ds)\n\n        ds = Dataset()\n        assert hasattr(ds, \"group_dataset\")\n        assert callable(ds.group_dataset)\n        assert \"group_dataset\" in dir(ds)\n\n    def test_dir(self, setattr_warn):\n        \"\"\"Dataset.dir() returns sorted list of named data_elements.\"\"\"\n        ds = self.ds\n        ds.PatientName = \"name\"\n        ds.PatientID = \"id\"\n        msg = (\n            r\"Camel case attribute 'NonDicomVariable' used which is not in \"\n            r\"the element keyword data dictionary\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            ds.NonDicomVariable = \"junk\"\n        ds.add_new((0x18, 0x1151), \"IS\", 150)  # X-ray Tube Current\n        ds.add_new((0x1111, 0x123), \"DS\", \"42.0\")  # private - no name in dir()\n        expected = [\n            \"PatientID\",\n            \"PatientName\",\n            \"TreatmentMachineName\",\n            \"XRayTubeCurrent\",\n        ]\n        assert expected == ds.dir()\n\n    def test_dir_filter(self, setattr_warn):\n        \"\"\"Test Dataset.dir(*filters) works OK.\"\"\"\n        ds = self.ds\n        ds.PatientName = \"name\"\n        ds.PatientID = \"id\"\n        msg = (\n            r\"Camel case attribute 'NonDicomVariable' used which is not in \"\n            r\"the element keyword data dictionary\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            ds.NonDicomVariable = \"junk\"\n        ds.add_new((0x18, 0x1151), \"IS\", 150)  # X-ray Tube Current\n        ds.add_new((0x1111, 0x123), \"DS\", \"42.0\")  # private - no name in dir()\n        assert \"PatientID\" in ds\n        assert \"XRayTubeCurrent\" in ds\n        assert \"TreatmentMachineName\" in ds\n        assert \"PatientName\" in ds\n        assert \"PatientBirthDate\" not in ds\n        assert [\"PatientID\", \"PatientName\"] == ds.dir(\"Patient\")\n        assert [\"PatientName\", \"TreatmentMachineName\"] == ds.dir(\"Name\")\n        expected = [\"PatientID\", \"PatientName\", \"TreatmentMachineName\"]\n        assert expected == ds.dir(\"Name\", \"Patient\")\n\n    def test_delete_dicom_attr(self):\n        \"\"\"Dataset: delete DICOM attribute by name.\"\"\"\n        del self.ds.TreatmentMachineName\n        with pytest.raises(AttributeError):\n            self.ds.TreatmentMachineName\n\n    def test_delete_dicom_command_group_length(self):\n        \"\"\"Dataset: delete CommandGroupLength doesn't raise AttributeError.\"\"\"\n        self.ds.CommandGroupLength = 100  # (0x0000, 0x0000)\n        del self.ds.CommandGroupLength\n        with pytest.raises(AttributeError):\n            self.ds.CommandGroupLength\n\n    def test_delete_other_attr(self):\n        \"\"\"Dataset: delete non-DICOM attribute by name.\"\"\"\n        self.ds.meaningoflife = 42\n        assert hasattr(self.ds, \"meaningoflife\")\n        del self.ds.meaningoflife\n        assert not hasattr(self.ds, \"meaningoflife\")\n\n    def test_delete_dicom_attr_we_dont_have(self):\n        \"\"\"Dataset: try delete of missing DICOM attribute.\"\"\"\n        with pytest.raises(AttributeError):\n            del self.ds.PatientName\n\n    def test_delete_item_long(self):\n        \"\"\"Dataset: delete item by tag number (long).\"\"\"\n        del self.ds[0x300A00B2]\n\n    def test_delete_item_tuple(self):\n        \"\"\"Dataset: delete item by tag number (tuple).\"\"\"\n        del self.ds[0x300A, 0x00B2]\n\n    def test_delete_non_existing_item(self):\n        \"\"\"Dataset: raise KeyError for non-existing item delete.\"\"\"\n        with pytest.raises(KeyError):\n            del self.ds[0x10, 0x10]\n\n    def test_equality_no_sequence(self):\n        \"\"\"Dataset: equality returns correct value with simple dataset\"\"\"\n        # Test empty dataset\n        assert Dataset() == Dataset()\n\n        d = Dataset()\n        d.SOPInstanceUID = \"1.2.3.4\"\n        d.PatientName = \"Test\"\n        assert d == d  # noqa: PLR0124 Need to check equality with self\n\n        e = Dataset()\n        e.PatientName = \"Test\"\n        e.SOPInstanceUID = \"1.2.3.4\"\n        assert d == e\n\n        e.SOPInstanceUID = \"1.2.3.5\"\n        assert not d == e\n\n        # Check VR\n        del e.SOPInstanceUID\n        e.add(DataElement(0x00080018, \"PN\", \"1.2.3.4\"))\n        assert not d == e\n\n        # Check Tag\n        del e.SOPInstanceUID\n        e.StudyInstanceUID = \"1.2.3.4\"\n        assert not d == e\n\n        # Check missing Element in self\n        e.SOPInstanceUID = \"1.2.3.4\"\n        assert not d == e\n\n        # Check missing Element in other\n        d = Dataset()\n        d.SOPInstanceUID = \"1.2.3.4\"\n        d.StudyInstanceUID = \"1.2.3.4.5\"\n\n        e = Dataset()\n        e.SOPInstanceUID = \"1.2.3.4\"\n        assert not d == e\n\n    def test_equality_private(self):\n        \"\"\"Dataset: equality returns correct value\"\"\"\n        \"\"\"when dataset has private elements\"\"\"\n        d = Dataset()\n        d_elem = DataElement(0x01110001, \"PN\", \"Private\")\n        assert d == d  # noqa: PLR0124 Need to check equality with self\n        d.add(d_elem)\n\n        e = Dataset()\n        e_elem = DataElement(0x01110001, \"PN\", \"Private\")\n        e.add(e_elem)\n        assert e == d\n\n        e[0x01110001].value = \"Public\"\n        assert not e == d\n\n    def test_equality_sequence(self):\n        \"\"\"Equality returns correct value with sequences\"\"\"\n        # Test even sequences\n        d = Dataset()\n        d.SOPInstanceUID = \"1.2.3.4\"\n        d.BeamSequence = []\n        beam_seq = Dataset()\n        beam_seq.PatientID = \"1234\"\n        beam_seq.PatientName = \"ANON\"\n        d.BeamSequence.append(beam_seq)\n        assert d == d  # noqa: PLR0124 Need to check equality with self\n\n        e = Dataset()\n        e.SOPInstanceUID = \"1.2.3.4\"\n        e.BeamSequence = []\n        beam_seq = Dataset()\n        beam_seq.PatientName = \"ANON\"\n        beam_seq.PatientID = \"1234\"\n        e.BeamSequence.append(beam_seq)\n        assert d == e\n\n        e.BeamSequence[0].PatientName = \"ANONY\"\n        assert not d == e\n\n        # Test uneven sequences\n        e.BeamSequence[0].PatientName = \"ANON\"\n        assert d == e\n\n        e.BeamSequence.append(beam_seq)\n        assert not d == e\n\n        d.BeamSequence.append(beam_seq)\n        assert d == e\n        d.BeamSequence.append(beam_seq)\n        assert not d == e\n\n    def test_equality_not_dataset(self):\n        \"\"\"Dataset: equality returns correct value when not the same class\"\"\"\n        d = Dataset()\n        d.SOPInstanceUID = \"1.2.3.4\"\n        # Make sure Dataset.__eq__() is being used, not dict__eq__()\n        assert not d == {\"SOPInstanceUID\": \"1.2.3.4\"}\n\n    def test_equality_unknown(self, setattr_warn):\n        \"\"\"Dataset: equality returns correct value with extra members\"\"\"\n        # Non-element class members are ignored in equality testing\n        d = Dataset()\n        msg = (\n            r\"Camel case attribute 'SOPEustaceUID' used which is not in \"\n            r\"the element keyword data dictionary\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            d.SOPEustaceUID = \"1.2.3.4\"\n        assert d == d  # noqa: PLR0124 Need to check equality with self\n\n        e = Dataset()\n        with pytest.warns(UserWarning, match=msg):\n            e.SOPEustaceUID = \"1.2.3.5\"\n        assert d == e\n\n    def test_equality_inheritance(self):\n        \"\"\"Dataset: equality returns correct value for subclass\"\"\"\n\n        class DatasetPlus(Dataset):\n            pass\n\n        d = Dataset()\n        d.PatientName = \"ANON\"\n        e = DatasetPlus()\n        e.PatientName = \"ANON\"\n        assert d == e\n        assert e == d\n        assert e == e  # noqa: PLR0124 Need to check equality with self\n\n        e.PatientName = \"ANONY\"\n        assert not d == e\n        assert not e == d\n\n    def test_equality_elements(self):\n        \"\"\"Test that Dataset equality only checks DataElements.\"\"\"\n        d = Dataset()\n        d.SOPInstanceUID = \"1.2.3.4\"\n        d.PatientName = \"Test\"\n        d.foo = \"foo\"\n        assert d == d  # noqa: PLR0124 Need to check equality with self\n\n        e = Dataset()\n        e.PatientName = \"Test\"\n        e.SOPInstanceUID = \"1.2.3.4\"\n        assert d == e\n\n    def test_inequality(self):\n        \"\"\"Test inequality operator\"\"\"\n        d = Dataset()\n        d.SOPInstanceUID = \"1.2.3.4\"\n        assert not d != d  # noqa: PLR0124 Need to check inequality with self\n\n        e = Dataset()\n        e.SOPInstanceUID = \"1.2.3.5\"\n        assert d != e\n\n    def test_hash(self):\n        \"\"\"DataElement: hash returns TypeError\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"ANON\"\n        with pytest.raises(TypeError):\n            hash(ds)\n\n    def test_property(self):\n        \"\"\"Test properties work OK.\"\"\"\n\n        class DSPlus(Dataset):\n            @property\n            def test(self):\n                return self._test\n\n            @test.setter\n            def test(self, value):\n                self._test = value\n\n        dsp = DSPlus()\n        dsp.test = \"ABCD\"\n        assert \"ABCD\" == dsp.test\n\n    def test_add_repeater_elem_by_keyword(self):\n        \"\"\"Repeater using keyword to add repeater group elements raises.\"\"\"\n        ds = Dataset()\n        with pytest.raises(ValueError):\n            ds.OverlayData = b\"\\x00\"\n\n    def test_setitem_slice_raises(self):\n        \"\"\"Test Dataset.__setitem__ raises if slicing used.\"\"\"\n        ds = Dataset()\n        with pytest.raises(NotImplementedError):\n            ds.__setitem__(slice(None), Dataset())\n\n    def test_getitem_slice_raises(self):\n        \"\"\"Test Dataset.__getitem__ raises if slice Tags invalid.\"\"\"\n        ds = Dataset()\n        with pytest.raises(ValueError):\n            ds.__getitem__(slice(None, -1))\n        with pytest.raises(ValueError):\n            ds.__getitem__(slice(-1, -1))\n        with pytest.raises(ValueError):\n            ds.__getitem__(slice(-1))\n\n    def test_empty_slice(self):\n        \"\"\"Test Dataset slicing with empty Dataset.\"\"\"\n        ds = Dataset()\n        assert ds[:] == Dataset()\n        with pytest.raises(ValueError):\n            ds.__getitem__(slice(None, -1))\n        with pytest.raises(ValueError):\n            ds.__getitem__(slice(-1, -1))\n        with pytest.raises(ValueError):\n            ds.__getitem__(slice(-1))\n        with pytest.raises(NotImplementedError):\n            ds.__setitem__(slice(None), Dataset())\n\n    def test_getitem_slice(self):\n        \"\"\"Test Dataset.__getitem__ using slices.\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.CommandLengthToEnd = 111  # 0000,0001\n        ds.Overlays = 12  # 0000,51B0\n        ds.LengthToEnd = 12  # 0008,0001\n        ds.SOPInstanceUID = \"1.2.3.4\"  # 0008,0018\n        ds.SkipFrameRangeFlag = \"TEST\"  # 0008,9460\n        ds.add_new(0x00090001, \"PN\", \"CITIZEN^1\")\n        ds.add_new(0x00090002, \"PN\", \"CITIZEN^2\")\n        ds.add_new(0x00090003, \"PN\", \"CITIZEN^3\")\n        ds.add_new(0x00090004, \"PN\", \"CITIZEN^4\")\n        ds.add_new(0x00090005, \"PN\", \"CITIZEN^5\")\n        ds.add_new(0x00090006, \"PN\", \"CITIZEN^6\")\n        ds.add_new(0x00090007, \"PN\", \"CITIZEN^7\")\n        ds.add_new(0x00090008, \"PN\", \"CITIZEN^8\")\n        ds.add_new(0x00090009, \"PN\", \"CITIZEN^9\")\n        ds.add_new(0x00090010, \"PN\", \"CITIZEN^10\")\n        ds.PatientName = \"CITIZEN^Jan\"  # 0010,0010\n        ds.PatientID = \"12345\"  # 0010,0010\n        ds.ExaminedBodyThickness = 1.223  # 0010,9431\n        ds.BeamSequence = [Dataset()]  # 300A,00B0\n        ds.BeamSequence[0].PatientName = \"ANON\"\n\n        # Slice all items - should return original dataset\n        assert ds[:] == ds\n\n        # Slice starting from and including (0008,0001)\n        test_ds = ds[0x00080001:]\n        assert \"CommandGroupLength\" not in test_ds\n        assert \"CommandLengthToEnd\" not in test_ds\n        assert \"Overlays\" not in test_ds\n        assert \"LengthToEnd\" in test_ds\n        assert \"BeamSequence\" in test_ds\n\n        # Slice ending at and not including (0009,0002)\n        test_ds = ds[:0x00090002]\n        assert \"CommandGroupLength\" in test_ds\n        assert \"CommandLengthToEnd\" in test_ds\n        assert \"Overlays\" in test_ds\n        assert \"LengthToEnd\" in test_ds\n        assert 0x00090001 in test_ds\n        assert 0x00090002 not in test_ds\n        assert \"BeamSequence\" not in test_ds\n\n        # Slice with a step - every second tag\n        # Should return zeroth tag, then second, fourth, etc...\n        test_ds = ds[::2]\n        assert \"CommandGroupLength\" in test_ds\n        assert \"CommandLengthToEnd\" not in test_ds\n        assert 0x00090001 in test_ds\n        assert 0x00090002 not in test_ds\n\n        # Slice starting at and including (0008,0018) and ending at and not\n        #   including (0009,0008)\n        test_ds = ds[0x00080018:0x00090008]\n        assert \"SOPInstanceUID\" in test_ds\n        assert 0x00090007 in test_ds\n        assert 0x00090008 not in test_ds\n\n        # Slice starting at and including (0008,0018) and ending at and not\n        #   including (0009,0008), every third element\n        test_ds = ds[0x00080018:0x00090008:3]\n        assert \"SOPInstanceUID\" in test_ds\n        assert 0x00090001 not in test_ds\n        assert 0x00090002 in test_ds\n        assert 0x00090003 not in test_ds\n        assert 0x00090004 not in test_ds\n        assert 0x00090005 in test_ds\n        assert 0x00090006 not in test_ds\n        assert 0x00090008 not in test_ds\n\n        # Slice starting and ending (and not including) (0008,0018)\n        assert ds[(0x0008, 0x0018):(0x0008, 0x0018)] == Dataset()\n\n        # Test slicing using other acceptable Tag initialisations\n        assert \"SOPInstanceUID\" in ds[(0x00080018):(0x00080019)]\n        assert \"SOPInstanceUID\" in ds[(0x0008, 0x0018):(0x0008, 0x0019)]\n        assert \"SOPInstanceUID\" in ds[\"0x00080018\":\"0x00080019\"]\n\n    def test_getitem_slice_ffff(self):\n        \"\"\"Test slicing with (FFFF,FFFF)\"\"\"\n        # Issue #92\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.CommandLengthToEnd = 111  # 0000,0001\n        ds.Overlays = 12  # 0000,51B0\n        ds.LengthToEnd = 12  # 0008,0001\n        ds.SOPInstanceUID = \"1.2.3.4\"  # 0008,0018\n        ds.SkipFrameRangeFlag = \"TEST\"  # 0008,9460\n        ds.add_new(0xFFFF0001, \"PN\", \"CITIZEN^1\")\n        ds.add_new(0xFFFF0002, \"PN\", \"CITIZEN^2\")\n        ds.add_new(0xFFFF0003, \"PN\", \"CITIZEN^3\")\n        ds.add_new(0xFFFFFFFE, \"PN\", \"CITIZEN^4\")\n        ds.add_new(0xFFFFFFFF, \"PN\", \"CITIZEN^5\")\n\n        assert \"CITIZEN^5\" == ds[:][0xFFFFFFFF].value\n        assert 0xFFFFFFFF not in ds[0x1000:0xFFFFFFFF]\n        assert 0xFFFFFFFF not in ds[(0x1000):(0xFFFF, 0xFFFF)]\n\n    def test_delitem_slice(self):\n        \"\"\"Test Dataset.__delitem__ using slices.\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.CommandLengthToEnd = 111  # 0000,0001\n        ds.Overlays = 12  # 0000,51B0\n        ds.LengthToEnd = 12  # 0008,0001\n        ds.SOPInstanceUID = \"1.2.3.4\"  # 0008,0018\n        ds.SkipFrameRangeFlag = \"TEST\"  # 0008,9460\n        ds.add_new(0x00090001, \"PN\", \"CITIZEN^1\")\n        ds.add_new(0x00090002, \"PN\", \"CITIZEN^2\")\n        ds.add_new(0x00090003, \"PN\", \"CITIZEN^3\")\n        ds.add_new(0x00090004, \"PN\", \"CITIZEN^4\")\n        ds.add_new(0x00090005, \"PN\", \"CITIZEN^5\")\n        ds.add_new(0x00090006, \"PN\", \"CITIZEN^6\")\n        ds.add_new(0x00090007, \"PN\", \"CITIZEN^7\")\n        ds.add_new(0x00090008, \"PN\", \"CITIZEN^8\")\n        ds.add_new(0x00090009, \"PN\", \"CITIZEN^9\")\n        ds.add_new(0x00090010, \"PN\", \"CITIZEN^10\")\n        ds.PatientName = \"CITIZEN^Jan\"  # 0010,0010\n        ds.PatientID = \"12345\"  # 0010,0010\n        ds.ExaminedBodyThickness = 1.223  # 0010,9431\n        ds.BeamSequence = [Dataset()]  # 300A,00B0\n        ds.BeamSequence[0].PatientName = \"ANON\"\n\n        # Delete the 0x0009 group\n        del ds[0x00090000:0x00100000]\n        assert \"SkipFrameRangeFlag\" in ds\n        assert 0x00090001 not in ds\n        assert 0x00090010 not in ds\n        assert \"PatientName\" in ds\n\n    def test_group_dataset(self):\n        \"\"\"Test Dataset.group_dataset\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.CommandLengthToEnd = 111  # 0000,0001\n        ds.Overlays = 12  # 0000,51B0\n        ds.LengthToEnd = 12  # 0008,0001\n        ds.SOPInstanceUID = \"1.2.3.4\"  # 0008,0018\n        ds.SkipFrameRangeFlag = \"TEST\"  # 0008,9460\n\n        # Test getting group 0x0000\n        group0000 = ds.group_dataset(0x0000)\n        assert \"CommandGroupLength\" in group0000\n        assert \"CommandLengthToEnd\" in group0000\n        assert \"Overlays\" in group0000\n        assert \"LengthToEnd\" not in group0000\n        assert \"SOPInstanceUID\" not in group0000\n        assert \"SkipFrameRangeFlag\" not in group0000\n\n        # Test getting group 0x0008\n        group0000 = ds.group_dataset(0x0008)\n        assert \"CommandGroupLength\" not in group0000\n        assert \"CommandLengthToEnd\" not in group0000\n        assert \"Overlays\" not in group0000\n        assert \"LengthToEnd\" in group0000\n        assert \"SOPInstanceUID\" in group0000\n        assert \"SkipFrameRangeFlag\" in group0000\n\n    def test_get_item(self):\n        \"\"\"Test Dataset.get_item\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.SOPInstanceUID = \"1.2.3.4\"  # 0008,0018\n\n        # Test non-deferred read\n        assert ds[0x00000000] == ds.get_item(0x00000000)\n        assert 120 == ds.get_item(0x00000000).value\n        assert ds[0x00080018] == ds.get_item(0x00080018)\n        assert \"1.2.3.4\" == ds.get_item(0x00080018).value\n\n        # Test deferred read\n        test_file = get_testdata_file(\"MR_small.dcm\")\n        ds = dcmread(test_file, force=True, defer_size=\"0.8 kB\")\n        ds_ref = dcmread(test_file, force=True)\n        # get_item will follow the deferred read branch\n        assert ds_ref.PixelData == ds.get_item(0x7FE00010).value\n\n    def test_get_item_slice(self):\n        \"\"\"Test Dataset.get_item with slice argument\"\"\"\n        # adapted from test_getitem_slice\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.CommandLengthToEnd = 111  # 0000,0001\n        ds.Overlays = 12  # 0000,51B0\n        ds.LengthToEnd = 12  # 0008,0001\n        ds.SOPInstanceUID = \"1.2.3.4\"  # 0008,0018\n        ds.SkipFrameRangeFlag = \"TEST\"  # 0008,9460\n        ds.add_new(0x00090001, \"PN\", \"CITIZEN^1\")\n        ds.add_new(0x00090002, \"PN\", \"CITIZEN^2\")\n        ds.add_new(0x00090003, \"PN\", \"CITIZEN^3\")\n        elem = RawDataElement(0x00090004, \"PN\", 9, b\"CITIZEN^4\", 0, True, True)\n        ds.__setitem__(0x00090004, elem)\n        elem = RawDataElement(0x00090005, \"PN\", 9, b\"CITIZEN^5\", 0, True, True)\n        ds.__setitem__(0x00090005, elem)\n        elem = RawDataElement(0x00090006, \"PN\", 9, b\"CITIZEN^6\", 0, True, True)\n        ds.__setitem__(0x00090006, elem)\n        ds.PatientName = \"CITIZEN^Jan\"  # 0010,0010\n        elem = RawDataElement(0x00100020, \"LO\", 5, b\"12345\", 0, True, True)\n        ds.__setitem__(0x00100020, elem)  # Patient ID\n        ds.ExaminedBodyThickness = 1.223  # 0010,9431\n        ds.BeamSequence = [Dataset()]  # 300A,00B0\n        ds.BeamSequence[0].PatientName = \"ANON\"\n\n        # Slice starting from and including (0008,0001)\n        test_ds = ds.get_item(slice(0x00080001, None))\n        assert \"CommandGroupLength\" not in test_ds\n        assert \"CommandLengthToEnd\" not in test_ds\n        assert \"Overlays\" not in test_ds\n        assert \"LengthToEnd\" in test_ds\n        assert \"BeamSequence\" in test_ds\n\n        # Slice ending at and not including (0009,0002)\n        test_ds = ds.get_item(slice(None, 0x00090002))\n        assert \"CommandGroupLength\" in test_ds\n        assert \"CommandLengthToEnd\" in test_ds\n        assert \"Overlays\" in test_ds\n        assert \"LengthToEnd\" in test_ds\n        assert 0x00090001 in test_ds\n        assert 0x00090002 not in test_ds\n        assert \"BeamSequence\" not in test_ds\n\n        # Slice with a step - every second tag\n        # Should return zeroth tag, then second, fourth, etc...\n        test_ds = ds.get_item(slice(None, None, 2))\n        assert \"CommandGroupLength\" in test_ds\n        assert \"CommandLengthToEnd\" not in test_ds\n        assert 0x00090001 in test_ds\n        assert 0x00090002 not in test_ds\n\n        # Slice starting at and including (0008,0018) and ending at and not\n        #   including (0009,0008)\n        test_ds = ds.get_item(slice(0x00080018, 0x00090006))\n        assert \"SOPInstanceUID\" in test_ds\n        assert 0x00090005 in test_ds\n        assert 0x00090006 not in test_ds\n\n        # Slice starting at and including (0008,0018) and ending at and not\n        #   including (0009,0006), every third element\n        test_ds = ds.get_item(slice(0x00080018, 0x00090008, 3))\n        assert \"SOPInstanceUID\" in test_ds\n        assert 0x00090001 not in test_ds\n        assert 0x00090002 in test_ds\n        assert not test_ds.get_item(0x00090002).is_raw\n        assert 0x00090003 not in test_ds\n        assert 0x00090004 not in test_ds\n        assert 0x00090005 in test_ds\n        assert test_ds.get_item(0x00090005).is_raw\n        assert 0x00090006 not in test_ds\n\n        # Slice starting and ending (and not including) (0008,0018)\n        assert Dataset() == ds.get_item(slice((0x0008, 0x0018), (0x0008, 0x0018)))\n\n        # Test slicing using other acceptable Tag initialisations\n        assert \"SOPInstanceUID\" in ds.get_item(slice(0x00080018, 0x00080019))\n        assert \"SOPInstanceUID\" in ds.get_item(\n            slice((0x0008, 0x0018), (0x0008, 0x0019))\n        )\n        assert \"SOPInstanceUID\" in ds.get_item(slice(\"0x00080018\", \"0x00080019\"))\n\n        # Slice all items - should return original dataset\n        assert ds == ds.get_item(slice(None, None))\n\n    def test_getitem_deferred(self):\n        \"\"\"Test get_item(..., keep_deferred)\"\"\"\n        test_file = get_testdata_file(\"MR_small.dcm\")\n        ds = dcmread(test_file, force=True, defer_size=\"0.8 kB\")\n        elem = ds.get_item(\"PixelData\", keep_deferred=True)\n        assert isinstance(elem, RawDataElement)\n        assert elem.value is None\n\n        elem = ds.get_item(\"PixelData\", keep_deferred=False)\n        assert isinstance(elem, DataElement)\n        assert elem.value is not None\n\n    def test_get_private_item(self):\n        ds = Dataset()\n        ds.add_new(0x00080005, \"CS\", \"ISO_IR 100\")\n        ds.add_new(0x00090010, \"LO\", \"Creator 1.0\")\n        ds.add_new(0x00091001, \"SH\", \"Version1\")\n        ds.add_new(0x00090011, \"LO\", \"Creator 2.0\")\n        ds.add_new(0x00091101, \"SH\", \"Version2\")\n        ds.add_new(0x00091102, \"US\", 2)\n\n        with pytest.raises(ValueError, match=\"Tag must be private\"):\n            ds.get_private_item(0x0008, 0x05, \"Creator 1.0\")\n        with pytest.raises(ValueError, match=\"Private creator must have a value\"):\n            ds.get_private_item(0x0009, 0x10, \"\")\n        with pytest.raises(KeyError, match=\"Private creator 'Creator 3.0' not found\"):\n            ds.get_private_item(0x0009, 0x10, \"Creator 3.0\")\n        item = ds.get_private_item(0x0009, 0x01, \"Creator 1.0\")\n        assert \"Version1\" == item.value\n        item = ds.get_private_item(0x0009, 0x01, \"Creator 2.0\")\n        assert \"Version2\" == item.value\n\n        with pytest.raises(KeyError):\n            ds.get_private_item(0x0009, 0x02, \"Creator 1.0\")\n        item = ds.get_private_item(0x0009, 0x02, \"Creator 2.0\")\n        assert 2 == item.value\n\n    def test_add_unknown_private_tag(self):\n        ds = Dataset()\n        with pytest.raises(ValueError, match=\"Tag must be private\"):\n            ds.add_new_private(\"Creator 1.0\", 0x0010, 0x01, \"VALUE\", VR.SH)\n        with pytest.raises(ValueError, match=\"Private creator must have a value\"):\n            ds.add_new_private(\"\", 0x0011, 0x01, \"VALUE\", VR.SH)\n        with pytest.raises(\n            KeyError,\n            match=\"Private creator 'Creator 1.0' not in the private dictionary\",\n        ):\n            ds.add_new_private(\"Creator 1.0\", 0x0011, 0x01, \"VALUE\")\n\n        ds.add_new_private(\"Creator 1.0\", 0x0011, 0x01, \"VALUE\", VR.SH)\n        item = ds.get_private_item(0x0011, 0x01, \"Creator 1.0\")\n        assert item.value == \"VALUE\"\n        assert item.private_creator == \"Creator 1.0\"\n        assert item.VR == VR.SH\n\n    def test_add_known_private_tag(self):\n        ds = Dataset()\n        ds.add_new_private(\"GEMS_GENIE_1\", 0x0009, 0x10, \"Test Study\")\n        item = ds.get_private_item(0x0009, 0x10, \"GEMS_GENIE_1\")\n        assert item.value == \"Test Study\"\n        assert item.private_creator == \"GEMS_GENIE_1\"\n        assert item.VR == VR.LO\n\n        add_private_dict_entry(\"Creator 1.0\", 0x00110001, VR.SH, \"Some Value\")\n        ds.add_new_private(\"Creator 1.0\", 0x0011, 0x01, \"VALUE\")\n        item = ds.get_private_item(0x0011, 0x01, \"Creator 1.0\")\n        assert item.value == \"VALUE\"\n        assert item.private_creator == \"Creator 1.0\"\n        assert item.VR == VR.SH\n\n    def test_private_block(self):\n        ds = Dataset()\n        ds.add_new(0x00080005, \"CS\", \"ISO_IR 100\")\n        ds.add_new(0x00090010, \"LO\", \"Creator 1.0\")\n        ds.add_new(0x00091001, \"SH\", \"Version1\")\n        # make sure it works with non-contiguous blocks\n        ds.add_new(0x00090020, \"LO\", \"Creator 2.0\")\n        ds.add_new(0x00092001, \"SH\", \"Version2\")\n        ds.add_new(0x00092002, \"US\", 2)\n\n        # Dataset.private_block\n        with pytest.raises(ValueError, match=\"Tag must be private\"):\n            ds.private_block(0x0008, \"Creator 1.0\")\n        with pytest.raises(ValueError, match=\"Private creator must have a value\"):\n            ds.private_block(0x0009, \"\")\n        with pytest.raises(KeyError, match=\"Private creator 'Creator 3.0' not found\"):\n            ds.private_block(0x0009, \"Creator 3.0\")\n\n        block = ds.private_block(0x0009, \"Creator 1.0\")\n\n        # test for containment\n        assert 1 in block\n        assert 2 not in block\n\n        # get item from private block\n        item = block[0x01]\n        assert \"Version1\" == item.value\n        block = ds.private_block(0x0009, \"Creator 2.0\")\n        with pytest.raises(ValueError, match=\"Element offset must be less than 256\"):\n            block[0x0101]\n\n        item = block[0x01]\n        assert \"Version2\" == item.value\n\n        # Dataset.get_private_item\n        with pytest.raises(KeyError):\n            ds.get_private_item(0x0009, 0x02, \"Creator 1.0\")\n\n        item = ds.get_private_item(0x0009, 0x02, \"Creator 2.0\")\n        assert 2 == item.value\n\n    def test_private_block_deepcopy(self):\n        \"\"\"Test deepcopying a private block.\"\"\"\n        ds = Dataset()\n        ds.private_block(0x000B, \"Foo\", create=True)\n\n        ds2 = copy.deepcopy(ds)\n        assert ds2[0x000B0010].value == \"Foo\"\n\n    def test_private_block_pickle(self):\n        \"\"\"Test pickling a private block.\"\"\"\n        ds = Dataset()\n        ds.private_block(0x000B, \"Foo\", create=True)\n\n        s = pickle.dumps({\"ds\": ds})\n        ds2 = pickle.loads(s)[\"ds\"]\n        assert ds2[0x000B0010].value == \"Foo\"\n\n    def test_private_creator_from_raw_ds(self):\n        # regression test for #1078\n        ct_filename = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(ct_filename)\n        ds.private_block(0x11, \"GEMS_PATI_01\", create=True)\n        assert [\"GEMS_PATI_01\"] == ds.private_creators(0x11)\n\n        assert [] == ds.private_creators(0x13)\n        ds.private_block(0x13, \"GEMS_PATI_01\", create=True)\n        assert [\"GEMS_PATI_01\"] == ds.private_creators(0x13)\n\n    def test_add_known_private_tag2(self):\n        # regression test for #1082\n        ds = dcmread(get_testdata_file(\"CT_small.dcm\"))\n        assert \"[Patient Status]\" == ds[0x11, 0x1010].name\n\n        block = ds.private_block(0x11, \"GEMS_PATI_01\")\n        block.add_new(0x10, \"SS\", 1)\n        assert \"[Patient Status]\" == ds[0x11, 0x1010].name\n\n    def test_add_new_private_tag(self):\n        ds = Dataset()\n        ds.add_new(0x00080005, \"CS\", \"ISO_IR 100\")\n        ds.add_new(0x00090010, \"LO\", \"Creator 1.0\")\n        ds.add_new(0x00090011, \"LO\", \"Creator 2.0\")\n\n        with pytest.raises(ValueError, match=\"Tag must be private\"):\n            ds.private_block(0x0008, \"Creator 1.0\")\n        block = ds.private_block(0x0009, \"Creator 2.0\", create=True)\n        block.add_new(0x01, \"SH\", \"Version2\")\n        assert \"Version2\" == ds[0x00091101].value\n        block = ds.private_block(0x0009, \"Creator 3.0\", create=True)\n        block.add_new(0x01, \"SH\", \"Version3\")\n        assert \"Creator 3.0\" == ds[0x00090012].value\n        assert \"Version3\" == ds[0x00091201].value\n\n    def test_delete_private_tag(self):\n        ds = Dataset()\n        ds.add_new(0x00080005, \"CS\", \"ISO_IR 100\")\n        ds.add_new(0x00090010, \"LO\", \"Creator 1.0\")\n        ds.add_new(0x00090011, \"LO\", \"Creator 2.0\")\n        ds.add_new(0x00091101, \"SH\", \"Version2\")\n\n        block = ds.private_block(0x0009, \"Creator 2.0\")\n        with pytest.raises(ValueError, match=\"Element offset must be less than 256\"):\n            del block[0x1001]\n        assert 1 in block\n        del block[0x01]\n        assert 1 not in block\n        with pytest.raises(KeyError):\n            del block[0x01]\n\n    def test_private_creators(self):\n        ds = Dataset()\n        ds.add_new(0x00080005, \"CS\", \"ISO_IR 100\")\n        ds.add_new(0x00090010, \"LO\", \"Creator 1.0\")\n        ds.add_new(0x00090011, \"LO\", \"Creator 2.0\")\n\n        with pytest.raises(ValueError, match=\"Group must be an odd number\"):\n            ds.private_creators(0x0008)\n        assert [\"Creator 1.0\", \"Creator 2.0\"] == ds.private_creators(0x0009)\n        assert not ds.private_creators(0x0011)\n\n    def test_non_contiguous_private_creators(self):\n        ds = Dataset()\n        ds.add_new(0x00080005, \"CS\", \"ISO_IR 100\")\n        ds.add_new(0x00090010, \"LO\", \"Creator 1.0\")\n        ds.add_new(0x00090020, \"LO\", \"Creator 2.0\")\n        ds.add_new(0x000900FF, \"LO\", \"Creator 3.0\")\n\n        assert [\"Creator 1.0\", \"Creator 2.0\", \"Creator 3.0\"] == ds.private_creators(\n            0x0009\n        )\n\n    def test_create_private_tag_after_removing_all(self):\n        # regression test for #1097 - make sure private blocks are updated\n        # after removing all private tags\n        ds = Dataset()\n        block = ds.private_block(0x000B, \"dog^1\", create=True)\n        block.add_new(0x01, \"SH\", \"Border Collie\")\n        block = ds.private_block(0x000B, \"dog^2\", create=True)\n        block.add_new(0x01, \"SH\", \"Poodle\")\n\n        ds.remove_private_tags()\n        block = ds.private_block(0x000B, \"dog^2\", create=True)\n        block.add_new(0x01, \"SH\", \"Poodle\")\n        assert len(ds) == 2\n        assert (0x000B0010) in ds\n        assert ds[0x000B0010].value == \"dog^2\"\n\n    def test_create_private_tag_after_removing_private_creator(self):\n        ds = Dataset()\n        block = ds.private_block(0x000B, \"dog^1\", create=True)\n        block.add_new(0x01, \"SH\", \"Border Collie\")\n\n        del ds[0x000B0010]\n        block = ds.private_block(0x000B, \"dog^1\", create=True)\n        block.add_new(0x02, \"SH\", \"Poodle\")\n        assert len(ds) == 3\n        assert ds[0x000B0010].value == \"dog^1\"\n\n        del ds[Tag(0x000B, 0x0010)]\n        block = ds.private_block(0x000B, \"dog^1\", create=True)\n        block.add_new(0x01, \"SH\", \"Pug\")\n        assert len(ds) == 3\n        assert ds[0x000B0010].value == \"dog^1\"\n\n        del ds[\"0x000b0010\"]\n        block = ds.private_block(0x000B, \"dog^1\", create=True)\n        block.add_new(0x01, \"SH\", \"Pug\")\n        assert len(ds) == 3\n        assert ds[0x000B0010].value == \"dog^1\"\n\n    def test_create_private_tag_after_removing_slice(self):\n        ds = Dataset()\n        block = ds.private_block(0x000B, \"dog^1\", create=True)\n        block.add_new(0x01, \"SH\", \"Border Collie\")\n        block = ds.private_block(0x000B, \"dog^2\", create=True)\n        block.add_new(0x01, \"SH\", \"Poodle\")\n\n        del ds[0x000B0010:0x000B1110]\n        block = ds.private_block(0x000B, \"dog^2\", create=True)\n        block.add_new(0x01, \"SH\", \"Poodle\")\n        assert len(ds) == 2\n        assert ds[0x000B0010].value == \"dog^2\"\n\n    def test_read_invalid_private_tag_number_as_un(self):\n        # regression test for #1347\n        ds = Dataset()\n        # not a valid private tag number nor a valid private creator\n        tag1 = Tag(0x70050000)  # this one caused a recursion\n        tag2 = Tag(0x70050005)\n        ds[tag1] = RawDataElement(tag1, None, 2, b\"\\x01\\x02\", 0, True, True)\n        ds[tag2] = RawDataElement(tag2, None, 2, b\"\\x03\\x04\", 0, True, True)\n        assert ds[tag1].value == b\"\\x01\\x02\"\n        assert ds[tag1].VR == \"UN\"\n        assert ds[tag2].value == b\"\\x03\\x04\"\n        assert ds[tag2].VR == \"UN\"\n\n    def test_invalid_private_creator(self):\n        # regression test for #1638\n        ds = Dataset()\n        ds.add_new(0x00250010, \"SL\", [13975, 13802])\n        ds.add_new(0x00250011, \"LO\", \"Valid Creator\")\n        ds.add_new(0x00251007, \"UN\", \"foobar\")\n        ds.add_new(0x00251107, \"UN\", \"foobaz\")\n        msg = r\"\\(0025,0010\\) '\\[13975, 13802]' is not a valid private creator\"\n        with pytest.warns(UserWarning, match=msg):\n            assert (\n                str(ds[0x00251007]) == \"(0025,1007) Private tag data\"\n                \"                    UN: 'foobar'\"\n            )\n        assert (\n            str(ds[0x00251107]) == \"(0025,1107) Private tag data\"\n            \"                    UN: 'foobaz'\"\n        )\n\n    def test_is_original_encoding(self):\n        \"\"\"Test Dataset.is_original_encoding\"\"\"\n        ds = Dataset()\n        assert not ds.is_original_encoding\n\n        # simulate reading\n        ds.SpecificCharacterSet = \"ISO_IR 100\"\n        ds.set_original_encoding(True, True, [\"latin_1\"])\n        assert not ds.is_original_encoding\n\n        ds._is_little_endian = True\n        ds._is_implicit_VR = True\n        assert ds.is_original_encoding\n        # changed character set\n        ds.SpecificCharacterSet = \"ISO_IR 192\"\n        assert not ds.is_original_encoding\n        # back to original character set\n        ds.SpecificCharacterSet = \"ISO_IR 100\"\n        assert ds.is_original_encoding\n        ds._is_little_endian = False\n        assert not ds.is_original_encoding\n        ds._is_little_endian = True\n        ds._is_implicit_VR = False\n        assert not ds.is_original_encoding\n\n        ds.set_original_encoding(True, True, None)\n        assert ds.original_character_set == [\"latin_1\"]\n\n    def test_original_charset_is_equal_to_charset_after_dcmread(self):\n        default_encoding_test_file = get_testdata_file(\"liver_1frame.dcm\")\n        non_default_encoding_test_file = get_testdata_file(\"CT_small.dcm\")\n\n        default_encoding_ds = dcmread(default_encoding_test_file)\n        non_default_encoding_ds = dcmread(non_default_encoding_test_file)\n\n        assert default_encoding_ds.original_character_set == \"iso8859\"\n        assert (\n            default_encoding_ds.original_character_set\n            == default_encoding_ds._character_set\n        )\n        assert (\n            default_encoding_ds.ReferencedSeriesSequence[0].original_character_set\n            == default_encoding_ds.ReferencedSeriesSequence[0]._character_set\n        )\n        assert (\n            default_encoding_ds.file_meta.original_character_set\n            == default_encoding_ds.file_meta._character_set\n        )\n        assert non_default_encoding_ds.original_character_set == [\"latin_1\"]\n        assert (\n            non_default_encoding_ds.original_character_set\n            == non_default_encoding_ds._character_set\n        )\n        assert (\n            non_default_encoding_ds.OtherPatientIDsSequence[0].original_character_set\n            == non_default_encoding_ds.OtherPatientIDsSequence[0]._character_set\n        )\n        assert (\n            non_default_encoding_ds.file_meta.original_character_set\n            == non_default_encoding_ds.file_meta._character_set\n        )\n\n    def test_remove_private_tags(self):\n        \"\"\"Test Dataset.remove_private_tags\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120  # 0000,0000\n        ds.SkipFrameRangeFlag = \"TEST\"  # 0008,9460\n        ds.add_new(0x00090001, \"PN\", \"CITIZEN^1\")\n        ds.add_new(0x00090010, \"PN\", \"CITIZEN^10\")\n        ds.PatientName = \"CITIZEN^Jan\"  # 0010,0010\n\n        ds.remove_private_tags()\n        assert Dataset() == ds[0x00090000:0x00100000]\n        assert \"CommandGroupLength\" in ds\n        assert \"SkipFrameRangeFlag\" in ds\n        assert \"PatientName\" in ds\n\n    def test_data_element(self):\n        \"\"\"Test Dataset.data_element.\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120\n        ds.SkipFrameRangeFlag = \"TEST\"\n        ds.add_new(0x00090001, \"PN\", \"CITIZEN^1\")\n        ds.BeamSequence = [Dataset()]\n        ds.BeamSequence[0].PatientName = \"ANON\"\n        assert ds[0x00000000] == ds.data_element(\"CommandGroupLength\")\n        assert ds[0x300A00B0] == ds.data_element(\"BeamSequence\")\n        assert ds.data_element(\"not an element keyword\") is None\n\n    def test_iterall(self):\n        \"\"\"Test Dataset.iterall\"\"\"\n        ds = Dataset()\n        ds.CommandGroupLength = 120\n        ds.SkipFrameRangeFlag = \"TEST\"\n        ds.add_new(0x00090001, \"PN\", \"CITIZEN^1\")\n        ds.BeamSequence = [Dataset()]\n        ds.BeamSequence[0].PatientName = \"ANON\"\n        elem_gen = ds.iterall()\n        assert ds.data_element(\"CommandGroupLength\") == next(elem_gen)\n        assert ds.data_element(\"SkipFrameRangeFlag\") == next(elem_gen)\n        assert ds[0x00090001] == next(elem_gen)\n        assert ds.data_element(\"BeamSequence\") == next(elem_gen)\n        assert ds.BeamSequence[0].data_element(\"PatientName\") == next(elem_gen)\n\n    def test_with(self):\n        \"\"\"Test Dataset.__enter__ and __exit__.\"\"\"\n        test_file = get_testdata_file(\"CT_small.dcm\")\n        with dcmread(test_file) as ds:\n            assert \"CompressedSamples^CT1\" == ds.PatientName\n\n    def test_exit_exception(self):\n        \"\"\"Test Dataset.__exit__ when an exception is raised.\"\"\"\n\n        class DSException(Dataset):\n            @property\n            def test(self):\n                raise ValueError(\"Random ex message!\")\n\n        with pytest.raises(ValueError, match=\"Random ex message!\"):\n            getattr(DSException(), \"test\")\n\n    def test_pixel_array_already_have(self):\n        \"\"\"Test Dataset._get_pixel_array when we already have the array\"\"\"\n        # Test that _pixel_array is returned unchanged unless required\n        fpath = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(fpath)\n        ds._pixel_id = get_image_pixel_ids(ds)\n        ds._pixel_array = \"Test Value\"\n        ds.convert_pixel_data()\n        assert get_image_pixel_ids(ds) == ds._pixel_id\n        assert \"Test Value\" == ds._pixel_array\n\n    @pytest.mark.skipif(not HAVE_NP, reason=\"Numpy is not available\")\n    def test_invalid_nr_frames_warns(self):\n        \"\"\"Test an invalid Number of Frames value shows an warning.\"\"\"\n        fpath = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(fpath)\n        ds.NumberOfFrames = 0\n        msg = r\"A value of '0' for \\(0028,0008\\) 'Number of Frames' is invalid\"\n        with pytest.warns(UserWarning, match=msg):\n            assert ds.pixel_array is not None\n\n    def test_pixel_array_id_changed(self, clear_pixel_data_handlers):\n        \"\"\"Test that we try to get new pixel data if the id has changed.\"\"\"\n        fpath = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(fpath)\n        ds.file_meta.TransferSyntaxUID = \"1.2.3.4\"\n        ds._pixel_id = 1234\n        assert id(ds.PixelData) != ds._pixel_id\n        ds._pixel_array = \"Test Value\"\n        msg = (\n            r\"Unable to decode the pixel data as a \\(0002,0010\\) 'Transfer Syntax UID' \"\n            \"value of '1.2.3.4' is not supported\"\n        )\n        with pytest.raises(NotImplementedError, match=msg):\n            ds.pixel_array\n\n        ds.pixel_array_options(use_v2_backend=True)\n        msg = \"Unable to decode pixel data with a transfer syntax UID of '1.2.3.4'\"\n        with pytest.raises(NotImplementedError, match=msg):\n            ds.convert_pixel_data()\n\n    def test_pixel_array_id_reset_on_delete(self):\n        \"\"\"Test _pixel_array and _pixel_id reset when deleting pixel data\"\"\"\n        fpath = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(fpath)\n        assert ds._pixel_id == {}\n        assert ds._pixel_array is None\n        ds._pixel_id = {\"SamplesPerPixel\": 3}\n        ds._pixel_array = True\n\n        del ds.PixelData\n        assert ds._pixel_id == {}\n        assert ds._pixel_array is None\n\n        ds.PixelData = b\"\\x00\\x01\"\n        ds._pixel_id = {\"SamplesPerPixel\": 3}\n        ds._pixel_array = True\n\n        del ds[\"PixelData\"]\n        assert ds._pixel_id == {}\n        assert ds._pixel_array is None\n\n        ds.PixelData = b\"\\x00\\x01\"\n        ds._pixel_id = {\"SamplesPerPixel\": 3}\n        ds._pixel_array = True\n\n        del ds[Tag(\"PixelData\")]\n        assert ds._pixel_id == {}\n        assert ds._pixel_array is None\n\n        ds.PixelData = b\"\\x00\\x01\"\n        ds._pixel_id = {\"SamplesPerPixel\": 3}\n        ds._pixel_array = True\n\n        del ds[0x7FE00010]\n        assert ds._pixel_id == {}\n        assert ds._pixel_array is None\n\n        ds.PixelData = b\"\\x00\\x01\"\n        ds._pixel_id = {\"SamplesPerPixel\": 3}\n        ds._pixel_array = True\n\n        del ds[0x7FE00000:0x7FE00012]\n        assert ds._pixel_id == {}\n        assert ds._pixel_array is None\n\n    def test_pixel_array_unknown_syntax(self):\n        \"\"\"Test that pixel_array for an unknown syntax raises exception.\"\"\"\n        ds = dcmread(get_testdata_file(\"CT_small.dcm\"))\n        ds.file_meta.TransferSyntaxUID = \"1.2.3.4\"\n        msg = (\n            r\"Unable to decode the pixel data as a \\(0002,0010\\) 'Transfer Syntax UID' \"\n            \"value of '1.2.3.4' is not supported\"\n        )\n        with pytest.raises(NotImplementedError, match=msg):\n            ds.pixel_array\n\n    def test_formatted_lines(self):\n        \"\"\"Test Dataset.formatted_lines\"\"\"\n        ds = Dataset()\n        with pytest.raises(StopIteration):\n            next(ds.formatted_lines())\n        ds.PatientName = \"CITIZEN^Jan\"\n        ds.BeamSequence = [Dataset()]\n        ds.BeamSequence[0].PatientID = \"JAN^Citizen\"\n        elem_format = \"%(tag)s\"\n        seq_format = \"%(name)s %(tag)s\"\n        indent_format = \">>>\"  # placeholder for future functionality\n\n        line_generator = ds.formatted_lines(\n            element_format=elem_format,\n            sequence_element_format=seq_format,\n            indent_format=indent_format,\n        )\n        assert \"(0010,0010)\" == next(line_generator)\n        assert \"Beam Sequence (300A,00B0)\" == next(line_generator)\n        assert \"(0010,0020)\" == next(line_generator)\n        with pytest.raises(StopIteration):\n            next(line_generator)\n\n    def test_formatted_lines_known_uid(self):\n        \"\"\"Test that the UID name is output when known.\"\"\"\n        ds = Dataset()\n        ds.TransferSyntaxUID = \"1.2.840.10008.1.2\"\n        assert \"Implicit VR Little Endian\" in str(ds)\n\n    def test_set_convert_private_elem_from_raw(self):\n        \"\"\"Test Dataset.__setitem__ with a raw private element\"\"\"\n        test_file = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(test_file, force=True)\n        # 'tag VR length value value_tell is_implicit_VR is_little_endian'\n        elem = RawDataElement((0x0043, 0x1029), \"OB\", 2, b\"\\x00\\x01\", 0, True, True)\n        ds.__setitem__((0x0043, 0x1029), elem)\n\n        assert b\"\\x00\\x01\" == ds[(0x0043, 0x1029)].value\n        assert isinstance(ds[(0x0043, 0x1029)], DataElement)\n\n    def test_top(self):\n        \"\"\"Test Dataset.top returns only top level str\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"CITIZEN^Jan\"\n        ds.BeamSequence = [Dataset()]\n        ds.BeamSequence[0].PatientID = \"JAN^Citizen\"\n        assert \"Patient's Name\" in ds.top()\n        assert \"Patient ID\" not in ds.top()\n\n    def test_trait_names(self):\n        \"\"\"Test Dataset.trait_names contains element keywords\"\"\"\n        test_file = get_testdata_file(\"CT_small.dcm\")\n        ds = dcmread(test_file, force=True)\n        names = ds.trait_names()\n        assert \"PatientName\" in names\n        assert \"save_as\" in names\n        assert \"PixelData\" in names\n\n    def test_walk(self):\n        \"\"\"Test Dataset.walk iterates through sequences\"\"\"\n\n        def test_callback(dataset, elem):\n            if elem.keyword == \"PatientID\":\n                dataset.PatientID = \"FIXED\"\n\n        ds = Dataset()\n        ds.PatientName = \"CITIZEN^Jan\"\n        ds.BeamSequence = [Dataset(), Dataset()]\n        ds.BeamSequence[0].PatientID = \"JAN^Citizen^Snr\"\n        ds.BeamSequence[0].PatientName = \"Some^Name\"\n        ds.BeamSequence[1].PatientID = \"JAN^Citizen^Jr\"\n        ds.BeamSequence[1].PatientName = \"Other^Name\"\n        ds.walk(test_callback, recursive=True)\n\n        assert \"CITIZEN^Jan\" == ds.PatientName\n        assert \"FIXED\" == ds.BeamSequence[0].PatientID\n        assert \"Some^Name\" == ds.BeamSequence[0].PatientName\n        assert \"FIXED\" == ds.BeamSequence[1].PatientID\n        assert \"Other^Name\" == ds.BeamSequence[1].PatientName\n\n    def test_update_with_dataset(self):\n        \"\"\"Regression test for #779\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"Test\"\n        ds2 = Dataset()\n        ds2.update(ds)\n        assert \"Test\" == ds2.PatientName\n\n        # Test sequences\n        ds2 = Dataset()\n        ds.BeamSequence = [Dataset(), Dataset()]\n        ds.BeamSequence[0].PatientName = \"TestA\"\n        ds.BeamSequence[1].PatientName = \"TestB\"\n\n        ds2.update(ds)\n        assert \"TestA\" == ds2.BeamSequence[0].PatientName\n        assert \"TestB\" == ds2.BeamSequence[1].PatientName\n\n        # Test overwrite\n        ds.PatientName = \"TestC\"\n        ds2.update(ds)\n        assert \"TestC\" == ds2.PatientName\n\n    def test_getitem_invalid_key_raises(self):\n        \"\"\"Test that __getitem__ raises KeyError on invalid key.\"\"\"\n        ds = Dataset()\n        with pytest.raises(KeyError, match=r\"'invalid'\"):\n            ds[\"invalid\"]\n\n    def test_setitem_invalid_key(self):\n        \"\"\"Test that __setitem__ behavior.\"\"\"\n        a = {}\n        with pytest.raises(KeyError, match=r\"'invalid'\"):\n            a[\"invalid\"]\n\n        ds = Dataset()\n        ds.PatientName = \"Citizen^Jan\"\n        msg = r\"Unable to convert the key 'invalid' to an element tag\"\n        with pytest.raises(ValueError, match=msg):\n            ds[\"invalid\"] = ds[\"PatientName\"]\n\n    def test_values(self):\n        \"\"\"Test Dataset.values().\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"Foo\"\n        ds.BeamSequence = [Dataset()]\n        ds.BeamSequence[0].PatientID = \"Bar\"\n\n        values = list(ds.values())\n        assert values[0] == ds[\"PatientName\"]\n        assert values[1] == ds[\"BeamSequence\"]\n        assert len(values) == 2\n\n    def test_pixel_rep(self):\n        \"\"\"Tests for Dataset._pixel_rep\"\"\"\n        ds = Dataset()\n        ds.PixelRepresentation = None\n        ds.BeamSequence = []\n\n        fp = io.BytesIO()\n        ds.save_as(fp, implicit_vr=True)\n        ds = dcmread(fp, force=True)\n        assert not hasattr(ds, \"_pixel_rep\")\n        assert ds.PixelRepresentation is None\n        assert ds.BeamSequence == []\n        # Attribute not set if Pixel Representation is None\n        assert not hasattr(ds, \"_pixel_rep\")\n\n        ds = dcmread(fp, force=True)\n        ds.PixelRepresentation = 0\n        assert ds.BeamSequence == []\n        assert ds._pixel_rep == 0\n\n        ds = dcmread(fp, force=True)\n        ds.PixelRepresentation = 1\n        assert ds.BeamSequence == []\n        assert ds._pixel_rep == 1\n\n        ds = Dataset()\n        ds.PixelRepresentation = 0\n        ds._set_pixel_representation(ds[\"PixelRepresentation\"])\n        assert ds._pixel_rep == 0\n\n    def test_update_raw(self):\n        \"\"\"Tests for Dataset.update_raw_element()\"\"\"\n        ds = Dataset()\n\n        msg = \"Either or both of 'vr' and 'value' are required\"\n        with pytest.raises(ValueError, match=msg):\n            ds.update_raw_element(None)\n\n        msg = \"Invalid VR value 'XX'\"\n        with pytest.raises(ValueError, match=msg):\n            ds.update_raw_element(None, vr=\"XX\")\n\n        msg = \"'value' must be bytes, not 'int'\"\n        with pytest.raises(TypeError, match=msg):\n            ds.update_raw_element(None, value=1234)\n\n        msg = r\"No element with tag \\(0010,0010\\) was found\"\n        with pytest.raises(KeyError, match=msg):\n            ds.update_raw_element(0x00100010, vr=\"US\")\n\n        ds.PatientName = \"Foo\"\n        msg = (\n            r\"The element with tag \\(0010,0010\\) has already been converted to a \"\n            \"'DataElement' instance, this method must be called earlier\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            ds.update_raw_element(0x00100010, vr=\"US\")\n\n        raw = RawDataElement(0x00100010, \"PN\", 4, b\"Fooo\", 0, True, True)\n        ds._dict[0x00100010] = raw\n        ds.update_raw_element(\"PatientName\", vr=\"US\")\n        assert ds.PatientName == [28486, 28527]\n        assert isinstance(ds[\"PatientName\"].VR, str)\n\n        raw = RawDataElement(0x00100010, \"PN\", 4, b\"Fooo\", 0, True, True)\n        ds._dict[0x00100010] = raw\n        ds.update_raw_element(0x00100010, value=b\"Bar\")\n        assert ds.PatientName == \"Bar\"\n\n    def test_is_decompressed(self):\n        \"\"\"Test Dataset.is_decompressed\"\"\"\n        ds = Dataset()\n        msg = (\n            \"Unable to determine the dataset's compression state as there's no \"\n            r\"\\(0002,0010\\) 'Transfer Syntax UID' element in the dataset's \"\n            \"'file_meta' or no 'file_meta' has been set\"\n        )\n        with pytest.raises(AttributeError, match=msg):\n            ds.is_decompressed\n\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\n        assert ds.is_decompressed is True\n        ds.file_meta.TransferSyntaxUID = JPEGBaseline8Bit\n        assert ds.is_decompressed is False\n\n    def test_pickle_lut(self):\n        \"\"\"Reversion test for #2160\"\"\"\n        ds = Dataset()\n        ds[\"LUTDescriptor\"] = DataElement(0x00283002, \"US\", [1, 2])\n        s = pickle.dumps({\"ds\": ds})\n        ds1 = pickle.loads(s)[\"ds\"]\n        assert ds == ds1\n        assert ds1.LUTDescriptor == [1, 2]\n\n\nclass TestDatasetSaveAs:\n    def test_no_transfer_syntax(self):\n        \"\"\"Test basic use of Dataset.save_as()\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"CITIZEN\"\n\n        # Requires implicit_vr\n        msg = (\n            \"Unable to determine the encoding to use for writing the dataset, \"\n            \"please set the file meta's Transfer Syntax UID or use the \"\n            \"'implicit_vr' and 'little_endian' arguments\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO())\n\n        # OK\n        ds.save_as(DicomBytesIO(), implicit_vr=True)\n\n    def test_little_endian_default(self):\n        \"\"\"Test that the default uses little endian.\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"CITIZEN\"\n        bs = io.BytesIO()\n        ds.save_as(bs, implicit_vr=True, little_endian=None)\n        assert ds[\"PatientName\"].tag.group == 0x0010\n        assert bs.getvalue()[:4] == b\"\\x10\\x00\\x10\\x00\"\n\n    def test_mismatch(self):\n        \"\"\"Test mismatch between transfer syntax and args.\"\"\"\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n\n        msg = (\n            \"The 'implicit_vr' value is not consistent with the required \"\n            \"VR encoding for the 'Implicit VR Little Endian' transfer syntax\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO(), implicit_vr=False, little_endian=False)\n\n        msg = (\n            \"The 'little_endian' value is not consistent with the required \"\n            \"endianness for the 'Implicit VR Little Endian' transfer syntax\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO(), implicit_vr=True, little_endian=False)\n\n    def test_priority_syntax(self):\n        \"\"\"Test prefer transfer syntax over dataset attributes.\"\"\"\n        ds = get_testdata_file(\"CT_small.dcm\", read=True)\n        assert not ds.original_encoding[0]\n        assert not ds._is_implicit_VR\n\n        # Explicit -> implicit\n        ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        fp = DicomBytesIO()\n        ds.save_as(fp)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding[0]\n        assert ds._is_implicit_VR\n\n        # Implicit -> explicit\n        fp = DicomBytesIO()\n        ds.file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\n        ds._is_implicit_VR = True\n        ds.save_as(fp)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert not ds.original_encoding[0]\n\n        ds = Dataset()\n        ds.preamble = b\"\\x00\" * 128\n        ds.PatientName = \"Foo\"\n        ds._is_little_endian = True\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = ExplicitVRBigEndian\n\n        # Big endian\n        fp = DicomBytesIO()\n        ds.save_as(fp)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert not ds.original_encoding[1]\n\n        # Little endian\n        ds._read_little = None\n        ds.file_meta.TransferSyntaxUID = ExplicitVRLittleEndian\n        fp = DicomBytesIO()\n        ds.save_as(fp)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding[1]\n\n    def test_priority_args(self):\n        \"\"\"Test prefer args over dataset attributes.\"\"\"\n        ds = get_testdata_file(\"CT_small.dcm\", read=True)\n        del ds.file_meta\n        assert not ds.original_encoding[0]\n        assert not ds._is_implicit_VR\n\n        # Explicit -> implicit\n        fp = DicomBytesIO()\n        ds.save_as(fp, implicit_vr=True)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding == (True, True)\n        assert ds._is_implicit_VR\n\n        # Implicit -> explicit\n        fp = DicomBytesIO()\n        ds.save_as(fp, implicit_vr=False)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding == (False, True)\n\n        ds = Dataset()\n        ds.preamble = b\"\\x00\" * 128\n        ds.PatientName = \"Foo\"\n        ds._is_little_endian = True\n\n        # Big endian\n        fp = DicomBytesIO()\n        ds.save_as(fp, implicit_vr=False, little_endian=False)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert not ds.original_encoding[1]\n\n        # Little endian\n        ds._read_little = None\n        fp = DicomBytesIO()\n        ds.save_as(fp, implicit_vr=False, little_endian=True)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding[1]\n\n    def test_priority_attr(self):\n        \"\"\"Test priority of dataset attrs over original.\"\"\"\n        ds = get_testdata_file(\"CT_small.dcm\", read=True)\n        del ds.file_meta\n        assert not ds.original_encoding[0]\n\n        # Explicit -> implicit\n        fp = DicomBytesIO()\n        ds._is_implicit_VR = True\n        ds.save_as(fp)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding == (True, True)\n\n        # Implicit -> explicit\n        fp = DicomBytesIO()\n        ds._is_implicit_VR = False\n        ds.save_as(fp)\n        fp.seek(0)\n        ds = dcmread(fp)\n        assert ds.original_encoding == (False, True)\n\n    def test_write_like_original(self):\n        ds = Dataset()\n        ds.SOPClassUID = \"1.2.3\"\n        ds.SOPInstanceUID = \"1.2.3.4\"\n        msg = (\n            \"'write_like_original' is deprecated and will be removed in v4.0, \"\n            \"please use 'enforce_file_format' instead\"\n        )\n\n        # Test kwarg - not enforce_file_format\n        with pytest.warns(DeprecationWarning, match=msg):\n            ds.save_as(DicomBytesIO(), write_like_original=False, implicit_vr=True)\n\n        # Test default - not enforce_file_format\n        ds.save_as(DicomBytesIO(), implicit_vr=True)\n\n    def test_save_as_compressed_no_encaps(self):\n        \"\"\"Test saving a compressed dataset with no encapsulation.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = JPEGBaseline8Bit\n        ds.PixelData = b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\"\n        ds[\"PixelData\"].VR = \"OB\"\n        msg = (\n            r\"The \\(7FE0,0010\\) 'Pixel Data' element value hasn't been encapsulated \"\n            \"as required for a compressed transfer syntax - see pydicom.encaps.\"\n            r\"encapsulate\\(\\) for more information\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(fp)\n\n    def test_save_as_compressed_encaps(self):\n        \"\"\"Test saving a compressed dataset with encapsulation.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = JPEGBaseline8Bit\n        ds.PixelData = encapsulate([b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\"])\n        ds[\"PixelData\"].VR = \"OB\"\n        ds.save_as(fp)\n\n    def test_save_as_no_pixel_data(self):\n        \"\"\"Test saving with no Pixel Data.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = JPEGBaseline8Bit\n        ds.save_as(fp)\n\n    def test_save_as_no_file_meta(self):\n        \"\"\"Test saving with no Transfer Syntax or file_meta.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.save_as(fp, implicit_vr=False)\n\n        del ds.file_meta\n        ds.save_as(fp, implicit_vr=False)\n\n    def test_save_as_private_transfer_syntax(self):\n        \"\"\"Test saving with a private transfer syntax.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = \"1.2.3.4.5.6\"\n\n        msg = (\n            \"The 'implicit_vr' and 'little_endian' arguments are required \"\n            \"when using a private transfer syntax\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(fp)\n\n        ds.save_as(fp, implicit_vr=False)\n\n    def test_save_as_set_little_implicit_with_tsyntax(self):\n        \"\"\"Test setting is_implicit_VR and is_little_endian from tsyntax\"\"\"\n        ds = Dataset()\n        ds.PatientName = \"CITIZEN\"\n        msg = (\n            \"Unable to determine the encoding to use for writing the dataset, \"\n            \"please set the file meta's Transfer Syntax UID or use the \"\n            \"'implicit_vr' and 'little_endian' arguments\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO())\n\n        # Test public transfer syntax OK\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = \"1.2.840.10008.1.2.1\"\n        ds.save_as(DicomBytesIO())\n\n    def test_save_as_undefined(self):\n        \"\"\"Test setting is_undefined_length correctly.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = JPEGBaseline8Bit\n        ds.PixelData = encapsulate([b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\"])\n        elem = ds[\"PixelData\"]\n        elem.VR = \"OB\"\n        # Compressed\n        # False to True\n        assert not elem.is_undefined_length\n        ds.save_as(fp)\n        assert elem.is_undefined_length\n        # True to True\n        ds.save_as(fp)\n        assert elem.is_undefined_length\n\n        # Uncompressed\n        ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        # True to False\n        ds.save_as(fp)\n        assert not elem.is_undefined_length\n        # False to False\n        ds.save_as(fp)\n        assert not elem.is_undefined_length\n\n    def test_save_as_undefined_private(self):\n        \"\"\"Test is_undefined_length unchanged with private tsyntax.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = \"1.2.3.4.5\"\n        ds.PixelData = encapsulate([b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\"])\n        elem = ds[\"PixelData\"]\n        elem.VR = \"OB\"\n        # Unchanged - False\n        assert not elem.is_undefined_length\n        ds.save_as(fp, implicit_vr=True)\n        assert not elem.is_undefined_length\n        # Unchanged - True\n        elem.is_undefined_length = True\n        ds.save_as(fp, implicit_vr=True)\n        assert elem.is_undefined_length\n\n    def test_save_as_undefined_no_tsyntax(self):\n        \"\"\"Test is_undefined_length unchanged with no tsyntax.\"\"\"\n        fp = DicomBytesIO()\n        ds = Dataset()\n        ds.PixelData = encapsulate([b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\"])\n        elem = ds[\"PixelData\"]\n        elem.VR = \"OB\"\n        # Unchanged - False\n        assert not elem.is_undefined_length\n        ds.save_as(fp, implicit_vr=False)\n        assert not elem.is_undefined_length\n        # Unchanged - True\n        elem.is_undefined_length = True\n        ds.save_as(fp, implicit_vr=False)\n        assert elem.is_undefined_length\n\n    def test_convert_big_little_endian_raises(self):\n        \"\"\"Test conversion between big <-> little endian raises exception\"\"\"\n        ds = Dataset()\n        ds._read_implicit = True\n        msg = (\n            r\"'Dataset.save_as\\(\\)' cannot be used to \"\n            r\"convert between little and big endian encoding. Please \"\n            r\"read the documentation for filewriter.dcmwrite\\(\\) \"\n            r\"if this is what you really want to do\"\n        )\n\n        # Test using is_little_endian\n        ds._is_implicit_VR = True\n        ds._is_little_endian = True\n        ds._read_little = False\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO())\n\n        ds._read_little = True\n        ds._is_little_endian = False\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO())\n\n        # Test using args\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO(), implicit_vr=True, little_endian=False)\n\n        ds._read_little = False\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO(), implicit_vr=True, little_endian=True)\n\n        # Test using transfer syntax\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO())\n\n        ds._read_little = True\n        ds.file_meta.TransferSyntaxUID = ExplicitVRBigEndian\n        with pytest.raises(ValueError, match=msg):\n            ds.save_as(DicomBytesIO())\n\n    def test_overwrite(self):\n        \"\"\"Test the overwrite argument\"\"\"\n        ds = dcmread(get_testdata_file(\"MR_small.dcm\"))\n        patient_name = ds.PatientName\n\n        with tempfile.TemporaryDirectory() as tdir:\n            p = Path(tdir) / \"foo.dcm\"\n            p.touch()\n\n            assert p.exists()\n\n            msg = r\"File exists: '(.*)foo.dcm'\"\n            with pytest.raises(FileExistsError, match=msg):\n                ds.save_as(p, overwrite=False)\n\n            ds.save_as(p, overwrite=True)\n            assert dcmread(p).PatientName == patient_name\n\n\nclass TestDatasetElements:\n    \"\"\"Test valid assignments of data elements\"\"\"\n\n    def setup_method(self):\n        self.ds = Dataset()\n        self.sub_ds1 = Dataset()\n        self.sub_ds2 = Dataset()\n\n    def test_sequence_assignment(self):\n        \"\"\"Assignment to SQ works only if valid Sequence assigned.\"\"\"\n        msg = r\"Sequence contents must be 'Dataset' instances\"\n        with pytest.raises(TypeError, match=msg):\n            self.ds.ConceptCodeSequence = [1, 2, 3]\n\n        # check also that assigning proper sequence *does* work\n        self.ds.ConceptCodeSequence = [self.sub_ds1, self.sub_ds2]\n        assert isinstance(self.ds.ConceptCodeSequence, Sequence)\n\n    def test_formatted_DS_assignment(self):\n        \"\"\"Assigning an auto-formatted decimal string works as expected.\"\"\"\n        ds = pydicom.Dataset()\n        ds.PatientWeight = DS(math.pi, auto_format=True)\n        assert ds.PatientWeight.auto_format\n        # Check correct 16-character string representation\n        assert str(ds.PatientWeight) == \"3.14159265358979\"\n\n    def test_ensure_file_meta(self):\n        assert not hasattr(self.ds, \"file_meta\")\n        self.ds.ensure_file_meta()\n        assert hasattr(self.ds, \"file_meta\")\n        assert not self.ds.file_meta\n\n    def test_validate_and_correct_file_meta(self):\n        file_meta = FileMetaDataset()\n        validate_file_meta(file_meta, enforce_standard=False)\n        with pytest.raises(AttributeError):\n            validate_file_meta(file_meta, enforce_standard=True)\n\n        file_meta = Dataset()  # not FileMetaDataset for bkwds-compat checks\n        file_meta.PatientID = \"PatientID\"\n        for enforce_standard in (True, False):\n            with pytest.raises(\n                ValueError,\n                match=r\"Only File Meta Information group \"\n                r\"\\(0002,eeee\\) elements may be present .*\",\n            ):\n                validate_file_meta(file_meta, enforce_standard=enforce_standard)\n\n        file_meta = FileMetaDataset()\n        file_meta.MediaStorageSOPClassUID = \"1.2.3\"\n        file_meta.MediaStorageSOPInstanceUID = \"1.2.4\"\n        # still missing TransferSyntaxUID\n        with pytest.raises(AttributeError):\n            validate_file_meta(file_meta, enforce_standard=True)\n\n        file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        validate_file_meta(file_meta, enforce_standard=True)\n\n        # check the default created values\n        assert b\"\\x00\\x01\" == file_meta.FileMetaInformationVersion\n        assert PYDICOM_IMPLEMENTATION_UID == file_meta.ImplementationClassUID\n        assert file_meta.ImplementationVersionName.startswith(\"PYDICOM \")\n\n        file_meta.ImplementationClassUID = \"1.2.3.4\"\n        file_meta.ImplementationVersionName = \"ACME LTD\"\n        validate_file_meta(file_meta, enforce_standard=True)\n        # check that existing values are left alone\n        assert \"1.2.3.4\" == file_meta.ImplementationClassUID\n        assert \"ACME LTD\" == file_meta.ImplementationVersionName\n\n\nclass TestFileDataset:\n    def setup_method(self):\n        self.test_file = get_testdata_file(\"CT_small.dcm\")\n\n    def test_pickle_raw_data(self):\n        ds = pydicom.dcmread(self.test_file)\n        s = pickle.dumps({\"ds\": ds})\n        ds1 = pickle.loads(s)[\"ds\"]\n        assert ds == ds1\n        assert ds1.Modality == \"CT\"\n\n    def test_pickle_data_elements(self):\n        ds = pydicom.dcmread(self.test_file)\n        for e in ds:\n            # make sure all data elements have been loaded\n            pass\n        s = pickle.dumps({\"ds\": ds})\n        ds1 = pickle.loads(s)[\"ds\"]\n        assert ds == ds1\n\n    def test_pickle_nested_sequence(self):\n        ds = pydicom.dcmread(get_testdata_file(\"nested_priv_SQ.dcm\"))\n        for e in ds:\n            # make sure all data elements have been loaded\n            pass\n        s = pickle.dumps({\"ds\": ds})\n        ds1 = pickle.loads(s)[\"ds\"]\n        assert ds == ds1\n\n    def test_pickle_modified(self):\n        \"\"\"Test pickling a modified dataset.\"\"\"\n        ds = pydicom.dcmread(self.test_file)\n        ds.PixelSpacing = [1.0, 1.0]\n        s = pickle.dumps({\"ds\": ds})\n        ds1 = pickle.loads(s)[\"ds\"]\n        assert ds == ds1\n        assert ds1.PixelSpacing == [1.0, 1.0]\n\n        ds1.PixelSpacing.insert(1, 2)\n        assert [1, 2, 1] == ds1.PixelSpacing\n\n    def test_equality_file_meta(self):\n        \"\"\"Dataset: equality ignores metadata\"\"\"\n        d = dcmread(self.test_file)\n        e = dcmread(self.test_file)\n        assert d == e\n\n        e._read_implicit = not e._read_implicit\n        assert d == e\n\n        e._read_implicit = not e._read_implicit\n        assert d == e\n        e._read_little = not e._read_little\n        assert d == e\n\n        e._read_little = not e._read_little\n        assert d == e\n        e.filename = \"test_filename.dcm\"\n        assert d == e\n\n    def test_creation_with_container(self):\n        \"\"\"FileDataset.__init__ works OK with a container such as gzip\"\"\"\n\n        class Dummy:\n            filename = \"/some/path/to/test\"\n\n        ds = Dataset()\n        ds.PatientName = \"CITIZEN^Jan\"\n        fds = FileDataset(Dummy(), ds)\n        assert \"/some/path/to/test\" == fds.filename\n\n    @pytest.mark.skipif(not HAVE_NP, reason=\"Numpy not available\")\n    def test_with_array(self):\n        \"\"\"Test Dataset within a numpy array\"\"\"\n        ds = get_testdata_file(\"CT_small.dcm\", read=True)\n        arr = numpy.array([ds])\n        assert arr[0].PatientName == ds.PatientName\n        assert arr.dtype == object\n        assert arr.shape == (1,)\n        assert arr.flags.writeable\n\n        arr[0].PatientName = \"Citizen^Jan\"\n        assert arr[0].PatientName == \"Citizen^Jan\"\n        assert \"BeamSequence\" not in arr[0]\n        arr[0].BeamSequence = []\n        assert arr[0].BeamSequence == []\n\n        elem = arr[0][\"PatientID\"]\n        assert isinstance(elem, DataElement)\n\n        b = DicomBytesIO()\n        arr[0].save_as(b)\n        b.seek(0)\n\n        out = dcmread(b)\n        assert out == arr[0]\n\n    def test_dataset_overrides_all_dict_attributes(self):\n        \"\"\"Ensure that we don't use inherited dict functionality\"\"\"\n        ds = Dataset()\n        di = dict()\n        expected_diff = {\n            \"fromkeys\",\n            \"__reversed__\",\n            \"__ror__\",\n            \"__ior__\",\n            \"__or__\",\n            \"__class_getitem__\",\n        }\n        if \"PyPy\" in python_implementation():\n            # __ror__ missing in <= 3.10.13\n            if \"__ror__\" not in dir(dict):\n                expected_diff.remove(\"__ror__\")\n\n        assert expected_diff == set(dir(di)) - set(dir(ds))\n\n    def test_copy_filelike_open(self):\n        f = open(get_testdata_file(\"CT_small.dcm\"), \"rb\")\n        ds = pydicom.dcmread(f)\n        assert not f.closed\n\n        ds_copy = copy.copy(ds)\n        assert ds.PatientName == ds_copy.PatientName\n        assert ds.filename.endswith(\"CT_small.dcm\")\n        assert ds.buffer is None\n        assert ds_copy.filename.endswith(\"CT_small.dcm\")\n        assert ds_copy.buffer is None\n        assert ds_copy == ds\n        assert ds_copy.fileobj_type == ds.fileobj_type\n\n        f.close()\n\n    def test_copy_filelike_closed(self):\n        f = open(get_testdata_file(\"CT_small.dcm\"), \"rb\")\n        ds = pydicom.dcmread(f)\n        f.close()\n        assert f.closed\n\n        ds_copy = copy.copy(ds)\n        assert ds.PatientName == ds_copy.PatientName\n        assert ds.filename.endswith(\"CT_small.dcm\")\n        assert ds.buffer is None\n        assert ds_copy.filename.endswith(\"CT_small.dcm\")\n        assert ds_copy.buffer is None\n        assert ds_copy == ds\n        assert ds_copy.fileobj_type == ds.fileobj_type\n\n    def test_copy_buffer_open(self):\n        with open(get_testdata_file(\"CT_small.dcm\"), \"rb\") as fb:\n            data = fb.read()\n        buff = io.BytesIO(data)\n        ds = pydicom.dcmread(buff)\n\n        ds_copy = copy.copy(ds)\n        assert ds.filename is None\n        assert ds.buffer is buff\n        assert ds_copy.filename is None\n        assert ds_copy == ds\n        # Shallow copy, the two buffers share the same object\n        assert ds_copy.buffer is ds.buffer\n        assert not ds.buffer.closed\n        assert ds_copy.fileobj_type == ds.fileobj_type\n\n    def test_copy_buffer_closed(self):\n        with open(get_testdata_file(\"CT_small.dcm\"), \"rb\") as fb:\n            data = fb.read()\n        buff = io.BytesIO(data)\n        ds = pydicom.dcmread(buff)\n        buff.close()\n        assert buff.closed\n\n        ds_copy = copy.copy(ds)\n        assert ds_copy == ds\n\n        assert ds.filename is None\n        assert ds.buffer is buff\n        assert ds.buffer.closed\n\n        assert ds_copy.filename is None\n        assert ds_copy.buffer is buff\n        assert ds_copy.buffer.closed\n\n        # Shallow copy, the two buffers share the same object\n        assert ds_copy.buffer is ds.buffer\n        assert ds_copy.fileobj_type == ds.fileobj_type\n\n    def test_deepcopy_filelike_open(self):\n        f = open(get_testdata_file(\"CT_small.dcm\"), \"rb\")\n        ds = pydicom.dcmread(f)\n        assert not f.closed\n\n        ds_copy = copy.deepcopy(ds)\n        assert ds.PatientName == ds_copy.PatientName\n        assert ds.filename.endswith(\"CT_small.dcm\")\n        assert ds.buffer is None\n        assert ds_copy.filename.endswith(\"CT_small.dcm\")\n        assert ds_copy.buffer is None\n        assert ds_copy == ds\n        assert ds_copy.fileobj_type == ds.fileobj_type\n\n        f.close()\n\n    def test_deepcopy_filelike_closed(self):\n        f = open(get_testdata_file(\"CT_small.dcm\"), \"rb\")\n        ds = pydicom.dcmread(f)\n        f.close()\n        assert f.closed\n\n        ds_copy = copy.deepcopy(ds)\n        assert ds.PatientName == ds_copy.PatientName\n        assert ds.filename.endswith(\"CT_small.dcm\")\n        assert ds.buffer is None\n        assert ds_copy.filename.endswith(\"CT_small.dcm\")\n        assert ds_copy.buffer is None\n        assert ds_copy == ds\n        assert ds_copy.fileobj_type == ds.fileobj_type\n\n    def test_deepcopy_buffer_open(self):\n        # regression test for #1147\n        with open(get_testdata_file(\"CT_small.dcm\"), \"rb\") as fb:\n            data = fb.read()\n        buff = io.BytesIO(data)\n        ds = pydicom.dcmread(buff)\n        assert not buff.closed\n\n        ds_copy = copy.deepcopy(ds)\n        assert ds_copy == ds\n\n        assert ds.filename is None\n        assert ds.buffer is buff\n        assert not ds.buffer.closed\n\n        assert ds_copy.filename is None\n        assert isinstance(ds_copy.buffer, io.BytesIO)\n        assert not ds_copy.buffer.closed\n\n        # Deep copy, the two buffers should not be the same object, but equal otherwise\n        assert ds.buffer is not ds_copy.buffer\n        assert ds.buffer.getvalue() == ds_copy.buffer.getvalue()\n\n    def test_deepcopy_buffer_closed(self):\n        # regression test for #1147\n        with open(get_testdata_file(\"CT_small.dcm\"), \"rb\") as fb:\n            data = fb.read()\n        buff = io.BytesIO(data)\n        ds = pydicom.dcmread(buff)\n        buff.close()\n        assert buff.closed\n        msg = (\n            r\"The ValueError exception '(.*)' occurred trying to deepcopy the \"\n            \"buffer-like the dataset was read from, the 'buffer' attribute will be \"\n            \"set to 'None' in the copied object\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            ds_copy = copy.deepcopy(ds)\n\n        assert ds_copy == ds\n\n        # Deep copy, the two buffers should not be the same object but\n        #   cannot copy a closed IOBase object\n        assert ds.filename is None\n        assert ds.buffer is buff\n        assert ds.buffer.closed\n\n        assert ds_copy.filename is None\n        assert ds_copy.buffer is None\n\n    def test_equality_with_different_metadata(self):\n        ds = dcmread(get_testdata_file(\"CT_small.dcm\"))\n        ds2 = copy.deepcopy(ds)\n        assert ds == ds2\n        ds.filename = \"foo.dcm\"\n        ds._read_implicit = not ds._read_implicit\n        ds._read_little = not ds._read_little\n        ds.file_meta = None\n        ds.preamble = None\n        assert ds == ds2\n\n    def test_deepcopy_without_filename(self):\n        \"\"\"Regression test for #1571.\"\"\"\n        file_meta = FileMetaDataset()\n        ds = FileDataset(\n            filename_or_obj=\"\", dataset={}, file_meta=file_meta, preamble=b\"\\0\" * 128\n        )\n        assert ds.filename == \"\"\n        assert ds.buffer is None\n\n        ds2 = copy.deepcopy(ds)\n        assert ds2.filename == \"\"\n        assert ds2.buffer is None\n\n    def test_deepcopy_dataset_subclass(self):\n        \"\"\"Regression test for #1813.\"\"\"\n\n        class MyDatasetSubclass(pydicom.Dataset):\n            pass\n\n        my_dataset_subclass = MyDatasetSubclass()\n\n        ds2 = copy.deepcopy(my_dataset_subclass)\n        assert ds2.__class__ is MyDatasetSubclass\n\n    def test_deepcopy_after_update(self):\n        \"\"\"Regression test for #1816\"\"\"\n        ds = Dataset()\n        ds.BeamSequence = []\n\n        ds2 = Dataset()\n        ds2.update(ds)\n\n        ds3 = copy.deepcopy(ds2)\n        assert ds3 == ds\n\n    def test_buffer(self):\n        \"\"\"Test the buffer attribute.\"\"\"\n        with open(get_testdata_file(\"CT_small.dcm\"), \"rb\") as fb:\n            buffer = io.BytesIO(fb.read())\n\n        ds = dcmread(buffer)\n        assert ds.filename is None\n        assert ds.buffer is buffer\n        assert ds.fileobj_type == io.BytesIO\n\n        # Deflated datasets get inflated to a DicomBytesIO() buffer\n        ds = dcmread(get_testdata_file(\"image_dfl.dcm\"))\n        assert ds.filename.endswith(\"image_dfl.dcm\")\n        assert isinstance(ds.buffer, DicomBytesIO)\n        assert ds.fileobj_type == DicomBytesIO\n\n\nclass TestDatasetOverlayArray:\n    \"\"\"Tests for Dataset.overlay_array().\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup the test datasets and the environment.\"\"\"\n        self.ds = dcmread(get_testdata_file(\"MR-SIEMENS-DICOM-WithOverlays.dcm\"))\n\n    @pytest.mark.skipif(HAVE_NP, reason=\"numpy is available\")\n    def test_possible_not_available(self):\n        \"\"\"Test with possible but not available handlers.\"\"\"\n        msg = r\"NumPy is required for FileDataset.overlay_array\\(\\)\"\n        with pytest.raises(ImportError, match=msg):\n            self.ds.overlay_array(0x6000)\n\n    @pytest.mark.skipif(not HAVE_NP, reason=\"numpy is not available\")\n    def test_possible_available(self):\n        \"\"\"Test with possible and available handlers.\"\"\"\n        assert isinstance(self.ds.overlay_array(0x6000), numpy.ndarray)\n\n\nclass TestFileMeta:\n    def test_type_exception(self):\n        \"\"\"Assigning ds.file_meta warns if not FileMetaDataset instance\"\"\"\n        ds = Dataset()\n        msg = \"'Dataset.file_meta' must be a 'FileMetaDataset' instance\"\n        with pytest.raises(TypeError, match=msg):\n            ds.file_meta = list()\n\n    def test_assign_file_meta(self):\n        \"\"\"Test can only set group 2 elements in File Meta\"\"\"\n        # FileMetaDataset accepts only group 2\n        file_meta = FileMetaDataset()\n        with pytest.raises(ValueError):\n            file_meta.PatientID = \"123\"\n\n        # No error if assign empty file meta\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n\n        # Can assign non-empty file_meta\n        ds_meta = FileMetaDataset()\n        ds_meta.TransferSyntaxUID = \"1.2\"\n        ds.file_meta = ds_meta\n\n        # Error on assigning file meta if any non-group 2\n        with pytest.raises(ValueError):\n            ds_meta.PatientName = \"x\"\n\n    def test_file_meta_conversion(self):\n        \"\"\"Test conversion to FileMetaDataset from Dataset.\"\"\"\n        ds = Dataset()\n        meta = Dataset()\n        meta.TransferSyntaxUID = \"1.2\"\n        ds.file_meta = meta\n        assert isinstance(ds.file_meta, FileMetaDataset)\n        assert ds.file_meta.TransferSyntaxUID == \"1.2\"\n\n        ds.file_meta = None\n        meta.PatientID = \"12345678\"\n        msg = (\n            r\"File meta datasets may only contain group 2 elements but the \"\n            r\"following elements are present: \\(0010,0020\\)\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            ds.file_meta = meta\n\n        assert ds.file_meta is None\n\n    def test_init_file_meta(self):\n        \"\"\"Check instantiation of FileMetaDataset\"\"\"\n        ds_meta = Dataset()\n        ds_meta.TransferSyntaxUID = \"1.2\"\n\n        # Accepts with group 2\n        file_meta = FileMetaDataset(ds_meta)\n        assert \"1.2\" == file_meta.TransferSyntaxUID\n\n        # Accepts dict\n        dict_meta = {0x20010: DataElement(0x20010, \"UI\", \"2.3\")}\n        file_meta = FileMetaDataset(dict_meta)\n        assert \"2.3\" == file_meta.TransferSyntaxUID\n\n        # Fails if not dict or Dataset\n        with pytest.raises(TypeError):\n            FileMetaDataset([\"1\", \"2\"])\n\n        # Raises error if init with non-group-2\n        ds_meta.PatientName = \"x\"\n        with pytest.raises(ValueError):\n            FileMetaDataset(ds_meta)\n\n        # None can be passed, to match Dataset behavior\n        FileMetaDataset(None)\n\n    def test_set_file_meta(self):\n        \"\"\"Check adding items to existing FileMetaDataset\"\"\"\n        file_meta = FileMetaDataset()\n\n        # Raise error if set non-group 2\n        with pytest.raises(ValueError):\n            file_meta.PatientID = \"1\"\n\n        # Check assigning via non-Tag\n        file_meta[0x20010] = DataElement(0x20010, \"UI\", \"2.3\")\n\n        # Check RawDataElement\n        file_meta[0x20010] = RawDataElement(0x20010, \"UI\", 4, \"1.23\", 0, True, True)\n\n    def test_del_file_meta(self):\n        \"\"\"Can delete the file_meta attribute\"\"\"\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        del ds.file_meta\n        assert not hasattr(ds, \"file_meta\")\n\n    def test_show_file_meta(self):\n        orig_show = pydicom.config.show_file_meta\n        pydicom.config.show_file_meta = True\n\n        ds = Dataset()\n        ds.file_meta = FileMetaDataset()\n        ds.file_meta.TransferSyntaxUID = \"1.2\"\n        ds.PatientName = \"test\"\n        shown = str(ds)\n\n        assert shown.startswith(\"Dataset.file_meta ---\")\n        assert shown.splitlines()[1].startswith(\"(0002,0010) Transfer Syntax UID\")\n\n        # Turn off file_meta display\n        pydicom.config.show_file_meta = False\n        shown = str(ds)\n        assert shown.startswith(\"(0010,0010) Patient's Name\")\n\n        pydicom.config.show_file_meta = orig_show\n\n    @pytest.mark.parametrize(\"copy_method\", [Dataset.copy, copy.copy, copy.deepcopy])\n    def test_copy(self, copy_method):\n        ds = Dataset()\n        ds.PatientName = \"John^Doe\"\n        ds.BeamSequence = [Dataset(), Dataset(), Dataset()]\n        ds.BeamSequence[0].Manufacturer = \"Linac, co.\"\n        ds.BeamSequence[1].Manufacturer = \"Linac and Sons, co.\"\n        ds.set_original_encoding(True, True, \"utf-8\")\n        ds_copy = copy_method(ds)\n        assert isinstance(ds_copy, Dataset)\n        assert len(ds_copy) == 2\n        assert ds_copy.PatientName == \"John^Doe\"\n        assert ds_copy.BeamSequence[0].Manufacturer == \"Linac, co.\"\n        assert ds_copy.BeamSequence[1].Manufacturer == \"Linac and Sons, co.\"\n        if copy_method == copy.deepcopy:\n            assert id(ds_copy.BeamSequence[0]) != id(ds.BeamSequence[0])\n        else:\n            # shallow copy\n            assert id(ds_copy.BeamSequence[0]) == id(ds.BeamSequence[0])\n        assert ds_copy.original_encoding == (True, True)\n        assert ds_copy.original_character_set == \"utf-8\"\n\n    def test_tsyntax_encoding(self):\n        file_meta = FileMetaDataset()\n        assert file_meta._tsyntax_encoding == (None, None)\n        file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        assert file_meta._tsyntax_encoding == (True, True)\n        file_meta.TransferSyntaxUID = \"1.2.3.4\"\n        assert file_meta._tsyntax_encoding == (None, None)\n        file_meta.TransferSyntaxUID = CTImageStorage\n        assert file_meta._tsyntax_encoding == (None, None)\n\n\n@pytest.fixture\ndef contains_raise():\n    \"\"\"Raise on invalid keys with Dataset.__contains__()\"\"\"\n    original = config.INVALID_KEY_BEHAVIOR\n    config.INVALID_KEY_BEHAVIOR = \"RAISE\"\n    yield\n    config.INVALID_KEY_BEHAVIOR = original\n\n\n@pytest.fixture\ndef contains_ignore():\n    \"\"\"Ignore invalid keys with Dataset.__contains__()\"\"\"\n    original = config.INVALID_KEY_BEHAVIOR\n    config.INVALID_KEY_BEHAVIOR = \"IGNORE\"\n    yield\n    config.INVALID_KEY_BEHAVIOR = original\n\n\n@pytest.fixture\ndef contains_warn():\n    \"\"\"Warn on invalid keys with Dataset.__contains__()\"\"\"\n    original = config.INVALID_KEY_BEHAVIOR\n    config.INVALID_KEY_BEHAVIOR = \"WARN\"\n    yield\n    config.INVALID_KEY_BEHAVIOR = original\n\n\nCAMEL_CASE = (\n    [  # Shouldn't warn\n        \"Rows\",\n        \"_Rows\",\n        \"Rows_\",\n        \"rows\",\n        \"_rows\",\n        \"__rows\",\n        \"rows_\",\n        \"ro_ws\",\n        \"rowds\",\n        \"BitsStored\",\n        \"bits_Stored\",\n        \"Bits_Stored\",\n        \"bits_stored\",\n        \"_BitsStored\",\n        \"BitsStored_\",\n        \"B_itsStored\",\n        \"BitsS_tored\",\n        \"12LeadECG\",\n        \"file_meta\",\n        \"filename\",\n        \"is_implicit_VR\",\n        \"is_little_endian\",\n        \"preamble\",\n        \"timestamp\",\n        \"fileobj_type\",\n        \"patient_records\",\n        \"_parent_encoding\",\n        \"_dict\",\n        \"read_encoding\",\n        \"_private_blocks\",\n        \"default_element_format\",\n        \"indent_chars\",\n        \"default_sequence_element_format\",\n        \"PatientName\",\n    ],\n    [  # Should warn\n        \"bitsStored\",\n        \"BitSStored\",\n        \"TwelveLeadECG\",\n        \"SOPInstanceUId\",\n        \"PatientsName\",\n        \"Rowds\",\n    ],\n)\n\n\n@pytest.fixture\ndef setattr_raise():\n    \"\"\"Raise on Dataset.__setattr__() close keyword matches.\"\"\"\n    original = config.INVALID_KEYWORD_BEHAVIOR\n    config.INVALID_KEYWORD_BEHAVIOR = \"RAISE\"\n    yield\n    config.INVALID_KEYWORD_BEHAVIOR = original\n\n\n@pytest.fixture\ndef setattr_ignore():\n    \"\"\"Ignore Dataset.__setattr__() close keyword matches.\"\"\"\n    original = config.INVALID_KEYWORD_BEHAVIOR\n    config.INVALID_KEYWORD_BEHAVIOR = \"IGNORE\"\n    yield\n    config.INVALID_KEYWORD_BEHAVIOR = original\n\n\n@pytest.fixture\ndef setattr_warn():\n    \"\"\"Warn on Dataset.__setattr__() close keyword matches.\"\"\"\n    original = config.INVALID_KEYWORD_BEHAVIOR\n    config.INVALID_KEYWORD_BEHAVIOR = \"WARN\"\n    yield\n    config.INVALID_KEYWORD_BEHAVIOR = original\n\n\ndef test_setattr_warns(setattr_warn):\n    \"\"\" \"Test warnings for Dataset.__setattr__() for close matches.\"\"\"\n    with assert_no_warning():\n        ds = Dataset()\n\n    deprecations = (\n        \"is_implicit_VR\",\n        \"is_little_endian\",\n        \"read_encoding\",\n    )\n\n    for s in CAMEL_CASE[0]:\n        if s in deprecations:\n            with pytest.warns(DeprecationWarning):\n                val = getattr(ds, s, None)\n                setattr(ds, s, val)\n        else:\n            with assert_no_warning():\n                val = getattr(ds, s, None)\n                setattr(ds, s, val)\n\n    for s in CAMEL_CASE[1]:\n        msg = (\n            r\"Camel case attribute '\" + s + r\"' used which is not in the \"\n            r\"element keyword data dictionary\"\n        )\n        with pytest.warns(UserWarning, match=msg):\n            val = getattr(ds, s, None)\n            setattr(ds, s, None)\n\n\ndef test_setattr_raises(setattr_raise):\n    \"\"\" \"Test exceptions for Dataset.__setattr__() for close matches.\"\"\"\n    with assert_no_warning():\n        ds = Dataset()\n\n    deprecations = (\n        \"is_implicit_VR\",\n        \"is_little_endian\",\n        \"read_encoding\",\n    )\n\n    for s in CAMEL_CASE[0]:\n        if s in deprecations:\n            with pytest.warns(DeprecationWarning):\n                val = getattr(ds, s, None)\n                setattr(ds, s, val)\n        else:\n            with assert_no_warning():\n                val = getattr(ds, s, None)\n                setattr(ds, s, val)\n\n    for s in CAMEL_CASE[1]:\n        msg = (\n            r\"Camel case attribute '\" + s + r\"' used which is not in the \"\n            r\"element keyword data dictionary\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            val = getattr(ds, s, None)\n            setattr(ds, s, None)\n\n\ndef test_setattr_ignore(setattr_ignore):\n    \"\"\"Test config.INVALID_KEYWORD_BEHAVIOR = 'IGNORE'\"\"\"\n    with assert_no_warning():\n        ds = Dataset()\n\n    deprecations = (\n        \"is_implicit_VR\",\n        \"is_little_endian\",\n        \"read_encoding\",\n    )\n\n    for s in CAMEL_CASE[0]:\n        if s in deprecations:\n            with pytest.warns(DeprecationWarning):\n                val = getattr(ds, s, None)\n                setattr(ds, s, val)\n        else:\n            with assert_no_warning():\n                val = getattr(ds, s, None)\n                setattr(ds, s, val)\n\n    ds = Dataset()\n    for s in CAMEL_CASE[1]:\n        with assert_no_warning():\n            getattr(ds, s, None)\n            setattr(ds, s, None)\n\n\nclass TestDatasetWithBufferedData:\n    \"\"\"Tests for datasets with buffered element values\"\"\"\n\n    def test_pickle_bytesio(self):\n        \"\"\"Test pickling a dataset with buffered element value\"\"\"\n        b = io.BytesIO(b\"\\x00\\x01\")\n        ds = Dataset()\n        ds.PixelData = b\n\n        s = pickle.dumps({\"ds\": ds})\n        ds1 = pickle.loads(s)[\"ds\"]\n        assert ds.PixelData is not ds1.PixelData\n        assert ds == ds1\n\n    def test_pickle_bufferedreader_raises(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            with open(f\"{tdir}/foo.bin\", \"wb\") as f:\n                f.write(b\"\\x00\\x01\\x02\\x03\\x04\")\n\n            with open(f\"{tdir}/foo.bin\", \"rb\") as f:\n                ds = Dataset()\n                ds.PixelData = f\n\n            with pytest.raises(TypeError, match=\"cannot\"):\n                pickle.dumps({\"ds\": ds})\n\n    def test_copy_bytesio(self):\n        \"\"\"Test copy.copy() for dataset with buffered element value\"\"\"\n        b = io.BytesIO(b\"\\x00\\x01\")\n        ds = Dataset()\n        ds.PixelData = b\n        ds2 = copy.copy(ds)\n        assert isinstance(ds2.PixelData, io.BytesIO)\n        assert ds2.PixelData is ds.PixelData\n\n    def test_copy_bytesio_closed(self):\n        \"\"\"Test copy.copy() for dataset with buffered element value\"\"\"\n        b = io.BytesIO(b\"\\x00\\x01\")\n        ds = Dataset()\n        ds.PixelData = b\n        b.close()\n\n        ds2 = copy.copy(ds)\n        assert isinstance(ds2.PixelData, io.BytesIO)\n        assert ds2.PixelData is ds.PixelData\n        assert ds2.PixelData.closed\n\n    def test_copy_bufferedreader(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            with open(f\"{tdir}/foo.bin\", \"wb\") as f:\n                f.write(b\"\\x00\\x01\\x02\\x03\\x04\")\n\n            with open(f\"{tdir}/foo.bin\", \"rb\") as f:\n                ds = Dataset()\n                ds.PixelData = f\n\n            ds2 = copy.copy(ds)\n            assert isinstance(ds2.PixelData, io.BufferedReader)\n            assert ds2.PixelData is ds.PixelData\n\n    def test_copy_bufferedreader_closed(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            with open(f\"{tdir}/foo.bin\", \"wb\") as f:\n                f.write(b\"\\x00\\x01\\x02\\x03\\x04\")\n\n            with open(f\"{tdir}/foo.bin\", \"rb\") as f:\n                ds = Dataset()\n                ds.PixelData = f\n\n            ds.PixelData.close()\n\n            ds2 = copy.copy(ds)\n            assert isinstance(ds2.PixelData, io.BufferedReader)\n            assert ds2.PixelData is ds.PixelData\n            assert ds2.PixelData.closed\n\n    def test_deepcopy_bytesio(self):\n        \"\"\"Test copy.deepcopy() for dataset with buffered element value\"\"\"\n        b = io.BytesIO(b\"\\x00\\x01\")\n        ds = Dataset()\n        ds.PixelData = b\n\n        ds2 = copy.deepcopy(ds)\n        assert isinstance(ds2.PixelData, io.BytesIO)\n        assert ds2.PixelData is not ds.PixelData\n        assert ds2.PixelData.getvalue() == ds.PixelData.getvalue()\n\n    def test_deepcopy_bytesio_closed(self):\n        \"\"\"Test copy.deepcopy() for dataset with buffered element value\"\"\"\n        b = io.BytesIO(b\"\\x00\\x01\")\n        ds = Dataset()\n        ds.PixelData = b\n        b.close()\n\n        msg = (\n            r\"Error deepcopying the buffered element \\(7FE0,0010\\) 'Pixel Data': I/O \"\n            \"operation on closed file\"\n        )\n        with pytest.raises(ValueError, match=msg):\n            copy.deepcopy(ds)\n\n    def test_deepcopy_bufferedreader_raises(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            with open(f\"{tdir}/foo.bin\", \"wb\") as f:\n                f.write(b\"\\x00\\x01\\x02\\x03\\x04\")\n\n            with open(f\"{tdir}/foo.bin\", \"rb\") as f:\n                ds = Dataset()\n                ds.PixelData = f\n\n        msg = (\n            r\"Error deepcopying the buffered element \\(7FE0,0010\\) 'Pixel Data': \"\n            r\"cannot (.*)BufferedReader'\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            copy.deepcopy(ds)\n\n\n@pytest.fixture\ndef use_future():\n    original = config._use_future\n    config._use_future = True\n    yield\n    config._use_future = original\n\n\nclass TestFuture:\n    def test_save_as_write_like_original_raises(self, use_future):\n        ds = Dataset()\n        msg = (\n            \"'write_like_original' is no longer accepted as a positional or \"\n            \"keyword argument, use 'enforce_file_format' instead\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            ds.save_as(None, write_like_original=False)\n\n    def test_save_as_endianness_conversion(self, use_future):\n        ds = Dataset()\n        ds._is_implicit_VR = True\n        ds._is_little_endian = True\n\n        ds._read_implicit = False\n        ds._read_little = False\n        ds.save_as(DicomBytesIO())\n\n        ds._read_little = True\n        ds._is_little_endian = False\n        ds.save_as(DicomBytesIO())\n\n    def test_is_original_encoding(self, use_future):\n        ds = Dataset()\n        ds._read_charset = [\"latin_1\"]\n        ds.SpecificCharacterSet = \"ISO_IR 100\"\n        assert ds.is_original_encoding\n        ds.SpecificCharacterSet = \"ISO_IR 192\"\n        assert not ds.is_original_encoding\n        ds.SpecificCharacterSet = \"ISO_IR 100\"\n        assert ds.is_original_encoding\n\n    def test_is_little_endian_raises(self, use_future):\n        ds = Dataset()\n        assert not hasattr(ds, \"_is_little_endian\")\n\n        msg = \"'Dataset' object has no attribute 'is_little_endian'\"\n        with pytest.raises(AttributeError, match=msg):\n            ds.is_little_endian = True\n\n        ds._is_little_endian = True\n        with pytest.raises(AttributeError, match=msg):\n            ds.is_little_endian\n\n    def test_is_implicit_VR_raises(self, use_future):\n        ds = Dataset()\n        assert not hasattr(ds, \"_is_implicit_VR\")\n\n        msg = \"'Dataset' object has no attribute 'is_implicit_VR'\"\n        with pytest.raises(AttributeError, match=msg):\n            ds.is_implicit_VR = True\n\n        ds._is_implicit_VR = True\n        with pytest.raises(AttributeError, match=msg):\n            ds.is_implicit_VR\n\n    def test_read_encoding_raises(self, use_future):\n        ds = Dataset()\n        msg = \"'Dataset' object has no attribute 'read_encoding'\"\n        with pytest.raises(AttributeError, match=msg):\n            ds.read_encoding = \"foo\"\n\n        ds._read_charset = \"foo\"\n        with pytest.raises(AttributeError, match=msg):\n            ds.read_encoding\n\n    def test_read_implicit_vr_raises(self, use_future):\n        ds = Dataset()\n        ds._read_implicit = True\n        msg = \"'Dataset' object has no attribute 'read_implicit_vr'\"\n        with pytest.raises(AttributeError, match=msg):\n            ds.read_implicit_vr\n\n    def test_read_little_endian_raises(self, use_future):\n        ds = Dataset()\n        ds._read_little = True\n        msg = \"'Dataset' object has no attribute 'read_little_endian'\"\n        with pytest.raises(AttributeError, match=msg):\n            ds.read_little_endian\n\n    def test_slice(self, use_future):\n        ds = Dataset()\n        ds._is_little_endian = True\n        ds._is_implicit_VR = True\n\n        ds = ds[0x00080001:]\n        assert not hasattr(ds, \"_is_little_endian\")\n        assert not hasattr(ds, \"_is_implicit_VR\")\n\n    def test_convert_pixel_data(self, use_future):\n        msg = \"'Dataset' object has no attribute 'convert_pixel_data'\"\n        with pytest.raises(AttributeError, match=msg):\n            Dataset().convert_pixel_data()\n\n    def test_pixel_array_options(self, use_future):\n        msg = (\n            r\"Dataset.pixel_array_options\\(\\) got an unexpected \"\n            \"keyword argument 'use_v2_backend'\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            Dataset().pixel_array_options(use_v2_backend=True)\n\n    def test_decompress(self, use_future):\n        msg = (\n            r\"Dataset.decompress\\(\\) got an unexpected \"\n            \"keyword argument 'handler_name'\"\n        )\n        with pytest.raises(TypeError, match=msg):\n            Dataset().decompress(handler_name=\"foo\")\n",
  "GT_file_code": {
    "modified_testcases/test_helpers.py": "# Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n\"\"\"Helper functions for tests.\"\"\"\n\nimport warnings\nfrom contextlib import contextmanager\nfrom collections.abc import Generator\n\n\n@contextmanager\ndef assert_no_warning() -> Generator:\n    \"\"\"Assert that no warning is issued.\n    Any warning will be handled as an error.\n    \"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\")\n        yield\n"
  },
  "GT_src_dict": {
    "modified_testcases/test_helpers.py": {
      "assert_no_warning": {
        "code": "def assert_no_warning() -> Generator:\n    \"\"\"Assert that no warning is issued during the execution of a block of code. Any warning raised within the context will be treated as an error, allowing for strict verification of code behavior without warnings.\n\nReturns:\n    Generator: A context manager that can be used with the `with` statement, providing a temporary scope in which warnings are handled as exceptions.\n\nDependencies:\n    - `warnings`: This module is utilized to control the verbosity of warning messages; specifically, it's used to catch and filter warnings. The `warnings.catch_warnings()` context manager allows for the modification of warning behavior locally.\n    - `warnings.simplefilter(\"error\")`: This line sets the filter for warnings to \"error,\" meaning any warning raised will raise an exception instead.\n\nUsage:\n    Use this context manager to ensure that a block of code does not produce any warnings, which might indicate potential issues in the code being tested.\"\"\"\n    'Assert that no warning is issued.\\n    Any warning will be handled as an error.\\n    '\n    with warnings.catch_warnings():\n        warnings.simplefilter('error')\n        yield",
        "docstring": "Assert that no warning is issued during the execution of a block of code. Any warning raised within the context will be treated as an error, allowing for strict verification of code behavior without warnings.\n\nReturns:\n    Generator: A context manager that can be used with the `with` statement, providing a temporary scope in which warnings are handled as exceptions.\n\nDependencies:\n    - `warnings`: This module is utilized to control the verbosity of warning messages; specifically, it's used to catch and filter warnings. The `warnings.catch_warnings()` context manager allows for the modification of warning behavior locally.\n    - `warnings.simplefilter(\"error\")`: This line sets the filter for warnings to \"error,\" meaning any warning raised will raise an exception instead.\n\nUsage:\n    Use this context manager to ensure that a block of code does not produce any warnings, which might indicate potential issues in the code being tested.",
        "signature": "def assert_no_warning() -> Generator:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {},
  "PRD": "# PROJECT NAME: pydicom-test_dataset\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 modified_testcases/\n    \u2514\u2500\u2500 test_helpers.py\n        \u2514\u2500\u2500 assert_no_warning\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module is designed to validate, manipulate, and test the functionality of DICOM dataset objects in the `pydicom` library, focusing on ensuring strict adherence to DICOM standards for data handling and file formatting. It provides capabilities for creating, storing, and managing DICOM attributes and elements, including support for nested sequences, private tags, and pixel data operations. The module enables functionality for reading, writing, and validating DICOM metadata, enforcing data consistency, and handling errors or anomalies in DICOM datasets. For developers, it ensures robust interaction with DICOM files, allowing for deep copying, serialization (e.g., pickling), validation of file meta information, equality comparisons, and compliance with low-level encoding and transfer syntax requirements. Overall, it supports seamless handling of DICOM datasets across a variety of use cases, from creation to validation, while maintaining flexibility and extensibility.\n\n## FILE 1: modified_testcases/test_helpers.py\n\n- FUNCTION NAME: assert_no_warning\n  - SIGNATURE: def assert_no_warning() -> Generator:\n  - DOCSTRING: \n```python\n\"\"\"\nAssert that no warning is issued during the execution of a block of code. Any warning raised within the context will be treated as an error, allowing for strict verification of code behavior without warnings.\n\nReturns:\n    Generator: A context manager that can be used with the `with` statement, providing a temporary scope in which warnings are handled as exceptions.\n\nDependencies:\n    - `warnings`: This module is utilized to control the verbosity of warning messages; specifically, it's used to catch and filter warnings. The `warnings.catch_warnings()` context manager allows for the modification of warning behavior locally.\n    - `warnings.simplefilter(\"error\")`: This line sets the filter for warnings to \"error,\" meaning any warning raised will raise an exception instead.\n\nUsage:\n    Use this context manager to ensure that a block of code does not produce any warnings, which might indicate potential issues in the code being tested.\n\"\"\"\n```\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "modified_testcases/test_helpers.py": "\"\"\"Helper functions for tests.\"\"\"\nimport warnings\nfrom contextlib import contextmanager\nfrom collections.abc import Generator"
  },
  "call_tree": {
    "modified_testcases/test_dataset.py:TestDataset:test_for_stray_raw_data_element": {
      "modified_testcases/test_dataset.py:TestDataset:_reset": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_attribute_error_in_property_correct_debug": {
      "modified_testcases/test_dataset.py:TestDataset:Foo": {},
      "modified_testcases/test_dataset.py:TestDataset:test": {
        "modified_testcases/test_dataset.py:TestDataset:bar": {}
      }
    },
    "modified_testcases/test_dataset.py:TestDataset:test_tag_exception_print": {
      "modified_testcases/test_dataset.py:BadRepr:__repr__": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_tag_exception_walk": {
      "modified_testcases/test_dataset.py:TestDataset:func": {
        "modified_testcases/test_dataset.py:TestDataset:callback": {
          "modified_testcases/test_dataset.py:BadRepr:__repr__": {}
        }
      }
    },
    "modified_testcases/test_dataset.py:TestDataset:test_contains_ignore": {
      "modified_testcases/test_helpers.py:assert_no_warning": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_dir_subclass": {
      "modified_testcases/test_dataset.py:TestDataset:DSP": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_equality_inheritance": {
      "modified_testcases/test_dataset.py:TestDataset:DatasetPlus": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_property": {
      "modified_testcases/test_dataset.py:TestDataset:DSPlus": {},
      "modified_testcases/test_dataset.py:TestDataset:test": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_exit_exception": {
      "modified_testcases/test_dataset.py:TestDataset:DSException": {},
      "modified_testcases/test_dataset.py:TestDataset:test": {}
    },
    "modified_testcases/test_dataset.py:TestDataset:test_walk": {
      "modified_testcases/test_dataset.py:TestDataset:test_callback": {}
    },
    "modified_testcases/test_dataset.py:TestFileDataset:test_creation_with_container": {
      "modified_testcases/test_dataset.py:TestFileDataset:Dummy": {}
    },
    "modified_testcases/test_dataset.py:TestFileDataset:test_deepcopy_dataset_subclass": {
      "modified_testcases/test_dataset.py:TestFileDataset:MyDatasetSubclass": {}
    },
    "modified_testcases/test_dataset.py:test_setattr_warns": {
      "modified_testcases/test_helpers.py:assert_no_warning": {}
    },
    "modified_testcases/test_dataset.py:test_setattr_raises": {
      "modified_testcases/test_helpers.py:assert_no_warning": {}
    },
    "modified_testcases/test_dataset.py:test_setattr_ignore": {
      "modified_testcases/test_helpers.py:assert_no_warning": {}
    }
  }
}