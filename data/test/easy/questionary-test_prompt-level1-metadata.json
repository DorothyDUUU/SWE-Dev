{
  "dir_path": "/app/questionary",
  "package_name": "questionary",
  "sample_name": "questionary-test_prompt",
  "src_dir": "examples/",
  "test_dir": "tests/",
  "test_file": "modified_testcases/test_prompt.py",
  "test_code": "import unittest\nfrom questionary.prompt import prompt, PromptParameterException\nfrom tests.utils import patched_prompt\n\nclass TestPrompt(unittest.TestCase):\n\n    def test_missing_message(self):\n        with self.assertRaises(PromptParameterException):\n            prompt([{\"type\": \"confirm\", \"name\": \"continue\", \"default\": True}])\n\n    def test_missing_type(self):\n        with self.assertRaises(PromptParameterException):\n            prompt(\n                [\n                    {\n                        \"message\": \"Do you want to continue?\",\n                        \"name\": \"continue\",\n                        \"default\": True,\n                    }\n                ]\n            )\n\n    def test_missing_name(self):\n        with self.assertRaises(PromptParameterException):\n            prompt(\n                [\n                    {\n                        \"type\": \"confirm\",\n                        \"message\": \"Do you want to continue?\",\n                        \"default\": True,\n                    }\n                ]\n            )\n\n    def test_invalid_question_type(self):\n        with self.assertRaises(ValueError):\n            prompt(\n                [\n                    {\n                        \"type\": \"mytype\",\n                        \"message\": \"Do you want to continue?\",\n                        \"name\": \"continue\",\n                        \"default\": True,\n                    }\n                ]\n            )\n\n    def test_missing_print_message(self):\n        \"\"\"Test 'print' raises exception if missing 'message'\"\"\"\n        with self.assertRaises(PromptParameterException):\n            prompt(\n                [\n                    {\n                        \"name\": \"test\",\n                        \"type\": \"print\",\n                    }\n                ]\n            )\n\n    def test_print_no_name(self):\n        \"\"\"'print' type doesn't require a name so it\n        should not throw PromptParameterException\"\"\"\n        questions = [{\"type\": \"print\", \"message\": \"Hello World\"}]\n        result = patched_prompt(questions, \"\")\n        self.assertEqual(result, {})\n\n    def test_print_with_name(self):\n        \"\"\"'print' type should return {name: None} when name is provided\"\"\"\n        questions = [{\"name\": \"hello\", \"type\": \"print\", \"message\": \"Hello World\"}]\n        result = patched_prompt(questions, \"\")\n        self.assertEqual(result, {\"hello\": None})\n\nif __name__ == \"__main__\":\n    unittest.main()",
  "GT_file_code": {
    "questionary/prompt.py": "from typing import Any\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Union\n\nfrom prompt_toolkit.output import ColorDepth\n\nfrom questionary import utils\nfrom questionary.constants import DEFAULT_KBI_MESSAGE\nfrom questionary.prompts import AVAILABLE_PROMPTS\nfrom questionary.prompts import prompt_by_name\nfrom questionary.prompts.common import print_formatted_text\n\n\nclass PromptParameterException(ValueError):\n    \"\"\"Received a prompt with a missing parameter.\"\"\"\n\n    def __init__(self, message: str, errors: Optional[BaseException] = None) -> None:\n        # Call the base class constructor with the parameters it needs\n        super().__init__(f\"You must provide a `{message}` value\", errors)\n\n\ndef prompt(\n    questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]],\n    answers: Optional[Mapping[str, Any]] = None,\n    patch_stdout: bool = False,\n    true_color: bool = False,\n    kbi_msg: str = DEFAULT_KBI_MESSAGE,\n    **kwargs: Any,\n) -> Dict[str, Any]:\n    \"\"\"Prompt the user for input on all the questions.\n\n    Catches keyboard interrupts and prints a message.\n\n    See :func:`unsafe_prompt` for possible question configurations.\n\n    Args:\n        questions: A list of question configs representing questions to\n                   ask. A question config may have the following options:\n\n                   * type - The type of question.\n                   * name - An ID for the question (to identify it in the answers :obj:`dict`).\n\n                   * when - Callable to conditionally show the question. This function\n                     takes a :obj:`dict` representing the current answers.\n\n                   * filter - Function that the answer is passed to. The return value of this\n                     function is saved as the answer.\n\n                   Additional options correspond to the parameter names for\n                   particular question types.\n\n        answers: Default answers.\n\n        patch_stdout: Ensure that the prompt renders correctly if other threads\n                      are printing to stdout.\n\n        kbi_msg: The message to be printed on a keyboard interrupt.\n        true_color: Use true color output.\n\n        color_depth: Color depth to use. If ``true_color`` is set to true then this\n                     value is ignored.\n\n        type: Default ``type`` value to use in question config.\n        filter: Default ``filter`` value to use in question config.\n        name: Default ``name`` value to use in question config.\n        when: Default ``when`` value to use in question config.\n        default: Default ``default`` value to use in question config.\n        kwargs: Additional options passed to every question.\n\n    Returns:\n        Dictionary of question answers.\n    \"\"\"\n\n    try:\n        return unsafe_prompt(questions, answers, patch_stdout, true_color, **kwargs)\n    except KeyboardInterrupt:\n        print(kbi_msg)\n        return {}\n\n\ndef unsafe_prompt(\n    questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]],\n    answers: Optional[Mapping[str, Any]] = None,\n    patch_stdout: bool = False,\n    true_color: bool = False,\n    **kwargs: Any,\n) -> Dict[str, Any]:\n    \"\"\"Prompt the user for input on all the questions.\n\n    Won't catch keyboard interrupts.\n\n    Args:\n        questions: A list of question configs representing questions to\n                   ask. A question config may have the following options:\n\n                   * type - The type of question.\n                   * name - An ID for the question (to identify it in the answers :obj:`dict`).\n\n                   * when - Callable to conditionally show the question. This function\n                     takes a :obj:`dict` representing the current answers.\n\n                   * filter - Function that the answer is passed to. The return value of this\n                     function is saved as the answer.\n\n                   Additional options correspond to the parameter names for\n                   particular question types.\n\n        answers: Default answers.\n\n        patch_stdout: Ensure that the prompt renders correctly if other threads\n                      are printing to stdout.\n\n        true_color: Use true color output.\n\n        color_depth: Color depth to use. If ``true_color`` is set to true then this\n                     value is ignored.\n\n        type: Default ``type`` value to use in question config.\n        filter: Default ``filter`` value to use in question config.\n        name: Default ``name`` value to use in question config.\n        when: Default ``when`` value to use in question config.\n        default: Default ``default`` value to use in question config.\n        kwargs: Additional options passed to every question.\n\n    Returns:\n        Dictionary of question answers.\n\n    Raises:\n        KeyboardInterrupt: raised on keyboard interrupt\n    \"\"\"\n\n    if isinstance(questions, dict):\n        questions = [questions]\n\n    answers = dict(answers or {})\n\n    for question_config in questions:\n        question_config = dict(question_config)\n        # import the question\n        if \"type\" not in question_config:\n            raise PromptParameterException(\"type\")\n        # every type except 'print' needs a name\n        if \"name\" not in question_config and question_config[\"type\"] != \"print\":\n            raise PromptParameterException(\"name\")\n\n        _kwargs = kwargs.copy()\n        _kwargs.update(question_config)\n\n        _type = _kwargs.pop(\"type\")\n        _filter = _kwargs.pop(\"filter\", None)\n        name = _kwargs.pop(\"name\", None) if _type == \"print\" else _kwargs.pop(\"name\")\n        when = _kwargs.pop(\"when\", None)\n\n        if true_color:\n            _kwargs[\"color_depth\"] = ColorDepth.TRUE_COLOR\n\n        if when:\n            # at least a little sanity check!\n            if callable(question_config[\"when\"]):\n                try:\n                    if not question_config[\"when\"](answers):\n                        continue\n                except Exception as exception:\n                    raise ValueError(\n                        f\"Problem in 'when' check of \" f\"{name} question: {exception}\"\n                    ) from exception\n            else:\n                raise ValueError(\n                    \"'when' needs to be function that accepts a dict argument\"\n                )\n\n        # handle 'print' type\n        if _type == \"print\":\n            try:\n                message = _kwargs.pop(\"message\")\n            except KeyError as e:\n                raise PromptParameterException(\"message\") from e\n\n            # questions can take 'input' arg but print_formatted_text does not\n            # Remove 'input', if present, to avoid breaking during tests\n            _kwargs.pop(\"input\", None)\n\n            print_formatted_text(message, **_kwargs)\n            if name:\n                answers[name] = None\n            continue\n\n        choices = question_config.get(\"choices\")\n        if choices is not None and callable(choices):\n            calculated_choices = choices(answers)\n            question_config[\"choices\"] = calculated_choices\n            kwargs[\"choices\"] = calculated_choices\n\n        if _filter:\n            # at least a little sanity check!\n            if not callable(_filter):\n                raise ValueError(\n                    \"'filter' needs to be function that accepts an argument\"\n                )\n\n        if callable(question_config.get(\"default\")):\n            _kwargs[\"default\"] = question_config[\"default\"](answers)\n\n        create_question_func = prompt_by_name(_type)\n\n        if not create_question_func:\n            raise ValueError(\n                f\"No question type '{_type}' found. \"\n                f\"Known question types are {', '.join(AVAILABLE_PROMPTS)}.\"\n            )\n\n        missing_args = list(utils.missing_arguments(create_question_func, _kwargs))\n        if missing_args:\n            raise PromptParameterException(missing_args[0])\n\n        question = create_question_func(**_kwargs)\n\n        answer = question.unsafe_ask(patch_stdout)\n\n        if answer is not None:\n            if _filter:\n                try:\n                    answer = _filter(answer)\n                except Exception as exception:\n                    raise ValueError(\n                        f\"Problem processing 'filter' of {name} \"\n                        f\"question: {exception}\"\n                    ) from exception\n            answers[name] = answer\n\n    return answers\n"
  },
  "GT_src_dict": {
    "questionary/prompt.py": {
      "prompt": {
        "code": "def prompt(questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]], answers: Optional[Mapping[str, Any]]=None, patch_stdout: bool=False, true_color: bool=False, kbi_msg: str=DEFAULT_KBI_MESSAGE, **kwargs: Any) -> Dict[str, Any]:\n    \"\"\"Prompts the user for input on a series of questions, handling keyboard interrupts gracefully.\n\nThis function accepts a collection of question configurations, which define the type, name, and behavior of each prompt. It delegates the actual prompting to the `unsafe_prompt` function and catches `KeyboardInterrupt` exceptions, displaying a specified message to the user.\n\nParameters:\n- questions (Union[Dict[str, Any], Iterable[Mapping[str, Any]]]): A dictionary or iterable of dictionaries containing question configurations. Each configuration can specify options like `type`, `name`, `when` (a callable for conditional prompting), and `filter` (a function for processing answers).\n- answers (Optional[Mapping[str, Any]]): A mapping of default answers that can be pre-filled in the prompts.\n- patch_stdout (bool, default: False): If True, ensures correct rendering of the prompt when other threads print to stdout.\n- true_color (bool, default: False): If True, enables true color output.\n- kbi_msg (str, default: DEFAULT_KBI_MESSAGE): The message to display on keyboard interrupts, sourced from the `DEFAULT_KBI_MESSAGE` constant.\n- **kwargs (Any): Additional parameters passed to each question configuration.\n\nReturns:\n- Dict[str, Any]: A dictionary containing user-provided answers for the prompted questions.\n\nRaises:\n- KeyboardInterrupt: Catching a keyboard interrupt allows the function to print a defined message and return an empty dictionary instead of raising the exception.\"\"\"\n    'Prompt the user for input on all the questions.\\n\\n    Catches keyboard interrupts and prints a message.\\n\\n    See :func:`unsafe_prompt` for possible question configurations.\\n\\n    Args:\\n        questions: A list of question configs representing questions to\\n                   ask. A question config may have the following options:\\n\\n                   * type - The type of question.\\n                   * name - An ID for the question (to identify it in the answers :obj:`dict`).\\n\\n                   * when - Callable to conditionally show the question. This function\\n                     takes a :obj:`dict` representing the current answers.\\n\\n                   * filter - Function that the answer is passed to. The return value of this\\n                     function is saved as the answer.\\n\\n                   Additional options correspond to the parameter names for\\n                   particular question types.\\n\\n        answers: Default answers.\\n\\n        patch_stdout: Ensure that the prompt renders correctly if other threads\\n                      are printing to stdout.\\n\\n        kbi_msg: The message to be printed on a keyboard interrupt.\\n        true_color: Use true color output.\\n\\n        color_depth: Color depth to use. If ``true_color`` is set to true then this\\n                     value is ignored.\\n\\n        type: Default ``type`` value to use in question config.\\n        filter: Default ``filter`` value to use in question config.\\n        name: Default ``name`` value to use in question config.\\n        when: Default ``when`` value to use in question config.\\n        default: Default ``default`` value to use in question config.\\n        kwargs: Additional options passed to every question.\\n\\n    Returns:\\n        Dictionary of question answers.\\n    '\n    try:\n        return unsafe_prompt(questions, answers, patch_stdout, true_color, **kwargs)\n    except KeyboardInterrupt:\n        print(kbi_msg)\n        return {}",
        "docstring": "Prompts the user for input on a series of questions, handling keyboard interrupts gracefully.\n\nThis function accepts a collection of question configurations, which define the type, name, and behavior of each prompt. It delegates the actual prompting to the `unsafe_prompt` function and catches `KeyboardInterrupt` exceptions, displaying a specified message to the user.\n\nParameters:\n- questions (Union[Dict[str, Any], Iterable[Mapping[str, Any]]]): A dictionary or iterable of dictionaries containing question configurations. Each configuration can specify options like `type`, `name`, `when` (a callable for conditional prompting), and `filter` (a function for processing answers).\n- answers (Optional[Mapping[str, Any]]): A mapping of default answers that can be pre-filled in the prompts.\n- patch_stdout (bool, default: False): If True, ensures correct rendering of the prompt when other threads print to stdout.\n- true_color (bool, default: False): If True, enables true color output.\n- kbi_msg (str, default: DEFAULT_KBI_MESSAGE): The message to display on keyboard interrupts, sourced from the `DEFAULT_KBI_MESSAGE` constant.\n- **kwargs (Any): Additional parameters passed to each question configuration.\n\nReturns:\n- Dict[str, Any]: A dictionary containing user-provided answers for the prompted questions.\n\nRaises:\n- KeyboardInterrupt: Catching a keyboard interrupt allows the function to print a defined message and return an empty dictionary instead of raising the exception.",
        "signature": "def prompt(questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]], answers: Optional[Mapping[str, Any]]=None, patch_stdout: bool=False, true_color: bool=False, kbi_msg: str=DEFAULT_KBI_MESSAGE, **kwargs: Any) -> Dict[str, Any]:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {
    "questionary/prompt.py:prompt": {
      "questionary/prompt.py": {
        "unsafe_prompt": {
          "code": "def unsafe_prompt(questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]], answers: Optional[Mapping[str, Any]]=None, patch_stdout: bool=False, true_color: bool=False, **kwargs: Any) -> Dict[str, Any]:\n    \"\"\"Prompt the user for input on all the questions.\n\n    Won't catch keyboard interrupts.\n\n    Args:\n        questions: A list of question configs representing questions to\n                   ask. A question config may have the following options:\n\n                   * type - The type of question.\n                   * name - An ID for the question (to identify it in the answers :obj:`dict`).\n\n                   * when - Callable to conditionally show the question. This function\n                     takes a :obj:`dict` representing the current answers.\n\n                   * filter - Function that the answer is passed to. The return value of this\n                     function is saved as the answer.\n\n                   Additional options correspond to the parameter names for\n                   particular question types.\n\n        answers: Default answers.\n\n        patch_stdout: Ensure that the prompt renders correctly if other threads\n                      are printing to stdout.\n\n        true_color: Use true color output.\n\n        color_depth: Color depth to use. If ``true_color`` is set to true then this\n                     value is ignored.\n\n        type: Default ``type`` value to use in question config.\n        filter: Default ``filter`` value to use in question config.\n        name: Default ``name`` value to use in question config.\n        when: Default ``when`` value to use in question config.\n        default: Default ``default`` value to use in question config.\n        kwargs: Additional options passed to every question.\n\n    Returns:\n        Dictionary of question answers.\n\n    Raises:\n        KeyboardInterrupt: raised on keyboard interrupt\n    \"\"\"\n    if isinstance(questions, dict):\n        questions = [questions]\n    answers = dict(answers or {})\n    for question_config in questions:\n        question_config = dict(question_config)\n        if 'type' not in question_config:\n            raise PromptParameterException('type')\n        if 'name' not in question_config and question_config['type'] != 'print':\n            raise PromptParameterException('name')\n        _kwargs = kwargs.copy()\n        _kwargs.update(question_config)\n        _type = _kwargs.pop('type')\n        _filter = _kwargs.pop('filter', None)\n        name = _kwargs.pop('name', None) if _type == 'print' else _kwargs.pop('name')\n        when = _kwargs.pop('when', None)\n        if true_color:\n            _kwargs['color_depth'] = ColorDepth.TRUE_COLOR\n        if when:\n            if callable(question_config['when']):\n                try:\n                    if not question_config['when'](answers):\n                        continue\n                except Exception as exception:\n                    raise ValueError(f\"Problem in 'when' check of {name} question: {exception}\") from exception\n            else:\n                raise ValueError(\"'when' needs to be function that accepts a dict argument\")\n        if _type == 'print':\n            try:\n                message = _kwargs.pop('message')\n            except KeyError as e:\n                raise PromptParameterException('message') from e\n            _kwargs.pop('input', None)\n            print_formatted_text(message, **_kwargs)\n            if name:\n                answers[name] = None\n            continue\n        choices = question_config.get('choices')\n        if choices is not None and callable(choices):\n            calculated_choices = choices(answers)\n            question_config['choices'] = calculated_choices\n            kwargs['choices'] = calculated_choices\n        if _filter:\n            if not callable(_filter):\n                raise ValueError(\"'filter' needs to be function that accepts an argument\")\n        if callable(question_config.get('default')):\n            _kwargs['default'] = question_config['default'](answers)\n        create_question_func = prompt_by_name(_type)\n        if not create_question_func:\n            raise ValueError(f\"No question type '{_type}' found. Known question types are {', '.join(AVAILABLE_PROMPTS)}.\")\n        missing_args = list(utils.missing_arguments(create_question_func, _kwargs))\n        if missing_args:\n            raise PromptParameterException(missing_args[0])\n        question = create_question_func(**_kwargs)\n        answer = question.unsafe_ask(patch_stdout)\n        if answer is not None:\n            if _filter:\n                try:\n                    answer = _filter(answer)\n                except Exception as exception:\n                    raise ValueError(f\"Problem processing 'filter' of {name} question: {exception}\") from exception\n            answers[name] = answer\n    return answers",
          "docstring": "Prompt the user for input on all the questions.\n\nWon't catch keyboard interrupts.\n\nArgs:\n    questions: A list of question configs representing questions to\n               ask. A question config may have the following options:\n\n               * type - The type of question.\n               * name - An ID for the question (to identify it in the answers :obj:`dict`).\n\n               * when - Callable to conditionally show the question. This function\n                 takes a :obj:`dict` representing the current answers.\n\n               * filter - Function that the answer is passed to. The return value of this\n                 function is saved as the answer.\n\n               Additional options correspond to the parameter names for\n               particular question types.\n\n    answers: Default answers.\n\n    patch_stdout: Ensure that the prompt renders correctly if other threads\n                  are printing to stdout.\n\n    true_color: Use true color output.\n\n    color_depth: Color depth to use. If ``true_color`` is set to true then this\n                 value is ignored.\n\n    type: Default ``type`` value to use in question config.\n    filter: Default ``filter`` value to use in question config.\n    name: Default ``name`` value to use in question config.\n    when: Default ``when`` value to use in question config.\n    default: Default ``default`` value to use in question config.\n    kwargs: Additional options passed to every question.\n\nReturns:\n    Dictionary of question answers.\n\nRaises:\n    KeyboardInterrupt: raised on keyboard interrupt",
          "signature": "def unsafe_prompt(questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]], answers: Optional[Mapping[str, Any]]=None, patch_stdout: bool=False, true_color: bool=False, **kwargs: Any) -> Dict[str, Any]:",
          "type": "Function",
          "class_signature": null
        }
      }
    }
  },
  "PRD": "# PROJECT NAME: questionary-test_prompt\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 questionary/\n    \u2514\u2500\u2500 prompt.py\n        \u2514\u2500\u2500 prompt\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThis module is designed to validate and test the behavior of a customizable questionnaire or interactive prompting system by ensuring input configurations meet expected standards and handle errors gracefully. It provides functionalities to test various scenarios, including missing or invalid parameters, unsupported question types, and edge cases for specific prompt configurations like print-type prompts. By performing rigorous validation, the module helps developers ensure that their use of the prompting library is robust, reliable, and user-friendly. This reduces the risk of runtime errors, improves error-handling consistency, and ensures a seamless experience for end-users interacting with the questionnaire tool.\n\n## FILE 1: questionary/prompt.py\n\n- FUNCTION NAME: prompt\n  - SIGNATURE: def prompt(questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]], answers: Optional[Mapping[str, Any]]=None, patch_stdout: bool=False, true_color: bool=False, kbi_msg: str=DEFAULT_KBI_MESSAGE, **kwargs: Any) -> Dict[str, Any]:\n  - DOCSTRING: \n```python\n\"\"\"\nPrompts the user for input on a series of questions, handling keyboard interrupts gracefully.\n\nThis function accepts a collection of question configurations, which define the type, name, and behavior of each prompt. It delegates the actual prompting to the `unsafe_prompt` function and catches `KeyboardInterrupt` exceptions, displaying a specified message to the user.\n\nParameters:\n- questions (Union[Dict[str, Any], Iterable[Mapping[str, Any]]]): A dictionary or iterable of dictionaries containing question configurations. Each configuration can specify options like `type`, `name`, `when` (a callable for conditional prompting), and `filter` (a function for processing answers).\n- answers (Optional[Mapping[str, Any]]): A mapping of default answers that can be pre-filled in the prompts.\n- patch_stdout (bool, default: False): If True, ensures correct rendering of the prompt when other threads print to stdout.\n- true_color (bool, default: False): If True, enables true color output.\n- kbi_msg (str, default: DEFAULT_KBI_MESSAGE): The message to display on keyboard interrupts, sourced from the `DEFAULT_KBI_MESSAGE` constant.\n- **kwargs (Any): Additional parameters passed to each question configuration.\n\nReturns:\n- Dict[str, Any]: A dictionary containing user-provided answers for the prompted questions.\n\nRaises:\n- KeyboardInterrupt: Catching a keyboard interrupt allows the function to print a defined message and return an empty dictionary instead of raising the exception.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - questionary/prompt.py:unsafe_prompt\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "questionary/prompt.py": "from typing import Any\nfrom typing import Dict\nfrom typing import Iterable\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Union\nfrom prompt_toolkit.output import ColorDepth\nfrom questionary import utils\nfrom questionary.constants import DEFAULT_KBI_MESSAGE\nfrom questionary.prompts import AVAILABLE_PROMPTS\nfrom questionary.prompts import prompt_by_name\nfrom questionary.prompts.common import print_formatted_text\n\nclass PromptParameterException(ValueError):\n    \"\"\"Received a prompt with a missing parameter.\"\"\"\n\n    def __init__(self, message: str, errors: Optional[BaseException]=None) -> None:\n        super().__init__(f'You must provide a `{message}` value', errors)\n\ndef unsafe_prompt(questions: Union[Dict[str, Any], Iterable[Mapping[str, Any]]], answers: Optional[Mapping[str, Any]]=None, patch_stdout: bool=False, true_color: bool=False, **kwargs: Any) -> Dict[str, Any]:\n    \"\"\"Prompt the user for input on all the questions.\n\n    Won't catch keyboard interrupts.\n\n    Args:\n        questions: A list of question configs representing questions to\n                   ask. A question config may have the following options:\n\n                   * type - The type of question.\n                   * name - An ID for the question (to identify it in the answers :obj:`dict`).\n\n                   * when - Callable to conditionally show the question. This function\n                     takes a :obj:`dict` representing the current answers.\n\n                   * filter - Function that the answer is passed to. The return value of this\n                     function is saved as the answer.\n\n                   Additional options correspond to the parameter names for\n                   particular question types.\n\n        answers: Default answers.\n\n        patch_stdout: Ensure that the prompt renders correctly if other threads\n                      are printing to stdout.\n\n        true_color: Use true color output.\n\n        color_depth: Color depth to use. If ``true_color`` is set to true then this\n                     value is ignored.\n\n        type: Default ``type`` value to use in question config.\n        filter: Default ``filter`` value to use in question config.\n        name: Default ``name`` value to use in question config.\n        when: Default ``when`` value to use in question config.\n        default: Default ``default`` value to use in question config.\n        kwargs: Additional options passed to every question.\n\n    Returns:\n        Dictionary of question answers.\n\n    Raises:\n        KeyboardInterrupt: raised on keyboard interrupt\n    \"\"\"\n    if isinstance(questions, dict):\n        questions = [questions]\n    answers = dict(answers or {})\n    for question_config in questions:\n        question_config = dict(question_config)\n        if 'type' not in question_config:\n            raise PromptParameterException('type')\n        if 'name' not in question_config and question_config['type'] != 'print':\n            raise PromptParameterException('name')\n        _kwargs = kwargs.copy()\n        _kwargs.update(question_config)\n        _type = _kwargs.pop('type')\n        _filter = _kwargs.pop('filter', None)\n        name = _kwargs.pop('name', None) if _type == 'print' else _kwargs.pop('name')\n        when = _kwargs.pop('when', None)\n        if true_color:\n            _kwargs['color_depth'] = ColorDepth.TRUE_COLOR\n        if when:\n            if callable(question_config['when']):\n                try:\n                    if not question_config['when'](answers):\n                        continue\n                except Exception as exception:\n                    raise ValueError(f\"Problem in 'when' check of {name} question: {exception}\") from exception\n            else:\n                raise ValueError(\"'when' needs to be function that accepts a dict argument\")\n        if _type == 'print':\n            try:\n                message = _kwargs.pop('message')\n            except KeyError as e:\n                raise PromptParameterException('message') from e\n            _kwargs.pop('input', None)\n            print_formatted_text(message, **_kwargs)\n            if name:\n                answers[name] = None\n            continue\n        choices = question_config.get('choices')\n        if choices is not None and callable(choices):\n            calculated_choices = choices(answers)\n            question_config['choices'] = calculated_choices\n            kwargs['choices'] = calculated_choices\n        if _filter:\n            if not callable(_filter):\n                raise ValueError(\"'filter' needs to be function that accepts an argument\")\n        if callable(question_config.get('default')):\n            _kwargs['default'] = question_config['default'](answers)\n        create_question_func = prompt_by_name(_type)\n        if not create_question_func:\n            raise ValueError(f\"No question type '{_type}' found. Known question types are {', '.join(AVAILABLE_PROMPTS)}.\")\n        missing_args = list(utils.missing_arguments(create_question_func, _kwargs))\n        if missing_args:\n            raise PromptParameterException(missing_args[0])\n        question = create_question_func(**_kwargs)\n        answer = question.unsafe_ask(patch_stdout)\n        if answer is not None:\n            if _filter:\n                try:\n                    answer = _filter(answer)\n                except Exception as exception:\n                    raise ValueError(f\"Problem processing 'filter' of {name} question: {exception}\") from exception\n            answers[name] = answer\n    return answers"
  },
  "call_tree": {
    "modified_testcases/test_prompt.py:TestPrompt:test_invalid_question_type": {
      "questionary/prompt.py:prompt": {
        "questionary/prompt.py:unsafe_prompt": {
          "questionary/prompts/__init__.py:prompt_by_name": {}
        }
      }
    },
    "modified_testcases/test_prompt.py:TestPrompt:test_missing_message": {
      "questionary/prompt.py:prompt": {
        "questionary/prompt.py:unsafe_prompt": {
          "questionary/prompts/__init__.py:prompt_by_name": {},
          "questionary/utils.py:missing_arguments": {
            "questionary/utils.py:required_arguments": {
              "questionary/utils.py:default_values_of": {},
              "questionary/utils.py:arguments_of": {}
            }
          },
          "questionary/prompt.py:PromptParameterException:__init__": {}
        }
      }
    },
    "modified_testcases/test_prompt.py:TestPrompt:test_missing_name": {
      "questionary/prompt.py:prompt": {
        "questionary/prompt.py:unsafe_prompt": {
          "questionary/prompt.py:PromptParameterException:__init__": {}
        }
      }
    },
    "modified_testcases/test_prompt.py:TestPrompt:test_missing_print_message": {
      "questionary/prompt.py:prompt": {
        "questionary/prompt.py:unsafe_prompt": {
          "questionary/prompt.py:PromptParameterException:__init__": {}
        }
      }
    },
    "modified_testcases/test_prompt.py:TestPrompt:test_missing_type": {
      "questionary/prompt.py:prompt": {
        "questionary/prompt.py:unsafe_prompt": {
          "questionary/prompt.py:PromptParameterException:__init__": {}
        }
      }
    },
    "modified_testcases/test_prompt.py:TestPrompt:test_print_no_name": {
      "tests/utils.py:patched_prompt": {
        "tests/utils.py:execute_with_input_pipe": {
          "tests/utils.py:run": {
            "questionary/prompt.py:prompt": {
              "questionary/prompt.py:unsafe_prompt": {
                "questionary/prompts/common.py:print_formatted_text": {}
              }
            }
          }
        }
      }
    },
    "modified_testcases/test_prompt.py:TestPrompt:test_print_with_name": {
      "tests/utils.py:patched_prompt": {
        "tests/utils.py:execute_with_input_pipe": {
          "tests/utils.py:run": {
            "questionary/prompt.py:prompt": {
              "questionary/prompt.py:unsafe_prompt": {
                "questionary/prompts/common.py:print_formatted_text": {}
              }
            }
          }
        }
      }
    }
  }
}