{
  "dir_path": "/app/elasticsearch_curator",
  "package_name": "elasticsearch_curator",
  "sample_name": "elasticsearch_curator-test_helpers_getters",
  "src_dir": "curator/",
  "test_dir": "tests/",
  "test_file": "tests/unit/test_helpers_getters.py",
  "test_code": "\"\"\"Unit testing for helpers.creators functions\"\"\"\n\nfrom unittest import TestCase\nfrom unittest.mock import Mock\nimport pytest\nfrom elastic_transport import ApiResponseMeta\nfrom elasticsearch8 import NotFoundError, TransportError\nfrom curator.exceptions import CuratorException, FailedExecution, MissingArgument\nfrom curator.helpers import getters\n\nFAKE_FAIL = Exception('Simulated Failure')\nNAMED_INDICES = [\"index-2015.01.01\", \"index-2015.02.01\"]\nREPO_NAME = 'repo_name'\nTEST_REPO = {REPO_NAME: {}}\nSNAP_NAME = 'snap_name'\nSINGLE = {'snapshot': SNAP_NAME, 'indices': NAMED_INDICES}\nSNAPSHOT = {'snapshots': [SINGLE]}\nSNAPSHOTS = {\n    'snapshots': [SINGLE, {'snapshot': 'snapshot-2015.03.01', 'indices': NAMED_INDICES}]\n}\n\n\nclass TestByteSize(TestCase):\n    \"\"\"TestByteSize\n\n    Test helpers.getters.byte_size functionality.\n    \"\"\"\n\n    def test_byte_size(self):\n        \"\"\"test_byte_size\n\n        Output should match expected\n        \"\"\"\n        size = 3 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024\n        unit = ['Z', 'E', 'P', 'T', 'G', 'M', 'K', '']\n        for i in range(0, 7):\n            assert f'3.0{unit[i]}B' == getters.byte_size(size)\n            size /= 1024\n\n    def test_byte_size_yotta(self):\n        \"\"\"test_byte_size_yotta\n\n        Output should match expected\n        \"\"\"\n        size = 3 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024\n        assert '3.0YB' == getters.byte_size(size)\n\n    def test_raise_invalid(self):\n        \"\"\"test_raise_invalid\n\n        Should raise a TypeError exception if an invalid value is passed\n        \"\"\"\n        with pytest.raises(TypeError):\n            getters.byte_size('invalid')\n\n\nclass TestGetIndices(TestCase):\n    \"\"\"TestGetIndices\n\n    Test helpers.getters.get_indices functionality.\n    \"\"\"\n\n    IDX1 = 'index-2016.03.03'\n    IDX2 = 'index-2016.03.04'\n    RESPONSE = [{'index': IDX1, 'state': 'open'}, {'index': IDX2, 'state': 'open'}]\n\n    def test_client_exception(self):\n        \"\"\"test_client_exception\n\n        Should raise a FailedExecution exception when an upstream exception occurs\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = self.RESPONSE\n        client.cat.indices.side_effect = FAKE_FAIL\n        with pytest.raises(FailedExecution):\n            getters.get_indices(client)\n\n    def test_positive(self):\n        \"\"\"test_positive\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = self.RESPONSE\n        self.assertEqual([self.IDX1, self.IDX2], sorted(getters.get_indices(client)))\n\n    def test_empty(self):\n        \"\"\"test_empty\n\n        Output should be an empty list\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = {}\n        self.assertEqual([], getters.get_indices(client))\n\n\nclass TestGetRepository(TestCase):\n    \"\"\"TestGetRepository\n\n    Test helpers.getters.get_repository functionality.\n    \"\"\"\n\n    MULTI = {'other': {}, REPO_NAME: {}}\n\n    def test_get_repository_missing_arg(self):\n        \"\"\"test_get_repository_missing_arg\n\n        Should return an empty response if no repository name provided\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = {}\n        assert not getters.get_repository(client)\n\n    def test_get_repository_positive(self):\n        \"\"\"test_get_repository_positive\n\n        Return value should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        assert TEST_REPO == getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_transporterror_negative(self):\n        \"\"\"test_get_repository_transporterror_negative\n\n        Should raise a CuratorException if a TransportError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.side_effect = TransportError(\n            503, ('exception', 'reason')\n        )\n        with pytest.raises(CuratorException, match=r'503 Check Elasticsearch logs'):\n            getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_notfounderror_negative(self):\n        \"\"\"test_get_repository_notfounderror_negative\n\n        Should raise a CuratorException if a NotFoundError is raised first\n        \"\"\"\n        client = Mock()\n        # 5 positional args for meta: status, http_version, headers, duration, node\n        meta = ApiResponseMeta(404, '1.1', {}, 0.01, None)\n        body = 'simulated error'\n        msg = 'simulated error'\n        # 3 positional args for NotFoundError: message, meta, body\n        effect = NotFoundError(msg, meta, body)\n        client.snapshot.get_repository.side_effect = effect\n        with pytest.raises(CuratorException, match=r'Error: NotFoundError'):\n            getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_all_positive(self):\n        \"\"\"test_get_repository_all_positive\n\n        Return value should match expected with multiple repositories\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = self.MULTI\n        assert self.MULTI == getters.get_repository(client)\n\n\nclass TestGetSnapshot(TestCase):\n    \"\"\"TestGetSnapshot\n\n    Test helpers.getters.get_snapshot functionality.\n    \"\"\"\n\n    def test_get_snapshot_missing_repository_arg(self):\n        \"\"\"test_get_snapshot_missing_repository_arg\n\n        Should raise a MissingArgument exception when repository not passed\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'No value for \"repository\" provided'\n        ):\n            getters.get_snapshot(client, snapshot=SNAP_NAME)\n\n    def test_get_snapshot_positive(self):\n        \"\"\"test_get_snapshot_positive\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOT\n        assert SNAPSHOT == getters.get_snapshot(\n            client, repository=REPO_NAME, snapshot=SNAP_NAME\n        )\n\n    def test_get_snapshot_transporterror_negative(self):\n        \"\"\"test_get_snapshot_transporterror_negative\n\n        Should raise a FailedExecution exception if a TransportError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        client.snapshot.get.side_effect = TransportError(401, \"simulated error\")\n        with pytest.raises(FailedExecution, match=r'Error: 401'):\n            getters.get_snapshot(client, repository=REPO_NAME, snapshot=SNAP_NAME)\n\n    def test_get_snapshot_notfounderror_negative(self):\n        \"\"\"test_get_snapshot_notfounderror_negative\n\n        Should raise a FailedExecution exception if a NotFoundError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        # 5 positional args for meta: status, http_version, headers, duration, node\n        meta = ApiResponseMeta(404, '1.1', {}, 1.0, None)\n        client.snapshot.get.side_effect = NotFoundError(\n            'simulated error', meta, 'simulated error'\n        )\n        with pytest.raises(FailedExecution, match=r'Error: NotFoundError'):\n            getters.get_snapshot(client, repository=REPO_NAME, snapshot=SNAP_NAME)\n\n\nclass TestGetSnapshotData(TestCase):\n    \"\"\"TestGetSnapshotData\n\n    Test helpers.getters.get_snapshot_data functionality.\n    \"\"\"\n\n    def test_missing_repo_arg(self):\n        \"\"\"test_missing_repo_arg\n\n        Should raise a MissingArgument exception if the repository arg is missing\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'No value for \"repository\" provided'\n        ):\n            getters.get_snapshot_data(client)\n\n    def test_return_data(self):\n        \"\"\"test_return_data\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOTS\n        client.snapshot.get_repository.return_value = TEST_REPO\n        assert SNAPSHOTS['snapshots'] == getters.get_snapshot_data(\n            client, repository=REPO_NAME\n        )\n\n    def test_raises_exception_onfail(self):\n        \"\"\"test_raises_exception_onfail\n\n        Should raise a FailedExecution exception if a TransportError is raised upstream\n        first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOTS\n        client.snapshot.get.side_effect = TransportError(401, \"simulated error\")\n        client.snapshot.get_repository.return_value = TEST_REPO\n        with pytest.raises(FailedExecution, match=r'Error: 401'):\n            getters.get_snapshot_data(client, repository=REPO_NAME)\n\n\nclass TestNodeRoles(TestCase):\n    \"\"\"TestNodeRoles\n\n    Test helpers.getters.node_roles functionality.\n    \"\"\"\n\n    def test_node_roles(self):\n        \"\"\"test_node_roles\n\n        Output should match expected\n        \"\"\"\n        node_id = 'my_node'\n        expected = ['data']\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'roles': expected}}}\n        assert expected == getters.node_roles(client, node_id)\n\n\nclass TestSingleDataPath(TestCase):\n    \"\"\"TestSingleDataPath\n\n    Test helpers.getters.single_data_path functionality.\n    \"\"\"\n\n    def test_single_data_path(self):\n        \"\"\"test_single_data_path\n\n        Return value should be True with only one data path\n        \"\"\"\n        node_id = 'my_node'\n        client = Mock()\n        client.nodes.stats.return_value = {\n            'nodes': {node_id: {'fs': {'data': ['one']}}}\n        }\n        assert getters.single_data_path(client, node_id)\n\n    def test_two_data_paths(self):\n        \"\"\"test_two_data_paths\n\n        Return value should be False with two data paths\n        \"\"\"\n        node_id = 'my_node'\n        client = Mock()\n        client.nodes.stats.return_value = {\n            'nodes': {node_id: {'fs': {'data': ['one', 'two']}}}\n        }\n        assert not getters.single_data_path(client, node_id)\n\n\nclass TestNameToNodeId(TestCase):\n    \"\"\"TestNameToNodeId\n\n    Test helpers.getters.name_to_node_id functionality.\n    \"\"\"\n\n    def test_positive(self):\n        \"\"\"test_positive\n\n        Output should match expected\n        \"\"\"\n        node_id = 'node_id'\n        node_name = 'node_name'\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'name': node_name}}}\n        assert node_id == getters.name_to_node_id(client, node_name)\n\n    def test_negative(self):\n        \"\"\"test_negative\n\n        Output should be None due to mismatch\n        \"\"\"\n        node_id = 'node_id'\n        node_name = 'node_name'\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'name': node_name}}}\n        assert None is getters.name_to_node_id(client, 'wrong_name')\n\n\nclass TestNodeIdToName(TestCase):\n    \"\"\"TestNodeIdToName\n\n    Test helpers.getters.node_id_to_name functionality.\n    \"\"\"\n\n    def test_negative(self):\n        \"\"\"test_negative\n\n        Output should be None due to mismatch\n        \"\"\"\n        client = Mock()\n        client.nodes.info.return_value = {\n            'nodes': {'my_node_id': {'name': 'my_node_name'}}\n        }\n        assert None is getters.node_id_to_name(client, 'not_my_node_id')\n\n\nclass TestGetAliasActions(TestCase):\n    \"\"\"TestGetAliasActions\n\n    Test helpers.getters.get_alias_actions functionality.\n    \"\"\"\n\n    def test_get_alias_actions(self):\n        \"\"\"test_get_alias_actions\"\"\"\n        name = 'alias1'\n        aliases = {name: {}}\n        oldidx = 'old'\n        newidx = 'new'\n        expected = [\n            {'remove': {'index': oldidx, 'alias': name}},\n            {'add': {'index': newidx, 'alias': name}},\n        ]\n        assert getters.get_alias_actions(oldidx, newidx, aliases) == expected\n\n\nclass TestGetTierPreference(TestCase):\n    \"\"\"TestGetTierPreference\n\n    Test helpers.getters.get_tier_preference functionality.\n    \"\"\"\n\n    def test_get_tier_preference1(self):\n        \"\"\"test_get_tier_preference1\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_frozen', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_frozen'\n\n    def test_get_tier_preference2(self):\n        \"\"\"test_get_tier_preference2\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_cold,data_warm,data_hot'\n\n    def test_get_tier_preference3(self):\n        \"\"\"test_get_tier_preference3\"\"\"\n        client = Mock()\n        roles = ['data_content']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_content'\n\n    def test_get_tier_preference4(self):\n        \"\"\"test_get_tier_preference4\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_frozen', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert (\n            getters.get_tier_preference(client, target_tier='data_cold')\n            == 'data_cold,data_warm,data_hot'\n        )\n\n    def test_get_tier_preference5(self):\n        \"\"\"test_get_tier_preference5\"\"\"\n        client = Mock()\n        roles = ['data_content']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert (\n            getters.get_tier_preference(client, target_tier='data_hot')\n            == 'data_content'\n        )\n",
  "GT_file_code": {
    "curator/helpers/getters.py": "\"\"\"Utility functions that get things\"\"\"\n\nimport logging\nfrom elasticsearch8 import exceptions as es8exc\nfrom curator.exceptions import (\n    ConfigurationError,\n    CuratorException,\n    FailedExecution,\n    MissingArgument,\n)\n\n\ndef byte_size(num, suffix='B'):\n    \"\"\"\n    :param num: The number of byte\n    :param suffix: An arbitrary suffix, like ``Bytes``\n\n    :type num: int\n    :type suffix: str\n\n    :returns: A formatted string indicating the size in bytes, with the proper unit,\n        e.g. KB, MB, GB, TB, etc.\n    :rtype: float\n    \"\"\"\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return f'{num:3.1f}{unit}{suffix}'\n        num /= 1024.0\n    return f'{num:.1f}Y{suffix}'\n\n\ndef escape_dots(stringval):\n    \"\"\"\n    Escape any dots (periods) in ``stringval``.\n\n    Primarily used for ``filter_path`` where dots are indicators of path nesting\n\n    :param stringval: A string, ostensibly an index name\n\n    :type stringval: str\n\n    :returns: ``stringval``, but with any periods escaped with a backslash\n    :retval: str\n    \"\"\"\n    return stringval.replace('.', r'\\.')\n\n\ndef get_alias_actions(oldidx, newidx, aliases):\n    \"\"\"\n    :param oldidx: The old index name\n    :param newidx: The new index name\n    :param aliases: The aliases\n\n    :type oldidx: str\n    :type newidx: str\n    :type aliases: dict\n\n    :returns: A list of actions suitable for\n        :py:meth:`~.elasticsearch.client.IndicesClient.update_aliases` ``actions``\n        kwarg.\n    :rtype: list\n    \"\"\"\n    actions = []\n    for alias in aliases.keys():\n        actions.append({'remove': {'index': oldidx, 'alias': alias}})\n        actions.append({'add': {'index': newidx, 'alias': alias}})\n    return actions\n\n\ndef get_data_tiers(client):\n    \"\"\"\n    Get all valid data tiers from the node roles of each node in the cluster by\n    polling each node\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The available data tiers in ``tier: bool`` form.\n    :rtype: dict\n    \"\"\"\n\n    def role_check(role, node_info):\n        if role in node_info['roles']:\n            return True\n        return False\n\n    info = client.nodes.info()['nodes']\n    retval = {\n        'data_hot': False,\n        'data_warm': False,\n        'data_cold': False,\n        'data_frozen': False,\n    }\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            # This guarantees we don't overwrite a True with a False.\n            # We only add True values\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval\n\n\ndef get_indices(client, search_pattern='_all'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.CatClient.indices`\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The current list of indices from the cluster\n    :rtype: list\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    indices = []\n    try:\n        # Doing this in two stages because IndexList also calls for these args,\n        # and the unit tests need to Mock this call the same exact way.\n        resp = client.cat.indices(\n            index=search_pattern,\n            expand_wildcards='open,closed',\n            h='index,status',\n            format='json',\n        )\n    except Exception as err:\n        raise FailedExecution(f'Failed to get indices. Error: {err}') from err\n    if not resp:\n        return indices\n    for entry in resp:\n        indices.append(entry['index'])\n    logger.debug('All indices: %s', indices)\n    return indices\n\n\ndef get_repository(client, repository=''):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get_repository`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n\n    :returns: Configuration information for ``repository``.\n    :rtype: dict\n    \"\"\"\n    try:\n        return client.snapshot.get_repository(name=repository)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get repository {repository}.  Error: {err} Check Elasticsearch '\n            f'logs for more information.'\n        )\n        raise CuratorException(msg) from err\n\n\ndef get_snapshot(client, repository=None, snapshot=''):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n    :param snapshot: The snapshot name, or a comma-separated list of snapshots\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n    :type snapshot: str\n\n    :returns: Information about the provided ``snapshot``, a snapshot (or a\n        comma-separated list of snapshots). If no snapshot specified, it will\n        collect info for all snapshots.  If none exist, an empty :py:class:`dict`\n        will be returned.\n    :rtype: dict\n    \"\"\"\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    snapname = '*' if snapshot == '' else snapshot\n    try:\n        return client.snapshot.get(repository=repository, snapshot=snapshot)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get information about snapshot {snapname} from repository: '\n            f'{repository}.  Error: {err}'\n        )\n        raise FailedExecution(msg) from err\n\n\ndef get_snapshot_data(client, repository=None):\n    \"\"\"\n    Get all snapshots from repository and return a list.\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n\n    :returns: The list of all snapshots from ``repository``\n    :rtype: list\n    \"\"\"\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    try:\n        return client.snapshot.get(repository=repository, snapshot=\"*\")['snapshots']\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get snapshot information from repository: '\n            f'{repository}. Error: {err}'\n        )\n        raise FailedExecution(msg) from err\n\n\ndef get_tier_preference(client, target_tier='data_frozen'):\n    \"\"\"Do the tier preference thing in reverse order from coldest to hottest\n    Based on the value of ``target_tier``, build out the list to use.\n\n    :param client: A client connection object\n    :param target_tier: The target data tier, e.g. data_warm.\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type target_tier: str\n\n    :returns: A suitable tier preference string in csv format\n    :rtype: str\n    \"\"\"\n    tiermap = {\n        'data_content': 0,\n        'data_hot': 1,\n        'data_warm': 2,\n        'data_cold': 3,\n        'data_frozen': 4,\n    }\n    tiers = get_data_tiers(client)\n    test_list = []\n    for tier in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n        if tier in tiers and tiermap[tier] <= tiermap[target_tier]:\n            test_list.insert(0, tier)\n    if target_tier == 'data_frozen':\n        # We're migrating to frozen here. If a frozen tier exists, frozen searchable\n        # snapshot mounts should only ever go to the frozen tier.\n        if 'data_frozen' in tiers and tiers['data_frozen']:\n            return 'data_frozen'\n    # If there are no  nodes with the 'data_frozen' role...\n    preflist = []\n    for key in test_list:\n        # This ordering ensures that colder tiers are prioritized\n        if key in tiers and tiers[key]:\n            preflist.append(key)\n    # If all of these are false, then we have no data tiers and must use 'data_content'\n    if not preflist:\n        return 'data_content'\n    # This will join from coldest to hottest as csv string,\n    # e.g. 'data_cold,data_warm,data_hot'\n    return ','.join(preflist)\n\n\ndef get_write_index(client, alias):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param alias: An alias name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type alias: str\n\n    :returns: The the index name associated with the alias that is designated\n        ``is_write_index``\n    :rtype: str\n    \"\"\"\n    try:\n        response = client.indices.get_alias(index=alias)\n    except Exception as exc:\n        raise CuratorException(f'Alias {alias} not found') from exc\n    # If there are more than one in the list, one needs to be the write index\n    # otherwise the alias is a one to many, and can't do rollover.\n    retval = None\n    if len(list(response.keys())) > 1:\n        for index in list(response.keys()):\n            try:\n                if response[index]['aliases'][alias]['is_write_index']:\n                    retval = index\n            except KeyError as exc:\n                raise FailedExecution(\n                    'Invalid alias: is_write_index not found in 1 to many alias'\n                ) from exc\n    else:\n        # There's only one, so this is it\n        retval = list(response.keys())[0]\n    return retval\n\n\ndef index_size(client, idx, value='total'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.stats`\n\n    :param client: A client connection object\n    :param idx: An index name\n    :param value: One of either ``primaries`` or ``total``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type value: str\n\n    :returns: The sum of either ``primaries`` or ``total`` shards for index ``idx``\n    :rtype: integer\n    \"\"\"\n    fpath = f'indices.{escape_dots(idx)}.{value}.store.size_in_bytes'\n    return client.indices.stats(index=idx, filter_path=fpath)['indices'][idx][value][\n        'store'\n    ]['size_in_bytes']\n\n\ndef meta_getter(client, idx, get=None):\n    \"\"\"Meta Getter\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_settings` or\n    :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param idx: An Elasticsearch index\n    :param get: The kind of get to perform, e.g. settings or alias\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type get: str\n\n    :returns: The settings from the get call to the named index\n    :rtype: dict\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    acceptable = ['settings', 'alias']\n    if not get:\n        raise ConfigurationError('\"get\" can not be a NoneType')\n    if get not in acceptable:\n        raise ConfigurationError(f'\"get\" must be one of {acceptable}')\n    retval = {}\n    try:\n        if get == 'settings':\n            retval = client.indices.get_settings(index=idx)[idx]['settings']['index']\n        elif get == 'alias':\n            retval = client.indices.get_alias(index=idx)[idx]['aliases']\n    except es8exc.NotFoundError as missing:\n        logger.error('Index %s was not found!', idx)\n        raise es8exc.NotFoundError from missing\n    except KeyError as err:\n        logger.error('Key not found: %s', err)\n        raise KeyError from err\n    # pylint: disable=broad-except\n    except Exception as exc:\n        logger.error('Exception encountered: %s', exc)\n    return retval\n\n\ndef name_to_node_id(client, name):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param name: The node ``name``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type name: str\n\n    :returns: The node_id of the node identified by ``name``\n    :rtype: str\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    fpath = 'nodes'\n    info = client.nodes.info(filter_path=fpath)\n    for node in info['nodes']:\n        if info['nodes'][node]['name'] == name:\n            logger.debug('Found node_id \"%s\" for name \"%s\".', node, name)\n            return node\n    logger.error('No node_id found matching name: \"%s\"', name)\n    return None\n\n\ndef node_id_to_name(client, node_id):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: The name of the node identified by ``node_id``\n    :rtype: str\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    fpath = f'nodes.{node_id}.name'\n    info = client.nodes.info(filter_path=fpath)\n    name = None\n    if node_id in info['nodes']:\n        name = info['nodes'][node_id]['name']\n    else:\n        logger.error('No node_id found matching: \"%s\"', node_id)\n    logger.debug('Name associated with node_id \"%s\": %s', node_id, name)\n    return name\n\n\ndef node_roles(client, node_id):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: The list of roles assigned to the node identified by ``node_id``\n    :rtype: list\n    \"\"\"\n    fpath = f'nodes.{node_id}.roles'\n    return client.nodes.info(filter_path=fpath)['nodes'][node_id]['roles']\n\n\ndef single_data_path(client, node_id):\n    \"\"\"\n    In order for a shrink to work, it should be on a single filesystem, as shards\n    cannot span filesystems. Calls :py:meth:`~.elasticsearch.client.NodesClient.stats`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: ``True`` if the node has a single filesystem, else ``False``\n    :rtype: bool\n    \"\"\"\n    fpath = f'nodes.{node_id}.fs.data'\n    response = client.nodes.stats(filter_path=fpath)\n    return len(response['nodes'][node_id]['fs']['data']) == 1\n",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\"\n"
  },
  "GT_src_dict": {
    "curator/helpers/getters.py": {
      "byte_size": {
        "code": "def byte_size(num, suffix='B'):\n    \"\"\"Convert a given byte size into a human-readable format with appropriate units.\n\n:param num: The size in bytes to be converted.\n:type num: int\n:param suffix: A suffix to append to the size string (default is 'B' for Bytes).\n:type suffix: str\n\n:returns: A formatted string representing the byte size in appropriate units (e.g., KB, MB, GB),\nwith a precision of one decimal place.\n:rtype: str\n\nThe function divides the input number by 1024 sequentially until it finds the appropriate unit \nfor representation. The unit prefixes used are: \n- '' for Bytes \n- 'K' for Kilobytes \n- 'M' for Megabytes \n- 'G' for Gigabytes \n- 'T' for Terabytes \n- 'P' for Petabytes \n- 'E' for Exabytes \n- 'Z' for Zettabytes. \n\nThis utility is helpful for formatting data sizes in a more understandable way throughout the codebase.\"\"\"\n    '\\n    :param num: The number of byte\\n    :param suffix: An arbitrary suffix, like ``Bytes``\\n\\n    :type num: int\\n    :type suffix: str\\n\\n    :returns: A formatted string indicating the size in bytes, with the proper unit,\\n        e.g. KB, MB, GB, TB, etc.\\n    :rtype: float\\n    '\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return f'{num:3.1f}{unit}{suffix}'\n        num /= 1024.0\n    return f'{num:.1f}Y{suffix}'",
        "docstring": "Convert a given byte size into a human-readable format with appropriate units.\n\n:param num: The size in bytes to be converted.\n:type num: int\n:param suffix: A suffix to append to the size string (default is 'B' for Bytes).\n:type suffix: str\n\n:returns: A formatted string representing the byte size in appropriate units (e.g., KB, MB, GB),\nwith a precision of one decimal place.\n:rtype: str\n\nThe function divides the input number by 1024 sequentially until it finds the appropriate unit \nfor representation. The unit prefixes used are: \n- '' for Bytes \n- 'K' for Kilobytes \n- 'M' for Megabytes \n- 'G' for Gigabytes \n- 'T' for Terabytes \n- 'P' for Petabytes \n- 'E' for Exabytes \n- 'Z' for Zettabytes. \n\nThis utility is helpful for formatting data sizes in a more understandable way throughout the codebase.",
        "signature": "def byte_size(num, suffix='B'):",
        "type": "Function",
        "class_signature": null
      },
      "get_alias_actions": {
        "code": "def get_alias_actions(oldidx, newidx, aliases):\n    \"\"\"Generate actions for updating index aliases in Elasticsearch. \n\nThis function creates a list of actions to remove aliases from an old index and add them to a new index. The primary purpose is to facilitate an alias update operation in Elasticsearch by specifying the actions required to reassign aliases from one index to another.\n\nParameters:\n- oldidx (str): The name of the index from which aliases are being removed.\n- newidx (str): The name of the index to which aliases are being added.\n- aliases (dict): A dictionary of alias names, where each key represents an alias.\n\nReturns:\n- list: A list of actions formatted for use with the Elasticsearch IndicesClient update_aliases method, containing 'remove' actions for the old index and 'add' actions for the new index.\n\nThis function interacts with the Elasticsearch system to manage index aliases effectively.\"\"\"\n    '\\n    :param oldidx: The old index name\\n    :param newidx: The new index name\\n    :param aliases: The aliases\\n\\n    :type oldidx: str\\n    :type newidx: str\\n    :type aliases: dict\\n\\n    :returns: A list of actions suitable for\\n        :py:meth:`~.elasticsearch.client.IndicesClient.update_aliases` ``actions``\\n        kwarg.\\n    :rtype: list\\n    '\n    actions = []\n    for alias in aliases.keys():\n        actions.append({'remove': {'index': oldidx, 'alias': alias}})\n        actions.append({'add': {'index': newidx, 'alias': alias}})\n    return actions",
        "docstring": "Generate actions for updating index aliases in Elasticsearch. \n\nThis function creates a list of actions to remove aliases from an old index and add them to a new index. The primary purpose is to facilitate an alias update operation in Elasticsearch by specifying the actions required to reassign aliases from one index to another.\n\nParameters:\n- oldidx (str): The name of the index from which aliases are being removed.\n- newidx (str): The name of the index to which aliases are being added.\n- aliases (dict): A dictionary of alias names, where each key represents an alias.\n\nReturns:\n- list: A list of actions formatted for use with the Elasticsearch IndicesClient update_aliases method, containing 'remove' actions for the old index and 'add' actions for the new index.\n\nThis function interacts with the Elasticsearch system to manage index aliases effectively.",
        "signature": "def get_alias_actions(oldidx, newidx, aliases):",
        "type": "Function",
        "class_signature": null
      },
      "get_indices": {
        "code": "def get_indices(client, search_pattern='_all'):\n    \"\"\"Retrieve the current list of indices from an Elasticsearch cluster.\n\nThis function uses the Elasticsearch client's Cat API to fetch indices matching the specified search pattern. The response includes information about both open and closed indices, filtered to only include the 'index' and 'status' fields.\n\nParameters:\n- client (Elasticsearch): A client connection object for interacting with the Elasticsearch cluster.\n- search_pattern (str, optional): A pattern to match indices. Defaults to '_all', which retrieves all indices.\n\nReturns:\n- list: A list of index names currently in the cluster.\n\nRaises:\n- FailedExecution: If there is an error during the retrieval of indices.\n\nLoggers:\n- A logger from the `logging` module is used to log the list of indices at the debug level.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.CatClient.indices`\\n\\n    :param client: A client connection object\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n\\n    :returns: The current list of indices from the cluster\\n    :rtype: list\\n    '\n    logger = logging.getLogger(__name__)\n    indices = []\n    try:\n        resp = client.cat.indices(index=search_pattern, expand_wildcards='open,closed', h='index,status', format='json')\n    except Exception as err:\n        raise FailedExecution(f'Failed to get indices. Error: {err}') from err\n    if not resp:\n        return indices\n    for entry in resp:\n        indices.append(entry['index'])\n    logger.debug('All indices: %s', indices)\n    return indices",
        "docstring": "Retrieve the current list of indices from an Elasticsearch cluster.\n\nThis function uses the Elasticsearch client's Cat API to fetch indices matching the specified search pattern. The response includes information about both open and closed indices, filtered to only include the 'index' and 'status' fields.\n\nParameters:\n- client (Elasticsearch): A client connection object for interacting with the Elasticsearch cluster.\n- search_pattern (str, optional): A pattern to match indices. Defaults to '_all', which retrieves all indices.\n\nReturns:\n- list: A list of index names currently in the cluster.\n\nRaises:\n- FailedExecution: If there is an error during the retrieval of indices.\n\nLoggers:\n- A logger from the `logging` module is used to log the list of indices at the debug level.",
        "signature": "def get_indices(client, search_pattern='_all'):",
        "type": "Function",
        "class_signature": null
      },
      "get_repository": {
        "code": "def get_repository(client, repository=''):\n    \"\"\"Retrieve the configuration information for a specified Elasticsearch snapshot repository.\n\nParameters:\n- client (Elasticsearch): A client connection object to interact with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository to retrieve configuration for. Defaults to an empty string.\n\nReturns:\n- dict: A dictionary containing the configuration information for the specified repository.\n\nRaises:\n- CuratorException: If the repository cannot be found or accessed due to a TransportError or NotFoundError, an exception is raised with details about the failure, prompting the user to check Elasticsearch logs for more information.\n\nDependencies:\nThis function relies on the `snapshot` method from the `client` which is an instance of the Elasticsearch client, and the `es8exc` module from `elasticsearch8` for managing exceptions specific to Elasticsearch operations.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get_repository`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n\\n    :returns: Configuration information for ``repository``.\\n    :rtype: dict\\n    '\n    try:\n        return client.snapshot.get_repository(name=repository)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get repository {repository}.  Error: {err} Check Elasticsearch logs for more information.'\n        raise CuratorException(msg) from err",
        "docstring": "Retrieve the configuration information for a specified Elasticsearch snapshot repository.\n\nParameters:\n- client (Elasticsearch): A client connection object to interact with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository to retrieve configuration for. Defaults to an empty string.\n\nReturns:\n- dict: A dictionary containing the configuration information for the specified repository.\n\nRaises:\n- CuratorException: If the repository cannot be found or accessed due to a TransportError or NotFoundError, an exception is raised with details about the failure, prompting the user to check Elasticsearch logs for more information.\n\nDependencies:\nThis function relies on the `snapshot` method from the `client` which is an instance of the Elasticsearch client, and the `es8exc` module from `elasticsearch8` for managing exceptions specific to Elasticsearch operations.",
        "signature": "def get_repository(client, repository=''):",
        "type": "Function",
        "class_signature": null
      },
      "get_snapshot": {
        "code": "def get_snapshot(client, repository=None, snapshot=''):\n    \"\"\"Retrieve information about a specified snapshot from a given Elasticsearch snapshot repository.\n\nParameters:\n- client (Elasticsearch): A client connection object to interact with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository from which to retrieve snapshots. This parameter is mandatory.\n- snapshot (str): The name of a specific snapshot or a comma-separated list of snapshots to retrieve. If empty, information for all snapshots in the repository will be fetched.\n\nReturns:\n- dict: A dictionary containing detailed information about the specified snapshot(s). If no snapshots exist, an empty dictionary will be returned.\n\nRaises:\n- MissingArgument: If the 'repository' parameter is not provided.\n- FailedExecution: If there is an error retrieving snapshot information, typically due to connection issues or non-existence of the specified snapshot.\n\nThe function interacts with the `client.snapshot.get` method of the Elasticsearch client to fetch snapshot data. Additionally, it references exceptions defined in the `elasticsearch.exceptions` module for handling potential errors.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n    :param snapshot: The snapshot name, or a comma-separated list of snapshots\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n    :type snapshot: str\\n\\n    :returns: Information about the provided ``snapshot``, a snapshot (or a\\n        comma-separated list of snapshots). If no snapshot specified, it will\\n        collect info for all snapshots.  If none exist, an empty :py:class:`dict`\\n        will be returned.\\n    :rtype: dict\\n    '\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    snapname = '*' if snapshot == '' else snapshot\n    try:\n        return client.snapshot.get(repository=repository, snapshot=snapshot)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get information about snapshot {snapname} from repository: {repository}.  Error: {err}'\n        raise FailedExecution(msg) from err",
        "docstring": "Retrieve information about a specified snapshot from a given Elasticsearch snapshot repository.\n\nParameters:\n- client (Elasticsearch): A client connection object to interact with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository from which to retrieve snapshots. This parameter is mandatory.\n- snapshot (str): The name of a specific snapshot or a comma-separated list of snapshots to retrieve. If empty, information for all snapshots in the repository will be fetched.\n\nReturns:\n- dict: A dictionary containing detailed information about the specified snapshot(s). If no snapshots exist, an empty dictionary will be returned.\n\nRaises:\n- MissingArgument: If the 'repository' parameter is not provided.\n- FailedExecution: If there is an error retrieving snapshot information, typically due to connection issues or non-existence of the specified snapshot.\n\nThe function interacts with the `client.snapshot.get` method of the Elasticsearch client to fetch snapshot data. Additionally, it references exceptions defined in the `elasticsearch.exceptions` module for handling potential errors.",
        "signature": "def get_snapshot(client, repository=None, snapshot=''):",
        "type": "Function",
        "class_signature": null
      },
      "get_snapshot_data": {
        "code": "def get_snapshot_data(client, repository=None):\n    \"\"\"Retrieve all snapshots from a specified Elasticsearch snapshot repository.\n\n:param client: An Elasticsearch client connection object used to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository from which to retrieve snapshots. This parameter is mandatory.\n:type repository: str\n\n:raises MissingArgument: If the `repository` parameter is not provided.\n:raises FailedExecution: If there is an error accessing the snapshot information, capturing Elasticsearch transport errors or a not found error.\n\n:returns: A list of all snapshots from the specified `repository`. The list may be empty if no snapshots exist in the repository.\n:rtype: list\n\nThis function interacts with the Elasticsearch client's snapshot capabilities via the `snapshot.get` method to gather snapshot data and relies on constants that represent error handling during the retrieval process.\"\"\"\n    '\\n    Get all snapshots from repository and return a list.\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n\\n    :returns: The list of all snapshots from ``repository``\\n    :rtype: list\\n    '\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    try:\n        return client.snapshot.get(repository=repository, snapshot='*')['snapshots']\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get snapshot information from repository: {repository}. Error: {err}'\n        raise FailedExecution(msg) from err",
        "docstring": "Retrieve all snapshots from a specified Elasticsearch snapshot repository.\n\n:param client: An Elasticsearch client connection object used to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository from which to retrieve snapshots. This parameter is mandatory.\n:type repository: str\n\n:raises MissingArgument: If the `repository` parameter is not provided.\n:raises FailedExecution: If there is an error accessing the snapshot information, capturing Elasticsearch transport errors or a not found error.\n\n:returns: A list of all snapshots from the specified `repository`. The list may be empty if no snapshots exist in the repository.\n:rtype: list\n\nThis function interacts with the Elasticsearch client's snapshot capabilities via the `snapshot.get` method to gather snapshot data and relies on constants that represent error handling during the retrieval process.",
        "signature": "def get_snapshot_data(client, repository=None):",
        "type": "Function",
        "class_signature": null
      },
      "get_tier_preference": {
        "code": "def get_tier_preference(client, target_tier='data_frozen'):\n    \"\"\"Determine the preferred data tiers for Elasticsearch allocation based on the specified target tier. The function retrieves the available data tiers from the Elasticsearch cluster and constructs a string that lists suitable tiers from coldest to hottest, depending on the value of `target_tier`. \n\nParameters:\n- client: A client connection object to interact with the Elasticsearch cluster.\n- target_tier: A string indicating the target data tier to consider for preference (default is 'data_frozen'). Valid values include 'data_content', 'data_hot', 'data_warm', 'data_cold', and 'data_frozen'.\n\nReturns:\n- A comma-separated string representing the preferred data tiers, prioritizing colder tiers first. If no suitable tiers are available, it defaults to 'data_content'.\n\nThe function utilizes the `get_data_tiers` function to fetch the available data tiers and utilizes a `tiermap` constant defined within the function to map tier names to numerical values indicating their relative 'coldness' or 'hotness'.\"\"\"\n    'Do the tier preference thing in reverse order from coldest to hottest\\n    Based on the value of ``target_tier``, build out the list to use.\\n\\n    :param client: A client connection object\\n    :param target_tier: The target data tier, e.g. data_warm.\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type target_tier: str\\n\\n    :returns: A suitable tier preference string in csv format\\n    :rtype: str\\n    '\n    tiermap = {'data_content': 0, 'data_hot': 1, 'data_warm': 2, 'data_cold': 3, 'data_frozen': 4}\n    tiers = get_data_tiers(client)\n    test_list = []\n    for tier in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n        if tier in tiers and tiermap[tier] <= tiermap[target_tier]:\n            test_list.insert(0, tier)\n    if target_tier == 'data_frozen':\n        if 'data_frozen' in tiers and tiers['data_frozen']:\n            return 'data_frozen'\n    preflist = []\n    for key in test_list:\n        if key in tiers and tiers[key]:\n            preflist.append(key)\n    if not preflist:\n        return 'data_content'\n    return ','.join(preflist)",
        "docstring": "Determine the preferred data tiers for Elasticsearch allocation based on the specified target tier. The function retrieves the available data tiers from the Elasticsearch cluster and constructs a string that lists suitable tiers from coldest to hottest, depending on the value of `target_tier`. \n\nParameters:\n- client: A client connection object to interact with the Elasticsearch cluster.\n- target_tier: A string indicating the target data tier to consider for preference (default is 'data_frozen'). Valid values include 'data_content', 'data_hot', 'data_warm', 'data_cold', and 'data_frozen'.\n\nReturns:\n- A comma-separated string representing the preferred data tiers, prioritizing colder tiers first. If no suitable tiers are available, it defaults to 'data_content'.\n\nThe function utilizes the `get_data_tiers` function to fetch the available data tiers and utilizes a `tiermap` constant defined within the function to map tier names to numerical values indicating their relative 'coldness' or 'hotness'.",
        "signature": "def get_tier_preference(client, target_tier='data_frozen'):",
        "type": "Function",
        "class_signature": null
      },
      "name_to_node_id": {
        "code": "def name_to_node_id(client, name):\n    \"\"\"Retrieve the node_id corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node whose ID is to be retrieved.\n:type name: str\n\n:returns: The node_id of the Elasticsearch node identified by the specified name, or None if no matching node is found.\n:rtype: str\n\nThis function interacts with the Elasticsearch NodesClient's info method to fetch node information. It utilizes the `filter_path` parameter to limit the retrieved information to only the nodes. If a node with the specified name is found, it logs the discovery; otherwise, it logs an error indicating the absence of a match.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param name: The node ``name``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type name: str\\n\\n    :returns: The node_id of the node identified by ``name``\\n    :rtype: str\\n    '\n    logger = logging.getLogger(__name__)\n    fpath = 'nodes'\n    info = client.nodes.info(filter_path=fpath)\n    for node in info['nodes']:\n        if info['nodes'][node]['name'] == name:\n            logger.debug('Found node_id \"%s\" for name \"%s\".', node, name)\n            return node\n    logger.error('No node_id found matching name: \"%s\"', name)\n    return None",
        "docstring": "Retrieve the node_id corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node whose ID is to be retrieved.\n:type name: str\n\n:returns: The node_id of the Elasticsearch node identified by the specified name, or None if no matching node is found.\n:rtype: str\n\nThis function interacts with the Elasticsearch NodesClient's info method to fetch node information. It utilizes the `filter_path` parameter to limit the retrieved information to only the nodes. If a node with the specified name is found, it logs the discovery; otherwise, it logs an error indicating the absence of a match.",
        "signature": "def name_to_node_id(client, name):",
        "type": "Function",
        "class_signature": null
      },
      "node_id_to_name": {
        "code": "def node_id_to_name(client, node_id):\n    \"\"\"Retrieves the name of an Elasticsearch node identified by its node ID.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the node for which the name is sought.\n:type node_id: str\n\n:returns: The name of the node associated with the provided `node_id`, or None if the node ID does not exist in the cluster.\n:rtype: str\n\nThis function uses the Elasticsearch client's `NodesClient.info()` method to fetch node information, specifically targeting the node's name using the filter path `nodes.{node_id}.name`. If the given `node_id` is not found in the node information, an error is logged. It leverages logging to provide debug and error messages, facilitating diagnostics when the function is used.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: The name of the node identified by ``node_id``\\n    :rtype: str\\n    '\n    logger = logging.getLogger(__name__)\n    fpath = f'nodes.{node_id}.name'\n    info = client.nodes.info(filter_path=fpath)\n    name = None\n    if node_id in info['nodes']:\n        name = info['nodes'][node_id]['name']\n    else:\n        logger.error('No node_id found matching: \"%s\"', node_id)\n    logger.debug('Name associated with node_id \"%s\": %s', node_id, name)\n    return name",
        "docstring": "Retrieves the name of an Elasticsearch node identified by its node ID.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the node for which the name is sought.\n:type node_id: str\n\n:returns: The name of the node associated with the provided `node_id`, or None if the node ID does not exist in the cluster.\n:rtype: str\n\nThis function uses the Elasticsearch client's `NodesClient.info()` method to fetch node information, specifically targeting the node's name using the filter path `nodes.{node_id}.name`. If the given `node_id` is not found in the node information, an error is logged. It leverages logging to provide debug and error messages, facilitating diagnostics when the function is used.",
        "signature": "def node_id_to_name(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "node_roles": {
        "code": "def node_roles(client, node_id):\n    \"\"\"Retrieve the roles assigned to a specified Elasticsearch node.\n\n:param client: A client connection object used to interface with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the node whose roles are to be retrieved.\n:type node_id: str\n\n:returns: A list of roles assigned to the node identified by `node_id`.\n:rtype: list\n\nThis function interacts with the Elasticsearch `NodesClient.info` method to retrieve information about nodes in the cluster. The roles information is accessed through a filter path constructed using the provided `node_id`. This allows for focused retrieval of only the relevant data, improving efficiency.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: The list of roles assigned to the node identified by ``node_id``\\n    :rtype: list\\n    '\n    fpath = f'nodes.{node_id}.roles'\n    return client.nodes.info(filter_path=fpath)['nodes'][node_id]['roles']",
        "docstring": "Retrieve the roles assigned to a specified Elasticsearch node.\n\n:param client: A client connection object used to interface with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the node whose roles are to be retrieved.\n:type node_id: str\n\n:returns: A list of roles assigned to the node identified by `node_id`.\n:rtype: list\n\nThis function interacts with the Elasticsearch `NodesClient.info` method to retrieve information about nodes in the cluster. The roles information is accessed through a filter path constructed using the provided `node_id`. This allows for focused retrieval of only the relevant data, improving efficiency.",
        "signature": "def node_roles(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "single_data_path": {
        "code": "def single_data_path(client, node_id):\n    \"\"\"Check if a specific Elasticsearch node has a single filesystem for data storage.\n\nThis function is essential for performing certain operations like shard shrinking, which requires that shards do not span across multiple filesystems. The function retrieves the filesystem statistics for the specified node and checks whether it has only one data path.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the Elasticsearch node to check.\n:type node_id: str\n\n:returns: ``True`` if the node has a single filesystem, otherwise ``False``.\n:rtype: bool\n\n:raises KeyError: If the specified node_id is not found in the node statistics.\"\"\"\n    '\\n    In order for a shrink to work, it should be on a single filesystem, as shards\\n    cannot span filesystems. Calls :py:meth:`~.elasticsearch.client.NodesClient.stats`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: ``True`` if the node has a single filesystem, else ``False``\\n    :rtype: bool\\n    '\n    fpath = f'nodes.{node_id}.fs.data'\n    response = client.nodes.stats(filter_path=fpath)\n    return len(response['nodes'][node_id]['fs']['data']) == 1",
        "docstring": "Check if a specific Elasticsearch node has a single filesystem for data storage.\n\nThis function is essential for performing certain operations like shard shrinking, which requires that shards do not span across multiple filesystems. The function retrieves the filesystem statistics for the specified node and checks whether it has only one data path.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the Elasticsearch node to check.\n:type node_id: str\n\n:returns: ``True`` if the node has a single filesystem, otherwise ``False``.\n:rtype: bool\n\n:raises KeyError: If the specified node_id is not found in the node statistics.",
        "signature": "def single_data_path(client, node_id):",
        "type": "Function",
        "class_signature": null
      }
    },
    "curator/exceptions.py": {}
  },
  "dependency_dict": {
    "curator/helpers/getters.py:get_tier_preference": {
      "curator/helpers/getters.py": {
        "get_data_tiers": {
          "code": "def get_data_tiers(client):\n    \"\"\"\n    Get all valid data tiers from the node roles of each node in the cluster by\n    polling each node\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The available data tiers in ``tier: bool`` form.\n    :rtype: dict\n    \"\"\"\n\n    def role_check(role, node_info):\n        if role in node_info['roles']:\n            return True\n        return False\n    info = client.nodes.info()['nodes']\n    retval = {'data_hot': False, 'data_warm': False, 'data_cold': False, 'data_frozen': False}\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval",
          "docstring": "Get all valid data tiers from the node roles of each node in the cluster by\npolling each node\n\n:param client: A client connection object\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: The available data tiers in ``tier: bool`` form.\n:rtype: dict",
          "signature": "def get_data_tiers(client):",
          "type": "Function",
          "class_signature": null
        }
      }
    }
  },
  "call_tree": {
    "tests/unit/test_helpers_getters.py:TestByteSize:test_byte_size": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestByteSize:test_byte_size_yotta": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestByteSize:test_raise_invalid": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_client_exception": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_empty": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_positive": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_all_positive": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_missing_arg": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_notfounderror_negative": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_positive": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_transporterror_negative": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_missing_repository_arg": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_notfounderror_negative": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_positive": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_transporterror_negative": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_missing_repo_arg": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_raises_exception_onfail": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_return_data": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestNodeRoles:test_node_roles": {
      "curator/helpers/getters.py:node_roles": {}
    },
    "tests/unit/test_helpers_getters.py:TestSingleDataPath:test_single_data_path": {
      "curator/helpers/getters.py:single_data_path": {}
    },
    "tests/unit/test_helpers_getters.py:TestSingleDataPath:test_two_data_paths": {
      "curator/helpers/getters.py:single_data_path": {}
    },
    "tests/unit/test_helpers_getters.py:TestNameToNodeId:test_negative": {
      "curator/helpers/getters.py:name_to_node_id": {}
    },
    "tests/unit/test_helpers_getters.py:TestNameToNodeId:test_positive": {
      "curator/helpers/getters.py:name_to_node_id": {}
    },
    "tests/unit/test_helpers_getters.py:TestNodeIdToName:test_negative": {
      "curator/helpers/getters.py:node_id_to_name": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetAliasActions:test_get_alias_actions": {
      "curator/helpers/getters.py:get_alias_actions": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference1": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference2": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference3": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference4": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference5": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_cli.py:TestCLIMethods:test_action_is_none": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_cli.py:TestCLIMethods:test_no_action": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_integrations.py:TestFilters:test_filter_by_alias_bad_aliases": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    }
  },
  "PRD": "# PROJECT NAME: elasticsearch_curator-test_helpers_getters\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 curator/\n    \u251c\u2500\u2500 exceptions.py\n    \u2502   \u2514\u2500\u2500 ConfigurationError.ConfigurationError\n    \u2514\u2500\u2500 helpers/\n        \u2514\u2500\u2500 getters.py\n            \u251c\u2500\u2500 byte_size\n            \u251c\u2500\u2500 get_alias_actions\n            \u251c\u2500\u2500 get_indices\n            \u251c\u2500\u2500 get_repository\n            \u251c\u2500\u2500 get_snapshot\n            \u251c\u2500\u2500 get_snapshot_data\n            \u251c\u2500\u2500 get_tier_preference\n            \u251c\u2500\u2500 name_to_node_id\n            \u251c\u2500\u2500 node_id_to_name\n            \u251c\u2500\u2500 node_roles\n            \u2514\u2500\u2500 single_data_path\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module provides comprehensive unit testing functionality for the `helpers.getters` utility methods, which are designed to interact with Elasticsearch and its ecosystem. It ensures the correctness and robustness of core operations such as retrieving index-related metadata, managing repository and snapshot information, handling node roles and configurations, and validating storage paths. The tests simulate realistic scenarios to verify proper error handling, input validation, and expected outputs for diverse use cases. By guaranteeing the reliability of these utility functions, the module addresses key challenges developers face when managing Elasticsearch resources, minimizing the risk of runtime errors and simplifying the development of higher-level integrations.\n\n## FILE 1: curator/helpers/getters.py\n\n- FUNCTION NAME: get_alias_actions\n  - SIGNATURE: def get_alias_actions(oldidx, newidx, aliases):\n  - DOCSTRING: \n```python\n\"\"\"\nGenerate actions for updating index aliases in Elasticsearch. \n\nThis function creates a list of actions to remove aliases from an old index and add them to a new index. The primary purpose is to facilitate an alias update operation in Elasticsearch by specifying the actions required to reassign aliases from one index to another.\n\nParameters:\n- oldidx (str): The name of the index from which aliases are being removed.\n- newidx (str): The name of the index to which aliases are being added.\n- aliases (dict): A dictionary of alias names, where each key represents an alias.\n\nReturns:\n- list: A list of actions formatted for use with the Elasticsearch IndicesClient update_aliases method, containing 'remove' actions for the old index and 'add' actions for the new index.\n\nThis function interacts with the Elasticsearch system to manage index aliases effectively.\n\"\"\"\n```\n\n- FUNCTION NAME: name_to_node_id\n  - SIGNATURE: def name_to_node_id(client, name):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the node_id corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node whose ID is to be retrieved.\n:type name: str\n\n:returns: The node_id of the Elasticsearch node identified by the specified name, or None if no matching node is found.\n:rtype: str\n\nThis function interacts with the Elasticsearch NodesClient's info method to fetch node information. It utilizes the `filter_path` parameter to limit the retrieved information to only the nodes. If a node with the specified name is found, it logs the discovery; otherwise, it logs an error indicating the absence of a match.\n\"\"\"\n```\n\n- FUNCTION NAME: node_id_to_name\n  - SIGNATURE: def node_id_to_name(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieves the name of an Elasticsearch node identified by its node ID.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the node for which the name is sought.\n:type node_id: str\n\n:returns: The name of the node associated with the provided `node_id`, or None if the node ID does not exist in the cluster.\n:rtype: str\n\nThis function uses the Elasticsearch client's `NodesClient.info()` method to fetch node information, specifically targeting the node's name using the filter path `nodes.{node_id}.name`. If the given `node_id` is not found in the node information, an error is logged. It leverages logging to provide debug and error messages, facilitating diagnostics when the function is used.\n\"\"\"\n```\n\n- FUNCTION NAME: get_tier_preference\n  - SIGNATURE: def get_tier_preference(client, target_tier='data_frozen'):\n  - DOCSTRING: \n```python\n\"\"\"\nDetermine the preferred data tiers for Elasticsearch allocation based on the specified target tier. The function retrieves the available data tiers from the Elasticsearch cluster and constructs a string that lists suitable tiers from coldest to hottest, depending on the value of `target_tier`. \n\nParameters:\n- client: A client connection object to interact with the Elasticsearch cluster.\n- target_tier: A string indicating the target data tier to consider for preference (default is 'data_frozen'). Valid values include 'data_content', 'data_hot', 'data_warm', 'data_cold', and 'data_frozen'.\n\nReturns:\n- A comma-separated string representing the preferred data tiers, prioritizing colder tiers first. If no suitable tiers are available, it defaults to 'data_content'.\n\nThe function utilizes the `get_data_tiers` function to fetch the available data tiers and utilizes a `tiermap` constant defined within the function to map tier names to numerical values indicating their relative 'coldness' or 'hotness'.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/getters.py:get_data_tiers\n\n- FUNCTION NAME: get_snapshot_data\n  - SIGNATURE: def get_snapshot_data(client, repository=None):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve all snapshots from a specified Elasticsearch snapshot repository.\n\n:param client: An Elasticsearch client connection object used to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository from which to retrieve snapshots. This parameter is mandatory.\n:type repository: str\n\n:raises MissingArgument: If the `repository` parameter is not provided.\n:raises FailedExecution: If there is an error accessing the snapshot information, capturing Elasticsearch transport errors or a not found error.\n\n:returns: A list of all snapshots from the specified `repository`. The list may be empty if no snapshots exist in the repository.\n:rtype: list\n\nThis function interacts with the Elasticsearch client's snapshot capabilities via the `snapshot.get` method to gather snapshot data and relies on constants that represent error handling during the retrieval process.\n\"\"\"\n```\n\n- FUNCTION NAME: get_indices\n  - SIGNATURE: def get_indices(client, search_pattern='_all'):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the current list of indices from an Elasticsearch cluster.\n\nThis function uses the Elasticsearch client's Cat API to fetch indices matching the specified search pattern. The response includes information about both open and closed indices, filtered to only include the 'index' and 'status' fields.\n\nParameters:\n- client (Elasticsearch): A client connection object for interacting with the Elasticsearch cluster.\n- search_pattern (str, optional): A pattern to match indices. Defaults to '_all', which retrieves all indices.\n\nReturns:\n- list: A list of index names currently in the cluster.\n\nRaises:\n- FailedExecution: If there is an error during the retrieval of indices.\n\nLoggers:\n- A logger from the `logging` module is used to log the list of indices at the debug level.\n\"\"\"\n```\n\n- FUNCTION NAME: get_repository\n  - SIGNATURE: def get_repository(client, repository=''):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the configuration information for a specified Elasticsearch snapshot repository.\n\nParameters:\n- client (Elasticsearch): A client connection object to interact with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository to retrieve configuration for. Defaults to an empty string.\n\nReturns:\n- dict: A dictionary containing the configuration information for the specified repository.\n\nRaises:\n- CuratorException: If the repository cannot be found or accessed due to a TransportError or NotFoundError, an exception is raised with details about the failure, prompting the user to check Elasticsearch logs for more information.\n\nDependencies:\nThis function relies on the `snapshot` method from the `client` which is an instance of the Elasticsearch client, and the `es8exc` module from `elasticsearch8` for managing exceptions specific to Elasticsearch operations.\n\"\"\"\n```\n\n- FUNCTION NAME: get_snapshot\n  - SIGNATURE: def get_snapshot(client, repository=None, snapshot=''):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve information about a specified snapshot from a given Elasticsearch snapshot repository.\n\nParameters:\n- client (Elasticsearch): A client connection object to interact with the Elasticsearch cluster.\n- repository (str): The name of the snapshot repository from which to retrieve snapshots. This parameter is mandatory.\n- snapshot (str): The name of a specific snapshot or a comma-separated list of snapshots to retrieve. If empty, information for all snapshots in the repository will be fetched.\n\nReturns:\n- dict: A dictionary containing detailed information about the specified snapshot(s). If no snapshots exist, an empty dictionary will be returned.\n\nRaises:\n- MissingArgument: If the 'repository' parameter is not provided.\n- FailedExecution: If there is an error retrieving snapshot information, typically due to connection issues or non-existence of the specified snapshot.\n\nThe function interacts with the `client.snapshot.get` method of the Elasticsearch client to fetch snapshot data. Additionally, it references exceptions defined in the `elasticsearch.exceptions` module for handling potential errors.\n\"\"\"\n```\n\n- FUNCTION NAME: single_data_path\n  - SIGNATURE: def single_data_path(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nCheck if a specific Elasticsearch node has a single filesystem for data storage.\n\nThis function is essential for performing certain operations like shard shrinking, which requires that shards do not span across multiple filesystems. The function retrieves the filesystem statistics for the specified node and checks whether it has only one data path.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the Elasticsearch node to check.\n:type node_id: str\n\n:returns: ``True`` if the node has a single filesystem, otherwise ``False``.\n:rtype: bool\n\n:raises KeyError: If the specified node_id is not found in the node statistics.\n\"\"\"\n```\n\n- FUNCTION NAME: byte_size\n  - SIGNATURE: def byte_size(num, suffix='B'):\n  - DOCSTRING: \n```python\n\"\"\"\nConvert a given byte size into a human-readable format with appropriate units.\n\n:param num: The size in bytes to be converted.\n:type num: int\n:param suffix: A suffix to append to the size string (default is 'B' for Bytes).\n:type suffix: str\n\n:returns: A formatted string representing the byte size in appropriate units (e.g., KB, MB, GB),\nwith a precision of one decimal place.\n:rtype: str\n\nThe function divides the input number by 1024 sequentially until it finds the appropriate unit \nfor representation. The unit prefixes used are: \n- '' for Bytes \n- 'K' for Kilobytes \n- 'M' for Megabytes \n- 'G' for Gigabytes \n- 'T' for Terabytes \n- 'P' for Petabytes \n- 'E' for Exabytes \n- 'Z' for Zettabytes. \n\nThis utility is helpful for formatting data sizes in a more understandable way throughout the codebase.\n\"\"\"\n```\n\n- FUNCTION NAME: node_roles\n  - SIGNATURE: def node_roles(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the roles assigned to a specified Elasticsearch node.\n\n:param client: A client connection object used to interface with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier of the node whose roles are to be retrieved.\n:type node_id: str\n\n:returns: A list of roles assigned to the node identified by `node_id`.\n:rtype: list\n\nThis function interacts with the Elasticsearch `NodesClient.info` method to retrieve information about nodes in the cluster. The roles information is accessed through a filter path constructed using the provided `node_id`. This allows for focused retrieval of only the relevant data, improving efficiency.\n\"\"\"\n```\n\n## FILE 2: curator/exceptions.py\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "curator/helpers/getters.py": "\"\"\"Utility functions that get things\"\"\"\nimport logging\nfrom elasticsearch8 import exceptions as es8exc\nfrom curator.exceptions import ConfigurationError, CuratorException, FailedExecution, MissingArgument\n\ndef escape_dots(stringval):\n    \"\"\"\n    Escape any dots (periods) in ``stringval``.\n\n    Primarily used for ``filter_path`` where dots are indicators of path nesting\n\n    :param stringval: A string, ostensibly an index name\n\n    :type stringval: str\n\n    :returns: ``stringval``, but with any periods escaped with a backslash\n    :retval: str\n    \"\"\"\n    return stringval.replace('.', '\\\\.')\n\ndef get_data_tiers(client):\n    \"\"\"\n    Get all valid data tiers from the node roles of each node in the cluster by\n    polling each node\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The available data tiers in ``tier: bool`` form.\n    :rtype: dict\n    \"\"\"\n\n    def role_check(role, node_info):\n        if role in node_info['roles']:\n            return True\n        return False\n    info = client.nodes.info()['nodes']\n    retval = {'data_hot': False, 'data_warm': False, 'data_cold': False, 'data_frozen': False}\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval\n\ndef get_write_index(client, alias):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param alias: An alias name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type alias: str\n\n    :returns: The the index name associated with the alias that is designated\n        ``is_write_index``\n    :rtype: str\n    \"\"\"\n    try:\n        response = client.indices.get_alias(index=alias)\n    except Exception as exc:\n        raise CuratorException(f'Alias {alias} not found') from exc\n    retval = None\n    if len(list(response.keys())) > 1:\n        for index in list(response.keys()):\n            try:\n                if response[index]['aliases'][alias]['is_write_index']:\n                    retval = index\n            except KeyError as exc:\n                raise FailedExecution('Invalid alias: is_write_index not found in 1 to many alias') from exc\n    else:\n        retval = list(response.keys())[0]\n    return retval\n\ndef index_size(client, idx, value='total'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.stats`\n\n    :param client: A client connection object\n    :param idx: An index name\n    :param value: One of either ``primaries`` or ``total``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type value: str\n\n    :returns: The sum of either ``primaries`` or ``total`` shards for index ``idx``\n    :rtype: integer\n    \"\"\"\n    fpath = f'indices.{escape_dots(idx)}.{value}.store.size_in_bytes'\n    return client.indices.stats(index=idx, filter_path=fpath)['indices'][idx][value]['store']['size_in_bytes']\n\ndef meta_getter(client, idx, get=None):\n    \"\"\"Meta Getter\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_settings` or\n    :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param idx: An Elasticsearch index\n    :param get: The kind of get to perform, e.g. settings or alias\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type get: str\n\n    :returns: The settings from the get call to the named index\n    :rtype: dict\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    acceptable = ['settings', 'alias']\n    if not get:\n        raise ConfigurationError('\"get\" can not be a NoneType')\n    if get not in acceptable:\n        raise ConfigurationError(f'\"get\" must be one of {acceptable}')\n    retval = {}\n    try:\n        if get == 'settings':\n            retval = client.indices.get_settings(index=idx)[idx]['settings']['index']\n        elif get == 'alias':\n            retval = client.indices.get_alias(index=idx)[idx]['aliases']\n    except es8exc.NotFoundError as missing:\n        logger.error('Index %s was not found!', idx)\n        raise es8exc.NotFoundError from missing\n    except KeyError as err:\n        logger.error('Key not found: %s', err)\n        raise KeyError from err\n    except Exception as exc:\n        logger.error('Exception encountered: %s', exc)\n    return retval",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\n\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\""
  }
}