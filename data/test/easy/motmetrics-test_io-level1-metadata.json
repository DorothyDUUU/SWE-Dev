{
  "dir_path": "/app/motmetrics",
  "package_name": "motmetrics",
  "sample_name": "motmetrics-test_io",
  "src_dir": "motmetrics/",
  "test_dir": "motmetrics/tests/",
  "test_file": "motmetrics/tests/test_io.py",
  "test_code": "# py-motmetrics - Metrics for multiple object tracker (MOT) benchmarking.\n# https://github.com/cheind/py-motmetrics/\n#\n# MIT License\n# Copyright (c) 2017-2020 Christoph Heindl, Jack Valmadre and others.\n# See LICENSE file for terms.\n\n\"\"\"Tests IO functions.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport pandas as pd\n\nimport motmetrics as mm\n\nDATA_DIR = os.path.join(os.path.dirname(__file__), '../data')\n\n\ndef test_load_vatic():\n    \"\"\"Tests VATIC_TXT format.\"\"\"\n    df = mm.io.loadtxt(os.path.join(DATA_DIR, 'iotest/vatic.txt'), fmt=mm.io.Format.VATIC_TXT)\n\n    expected = pd.DataFrame([\n        # F,ID,Y,W,H,L,O,G,F,A1,A2,A3,A4\n        (0, 0, 412, 0, 430, 124, 0, 0, 0, 'worker', 0, 0, 0, 0),\n        (1, 0, 412, 10, 430, 114, 0, 0, 1, 'pc', 1, 0, 1, 0),\n        (1, 1, 412, 0, 430, 124, 0, 0, 1, 'pc', 0, 1, 0, 0),\n        (2, 2, 412, 0, 430, 124, 0, 0, 1, 'worker', 1, 1, 0, 1)\n    ])\n\n    assert (df.reset_index().values == expected.values).all()\n\n\ndef test_load_motchallenge():\n    \"\"\"Tests MOT15_2D format.\"\"\"\n    df = mm.io.loadtxt(os.path.join(DATA_DIR, 'iotest/motchallenge.txt'), fmt=mm.io.Format.MOT15_2D)\n\n    expected = pd.DataFrame([\n        (1, 1, 398, 181, 121, 229, 1, -1, -1),  # Note -1 on x and y for correcting matlab\n        (1, 2, 281, 200, 92, 184, 1, -1, -1),\n        (2, 2, 268, 201, 87, 182, 1, -1, -1),\n        (2, 3, 70, 150, 100, 284, 1, -1, -1),\n        (2, 4, 199, 205, 55, 137, 1, -1, -1),\n    ])\n\n    assert (df.reset_index().values == expected.values).all()\n\n\ndef test_load_detrac_mat():\n    \"\"\"Tests DETRAC_MAT format.\"\"\"\n    df = mm.io.loadtxt(os.path.join(DATA_DIR, 'iotest/detrac.mat'), fmt=mm.io.Format.DETRAC_MAT)\n\n    expected = pd.DataFrame([\n        (1., 1., 745., 356., 148., 115., 1., -1., -1.),\n        (2., 1., 738., 350., 145., 111., 1., -1., -1.),\n        (3., 1., 732., 343., 142., 107., 1., -1., -1.),\n        (4., 1., 725., 336., 139., 104., 1., -1., -1.)\n    ])\n\n    assert (df.reset_index().values == expected.values).all()\n\n\ndef test_load_detrac_xml():\n    \"\"\"Tests DETRAC_XML format.\"\"\"\n    df = mm.io.loadtxt(os.path.join(DATA_DIR, 'iotest/detrac.xml'), fmt=mm.io.Format.DETRAC_XML)\n\n    expected = pd.DataFrame([\n        (1., 1., 744.6, 356.33, 148.2, 115.14, 1., -1., -1.),\n        (2., 1., 738.2, 349.51, 145.21, 111.29, 1., -1., -1.),\n        (3., 1., 731.8, 342.68, 142.23, 107.45, 1., -1., -1.),\n        (4., 1., 725.4, 335.85, 139.24, 103.62, 1., -1., -1.)\n    ])\n\n    assert (df.reset_index().values == expected.values).all()\n",
  "GT_file_code": {
    "motmetrics/io.py": "# py-motmetrics - Metrics for multiple object tracker (MOT) benchmarking.\n# https://github.com/cheind/py-motmetrics/\n#\n# MIT License\n# Copyright (c) 2017-2020 Christoph Heindl, Jack Valmadre and others.\n# See LICENSE file for terms.\n\n\"\"\"Functions for loading data and writing summaries.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom enum import Enum\nimport io\n\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nimport xmltodict\n\n\nclass Format(Enum):\n    \"\"\"Enumerates supported file formats.\"\"\"\n\n    MOT16 = 'mot16'\n    \"\"\"Milan, Anton, et al. \"Mot16: A benchmark for multi-object tracking.\" arXiv preprint arXiv:1603.00831 (2016).\"\"\"\n\n    MOT15_2D = 'mot15-2D'\n    \"\"\"Leal-Taixe, Laura, et al. \"MOTChallenge 2015: Towards a benchmark for multi-target tracking.\" arXiv preprint arXiv:1504.01942 (2015).\"\"\"\n\n    VATIC_TXT = 'vatic-txt'\n    \"\"\"Vondrick, Carl, Donald Patterson, and Deva Ramanan. \"Efficiently scaling up crowdsourced video annotation.\" International Journal of Computer Vision 101.1 (2013): 184-204.\n    https://github.com/cvondrick/vatic\n    \"\"\"\n\n    DETRAC_MAT = 'detrac-mat'\n    \"\"\"Wen, Longyin et al. \"UA-DETRAC: A New Benchmark and Protocol for Multi-Object Detection and Tracking.\" arXiv preprint arXiv:arXiv:1511.04136 (2016).\n    http://detrac-db.rit.albany.edu/download\n    \"\"\"\n\n    DETRAC_XML = 'detrac-xml'\n    \"\"\"Wen, Longyin et al. \"UA-DETRAC: A New Benchmark and Protocol for Multi-Object Detection and Tracking.\" arXiv preprint arXiv:arXiv:1511.04136 (2016).\n    http://detrac-db.rit.albany.edu/download\n    \"\"\"\n\n\ndef load_motchallenge(fname, **kwargs):\n    r\"\"\"Load MOT challenge data.\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    sep : str\n        Allowed field separators, defaults to '\\s+|\\t+|,'\n    min_confidence : float\n        Rows with confidence less than this threshold are removed.\n        Defaults to -1. You should set this to 1 when loading\n        ground truth MOTChallenge data, so that invalid rectangles in\n        the ground truth are not considered during matching.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n\n    sep = kwargs.pop('sep', r'\\s+|\\t+|,')\n    min_confidence = kwargs.pop('min_confidence', -1)\n    df = pd.read_csv(\n        fname,\n        sep=sep,\n        index_col=[0, 1],\n        skipinitialspace=True,\n        header=None,\n        names=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'],\n        engine='python'\n    )\n\n    # Account for matlab convention.\n    df[['X', 'Y']] -= (1, 1)\n\n    # Removed trailing column\n    del df['unused']\n\n    # Remove all rows without sufficient confidence\n    return df[df['Confidence'] >= min_confidence]\n\n\ndef load_vatictxt(fname, **kwargs):\n    \"\"\"Load Vatic text format.\n\n    Loads the vatic CSV text having the following columns per row\n\n        0   Track ID. All rows with the same ID belong to the same path.\n        1   xmin. The top left x-coordinate of the bounding box.\n        2   ymin. The top left y-coordinate of the bounding box.\n        3   xmax. The bottom right x-coordinate of the bounding box.\n        4   ymax. The bottom right y-coordinate of the bounding box.\n        5   frame. The frame that this annotation represents.\n        6   lost. If 1, the annotation is outside of the view screen.\n        7   occluded. If 1, the annotation is occluded.\n        8   generated. If 1, the annotation was automatically interpolated.\n        9  label. The label for this annotation, enclosed in quotation marks.\n        10+ attributes. Each column after this is an attribute set in the current frame\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Lost', 'Occluded', 'Generated', 'ClassId', '<Attr1>', '<Attr2>', ...\n        where <Attr1> is placeholder for the actual attribute name capitalized (first letter). The order of attribute\n        columns is sorted in attribute name. The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    # pylint: disable=too-many-locals\n\n    sep = kwargs.pop('sep', ' ')\n\n    with io.open(fname) as f:\n        # First time going over file, we collect the set of all variable activities\n        activities = set()\n        for line in f:\n            for c in line.rstrip().split(sep)[10:]:\n                activities.add(c)\n        activitylist = sorted(list(activities))\n\n        # Second time we construct artificial binary columns for each activity\n        data = []\n        f.seek(0)\n        for line in f:\n            fields = line.rstrip().split()\n            attrs = ['0'] * len(activitylist)\n            for a in fields[10:]:\n                attrs[activitylist.index(a)] = '1'\n            fields = fields[:10]\n            fields.extend(attrs)\n            data.append(' '.join(fields))\n\n        strdata = '\\n'.join(data)\n\n        dtype = {\n            'Id': np.int64,\n            'X': np.float32,\n            'Y': np.float32,\n            'Width': np.float32,\n            'Height': np.float32,\n            'FrameId': np.int64,\n            'Lost': bool,\n            'Occluded': bool,\n            'Generated': bool,\n            'ClassId': str,\n        }\n\n        # Remove quotes from activities\n        activitylist = [a.replace('\\\"', '').capitalize() for a in activitylist]\n\n        # Add dtypes for activities\n        for a in activitylist:\n            dtype[a] = bool\n\n        # Read from CSV\n        names = ['Id', 'X', 'Y', 'Width', 'Height', 'FrameId', 'Lost', 'Occluded', 'Generated', 'ClassId']\n        names.extend(activitylist)\n        df = pd.read_csv(io.StringIO(strdata), names=names, index_col=['FrameId', 'Id'], header=None, sep=' ')\n\n        # Correct Width and Height which are actually XMax, Ymax in files.\n        w = df['Width'] - df['X']\n        h = df['Height'] - df['Y']\n        df['Width'] = w\n        df['Height'] = h\n\n        return df\n\n\ndef load_detrac_mat(fname):\n    \"\"\"Loads UA-DETRAC annotations data from mat files\n\n    Competition Site: http://detrac-db.rit.albany.edu/download\n\n    File contains a nested structure of 2d arrays for indexed by frame id\n    and Object ID. Separate arrays for top, left, width and height are given.\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    Currently none of these arguments used.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n\n    matData = scipy.io.loadmat(fname)\n\n    frameList = matData['gtInfo'][0][0][4][0]\n    leftArray = matData['gtInfo'][0][0][0].astype(np.float32)\n    topArray = matData['gtInfo'][0][0][1].astype(np.float32)\n    widthArray = matData['gtInfo'][0][0][3].astype(np.float32)\n    heightArray = matData['gtInfo'][0][0][2].astype(np.float32)\n\n    parsedGT = []\n    for f in frameList:\n        ids = [i + 1 for i, v in enumerate(leftArray[f - 1]) if v > 0]\n        for i in ids:\n            row = []\n            row.append(f)\n            row.append(i)\n            row.append(leftArray[f - 1, i - 1] - widthArray[f - 1, i - 1] / 2)\n            row.append(topArray[f - 1, i - 1] - heightArray[f - 1, i - 1])\n            row.append(widthArray[f - 1, i - 1])\n            row.append(heightArray[f - 1, i - 1])\n            row.append(1)\n            row.append(-1)\n            row.append(-1)\n            row.append(-1)\n            parsedGT.append(row)\n\n    df = pd.DataFrame(parsedGT,\n                      columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'])\n    df.set_index(['FrameId', 'Id'], inplace=True)\n\n    # Account for matlab convention.\n    df[['X', 'Y']] -= (1, 1)\n\n    # Removed trailing column\n    del df['unused']\n\n    return df\n\n\ndef load_detrac_xml(fname):\n    \"\"\"Loads UA-DETRAC annotations data from xml files\n\n    Competition Site: http://detrac-db.rit.albany.edu/download\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    Currently none of these arguments used.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n\n    with io.open(fname) as fd:\n        doc = xmltodict.parse(fd.read())\n    frameList = doc['sequence']['frame']\n\n    parsedGT = []\n    for f in frameList:\n        fid = int(f['@num'])\n        targetList = f['target_list']['target']\n        if not isinstance(targetList, list):\n            targetList = [targetList]\n\n        for t in targetList:\n            row = []\n            row.append(fid)\n            row.append(int(t['@id']))\n            row.append(float(t['box']['@left']))\n            row.append(float(t['box']['@top']))\n            row.append(float(t['box']['@width']))\n            row.append(float(t['box']['@height']))\n            row.append(1)\n            row.append(-1)\n            row.append(-1)\n            row.append(-1)\n            parsedGT.append(row)\n\n    df = pd.DataFrame(parsedGT,\n                      columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'])\n    df.set_index(['FrameId', 'Id'], inplace=True)\n\n    # Account for matlab convention.\n    df[['X', 'Y']] -= (1, 1)\n\n    # Removed trailing column\n    del df['unused']\n\n    return df\n\n\ndef loadtxt(fname, fmt=Format.MOT15_2D, **kwargs):\n    \"\"\"Load data from any known format.\"\"\"\n    fmt = Format(fmt)\n\n    switcher = {\n        Format.MOT16: load_motchallenge,\n        Format.MOT15_2D: load_motchallenge,\n        Format.VATIC_TXT: load_vatictxt,\n        Format.DETRAC_MAT: load_detrac_mat,\n        Format.DETRAC_XML: load_detrac_xml\n    }\n    func = switcher.get(fmt)\n    return func(fname, **kwargs)\n\n\ndef render_summary(summary, formatters=None, namemap=None, buf=None):\n    \"\"\"Render metrics summary to console friendly tabular output.\n\n    Params\n    ------\n    summary : pd.DataFrame\n        Dataframe containing summaries in rows.\n\n    Kwargs\n    ------\n    buf : StringIO-like, optional\n        Buffer to write to\n    formatters : dict, optional\n        Dicionary defining custom formatters for individual metrics.\n        I.e `{'mota': '{:.2%}'.format}`. You can get preset formatters\n        from MetricsHost.formatters\n    namemap : dict, optional\n        Dictionary defining new metric names for display. I.e\n        `{'num_false_positives': 'FP'}`.\n\n    Returns\n    -------\n    string\n        Formatted string\n    \"\"\"\n\n    if namemap is not None:\n        summary = summary.rename(columns=namemap)\n        if formatters is not None:\n            formatters = {namemap.get(c, c): f for c, f in formatters.items()}\n\n    output = summary.to_string(\n        buf=buf,\n        formatters=formatters,\n    )\n\n    return output\n\n\nmotchallenge_metric_names = {\n    'idf1': 'IDF1',\n    'idp': 'IDP',\n    'idr': 'IDR',\n    'recall': 'Rcll',\n    'precision': 'Prcn',\n    'num_unique_objects': 'GT',\n    'mostly_tracked': 'MT',\n    'partially_tracked': 'PT',\n    'mostly_lost': 'ML',\n    'num_false_positives': 'FP',\n    'num_misses': 'FN',\n    'num_switches': 'IDs',\n    'num_fragmentations': 'FM',\n    'mota': 'MOTA',\n    'motp': 'MOTP',\n    'num_transfer': 'IDt',\n    'num_ascend': 'IDa',\n    'num_migrate': 'IDm',\n}\n\"\"\"A list mappings for metric names to comply with MOTChallenge.\"\"\"\n"
  },
  "GT_src_dict": {
    "motmetrics/io.py": {
      "loadtxt": {
        "code": "def loadtxt(fname, fmt=Format.MOT15_2D, **kwargs):\n    \"\"\"Load data from a specified format supported by the py-motmetrics library.\n\nParams\n------\nfname : str\n    The filename to load data from, expected to be in one of the formats listed.\nfmt : Format, optional\n    The format of the data file. Defaults to Format.MOT15_2D. The available formats are defined in the Format enum, which includes:\n    - Format.MOT16\n    - Format.MOT15_2D\n    - Format.VATIC_TXT\n    - Format.DETRAC_MAT\n    - Format.DETRAC_XML\n\nKwargs\n------\n**kwargs : additional keyword arguments\n    These parameters are passed to the specific loading function corresponding to the selected format.\n\nReturns\n-------\ndf : pandas.DataFrame\n    A DataFrame containing the loaded data, indexed by ('FrameId', 'Id') with columns such as 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', and 'Visibility'.\n\nThis function utilizes a switch-case mechanism to select the appropriate loading function based on the format specified, and it simplifies the data loading process for different multi-object tracking formats handled by the library. It interacts with the Format enum to ensure the correct mapping to the respective loading function.\"\"\"\n    'Load data from any known format.'\n    fmt = Format(fmt)\n    switcher = {Format.MOT16: load_motchallenge, Format.MOT15_2D: load_motchallenge, Format.VATIC_TXT: load_vatictxt, Format.DETRAC_MAT: load_detrac_mat, Format.DETRAC_XML: load_detrac_xml}\n    func = switcher.get(fmt)\n    return func(fname, **kwargs)",
        "docstring": "Load data from a specified format supported by the py-motmetrics library.\n\nParams\n------\nfname : str\n    The filename to load data from, expected to be in one of the formats listed.\nfmt : Format, optional\n    The format of the data file. Defaults to Format.MOT15_2D. The available formats are defined in the Format enum, which includes:\n    - Format.MOT16\n    - Format.MOT15_2D\n    - Format.VATIC_TXT\n    - Format.DETRAC_MAT\n    - Format.DETRAC_XML\n\nKwargs\n------\n**kwargs : additional keyword arguments\n    These parameters are passed to the specific loading function corresponding to the selected format.\n\nReturns\n-------\ndf : pandas.DataFrame\n    A DataFrame containing the loaded data, indexed by ('FrameId', 'Id') with columns such as 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', and 'Visibility'.\n\nThis function utilizes a switch-case mechanism to select the appropriate loading function based on the format specified, and it simplifies the data loading process for different multi-object tracking formats handled by the library. It interacts with the Format enum to ensure the correct mapping to the respective loading function.",
        "signature": "def loadtxt(fname, fmt=Format.MOT15_2D, **kwargs):",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {
    "motmetrics/io.py:loadtxt": {
      "motmetrics/io.py": {
        "load_motchallenge": {
          "code": "def load_motchallenge(fname, **kwargs):\n    \"\"\"Load MOT challenge data.\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    sep : str\n        Allowed field separators, defaults to '\\\\s+|\\\\t+|,'\n    min_confidence : float\n        Rows with confidence less than this threshold are removed.\n        Defaults to -1. You should set this to 1 when loading\n        ground truth MOTChallenge data, so that invalid rectangles in\n        the ground truth are not considered during matching.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    sep = kwargs.pop('sep', '\\\\s+|\\\\t+|,')\n    min_confidence = kwargs.pop('min_confidence', -1)\n    df = pd.read_csv(fname, sep=sep, index_col=[0, 1], skipinitialspace=True, header=None, names=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'], engine='python')\n    df[['X', 'Y']] -= (1, 1)\n    del df['unused']\n    return df[df['Confidence'] >= min_confidence]",
          "docstring": "Load MOT challenge data.\n\nParams\n------\nfname : str\n    Filename to load data from\n\nKwargs\n------\nsep : str\n    Allowed field separators, defaults to '\\s+|\\t+|,'\nmin_confidence : float\n    Rows with confidence less than this threshold are removed.\n    Defaults to -1. You should set this to 1 when loading\n    ground truth MOTChallenge data, so that invalid rectangles in\n    the ground truth are not considered during matching.\n\nReturns\n------\ndf : pandas.DataFrame\n    The returned dataframe has the following columns\n        'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n    The dataframe is indexed by ('FrameId', 'Id')",
          "signature": "def load_motchallenge(fname, **kwargs):",
          "type": "Function",
          "class_signature": null
        },
        "load_vatictxt": {
          "code": "def load_vatictxt(fname, **kwargs):\n    \"\"\"Load Vatic text format.\n\n    Loads the vatic CSV text having the following columns per row\n\n        0   Track ID. All rows with the same ID belong to the same path.\n        1   xmin. The top left x-coordinate of the bounding box.\n        2   ymin. The top left y-coordinate of the bounding box.\n        3   xmax. The bottom right x-coordinate of the bounding box.\n        4   ymax. The bottom right y-coordinate of the bounding box.\n        5   frame. The frame that this annotation represents.\n        6   lost. If 1, the annotation is outside of the view screen.\n        7   occluded. If 1, the annotation is occluded.\n        8   generated. If 1, the annotation was automatically interpolated.\n        9  label. The label for this annotation, enclosed in quotation marks.\n        10+ attributes. Each column after this is an attribute set in the current frame\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Lost', 'Occluded', 'Generated', 'ClassId', '<Attr1>', '<Attr2>', ...\n        where <Attr1> is placeholder for the actual attribute name capitalized (first letter). The order of attribute\n        columns is sorted in attribute name. The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    sep = kwargs.pop('sep', ' ')\n    with io.open(fname) as f:\n        activities = set()\n        for line in f:\n            for c in line.rstrip().split(sep)[10:]:\n                activities.add(c)\n        activitylist = sorted(list(activities))\n        data = []\n        f.seek(0)\n        for line in f:\n            fields = line.rstrip().split()\n            attrs = ['0'] * len(activitylist)\n            for a in fields[10:]:\n                attrs[activitylist.index(a)] = '1'\n            fields = fields[:10]\n            fields.extend(attrs)\n            data.append(' '.join(fields))\n        strdata = '\\n'.join(data)\n        dtype = {'Id': np.int64, 'X': np.float32, 'Y': np.float32, 'Width': np.float32, 'Height': np.float32, 'FrameId': np.int64, 'Lost': bool, 'Occluded': bool, 'Generated': bool, 'ClassId': str}\n        activitylist = [a.replace('\"', '').capitalize() for a in activitylist]\n        for a in activitylist:\n            dtype[a] = bool\n        names = ['Id', 'X', 'Y', 'Width', 'Height', 'FrameId', 'Lost', 'Occluded', 'Generated', 'ClassId']\n        names.extend(activitylist)\n        df = pd.read_csv(io.StringIO(strdata), names=names, index_col=['FrameId', 'Id'], header=None, sep=' ')\n        w = df['Width'] - df['X']\n        h = df['Height'] - df['Y']\n        df['Width'] = w\n        df['Height'] = h\n        return df",
          "docstring": "Load Vatic text format.\n\nLoads the vatic CSV text having the following columns per row\n\n    0   Track ID. All rows with the same ID belong to the same path.\n    1   xmin. The top left x-coordinate of the bounding box.\n    2   ymin. The top left y-coordinate of the bounding box.\n    3   xmax. The bottom right x-coordinate of the bounding box.\n    4   ymax. The bottom right y-coordinate of the bounding box.\n    5   frame. The frame that this annotation represents.\n    6   lost. If 1, the annotation is outside of the view screen.\n    7   occluded. If 1, the annotation is occluded.\n    8   generated. If 1, the annotation was automatically interpolated.\n    9  label. The label for this annotation, enclosed in quotation marks.\n    10+ attributes. Each column after this is an attribute set in the current frame\n\nParams\n------\nfname : str\n    Filename to load data from\n\nReturns\n------\ndf : pandas.DataFrame\n    The returned dataframe has the following columns\n        'X', 'Y', 'Width', 'Height', 'Lost', 'Occluded', 'Generated', 'ClassId', '<Attr1>', '<Attr2>', ...\n    where <Attr1> is placeholder for the actual attribute name capitalized (first letter). The order of attribute\n    columns is sorted in attribute name. The dataframe is indexed by ('FrameId', 'Id')",
          "signature": "def load_vatictxt(fname, **kwargs):",
          "type": "Function",
          "class_signature": null
        },
        "load_detrac_mat": {
          "code": "def load_detrac_mat(fname):\n    \"\"\"Loads UA-DETRAC annotations data from mat files\n\n    Competition Site: http://detrac-db.rit.albany.edu/download\n\n    File contains a nested structure of 2d arrays for indexed by frame id\n    and Object ID. Separate arrays for top, left, width and height are given.\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    Currently none of these arguments used.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    matData = scipy.io.loadmat(fname)\n    frameList = matData['gtInfo'][0][0][4][0]\n    leftArray = matData['gtInfo'][0][0][0].astype(np.float32)\n    topArray = matData['gtInfo'][0][0][1].astype(np.float32)\n    widthArray = matData['gtInfo'][0][0][3].astype(np.float32)\n    heightArray = matData['gtInfo'][0][0][2].astype(np.float32)\n    parsedGT = []\n    for f in frameList:\n        ids = [i + 1 for i, v in enumerate(leftArray[f - 1]) if v > 0]\n        for i in ids:\n            row = []\n            row.append(f)\n            row.append(i)\n            row.append(leftArray[f - 1, i - 1] - widthArray[f - 1, i - 1] / 2)\n            row.append(topArray[f - 1, i - 1] - heightArray[f - 1, i - 1])\n            row.append(widthArray[f - 1, i - 1])\n            row.append(heightArray[f - 1, i - 1])\n            row.append(1)\n            row.append(-1)\n            row.append(-1)\n            row.append(-1)\n            parsedGT.append(row)\n    df = pd.DataFrame(parsedGT, columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'])\n    df.set_index(['FrameId', 'Id'], inplace=True)\n    df[['X', 'Y']] -= (1, 1)\n    del df['unused']\n    return df",
          "docstring": "Loads UA-DETRAC annotations data from mat files\n\nCompetition Site: http://detrac-db.rit.albany.edu/download\n\nFile contains a nested structure of 2d arrays for indexed by frame id\nand Object ID. Separate arrays for top, left, width and height are given.\n\nParams\n------\nfname : str\n    Filename to load data from\n\nKwargs\n------\nCurrently none of these arguments used.\n\nReturns\n------\ndf : pandas.DataFrame\n    The returned dataframe has the following columns\n        'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n    The dataframe is indexed by ('FrameId', 'Id')",
          "signature": "def load_detrac_mat(fname):",
          "type": "Function",
          "class_signature": null
        },
        "load_detrac_xml": {
          "code": "def load_detrac_xml(fname):\n    \"\"\"Loads UA-DETRAC annotations data from xml files\n\n    Competition Site: http://detrac-db.rit.albany.edu/download\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    Currently none of these arguments used.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    with io.open(fname) as fd:\n        doc = xmltodict.parse(fd.read())\n    frameList = doc['sequence']['frame']\n    parsedGT = []\n    for f in frameList:\n        fid = int(f['@num'])\n        targetList = f['target_list']['target']\n        if not isinstance(targetList, list):\n            targetList = [targetList]\n        for t in targetList:\n            row = []\n            row.append(fid)\n            row.append(int(t['@id']))\n            row.append(float(t['box']['@left']))\n            row.append(float(t['box']['@top']))\n            row.append(float(t['box']['@width']))\n            row.append(float(t['box']['@height']))\n            row.append(1)\n            row.append(-1)\n            row.append(-1)\n            row.append(-1)\n            parsedGT.append(row)\n    df = pd.DataFrame(parsedGT, columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'])\n    df.set_index(['FrameId', 'Id'], inplace=True)\n    df[['X', 'Y']] -= (1, 1)\n    del df['unused']\n    return df",
          "docstring": "Loads UA-DETRAC annotations data from xml files\n\nCompetition Site: http://detrac-db.rit.albany.edu/download\n\nParams\n------\nfname : str\n    Filename to load data from\n\nKwargs\n------\nCurrently none of these arguments used.\n\nReturns\n------\ndf : pandas.DataFrame\n    The returned dataframe has the following columns\n        'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n    The dataframe is indexed by ('FrameId', 'Id')",
          "signature": "def load_detrac_xml(fname):",
          "type": "Function",
          "class_signature": null
        }
      }
    }
  },
  "PRD": "# PROJECT NAME: motmetrics-test_io\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 motmetrics/\n    \u2514\u2500\u2500 io.py\n        \u2514\u2500\u2500 loadtxt\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThis module facilitates the evaluation and benchmarking of multiple object tracking (MOT) systems by providing robust functionality for loading, interpreting, and validating tracking data in various standardized formats. It supports widely used MOT data formats, such as VATIC_TXT, MOT15_2D, DETRAC_MAT, and DETRAC_XML, enabling seamless integration with commonly encountered datasets. By ensuring accurate and consistent parsing of ground truth and tracking data, the module streamlines the process of preparing datasets for analysis and comparison, reducing errors and development overhead for users and researchers. Its primary goal is to enable developers to evaluate the performance of tracking algorithms against established benchmarks with efficiency and reliability.\n\n## FILE 1: motmetrics/io.py\n\n- FUNCTION NAME: loadtxt\n  - SIGNATURE: def loadtxt(fname, fmt=Format.MOT15_2D, **kwargs):\n  - DOCSTRING: \n```python\n\"\"\"\nLoad data from a specified format supported by the py-motmetrics library.\n\nParams\n------\nfname : str\n    The filename to load data from, expected to be in one of the formats listed.\nfmt : Format, optional\n    The format of the data file. Defaults to Format.MOT15_2D. The available formats are defined in the Format enum, which includes:\n    - Format.MOT16\n    - Format.MOT15_2D\n    - Format.VATIC_TXT\n    - Format.DETRAC_MAT\n    - Format.DETRAC_XML\n\nKwargs\n------\n**kwargs : additional keyword arguments\n    These parameters are passed to the specific loading function corresponding to the selected format.\n\nReturns\n-------\ndf : pandas.DataFrame\n    A DataFrame containing the loaded data, indexed by ('FrameId', 'Id') with columns such as 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', and 'Visibility'.\n\nThis function utilizes a switch-case mechanism to select the appropriate loading function based on the format specified, and it simplifies the data loading process for different multi-object tracking formats handled by the library. It interacts with the Format enum to ensure the correct mapping to the respective loading function.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - motmetrics/io.py:load_motchallenge\n    - motmetrics/io.py:load_detrac_mat\n    - motmetrics/io.py:load_vatictxt\n    - motmetrics/io.py:load_detrac_xml\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "motmetrics/io.py": "\"\"\"Functions for loading data and writing summaries.\"\"\"\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom enum import Enum\nimport io\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nimport xmltodict\n\nclass Format(Enum):\n    \"\"\"Enumerates supported file formats.\"\"\"\n    MOT16 = 'mot16'\n    'Milan, Anton, et al. \"Mot16: A benchmark for multi-object tracking.\" arXiv preprint arXiv:1603.00831 (2016).'\n    MOT15_2D = 'mot15-2D'\n    'Leal-Taixe, Laura, et al. \"MOTChallenge 2015: Towards a benchmark for multi-target tracking.\" arXiv preprint arXiv:1504.01942 (2015).'\n    VATIC_TXT = 'vatic-txt'\n    'Vondrick, Carl, Donald Patterson, and Deva Ramanan. \"Efficiently scaling up crowdsourced video annotation.\" International Journal of Computer Vision 101.1 (2013): 184-204.\\n    https://github.com/cvondrick/vatic\\n    '\n    DETRAC_MAT = 'detrac-mat'\n    'Wen, Longyin et al. \"UA-DETRAC: A New Benchmark and Protocol for Multi-Object Detection and Tracking.\" arXiv preprint arXiv:arXiv:1511.04136 (2016).\\n    http://detrac-db.rit.albany.edu/download\\n    '\n    DETRAC_XML = 'detrac-xml'\n    'Wen, Longyin et al. \"UA-DETRAC: A New Benchmark and Protocol for Multi-Object Detection and Tracking.\" arXiv preprint arXiv:arXiv:1511.04136 (2016).\\n    http://detrac-db.rit.albany.edu/download\\n    '\n\ndef load_motchallenge(fname, **kwargs):\n    \"\"\"Load MOT challenge data.\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    sep : str\n        Allowed field separators, defaults to '\\\\s+|\\\\t+|,'\n    min_confidence : float\n        Rows with confidence less than this threshold are removed.\n        Defaults to -1. You should set this to 1 when loading\n        ground truth MOTChallenge data, so that invalid rectangles in\n        the ground truth are not considered during matching.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    sep = kwargs.pop('sep', '\\\\s+|\\\\t+|,')\n    min_confidence = kwargs.pop('min_confidence', -1)\n    df = pd.read_csv(fname, sep=sep, index_col=[0, 1], skipinitialspace=True, header=None, names=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'], engine='python')\n    df[['X', 'Y']] -= (1, 1)\n    del df['unused']\n    return df[df['Confidence'] >= min_confidence]\n\ndef load_vatictxt(fname, **kwargs):\n    \"\"\"Load Vatic text format.\n\n    Loads the vatic CSV text having the following columns per row\n\n        0   Track ID. All rows with the same ID belong to the same path.\n        1   xmin. The top left x-coordinate of the bounding box.\n        2   ymin. The top left y-coordinate of the bounding box.\n        3   xmax. The bottom right x-coordinate of the bounding box.\n        4   ymax. The bottom right y-coordinate of the bounding box.\n        5   frame. The frame that this annotation represents.\n        6   lost. If 1, the annotation is outside of the view screen.\n        7   occluded. If 1, the annotation is occluded.\n        8   generated. If 1, the annotation was automatically interpolated.\n        9  label. The label for this annotation, enclosed in quotation marks.\n        10+ attributes. Each column after this is an attribute set in the current frame\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Lost', 'Occluded', 'Generated', 'ClassId', '<Attr1>', '<Attr2>', ...\n        where <Attr1> is placeholder for the actual attribute name capitalized (first letter). The order of attribute\n        columns is sorted in attribute name. The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    sep = kwargs.pop('sep', ' ')\n    with io.open(fname) as f:\n        activities = set()\n        for line in f:\n            for c in line.rstrip().split(sep)[10:]:\n                activities.add(c)\n        activitylist = sorted(list(activities))\n        data = []\n        f.seek(0)\n        for line in f:\n            fields = line.rstrip().split()\n            attrs = ['0'] * len(activitylist)\n            for a in fields[10:]:\n                attrs[activitylist.index(a)] = '1'\n            fields = fields[:10]\n            fields.extend(attrs)\n            data.append(' '.join(fields))\n        strdata = '\\n'.join(data)\n        dtype = {'Id': np.int64, 'X': np.float32, 'Y': np.float32, 'Width': np.float32, 'Height': np.float32, 'FrameId': np.int64, 'Lost': bool, 'Occluded': bool, 'Generated': bool, 'ClassId': str}\n        activitylist = [a.replace('\"', '').capitalize() for a in activitylist]\n        for a in activitylist:\n            dtype[a] = bool\n        names = ['Id', 'X', 'Y', 'Width', 'Height', 'FrameId', 'Lost', 'Occluded', 'Generated', 'ClassId']\n        names.extend(activitylist)\n        df = pd.read_csv(io.StringIO(strdata), names=names, index_col=['FrameId', 'Id'], header=None, sep=' ')\n        w = df['Width'] - df['X']\n        h = df['Height'] - df['Y']\n        df['Width'] = w\n        df['Height'] = h\n        return df\n\ndef load_detrac_mat(fname):\n    \"\"\"Loads UA-DETRAC annotations data from mat files\n\n    Competition Site: http://detrac-db.rit.albany.edu/download\n\n    File contains a nested structure of 2d arrays for indexed by frame id\n    and Object ID. Separate arrays for top, left, width and height are given.\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    Currently none of these arguments used.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    matData = scipy.io.loadmat(fname)\n    frameList = matData['gtInfo'][0][0][4][0]\n    leftArray = matData['gtInfo'][0][0][0].astype(np.float32)\n    topArray = matData['gtInfo'][0][0][1].astype(np.float32)\n    widthArray = matData['gtInfo'][0][0][3].astype(np.float32)\n    heightArray = matData['gtInfo'][0][0][2].astype(np.float32)\n    parsedGT = []\n    for f in frameList:\n        ids = [i + 1 for i, v in enumerate(leftArray[f - 1]) if v > 0]\n        for i in ids:\n            row = []\n            row.append(f)\n            row.append(i)\n            row.append(leftArray[f - 1, i - 1] - widthArray[f - 1, i - 1] / 2)\n            row.append(topArray[f - 1, i - 1] - heightArray[f - 1, i - 1])\n            row.append(widthArray[f - 1, i - 1])\n            row.append(heightArray[f - 1, i - 1])\n            row.append(1)\n            row.append(-1)\n            row.append(-1)\n            row.append(-1)\n            parsedGT.append(row)\n    df = pd.DataFrame(parsedGT, columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'])\n    df.set_index(['FrameId', 'Id'], inplace=True)\n    df[['X', 'Y']] -= (1, 1)\n    del df['unused']\n    return df\n\ndef load_detrac_xml(fname):\n    \"\"\"Loads UA-DETRAC annotations data from xml files\n\n    Competition Site: http://detrac-db.rit.albany.edu/download\n\n    Params\n    ------\n    fname : str\n        Filename to load data from\n\n    Kwargs\n    ------\n    Currently none of these arguments used.\n\n    Returns\n    ------\n    df : pandas.DataFrame\n        The returned dataframe has the following columns\n            'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility'\n        The dataframe is indexed by ('FrameId', 'Id')\n    \"\"\"\n    with io.open(fname) as fd:\n        doc = xmltodict.parse(fd.read())\n    frameList = doc['sequence']['frame']\n    parsedGT = []\n    for f in frameList:\n        fid = int(f['@num'])\n        targetList = f['target_list']['target']\n        if not isinstance(targetList, list):\n            targetList = [targetList]\n        for t in targetList:\n            row = []\n            row.append(fid)\n            row.append(int(t['@id']))\n            row.append(float(t['box']['@left']))\n            row.append(float(t['box']['@top']))\n            row.append(float(t['box']['@width']))\n            row.append(float(t['box']['@height']))\n            row.append(1)\n            row.append(-1)\n            row.append(-1)\n            row.append(-1)\n            parsedGT.append(row)\n    df = pd.DataFrame(parsedGT, columns=['FrameId', 'Id', 'X', 'Y', 'Width', 'Height', 'Confidence', 'ClassId', 'Visibility', 'unused'])\n    df.set_index(['FrameId', 'Id'], inplace=True)\n    df[['X', 'Y']] -= (1, 1)\n    del df['unused']\n    return df\n\ndef render_summary(summary, formatters=None, namemap=None, buf=None):\n    \"\"\"Render metrics summary to console friendly tabular output.\n\n    Params\n    ------\n    summary : pd.DataFrame\n        Dataframe containing summaries in rows.\n\n    Kwargs\n    ------\n    buf : StringIO-like, optional\n        Buffer to write to\n    formatters : dict, optional\n        Dicionary defining custom formatters for individual metrics.\n        I.e `{'mota': '{:.2%}'.format}`. You can get preset formatters\n        from MetricsHost.formatters\n    namemap : dict, optional\n        Dictionary defining new metric names for display. I.e\n        `{'num_false_positives': 'FP'}`.\n\n    Returns\n    -------\n    string\n        Formatted string\n    \"\"\"\n    if namemap is not None:\n        summary = summary.rename(columns=namemap)\n        if formatters is not None:\n            formatters = {namemap.get(c, c): f for c, f in formatters.items()}\n    output = summary.to_string(buf=buf, formatters=formatters)\n    return output\nmotchallenge_metric_names = {'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', 'precision': 'Prcn', 'num_unique_objects': 'GT', 'mostly_tracked': 'MT', 'partially_tracked': 'PT', 'mostly_lost': 'ML', 'num_false_positives': 'FP', 'num_misses': 'FN', 'num_switches': 'IDs', 'num_fragmentations': 'FM', 'mota': 'MOTA', 'motp': 'MOTP', 'num_transfer': 'IDt', 'num_ascend': 'IDa', 'num_migrate': 'IDm'}\n'A list mappings for metric names to comply with MOTChallenge.'"
  },
  "call_tree": {
    "motmetrics/tests/test_io.py:test_load_vatic": {
      "motmetrics/io.py:loadtxt": {
        "motmetrics/io.py:load_vatictxt": {}
      }
    },
    "motmetrics/tests/test_io.py:test_load_motchallenge": {
      "motmetrics/io.py:loadtxt": {
        "motmetrics/io.py:load_motchallenge": {}
      }
    },
    "motmetrics/tests/test_io.py:test_load_detrac_mat": {
      "motmetrics/io.py:loadtxt": {
        "motmetrics/io.py:load_detrac_mat": {}
      }
    },
    "motmetrics/tests/test_io.py:test_load_detrac_xml": {
      "motmetrics/io.py:loadtxt": {
        "motmetrics/io.py:load_detrac_xml": {}
      }
    }
  }
}