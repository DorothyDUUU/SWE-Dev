{
  "dir_path": "/app/skforecast",
  "package_name": "skforecast",
  "sample_name": "skforecast-test_mean_absolute_scaled_error",
  "src_dir": "skforecast/",
  "test_dir": "tests/",
  "test_file": "skforecast/metrics/tests/tests_metrics/test_mean_absolute_scaled_error.py",
  "test_code": "# Unit test mean_absolute_scaled_error\n# ==============================================================================\nimport re\nimport pytest\nimport numpy as np\nimport pandas as pd\nfrom skforecast.metrics import mean_absolute_scaled_error\n\n\ndef test_mean_absolute_scaled_error_input_types():\n    \"\"\"\n    Test input types of mean_absolute_scaled_error.\n    \"\"\"\n    y_true = np.array([1.0, 2.0, 3.0, 4.0])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    y_train = np.array([0.5, 1.5, 2.5, 3.5, 4.5])\n\n    err_msg = re.escape(\"`y_true` must be a pandas Series or numpy ndarray\")\n    with pytest.raises(TypeError, match = err_msg):\n        mean_absolute_scaled_error([1, 2, 3], y_pred, y_train)\n    \n    err_msg = re.escape(\"`y_pred` must be a pandas Series or numpy ndarray\")\n    with pytest.raises(TypeError, match = err_msg):\n        mean_absolute_scaled_error(y_true, [1, 2, 3], y_train)\n    \n    err_msg = re.escape(\"`y_train` must be a list, pandas Series or numpy ndarray\")\n    with pytest.raises(TypeError, match = err_msg):\n        mean_absolute_scaled_error(y_true, y_pred, 'not_valid_input')\n    \n    err_msg = re.escape(\n        (\"When `y_train` is a list, each element must be a pandas Series \"\n         \"or numpy ndarray\")\n    )\n    with pytest.raises(TypeError, match = err_msg):\n        mean_absolute_scaled_error(y_true, y_pred, [1, 2, 3])\n\n\ndef test_mean_absolute_scaled_error_input_length():\n    \"\"\"\n    Test input lengths of mean_absolute_scaled_error.\n    \"\"\"\n    y_true = np.array([1.0, 2.0, 3.0, 4.0])\n    y_pred = np.array([1.1, 1.9, 3.2])\n    y_train = np.array([0.5, 1.5, 2.5, 3.5, 4.5])\n\n    err_msg = re.escape(\"`y_true` and `y_pred` must have the same length\")\n    with pytest.raises(ValueError, match = err_msg):\n        mean_absolute_scaled_error(y_true, y_pred, y_train)\n\n    err_msg = re.escape(\"`y_true` and `y_pred` must have the same length\")\n    with pytest.raises(ValueError, match = err_msg):\n        mean_absolute_scaled_error(y_true, y_pred, y_train)\n\n\ndef test_mean_absolute_scaled_error_empty_input():\n    \"\"\"\n    Test empty input of mean_absolute_scaled_error.\n    \"\"\"\n    y_true = np.array([1.0, 2.0, 3.0, 4.0])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    y_train = np.array([0.5, 1.5, 2.5, 3.5, 4.5])\n\n    err_msg = re.escape(\"`y_true` and `y_pred` must have at least one element\")\n    with pytest.raises(ValueError, match = err_msg):\n        mean_absolute_scaled_error(np.array([]), np.array([]), y_train)\n\n\ndef test_mean_absolute_scaled_error_output():\n    \"\"\"\n    Check that the output of mean_absolute_scaled_error is correct.\n    \"\"\"\n    y_true = np.array([1.0, 2.0, 3.0, 4.0])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    y_train = np.array([0.5, 1.5, 2.5, 3.5, 4.5])\n    expected_mase = np.mean(np.abs(y_true - y_pred)) / np.mean(np.abs(np.diff(y_train)))\n\n    assert np.isclose(mean_absolute_scaled_error(y_true, y_pred, y_train), expected_mase)\n\n\ndef test_mean_absolute_scaled_error_pandas_series_input():\n    \"\"\"\n    Test pandas Series input of mean_absolute_scaled_error.\n    \"\"\"\n    y_true = np.array([1.0, 2.0, 3.0, 4.0])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    y_train = np.array([0.5, 1.5, 2.5, 3.5, 4.5])\n    y_true_series = pd.Series(y_true)\n    y_pred_series = pd.Series(y_pred)\n    y_train_series = pd.Series(y_train)\n\n    expected_mase = np.mean(np.abs(y_true - y_pred)) / np.mean(np.abs(np.diff(y_train)))\n\n    assert np.isclose(mean_absolute_scaled_error(y_true_series, y_pred_series, y_train_series), expected_mase)\n    \n",
  "GT_file_code": {
    "skforecast/metrics/metrics.py": "################################################################################\n#                                metrics                                       #\n#                                                                              #\n# This work by skforecast team is licensed under the BSD 3-Clause License.     #\n################################################################################\n# coding=utf-8\n\nfrom typing import Union, Callable\nimport numpy as np\nimport pandas as pd\nimport inspect\nfrom functools import wraps\nfrom sklearn.metrics import (\n    mean_squared_error,\n    mean_absolute_error,\n    mean_absolute_percentage_error,\n    mean_squared_log_error,\n    median_absolute_error,\n)\n\n\ndef _get_metric(metric: str) -> Callable:\n    \"\"\"\n    Get the corresponding scikit-learn function to calculate the metric.\n\n    Parameters\n    ----------\n    metric : str\n        Metric used to quantify the goodness of fit of the model.\n\n    Returns\n    -------\n    metric : Callable\n        scikit-learn function to calculate the desired metric.\n\n    \"\"\"\n\n    allowed_metrics = [\n        \"mean_squared_error\",\n        \"mean_absolute_error\",\n        \"mean_absolute_percentage_error\",\n        \"mean_squared_log_error\",\n        \"mean_absolute_scaled_error\",\n        \"root_mean_squared_scaled_error\",\n        \"median_absolute_error\",\n    ]\n\n    if metric not in allowed_metrics:\n        raise ValueError((f\"Allowed metrics are: {allowed_metrics}. Got {metric}.\"))\n\n    metrics = {\n        \"mean_squared_error\": mean_squared_error,\n        \"mean_absolute_error\": mean_absolute_error,\n        \"mean_absolute_percentage_error\": mean_absolute_percentage_error,\n        \"mean_squared_log_error\": mean_squared_log_error,\n        \"mean_absolute_scaled_error\": mean_absolute_scaled_error,\n        \"root_mean_squared_scaled_error\": root_mean_squared_scaled_error,\n        \"median_absolute_error\": median_absolute_error,\n    }\n\n    metric = add_y_train_argument(metrics[metric])\n\n    return metric\n\n\ndef add_y_train_argument(func: Callable) -> Callable:\n    \"\"\"\n    Add `y_train` argument to a function if it is not already present.\n\n    Parameters\n    ----------\n    func : callable\n        Function to which the argument is added.\n\n    Returns\n    -------\n    wrapper : callable\n        Function with `y_train` argument added.\n    \n    \"\"\"\n\n    sig = inspect.signature(func)\n    \n    if \"y_train\" in sig.parameters:\n        return func\n\n    new_params = list(sig.parameters.values()) + [\n        inspect.Parameter(\"y_train\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    new_sig = sig.replace(parameters=new_params)\n\n    @wraps(func)\n    def wrapper(*args, y_train=None, **kwargs):\n        return func(*args, **kwargs)\n    \n    wrapper.__signature__ = new_sig\n    \n    return wrapper\n\n\ndef mean_absolute_scaled_error(\n    y_true: Union[pd.Series, np.ndarray],\n    y_pred: Union[pd.Series, np.ndarray],\n    y_train: Union[list, pd.Series, np.ndarray],\n) -> float:\n    \"\"\"\n    Mean Absolute Scaled Error (MASE)\n\n    MASE is a scale-independent error metric that measures the accuracy of\n    a forecast. It is the mean absolute error of the forecast divided by the\n    mean absolute error of a naive forecast in the training set. The naive\n    forecast is the one obtained by shifting the time series by one period.\n    If y_train is a list of numpy arrays or pandas Series, it is considered\n    that each element is the true value of the target variable in the training\n    set for each time series. In this case, the naive forecast is calculated\n    for each time series separately.\n\n    Parameters\n    ----------\n    y_true : pandas Series, numpy ndarray\n        True values of the target variable.\n    y_pred : pandas Series, numpy ndarray\n        Predicted values of the target variable.\n    y_train : list, pandas Series, numpy ndarray\n        True values of the target variable in the training set. If `list`, it\n        is consider that each element is the true value of the target variable\n        in the training set for each time series.\n\n    Returns\n    -------\n    mase : float\n        MASE value.\n    \n    \"\"\"\n\n    if not isinstance(y_true, (pd.Series, np.ndarray)):\n        raise TypeError(\"`y_true` must be a pandas Series or numpy ndarray.\")\n    if not isinstance(y_pred, (pd.Series, np.ndarray)):\n        raise TypeError(\"`y_pred` must be a pandas Series or numpy ndarray.\")\n    if not isinstance(y_train, (list, pd.Series, np.ndarray)):\n        raise TypeError(\"`y_train` must be a list, pandas Series or numpy ndarray.\")\n    if isinstance(y_train, list):\n        for x in y_train:\n            if not isinstance(x, (pd.Series, np.ndarray)):\n                raise TypeError(\n                    (\"When `y_train` is a list, each element must be a pandas Series \"\n                     \"or numpy ndarray.\")\n                )\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"`y_true` and `y_pred` must have the same length.\")\n    if len(y_true) == 0 or len(y_pred) == 0:\n        raise ValueError(\"`y_true` and `y_pred` must have at least one element.\")\n\n    if isinstance(y_train, list):\n        naive_forecast = np.concatenate([np.diff(x) for x in y_train])\n    else:\n        naive_forecast = np.diff(y_train)\n\n    mase = np.mean(np.abs(y_true - y_pred)) / np.nanmean(np.abs(naive_forecast))\n\n    return mase\n\n\ndef root_mean_squared_scaled_error(\n    y_true: Union[pd.Series, np.ndarray],\n    y_pred: Union[pd.Series, np.ndarray],\n    y_train: Union[list, pd.Series, np.ndarray],\n) -> float:\n    \"\"\"\n    Root Mean Squared Scaled Error (RMSSE)\n\n    RMSSE is a scale-independent error metric that measures the accuracy of\n    a forecast. It is the root mean squared error of the forecast divided by\n    the root mean squared error of a naive forecast in the training set. The\n    naive forecast is the one obtained by shifting the time series by one period.\n    If y_train is a list of numpy arrays or pandas Series, it is considered\n    that each element is the true value of the target variable in the training\n    set for each time series. In this case, the naive forecast is calculated\n    for each time series separately.\n\n    Parameters\n    ----------\n    y_true : pandas Series, numpy ndarray\n        True values of the target variable.\n    y_pred : pandas Series, numpy ndarray\n        Predicted values of the target variable.\n    y_train : list, pandas Series, numpy ndarray\n        True values of the target variable in the training set. If list, it\n        is consider that each element is the true value of the target variable\n        in the training set for each time series.\n\n    Returns\n    -------\n    rmsse : float\n        RMSSE value.\n    \n    \"\"\"\n\n    if not isinstance(y_true, (pd.Series, np.ndarray)):\n        raise TypeError(\"`y_true` must be a pandas Series or numpy ndarray.\")\n    if not isinstance(y_pred, (pd.Series, np.ndarray)):\n        raise TypeError(\"`y_pred` must be a pandas Series or numpy ndarray.\")\n    if not isinstance(y_train, (list, pd.Series, np.ndarray)):\n        raise TypeError(\"`y_train` must be a list, pandas Series or numpy ndarray.\")\n    if isinstance(y_train, list):\n        for x in y_train:\n            if not isinstance(x, (pd.Series, np.ndarray)):\n                raise TypeError(\n                    (\"When `y_train` is a list, each element must be a pandas Series \"\n                     \"or numpy ndarray.\")\n                )\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"`y_true` and `y_pred` must have the same length.\")\n    if len(y_true) == 0 or len(y_pred) == 0:\n        raise ValueError(\"`y_true` and `y_pred` must have at least one element.\")\n\n    if isinstance(y_train, list):\n        naive_forecast = np.concatenate([np.diff(x) for x in y_train])\n    else:\n        naive_forecast = np.diff(y_train)\n    \n    rmsse = np.sqrt(np.mean((y_true - y_pred) ** 2)) / np.sqrt(np.nanmean(naive_forecast ** 2))\n    \n    return rmsse\n"
  },
  "GT_src_dict": {
    "skforecast/metrics/metrics.py": {
      "mean_absolute_scaled_error": {
        "code": "def mean_absolute_scaled_error(y_true: Union[pd.Series, np.ndarray], y_pred: Union[pd.Series, np.ndarray], y_train: Union[list, pd.Series, np.ndarray]) -> float:\n    \"\"\"Mean Absolute Scaled Error (MASE)\n\nThe `mean_absolute_scaled_error` function calculates the Mean Absolute Scaled Error, a scale-independent metric that assesses the accuracy of forecasts. MASE is determined by the mean absolute error of the predictions divided by the mean absolute error of a naive forecast, which is based on shifting the time series by one period. This function can handle both single time series and multiple time series represented as a list.\n\nParameters\n----------\ny_true : Union[pd.Series, np.ndarray]\n    True values of the target variable.\ny_pred : Union[pd.Series, np.ndarray]\n    Predicted values of the target variable.\ny_train : Union[list, pd.Series, np.ndarray]\n    True values of the target variable in the training set. If a list, each element should represent a separate time series.\n\nReturns\n-------\nfloat\n    The MASE value, indicating the accuracy of the forecast.\n\nRaises\n------\nTypeError\n    If `y_true`, `y_pred`, or `y_train` are not of the expected types.\nValueError\n    If the lengths of `y_true` and `y_pred` do not match or if they are empty.\n\nDependencies\n------------\nThis function utilizes NumPy for numerical operations and assumes the presence of the `np.diff` function for calculating naive forecasts. The handling of `y_train` allows for flexibility in input formats, enabling individual or multiple time series processing.\"\"\"\n    '\\n    Mean Absolute Scaled Error (MASE)\\n\\n    MASE is a scale-independent error metric that measures the accuracy of\\n    a forecast. It is the mean absolute error of the forecast divided by the\\n    mean absolute error of a naive forecast in the training set. The naive\\n    forecast is the one obtained by shifting the time series by one period.\\n    If y_train is a list of numpy arrays or pandas Series, it is considered\\n    that each element is the true value of the target variable in the training\\n    set for each time series. In this case, the naive forecast is calculated\\n    for each time series separately.\\n\\n    Parameters\\n    ----------\\n    y_true : pandas Series, numpy ndarray\\n        True values of the target variable.\\n    y_pred : pandas Series, numpy ndarray\\n        Predicted values of the target variable.\\n    y_train : list, pandas Series, numpy ndarray\\n        True values of the target variable in the training set. If `list`, it\\n        is consider that each element is the true value of the target variable\\n        in the training set for each time series.\\n\\n    Returns\\n    -------\\n    mase : float\\n        MASE value.\\n    \\n    '\n    if not isinstance(y_true, (pd.Series, np.ndarray)):\n        raise TypeError('`y_true` must be a pandas Series or numpy ndarray.')\n    if not isinstance(y_pred, (pd.Series, np.ndarray)):\n        raise TypeError('`y_pred` must be a pandas Series or numpy ndarray.')\n    if not isinstance(y_train, (list, pd.Series, np.ndarray)):\n        raise TypeError('`y_train` must be a list, pandas Series or numpy ndarray.')\n    if isinstance(y_train, list):\n        for x in y_train:\n            if not isinstance(x, (pd.Series, np.ndarray)):\n                raise TypeError('When `y_train` is a list, each element must be a pandas Series or numpy ndarray.')\n    if len(y_true) != len(y_pred):\n        raise ValueError('`y_true` and `y_pred` must have the same length.')\n    if len(y_true) == 0 or len(y_pred) == 0:\n        raise ValueError('`y_true` and `y_pred` must have at least one element.')\n    if isinstance(y_train, list):\n        naive_forecast = np.concatenate([np.diff(x) for x in y_train])\n    else:\n        naive_forecast = np.diff(y_train)\n    mase = np.mean(np.abs(y_true - y_pred)) / np.nanmean(np.abs(naive_forecast))\n    return mase",
        "docstring": "Mean Absolute Scaled Error (MASE)\n\nThe `mean_absolute_scaled_error` function calculates the Mean Absolute Scaled Error, a scale-independent metric that assesses the accuracy of forecasts. MASE is determined by the mean absolute error of the predictions divided by the mean absolute error of a naive forecast, which is based on shifting the time series by one period. This function can handle both single time series and multiple time series represented as a list.\n\nParameters\n----------\ny_true : Union[pd.Series, np.ndarray]\n    True values of the target variable.\ny_pred : Union[pd.Series, np.ndarray]\n    Predicted values of the target variable.\ny_train : Union[list, pd.Series, np.ndarray]\n    True values of the target variable in the training set. If a list, each element should represent a separate time series.\n\nReturns\n-------\nfloat\n    The MASE value, indicating the accuracy of the forecast.\n\nRaises\n------\nTypeError\n    If `y_true`, `y_pred`, or `y_train` are not of the expected types.\nValueError\n    If the lengths of `y_true` and `y_pred` do not match or if they are empty.\n\nDependencies\n------------\nThis function utilizes NumPy for numerical operations and assumes the presence of the `np.diff` function for calculating naive forecasts. The handling of `y_train` allows for flexibility in input formats, enabling individual or multiple time series processing.",
        "signature": "def mean_absolute_scaled_error(y_true: Union[pd.Series, np.ndarray], y_pred: Union[pd.Series, np.ndarray], y_train: Union[list, pd.Series, np.ndarray]) -> float:",
        "type": "Function",
        "class_signature": null
      }
    }
  },
  "dependency_dict": {},
  "PRD": "# PROJECT NAME: skforecast-test_mean_absolute_scaled_error\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 skforecast/\n    \u2514\u2500\u2500 metrics/\n        \u2514\u2500\u2500 metrics.py\n            \u2514\u2500\u2500 mean_absolute_scaled_error\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module provides functionality to test the robustness, accuracy, and validity of the `mean_absolute_scaled_error` (MASE) metric, an essential tool for evaluating forecasting models by quantifying prediction error relative to historical data variability. It ensures proper handling of various input types and structures, validates input lengths and non-empty requirements, and verifies that the calculated metric returns accurate and expected results under diverse conditions. By implementing rigorous test cases, the module guarantees the reliability of MASE calculations, helping developers identify potential issues early and maintain high-quality forecasting model evaluations. This supports users by fostering confidence in forecasting metrics and simplifying error diagnosis in development pipelines.\n\n## FILE 1: skforecast/metrics/metrics.py\n\n- FUNCTION NAME: mean_absolute_scaled_error\n  - SIGNATURE: def mean_absolute_scaled_error(y_true: Union[pd.Series, np.ndarray], y_pred: Union[pd.Series, np.ndarray], y_train: Union[list, pd.Series, np.ndarray]) -> float:\n  - DOCSTRING: \n```python\n\"\"\"\nMean Absolute Scaled Error (MASE)\n\nThe `mean_absolute_scaled_error` function calculates the Mean Absolute Scaled Error, a scale-independent metric that assesses the accuracy of forecasts. MASE is determined by the mean absolute error of the predictions divided by the mean absolute error of a naive forecast, which is based on shifting the time series by one period. This function can handle both single time series and multiple time series represented as a list.\n\nParameters\n----------\ny_true : Union[pd.Series, np.ndarray]\n    True values of the target variable.\ny_pred : Union[pd.Series, np.ndarray]\n    Predicted values of the target variable.\ny_train : Union[list, pd.Series, np.ndarray]\n    True values of the target variable in the training set. If a list, each element should represent a separate time series.\n\nReturns\n-------\nfloat\n    The MASE value, indicating the accuracy of the forecast.\n\nRaises\n------\nTypeError\n    If `y_true`, `y_pred`, or `y_train` are not of the expected types.\nValueError\n    If the lengths of `y_true` and `y_pred` do not match or if they are empty.\n\nDependencies\n------------\nThis function utilizes NumPy for numerical operations and assumes the presence of the `np.diff` function for calculating naive forecasts. The handling of `y_train` allows for flexibility in input formats, enabling individual or multiple time series processing.\n\"\"\"\n```\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "skforecast/metrics/metrics.py": "from typing import Union, Callable\nimport numpy as np\nimport pandas as pd\nimport inspect\nfrom functools import wraps\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, mean_squared_log_error, median_absolute_error\n\ndef _get_metric(metric: str) -> Callable:\n    \"\"\"\n    Get the corresponding scikit-learn function to calculate the metric.\n\n    Parameters\n    ----------\n    metric : str\n        Metric used to quantify the goodness of fit of the model.\n\n    Returns\n    -------\n    metric : Callable\n        scikit-learn function to calculate the desired metric.\n\n    \"\"\"\n    allowed_metrics = ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_log_error', 'mean_absolute_scaled_error', 'root_mean_squared_scaled_error', 'median_absolute_error']\n    if metric not in allowed_metrics:\n        raise ValueError(f'Allowed metrics are: {allowed_metrics}. Got {metric}.')\n    metrics = {'mean_squared_error': mean_squared_error, 'mean_absolute_error': mean_absolute_error, 'mean_absolute_percentage_error': mean_absolute_percentage_error, 'mean_squared_log_error': mean_squared_log_error, 'mean_absolute_scaled_error': mean_absolute_scaled_error, 'root_mean_squared_scaled_error': root_mean_squared_scaled_error, 'median_absolute_error': median_absolute_error}\n    metric = add_y_train_argument(metrics[metric])\n    return metric\n\ndef add_y_train_argument(func: Callable) -> Callable:\n    \"\"\"\n    Add `y_train` argument to a function if it is not already present.\n\n    Parameters\n    ----------\n    func : callable\n        Function to which the argument is added.\n\n    Returns\n    -------\n    wrapper : callable\n        Function with `y_train` argument added.\n    \n    \"\"\"\n    sig = inspect.signature(func)\n    if 'y_train' in sig.parameters:\n        return func\n    new_params = list(sig.parameters.values()) + [inspect.Parameter('y_train', inspect.Parameter.KEYWORD_ONLY, default=None)]\n    new_sig = sig.replace(parameters=new_params)\n\n    @wraps(func)\n    def wrapper(*args, y_train=None, **kwargs):\n        return func(*args, **kwargs)\n    wrapper.__signature__ = new_sig\n    return wrapper\n\ndef root_mean_squared_scaled_error(y_true: Union[pd.Series, np.ndarray], y_pred: Union[pd.Series, np.ndarray], y_train: Union[list, pd.Series, np.ndarray]) -> float:\n    \"\"\"\n    Root Mean Squared Scaled Error (RMSSE)\n\n    RMSSE is a scale-independent error metric that measures the accuracy of\n    a forecast. It is the root mean squared error of the forecast divided by\n    the root mean squared error of a naive forecast in the training set. The\n    naive forecast is the one obtained by shifting the time series by one period.\n    If y_train is a list of numpy arrays or pandas Series, it is considered\n    that each element is the true value of the target variable in the training\n    set for each time series. In this case, the naive forecast is calculated\n    for each time series separately.\n\n    Parameters\n    ----------\n    y_true : pandas Series, numpy ndarray\n        True values of the target variable.\n    y_pred : pandas Series, numpy ndarray\n        Predicted values of the target variable.\n    y_train : list, pandas Series, numpy ndarray\n        True values of the target variable in the training set. If list, it\n        is consider that each element is the true value of the target variable\n        in the training set for each time series.\n\n    Returns\n    -------\n    rmsse : float\n        RMSSE value.\n    \n    \"\"\"\n    if not isinstance(y_true, (pd.Series, np.ndarray)):\n        raise TypeError('`y_true` must be a pandas Series or numpy ndarray.')\n    if not isinstance(y_pred, (pd.Series, np.ndarray)):\n        raise TypeError('`y_pred` must be a pandas Series or numpy ndarray.')\n    if not isinstance(y_train, (list, pd.Series, np.ndarray)):\n        raise TypeError('`y_train` must be a list, pandas Series or numpy ndarray.')\n    if isinstance(y_train, list):\n        for x in y_train:\n            if not isinstance(x, (pd.Series, np.ndarray)):\n                raise TypeError('When `y_train` is a list, each element must be a pandas Series or numpy ndarray.')\n    if len(y_true) != len(y_pred):\n        raise ValueError('`y_true` and `y_pred` must have the same length.')\n    if len(y_true) == 0 or len(y_pred) == 0:\n        raise ValueError('`y_true` and `y_pred` must have at least one element.')\n    if isinstance(y_train, list):\n        naive_forecast = np.concatenate([np.diff(x) for x in y_train])\n    else:\n        naive_forecast = np.diff(y_train)\n    rmsse = np.sqrt(np.mean((y_true - y_pred) ** 2)) / np.sqrt(np.nanmean(naive_forecast ** 2))\n    return rmsse"
  },
  "call_tree": {
    "skforecast/metrics/tests/tests_metrics/test_mean_absolute_scaled_error.py:test_mean_absolute_scaled_error_input_types": {
      "skforecast/metrics/metrics.py:mean_absolute_scaled_error": {}
    },
    "skforecast/metrics/tests/tests_metrics/test_mean_absolute_scaled_error.py:test_mean_absolute_scaled_error_input_length": {
      "skforecast/metrics/metrics.py:mean_absolute_scaled_error": {}
    },
    "skforecast/metrics/tests/tests_metrics/test_mean_absolute_scaled_error.py:test_mean_absolute_scaled_error_empty_input": {
      "skforecast/metrics/metrics.py:mean_absolute_scaled_error": {}
    },
    "skforecast/metrics/tests/tests_metrics/test_mean_absolute_scaled_error.py:test_mean_absolute_scaled_error_output": {
      "skforecast/metrics/metrics.py:mean_absolute_scaled_error": {}
    },
    "skforecast/metrics/tests/tests_metrics/test_mean_absolute_scaled_error.py:test_mean_absolute_scaled_error_pandas_series_input": {
      "skforecast/metrics/metrics.py:mean_absolute_scaled_error": {}
    }
  }
}