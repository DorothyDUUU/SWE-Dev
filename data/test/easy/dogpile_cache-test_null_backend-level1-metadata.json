{
  "dir_path": "/app/dogpile_cache",
  "package_name": "dogpile_cache",
  "sample_name": "dogpile_cache-test_null_backend",
  "src_dir": "dogpile/",
  "test_dir": "tests/",
  "test_file": "tests/cache/test_null_backend.py",
  "test_code": "import itertools\n\nfrom dogpile.cache.api import NO_VALUE\nfrom dogpile.testing import eq_\nfrom dogpile.testing.fixtures import _GenericBackendFixture\n\n\nclass NullBackendTest(_GenericBackendFixture):\n    backend = \"dogpile.cache.null\"\n\n    def test_get(self):\n        reg = self._region()\n\n        eq_(reg.get(\"some key\"), NO_VALUE)\n\n    def test_set(self):\n        reg = self._region()\n        reg.set(\"some key\", \"some value\")\n        eq_(reg.get(\"some key\"), NO_VALUE)\n\n    def test_delete(self):\n        reg = self._region()\n        reg.delete(\"some key\")\n        eq_(reg.get(\"some key\"), NO_VALUE)\n\n    def test_get_multi(self):\n        reg = self._region()\n\n        eq_(reg.get_multi([\"a\", \"b\", \"c\"]), [NO_VALUE, NO_VALUE, NO_VALUE])\n\n    def test_set_multi(self):\n        reg = self._region()\n        reg.set_multi({\"a\": 1, \"b\": 2, \"c\": 3})\n        eq_(reg.get_multi([\"a\", \"b\", \"c\"]), [NO_VALUE, NO_VALUE, NO_VALUE])\n\n    def test_delete_multi(self):\n        reg = self._region()\n        reg.delete_multi([\"a\", \"b\", \"c\"])\n        eq_(reg.get_multi([\"a\", \"b\", \"c\"]), [NO_VALUE, NO_VALUE, NO_VALUE])\n\n    def test_decorator(self):\n        reg = self._region()\n\n        counter = itertools.count(1)\n\n        @reg.cache_on_arguments()\n        def go(a, b):\n            val = next(counter)\n            return val, a, b\n\n        eq_(go(1, 2), (1, 1, 2))\n        eq_(go(1, 2), (2, 1, 2))\n        eq_(go(1, 3), (3, 1, 3))\n\n    def test_mutex(self):\n        backend = self._backend()\n        mutex = backend.get_mutex(\"foo\")\n\n        ac = mutex.acquire()\n        assert ac\n        mutex.release()\n\n        ac2 = mutex.acquire(False)\n        assert ac2\n        mutex.release()\n\n    def test_mutex_doesnt_actually_lock(self):\n        backend = self._backend()\n        mutex = backend.get_mutex(\"foo\")\n\n        ac = mutex.acquire()\n        assert ac\n\n        ac2 = mutex.acquire(False)\n        assert ac2\n        mutex.release()\n",
  "GT_file_code": {
    "dogpile/cache/region.py": "from __future__ import annotations\n\nimport contextlib\nimport datetime\nfrom functools import partial\nfrom functools import wraps\nimport json\nimport logging\nfrom numbers import Number\nimport threading\nimport time\nfrom typing import Any\nfrom typing import Callable\nfrom typing import cast\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import Type\nfrom typing import TYPE_CHECKING\nfrom typing import Union\n\nfrom decorator import decorate\n\nfrom . import exception\nfrom .api import BackendArguments\nfrom .api import BackendFormatted\nfrom .api import CachedValue\nfrom .api import CacheMutex\nfrom .api import CacheReturnType\nfrom .api import CantDeserializeException\nfrom .api import KeyType\nfrom .api import MetaDataType\nfrom .api import NO_VALUE\nfrom .api import NoValueType\nfrom .api import SerializedReturnType\nfrom .api import Serializer\nfrom .api import ValuePayload\nfrom .backends import _backend_loader\nfrom .backends import register_backend  # noqa\nfrom .proxy import ProxyBackend\nfrom .util import function_key_generator\nfrom .util import function_multi_key_generator\nfrom .util import repr_obj\nfrom .. import Lock\nfrom .. import NeedRegenerationException\nfrom ..util import coerce_string_conf\nfrom ..util import memoized_property\nfrom ..util import NameRegistry\nfrom ..util import PluginLoader\nfrom ..util.typing import Self\n\nvalue_version = 2\n\"\"\"An integer placed in the :class:`.CachedValue`\nso that new versions of dogpile.cache can detect cached\nvalues from a previous, backwards-incompatible version.\n\n\"\"\"\n\nlog = logging.getLogger(__name__)\n\n\nAsyncCreator = Callable[\n    [\"CacheRegion\", KeyType, Callable[[], ValuePayload], CacheMutex], None\n]\n\nExpirationTimeCallable = Callable[[], float]\n\nToStr = Callable[[Any], str]\n\nFunctionKeyGenerator = Callable[..., Callable[..., KeyType]]\n\nFunctionMultiKeyGenerator = Callable[..., Callable[..., Sequence[KeyType]]]\n\n\nclass RegionInvalidationStrategy:\n    \"\"\"Region invalidation strategy interface\n\n    Implement this interface and pass implementation instance\n    to :meth:`.CacheRegion.configure` to override default region invalidation.\n\n    Example::\n\n        class CustomInvalidationStrategy(RegionInvalidationStrategy):\n\n            def __init__(self):\n                self._soft_invalidated = None\n                self._hard_invalidated = None\n\n            def invalidate(self, hard=None):\n                if hard:\n                    self._soft_invalidated = None\n                    self._hard_invalidated = time.time()\n                else:\n                    self._soft_invalidated = time.time()\n                    self._hard_invalidated = None\n\n            def is_invalidated(self, timestamp):\n                return ((self._soft_invalidated and\n                         timestamp < self._soft_invalidated) or\n                        (self._hard_invalidated and\n                         timestamp < self._hard_invalidated))\n\n            def was_hard_invalidated(self):\n                return bool(self._hard_invalidated)\n\n            def is_hard_invalidated(self, timestamp):\n                return (self._hard_invalidated and\n                        timestamp < self._hard_invalidated)\n\n            def was_soft_invalidated(self):\n                return bool(self._soft_invalidated)\n\n            def is_soft_invalidated(self, timestamp):\n                return (self._soft_invalidated and\n                        timestamp < self._soft_invalidated)\n\n    The custom implementation is injected into a :class:`.CacheRegion`\n    at configure time using the\n    :paramref:`.CacheRegion.configure.region_invalidator` parameter::\n\n        region = CacheRegion()\n\n        region = region.configure(region_invalidator=CustomInvalidationStrategy())  # noqa\n\n    Invalidation strategies that wish to have access to the\n    :class:`.CacheRegion` itself should construct the invalidator given the\n    region as an argument::\n\n        class MyInvalidator(RegionInvalidationStrategy):\n            def __init__(self, region):\n                self.region = region\n                # ...\n\n            # ...\n\n        region = CacheRegion()\n        region = region.configure(region_invalidator=MyInvalidator(region))\n\n    .. versionadded:: 0.6.2\n\n    .. seealso::\n\n        :paramref:`.CacheRegion.configure.region_invalidator`\n\n    \"\"\"\n\n    def invalidate(self, hard: bool = True) -> None:\n        \"\"\"Region invalidation.\n\n        :class:`.CacheRegion` propagated call.\n        The default invalidation system works by setting\n        a current timestamp (using ``time.time()``) to consider all older\n        timestamps effectively invalidated.\n\n        \"\"\"\n\n        raise NotImplementedError()\n\n    def is_hard_invalidated(self, timestamp: float) -> bool:\n        \"\"\"Check timestamp to determine if it was hard invalidated.\n\n        :return: Boolean. True if ``timestamp`` is older than\n         the last region invalidation time and region is invalidated\n         in hard mode.\n\n        \"\"\"\n\n        raise NotImplementedError()\n\n    def is_soft_invalidated(self, timestamp: float) -> bool:\n        \"\"\"Check timestamp to determine if it was soft invalidated.\n\n        :return: Boolean. True if ``timestamp`` is older than\n         the last region invalidation time and region is invalidated\n         in soft mode.\n\n        \"\"\"\n\n        raise NotImplementedError()\n\n    def is_invalidated(self, timestamp: float) -> bool:\n        \"\"\"Check timestamp to determine if it was invalidated.\n\n        :return: Boolean. True if ``timestamp`` is older than\n         the last region invalidation time.\n\n        \"\"\"\n\n        raise NotImplementedError()\n\n    def was_soft_invalidated(self) -> bool:\n        \"\"\"Indicate the region was invalidated in soft mode.\n\n        :return: Boolean. True if region was invalidated in soft mode.\n\n        \"\"\"\n\n        raise NotImplementedError()\n\n    def was_hard_invalidated(self) -> bool:\n        \"\"\"Indicate the region was invalidated in hard mode.\n\n        :return: Boolean. True if region was invalidated in hard mode.\n\n        \"\"\"\n\n        raise NotImplementedError()\n\n\nclass DefaultInvalidationStrategy(RegionInvalidationStrategy):\n    def __init__(self):\n        self._is_hard_invalidated = None\n        self._invalidated = None\n\n    def invalidate(self, hard: bool = True) -> None:\n        self._is_hard_invalidated = bool(hard)\n        self._invalidated = time.time()\n\n    def is_invalidated(self, timestamp: float) -> bool:\n        return self._invalidated is not None and timestamp < self._invalidated\n\n    def was_hard_invalidated(self) -> bool:\n        return self._is_hard_invalidated is True\n\n    def is_hard_invalidated(self, timestamp: float) -> bool:\n        return self.was_hard_invalidated() and self.is_invalidated(timestamp)\n\n    def was_soft_invalidated(self) -> bool:\n        return self._is_hard_invalidated is False\n\n    def is_soft_invalidated(self, timestamp: float) -> bool:\n        return self.was_soft_invalidated() and self.is_invalidated(timestamp)\n\n\nclass CacheRegion:\n    r\"\"\"A front end to a particular cache backend.\n\n    :param name: Optional, a string name for the region.\n     This isn't used internally\n     but can be accessed via the ``.name`` parameter, helpful\n     for configuring a region from a config file.\n    :param function_key_generator:  Optional.  A\n     function that will produce a \"cache key\" given\n     a data creation function and arguments, when using\n     the :meth:`.CacheRegion.cache_on_arguments` method.\n     The structure of this function\n     should be two levels: given the data creation function,\n     return a new function that generates the key based on\n     the given arguments.  Such as::\n\n        def my_key_generator(namespace, fn, **kw):\n            fname = fn.__name__\n            def generate_key(*arg):\n                return namespace + \"_\" + fname + \"_\".join(str(s) for s in arg)\n            return generate_key\n\n\n        region = make_region(\n            function_key_generator = my_key_generator\n        ).configure(\n            \"dogpile.cache.dbm\",\n            expiration_time=300,\n            arguments={\n                \"filename\":\"file.dbm\"\n            }\n        )\n\n     The ``namespace`` is that passed to\n     :meth:`.CacheRegion.cache_on_arguments`.  It's not consulted\n     outside this function, so in fact can be of any form.\n     For example, it can be passed as a tuple, used to specify\n     arguments to pluck from \\**kw::\n\n        def my_key_generator(namespace, fn):\n            def generate_key(*arg, **kw):\n                return \":\".join(\n                        [kw[k] for k in namespace] +\n                        [str(x) for x in arg]\n                    )\n            return generate_key\n\n\n     Where the decorator might be used as::\n\n        @my_region.cache_on_arguments(namespace=('x', 'y'))\n        def my_function(a, b, **kw):\n            return my_data()\n\n     .. seealso::\n\n        :func:`.function_key_generator` - default key generator\n\n        :func:`.kwarg_function_key_generator` - optional gen that also\n        uses keyword arguments\n\n    :param function_multi_key_generator: Optional.\n     Similar to ``function_key_generator`` parameter, but it's used in\n     :meth:`.CacheRegion.cache_multi_on_arguments`. Generated function\n     should return list of keys. For example::\n\n        def my_multi_key_generator(namespace, fn, **kw):\n            namespace = fn.__name__ + (namespace or '')\n\n            def generate_keys(*args):\n                return [namespace + ':' + str(a) for a in args]\n\n            return generate_keys\n\n    :param key_mangler: Function which will be used on all incoming\n     keys before passing to the backend.  Defaults to ``None``,\n     in which case the key mangling function recommended by\n     the cache backend will be used.    A typical mangler\n     is the SHA1 mangler found at :func:`.sha1_mangle_key`\n     which coerces keys into a SHA1\n     hash, so that the string length is fixed.  To\n     disable all key mangling, set to ``False``.   Another typical\n     mangler is the built-in Python function ``str``, which can be used\n     to convert non-string or Unicode keys to bytestrings, which is\n     needed when using a backend such as bsddb or dbm under Python 2.x\n     in conjunction with Unicode keys.\n\n    :param serializer: function which will be applied to all values before\n     passing to the backend.  Defaults to ``None``, in which case the\n     serializer recommended by the backend will be used.   Typical\n     serializers include ``pickle.dumps`` and ``json.dumps``.\n\n     .. versionadded:: 1.1.0\n\n    :param deserializer: function which will be applied to all values returned\n     by the backend.  Defaults to ``None``, in which case the\n     deserializer recommended by the backend will be used.   Typical\n     deserializers include ``pickle.dumps`` and ``json.dumps``.\n\n     Deserializers can raise a :class:`.api.CantDeserializeException` if they\n     are unable to deserialize the value from the backend, indicating\n     deserialization failed and that caching should proceed to re-generate\n     a value.  This allows an application that has been updated to gracefully\n     re-cache old items which were persisted by a previous version of the\n     application and can no longer be successfully deserialized.\n\n     .. versionadded:: 1.1.0 added \"deserializer\" parameter\n\n     .. versionadded:: 1.2.0 added support for\n        :class:`.api.CantDeserializeException`\n\n    :param async_creation_runner:  A callable that, when specified,\n     will be passed to and called by dogpile.lock when\n     there is a stale value present in the cache.  It will be passed the\n     mutex and is responsible releasing that mutex when finished.\n     This can be used to defer the computation of expensive creator\n     functions to later points in the future by way of, for example, a\n     background thread, a long-running queue, or a task manager system\n     like Celery.\n\n     For a specific example using async_creation_runner, new values can\n     be created in a background thread like so::\n\n        import threading\n\n        def async_creation_runner(cache, somekey, creator, mutex):\n            ''' Used by dogpile.core:Lock when appropriate  '''\n            def runner():\n                try:\n                    value = creator()\n                    cache.set(somekey, value)\n                finally:\n                    mutex.release()\n\n            thread = threading.Thread(target=runner)\n            thread.start()\n\n\n        region = make_region(\n            async_creation_runner=async_creation_runner,\n        ).configure(\n            'dogpile.cache.memcached',\n            expiration_time=5,\n            arguments={\n                'url': '127.0.0.1:11211',\n                'distributed_lock': True,\n            }\n        )\n\n     Remember that the first request for a key with no associated\n     value will always block; async_creator will not be invoked.\n     However, subsequent requests for cached-but-expired values will\n     still return promptly.  They will be refreshed by whatever\n     asynchronous means the provided async_creation_runner callable\n     implements.\n\n     By default the async_creation_runner is disabled and is set\n     to ``None``.\n\n     .. versionadded:: 0.4.2 added the async_creation_runner\n        feature.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name: Optional[str] = None,\n        function_key_generator: FunctionKeyGenerator = function_key_generator,\n        function_multi_key_generator: FunctionMultiKeyGenerator = function_multi_key_generator,  # noqa E501\n        key_mangler: Optional[Callable[[KeyType], KeyType]] = None,\n        serializer: Optional[Callable[[ValuePayload], bytes]] = None,\n        deserializer: Optional[Callable[[bytes], ValuePayload]] = None,\n        async_creation_runner: Optional[AsyncCreator] = None,\n    ):\n        \"\"\"Construct a new :class:`.CacheRegion`.\"\"\"\n        self.name = name\n        self.function_key_generator = function_key_generator\n        self.function_multi_key_generator = function_multi_key_generator\n        self.key_mangler = self._user_defined_key_mangler = key_mangler\n        self.serializer = self._user_defined_serializer = serializer\n        self.deserializer = self._user_defined_deserializer = deserializer\n        self.async_creation_runner = async_creation_runner\n        self.region_invalidator: RegionInvalidationStrategy = (\n            DefaultInvalidationStrategy()\n        )\n\n    def configure(\n        self,\n        backend: str,\n        expiration_time: Optional[Union[float, datetime.timedelta]] = None,\n        arguments: Optional[BackendArguments] = None,\n        _config_argument_dict: Optional[Mapping[str, Any]] = None,\n        _config_prefix: Optional[str] = None,\n        wrap: Sequence[Union[ProxyBackend, Type[ProxyBackend]]] = (),\n        replace_existing_backend: bool = False,\n        region_invalidator: Optional[RegionInvalidationStrategy] = None,\n    ) -> Self:\n        \"\"\"Configure a :class:`.CacheRegion`.\n\n        The :class:`.CacheRegion` itself\n        is returned.\n\n        :param backend:   Required.  This is the name of the\n         :class:`.CacheBackend` to use, and is resolved by loading\n         the class from the ``dogpile.cache`` entrypoint.\n\n        :param expiration_time:   Optional.  The expiration time passed\n         to the dogpile system.  May be passed as an integer number\n         of seconds, or as a ``datetime.timedelta`` value.\n\n         .. versionadded 0.5.0\n            ``expiration_time`` may be optionally passed as a\n            ``datetime.timedelta`` value.\n\n         The :meth:`.CacheRegion.get_or_create`\n         method as well as the :meth:`.CacheRegion.cache_on_arguments`\n         decorator (though note:  **not** the :meth:`.CacheRegion.get`\n         method) will call upon the value creation function after this\n         time period has passed since the last generation.\n\n        :param arguments: Optional.  The structure here is passed\n         directly to the constructor of the :class:`.CacheBackend`\n         in use, though is typically a dictionary.\n\n        :param wrap: Optional.  A list of :class:`.ProxyBackend`\n         classes and/or instances, each of which will be applied\n         in a chain to ultimately wrap the original backend,\n         so that custom functionality augmentation can be applied.\n\n         .. versionadded:: 0.5.0\n\n         .. seealso::\n\n            :ref:`changing_backend_behavior`\n\n        :param replace_existing_backend: if True, the existing cache backend\n         will be replaced.  Without this flag, an exception is raised if\n         a backend is already configured.\n\n         .. versionadded:: 0.5.7\n\n        :param region_invalidator: Optional. Override default invalidation\n         strategy with custom implementation of\n         :class:`.RegionInvalidationStrategy`.\n\n         .. versionadded:: 0.6.2\n\n        \"\"\"\n\n        if \"backend\" in self.__dict__ and not replace_existing_backend:\n            raise exception.RegionAlreadyConfigured(\n                \"This region is already \"\n                \"configured with backend: %s.  \"\n                \"Specify replace_existing_backend=True to replace.\"\n                % self.backend\n            )\n\n        try:\n            backend_cls = _backend_loader.load(backend)\n        except PluginLoader.NotFound:\n            raise exception.PluginNotFound(\n                \"Couldn't find cache plugin to load: %s\" % backend\n            )\n\n        if _config_argument_dict:\n            self.backend = backend_cls.from_config_dict(\n                _config_argument_dict, _config_prefix\n            )\n        else:\n            self.backend = backend_cls(arguments or {})\n\n        self.expiration_time: Union[float, None]\n\n        if not expiration_time or isinstance(expiration_time, Number):\n            self.expiration_time = cast(Union[None, float], expiration_time)\n        elif isinstance(expiration_time, datetime.timedelta):\n            self.expiration_time = int(expiration_time.total_seconds())\n        else:\n            raise exception.ValidationError(\n                \"expiration_time is not a number or timedelta.\"\n            )\n\n        if not self._user_defined_key_mangler:\n            self.key_mangler = self.backend.key_mangler\n\n        if not self._user_defined_serializer:\n            self.serializer = self.backend.serializer\n\n        if not self._user_defined_deserializer:\n            self.deserializer = self.backend.deserializer\n\n        self._lock_registry = NameRegistry(self._create_mutex)\n\n        if getattr(wrap, \"__iter__\", False):\n            for wrapper in reversed(wrap):\n                self.wrap(wrapper)\n\n        if region_invalidator:\n            self.region_invalidator = region_invalidator\n\n        return self\n\n    def wrap(self, proxy: Union[ProxyBackend, Type[ProxyBackend]]) -> None:\n        \"\"\"Takes a ProxyBackend instance or class and wraps the\n        attached backend.\"\"\"\n\n        # if we were passed a type rather than an instance then\n        # initialize it.\n        if isinstance(proxy, type):\n            proxy_instance = proxy()\n        else:\n            proxy_instance = proxy\n\n        if not isinstance(proxy_instance, ProxyBackend):\n            raise TypeError(\n                \"%r is not a valid ProxyBackend\" % (proxy_instance,)\n            )\n\n        self.backend = proxy_instance.wrap(self.backend)\n\n    def _mutex(self, key):\n        return self._lock_registry.get(key)\n\n    class _LockWrapper(CacheMutex):\n        \"\"\"weakref-capable wrapper for threading.Lock\"\"\"\n\n        def __init__(self):\n            self.lock = threading.Lock()\n\n        def acquire(self, wait=True):\n            return self.lock.acquire(wait)\n\n        def release(self):\n            self.lock.release()\n\n        def locked(self):\n            return self.lock.locked()\n\n    def _create_mutex(self, key):\n        mutex = self.backend.get_mutex(key)\n        if mutex is not None:\n            return mutex\n        else:\n            return self._LockWrapper()\n\n    # cached value\n    _actual_backend = None\n\n    @property\n    def actual_backend(self):\n        \"\"\"Return the ultimate backend underneath any proxies.\n\n        The backend might be the result of one or more ``proxy.wrap``\n        applications. If so, derive the actual underlying backend.\n\n        .. versionadded:: 0.6.6\n\n        \"\"\"\n        if self._actual_backend is None:\n            _backend = self.backend\n            while hasattr(_backend, \"proxied\"):\n                _backend = _backend.proxied\n            self._actual_backend = _backend\n        return self._actual_backend\n\n    def invalidate(self, hard=True):\n        \"\"\"Invalidate this :class:`.CacheRegion`.\n\n        The default invalidation system works by setting\n        a current timestamp (using ``time.time()``)\n        representing the \"minimum creation time\" for\n        a value.  Any retrieved value whose creation\n        time is prior to this timestamp\n        is considered to be stale.  It does not\n        affect the data in the cache in any way, and is\n        **local to this instance of :class:`.CacheRegion`.**\n\n        .. warning::\n\n            The :meth:`.CacheRegion.invalidate` method's default mode of\n            operation is to set a timestamp **local to this CacheRegion\n            in this Python process only**.   It does not impact other Python\n            processes or regions as the timestamp is **only stored locally in\n            memory**.  To implement invalidation where the\n            timestamp is stored in the cache or similar so that all Python\n            processes can be affected by an invalidation timestamp, implement a\n            custom :class:`.RegionInvalidationStrategy`.\n\n        Once set, the invalidation time is honored by\n        the :meth:`.CacheRegion.get_or_create`,\n        :meth:`.CacheRegion.get_or_create_multi` and\n        :meth:`.CacheRegion.get` methods.\n\n        The method supports both \"hard\" and \"soft\" invalidation\n        options.  With \"hard\" invalidation,\n        :meth:`.CacheRegion.get_or_create` will force an immediate\n        regeneration of the value which all getters will wait for.\n        With \"soft\" invalidation, subsequent getters will return the\n        \"old\" value until the new one is available.\n\n        Usage of \"soft\" invalidation requires that the region or the method\n        is given a non-None expiration time.\n\n        .. versionadded:: 0.3.0\n\n        :param hard: if True, cache values will all require immediate\n         regeneration; dogpile logic won't be used.  If False, the\n         creation time of existing values will be pushed back before\n         the expiration time so that a return+regen will be invoked.\n\n         .. versionadded:: 0.5.1\n\n        \"\"\"\n        self.region_invalidator.invalidate(hard)\n\n    def configure_from_config(self, config_dict, prefix):\n        \"\"\"Configure from a configuration dictionary\n        and a prefix.\n\n        Example::\n\n            local_region = make_region()\n            memcached_region = make_region()\n\n            # regions are ready to use for function\n            # decorators, but not yet for actual caching\n\n            # later, when config is available\n            myconfig = {\n                \"cache.local.backend\":\"dogpile.cache.dbm\",\n                \"cache.local.arguments.filename\":\"/path/to/dbmfile.dbm\",\n                \"cache.memcached.backend\":\"dogpile.cache.pylibmc\",\n                \"cache.memcached.arguments.url\":\"127.0.0.1, 10.0.0.1\",\n            }\n            local_region.configure_from_config(myconfig, \"cache.local.\")\n            memcached_region.configure_from_config(myconfig,\n                                                \"cache.memcached.\")\n\n        \"\"\"\n        config_dict = coerce_string_conf(config_dict)\n        return self.configure(\n            config_dict[\"%sbackend\" % prefix],\n            expiration_time=config_dict.get(\n                \"%sexpiration_time\" % prefix, None\n            ),\n            _config_argument_dict=config_dict,\n            _config_prefix=\"%sarguments.\" % prefix,\n            wrap=config_dict.get(\"%swrap\" % prefix, None),\n            replace_existing_backend=config_dict.get(\n                \"%sreplace_existing_backend\" % prefix, False\n            ),\n        )\n\n    @memoized_property\n    def backend(self):\n        raise exception.RegionNotConfigured(\n            \"No backend is configured on this region.\"\n        )\n\n    @property\n    def is_configured(self):\n        \"\"\"Return True if the backend has been configured via the\n        :meth:`.CacheRegion.configure` method already.\n\n        .. versionadded:: 0.5.1\n\n        \"\"\"\n        return \"backend\" in self.__dict__\n\n    def get(\n        self,\n        key: KeyType,\n        expiration_time: Optional[float] = None,\n        ignore_expiration: bool = False,\n    ) -> Union[ValuePayload, NoValueType]:\n        \"\"\"Return a value from the cache, based on the given key.\n\n        If the value is not present, the method returns the token\n        :data:`.api.NO_VALUE`. :data:`.api.NO_VALUE` evaluates to False, but is\n        separate from ``None`` to distinguish between a cached value of\n        ``None``.\n\n        By default, the configured expiration time of the\n        :class:`.CacheRegion`, or alternatively the expiration\n        time supplied by the ``expiration_time`` argument,\n        is tested against the creation time of the retrieved\n        value versus the current time (as reported by ``time.time()``).\n        If stale, the cached value is ignored and the :data:`.api.NO_VALUE`\n        token is returned.  Passing the flag ``ignore_expiration=True``\n        bypasses the expiration time check.\n\n        .. versionchanged:: 0.3.0\n           :meth:`.CacheRegion.get` now checks the value's creation time\n           against the expiration time, rather than returning\n           the value unconditionally.\n\n        The method also interprets the cached value in terms\n        of the current \"invalidation\" time as set by\n        the :meth:`.invalidate` method.   If a value is present,\n        but its creation time is older than the current\n        invalidation time, the :data:`.api.NO_VALUE` token is returned.\n        Passing the flag ``ignore_expiration=True`` bypasses\n        the invalidation time check.\n\n        .. versionadded:: 0.3.0\n           Support for the :meth:`.CacheRegion.invalidate`\n           method.\n\n        :param key: Key to be retrieved. While it's typical for a key to be a\n         string, it is ultimately passed directly down to the cache backend,\n         before being optionally processed by the key_mangler function, so can\n         be of any type recognized by the backend or by the key_mangler\n         function, if present.\n\n        :param expiration_time: Optional expiration time value\n         which will supersede that configured on the :class:`.CacheRegion`\n         itself.\n\n         .. note:: The :paramref:`.CacheRegion.get.expiration_time`\n            argument is **not persisted in the cache** and is relevant\n            only to **this specific cache retrieval operation**, relative to\n            the creation time stored with the existing cached value.\n            Subsequent calls to :meth:`.CacheRegion.get` are **not** affected\n            by this value.\n\n         .. versionadded:: 0.3.0\n\n        :param ignore_expiration: if ``True``, the value is returned\n         from the cache if present, regardless of configured\n         expiration times or whether or not :meth:`.invalidate`\n         was called.\n\n         .. versionadded:: 0.3.0\n\n        .. seealso::\n\n            :meth:`.CacheRegion.get_multi`\n\n            :meth:`.CacheRegion.get_or_create`\n\n            :meth:`.CacheRegion.set`\n\n            :meth:`.CacheRegion.delete`\n\n\n        \"\"\"\n        value = self._get_cache_value(key, expiration_time, ignore_expiration)\n        return value.payload\n\n    def get_value_metadata(\n        self,\n        key: KeyType,\n        expiration_time: Optional[float] = None,\n        ignore_expiration: bool = False,\n    ) -> Optional[CachedValue]:\n        \"\"\"Return the :class:`.CachedValue` object directly from the cache.\n\n        This is the enclosing datastructure that includes the value as well as\n        the metadata, including the timestamp when the value was cached.\n        Convenience accessors on :class:`.CachedValue` also provide for common\n        data such as :attr:`.CachedValue.cached_time` and\n        :attr:`.CachedValue.age`.\n\n\n        .. versionadded:: 1.3. Added :meth:`.CacheRegion.get_value_metadata`\n        \"\"\"\n        cache_value = self._get_cache_value(\n            key, expiration_time, ignore_expiration\n        )\n        if cache_value is NO_VALUE:\n            return None\n        else:\n            if TYPE_CHECKING:\n                assert isinstance(cache_value, CachedValue)\n            return cache_value\n\n    def _get_cache_value(\n        self,\n        key: KeyType,\n        expiration_time: Optional[float] = None,\n        ignore_expiration: bool = False,\n    ) -> CacheReturnType:\n        if self.key_mangler:\n            key = self.key_mangler(key)\n        value = self._get_from_backend(key)\n        value = self._unexpired_value_fn(expiration_time, ignore_expiration)(\n            value\n        )\n        return value\n\n    def _unexpired_value_fn(self, expiration_time, ignore_expiration):\n        if ignore_expiration:\n            return lambda value: value\n        else:\n            if expiration_time is None:\n                expiration_time = self.expiration_time\n\n            current_time = time.time()\n\n            def value_fn(value):\n                if value is NO_VALUE:\n                    return value\n                elif (\n                    expiration_time is not None\n                    and current_time - value.metadata[\"ct\"] > expiration_time\n                ):\n                    return NO_VALUE\n                elif self.region_invalidator.is_invalidated(\n                    value.metadata[\"ct\"]\n                ):\n                    return NO_VALUE\n                else:\n                    return value\n\n            return value_fn\n\n    def get_multi(self, keys, expiration_time=None, ignore_expiration=False):\n        \"\"\"Return multiple values from the cache, based on the given keys.\n\n        Returns values as a list matching the keys given.\n\n        E.g.::\n\n            values = region.get_multi([\"one\", \"two\", \"three\"])\n\n        To convert values to a dictionary, use ``zip()``::\n\n            keys = [\"one\", \"two\", \"three\"]\n            values = region.get_multi(keys)\n            dictionary = dict(zip(keys, values))\n\n        Keys which aren't present in the list are returned as\n        the ``NO_VALUE`` token.  ``NO_VALUE`` evaluates to False,\n        but is separate from\n        ``None`` to distinguish between a cached value of ``None``.\n\n        By default, the configured expiration time of the\n        :class:`.CacheRegion`, or alternatively the expiration\n        time supplied by the ``expiration_time`` argument,\n        is tested against the creation time of the retrieved\n        value versus the current time (as reported by ``time.time()``).\n        If stale, the cached value is ignored and the ``NO_VALUE``\n        token is returned.  Passing the flag ``ignore_expiration=True``\n        bypasses the expiration time check.\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        if not keys:\n            return []\n\n        if self.key_mangler is not None:\n            keys = [self.key_mangler(key) for key in keys]\n\n        backend_values = self._get_multi_from_backend(keys)\n\n        _unexpired_value_fn = self._unexpired_value_fn(\n            expiration_time, ignore_expiration\n        )\n        return [\n            value.payload if value is not NO_VALUE else value\n            for value in (\n                _unexpired_value_fn(value) for value in backend_values\n            )\n        ]\n\n    @contextlib.contextmanager\n    def _log_time(self, keys):\n        start_time = time.time()\n        yield\n        seconds = time.time() - start_time\n        log.debug(\n            \"Cache value generated in %(seconds).3f seconds for key(s): \"\n            \"%(keys)r\",\n            {\"seconds\": seconds, \"keys\": repr_obj(keys)},\n        )\n\n    def _is_cache_miss(self, value, orig_key):\n        if value is NO_VALUE:\n            log.debug(\"No value present for key: %r\", orig_key)\n        elif value.metadata[\"v\"] != value_version:\n            log.debug(\"Dogpile version update for key: %r\", orig_key)\n        elif self.region_invalidator.is_hard_invalidated(value.metadata[\"ct\"]):\n            log.debug(\"Hard invalidation detected for key: %r\", orig_key)\n        else:\n            return False\n\n        return True\n\n    def key_is_locked(self, key: KeyType) -> bool:\n        \"\"\"Return True if a particular cache key is currently being generated\n        within the dogpile lock.\n\n        .. versionadded:: 1.1.2\n\n        \"\"\"\n        mutex = self._mutex(key)\n        locked: bool = mutex.locked()\n        return locked\n\n    def get_or_create(\n        self,\n        key: KeyType,\n        creator: Callable[..., ValuePayload],\n        expiration_time: Optional[float] = None,\n        should_cache_fn: Optional[Callable[[ValuePayload], bool]] = None,\n        creator_args: Optional[Tuple[Any, Mapping[str, Any]]] = None,\n    ) -> ValuePayload:\n        \"\"\"Return a cached value based on the given key.\n\n        If the value does not exist or is considered to be expired\n        based on its creation time, the given\n        creation function may or may not be used to recreate the value\n        and persist the newly generated value in the cache.\n\n        Whether or not the function is used depends on if the\n        *dogpile lock* can be acquired or not.  If it can't, it means\n        a different thread or process is already running a creation\n        function for this key against the cache.  When the dogpile\n        lock cannot be acquired, the method will block if no\n        previous value is available, until the lock is released and\n        a new value available.  If a previous value\n        is available, that value is returned immediately without blocking.\n\n        If the :meth:`.invalidate` method has been called, and\n        the retrieved value's timestamp is older than the invalidation\n        timestamp, the value is unconditionally prevented from\n        being returned.  The method will attempt to acquire the dogpile\n        lock to generate a new value, or will wait\n        until the lock is released to return the new value.\n\n        .. versionchanged:: 0.3.0\n          The value is unconditionally regenerated if the creation\n          time is older than the last call to :meth:`.invalidate`.\n\n        :param key: Key to be retrieved. While it's typical for a key to be a\n         string, it is ultimately passed directly down to the cache backend,\n         before being optionally processed by the key_mangler function, so can\n         be of any type recognized by the backend or by the key_mangler\n         function, if present.\n\n        :param creator: function which creates a new value.\n\n        :param creator_args: optional tuple of (args, kwargs) that will be\n         passed to the creator function if present.\n\n         .. versionadded:: 0.7.0\n\n        :param expiration_time: optional expiration time which will override\n         the expiration time already configured on this :class:`.CacheRegion`\n         if not None.   To set no expiration, use the value -1.\n\n         .. note:: The :paramref:`.CacheRegion.get_or_create.expiration_time`\n            argument is **not persisted in the cache** and is relevant\n            only to **this specific cache retrieval operation**, relative to\n            the creation time stored with the existing cached value.\n            Subsequent calls to :meth:`.CacheRegion.get_or_create` are **not**\n            affected by this value.\n\n        :param should_cache_fn: optional callable function which will receive\n         the value returned by the \"creator\", and will then return True or\n         False, indicating if the value should actually be cached or not.  If\n         it returns False, the value is still returned, but isn't cached.\n         E.g.::\n\n            def dont_cache_none(value):\n                return value is not None\n\n            value = region.get_or_create(\"some key\",\n                                create_value,\n                                should_cache_fn=dont_cache_none)\n\n         Above, the function returns the value of create_value() if\n         the cache is invalid, however if the return value is None,\n         it won't be cached.\n\n         .. versionadded:: 0.4.3\n\n        .. seealso::\n\n            :meth:`.CacheRegion.get`\n\n            :meth:`.CacheRegion.cache_on_arguments` - applies\n            :meth:`.get_or_create` to any function using a decorator.\n\n            :meth:`.CacheRegion.get_or_create_multi` - multiple key/value\n            version\n\n        \"\"\"\n        orig_key = key\n        if self.key_mangler:\n            key = self.key_mangler(key)\n\n        def get_value():\n            value = self._get_from_backend(key)\n            if self._is_cache_miss(value, orig_key):\n                raise NeedRegenerationException()\n\n            ct = cast(CachedValue, value).metadata[\"ct\"]\n            if self.region_invalidator.is_soft_invalidated(ct):\n                if expiration_time is None:\n                    raise exception.DogpileCacheException(\n                        \"Non-None expiration time required \"\n                        \"for soft invalidation\"\n                    )\n                ct = time.time() - expiration_time - 0.0001\n\n            return value.payload, ct\n\n        def gen_value():\n            with self._log_time(orig_key):\n                if creator_args:\n                    created_value = creator(\n                        *creator_args[0], **creator_args[1]\n                    )\n                else:\n                    created_value = creator()\n            value = self._value(created_value)\n\n            if (\n                expiration_time is None\n                and self.region_invalidator.was_soft_invalidated()\n            ):\n                raise exception.DogpileCacheException(\n                    \"Non-None expiration time required \"\n                    \"for soft invalidation\"\n                )\n\n            if not should_cache_fn or should_cache_fn(created_value):\n                self._set_cached_value_to_backend(key, value)\n\n            return value.payload, value.metadata[\"ct\"]\n\n        if expiration_time is None:\n            expiration_time = self.expiration_time\n\n        if expiration_time == -1:\n            expiration_time = None\n\n        async_creator: Optional[Callable[[CacheMutex], AsyncCreator]]\n        if self.async_creation_runner:\n            acr = self.async_creation_runner\n\n            def async_creator(mutex):\n                if creator_args:\n                    ca = creator_args\n\n                    @wraps(creator)\n                    def go():\n                        return creator(*ca[0], **ca[1])\n\n                else:\n                    go = creator  # type: ignore\n                return acr(self, orig_key, go, mutex)\n\n        else:\n            async_creator = None\n\n        with Lock(\n            self._mutex(key),\n            gen_value,\n            get_value,\n            expiration_time,\n            async_creator,\n        ) as value:\n            return value\n\n    def get_or_create_multi(\n        self,\n        keys: Sequence[KeyType],\n        creator: Callable[[], ValuePayload],\n        expiration_time: Optional[float] = None,\n        should_cache_fn: Optional[Callable[[ValuePayload], bool]] = None,\n    ) -> Sequence[ValuePayload]:\n        \"\"\"Return a sequence of cached values based on a sequence of keys.\n\n        The behavior for generation of values based on keys corresponds\n        to that of :meth:`.Region.get_or_create`, with the exception that\n        the ``creator()`` function may be asked to generate any subset of\n        the given keys.   The list of keys to be generated is passed to\n        ``creator()``, and ``creator()`` should return the generated values\n        as a sequence corresponding to the order of the keys.\n\n        The method uses the same approach as :meth:`.Region.get_multi`\n        and :meth:`.Region.set_multi` to get and set values from the\n        backend.\n\n        If you are using a :class:`.CacheBackend` or :class:`.ProxyBackend`\n        that modifies values, take note this function invokes\n        ``.set_multi()`` for newly generated values using the same values it\n        returns to the calling function. A correct implementation of\n        ``.set_multi()`` will not modify values in-place on the submitted\n        ``mapping`` dict.\n\n        :param keys: Sequence of keys to be retrieved.\n\n        :param creator: function which accepts a sequence of keys and\n         returns a sequence of new values.\n\n        :param expiration_time: optional expiration time which will override\n         the expiration time already configured on this :class:`.CacheRegion`\n         if not None.   To set no expiration, use the value -1.\n\n        :param should_cache_fn: optional callable function which will receive\n         each value returned by the \"creator\", and will then return True or\n         False, indicating if the value should actually be cached or not.  If\n         it returns False, the value is still returned, but isn't cached.\n\n        .. versionadded:: 0.5.0\n\n        .. seealso::\n\n\n            :meth:`.CacheRegion.cache_multi_on_arguments`\n\n            :meth:`.CacheRegion.get_or_create`\n\n        \"\"\"\n\n        def get_value(key):\n            value = values.get(key, NO_VALUE)\n\n            if self._is_cache_miss(value, orig_key):\n                # dogpile.core understands a 0 here as\n                # \"the value is not available\", e.g.\n                # _has_value() will return False.\n                return value.payload, 0\n            else:\n                ct = cast(CachedValue, value).metadata[\"ct\"]\n                if self.region_invalidator.is_soft_invalidated(ct):\n                    if expiration_time is None:\n                        raise exception.DogpileCacheException(\n                            \"Non-None expiration time required \"\n                            \"for soft invalidation\"\n                        )\n                    ct = time.time() - expiration_time - 0.0001\n\n                return value.payload, ct\n\n        def gen_value() -> ValuePayload:\n            raise NotImplementedError()\n\n        def async_creator(mutexes, key, mutex):\n            mutexes[key] = mutex\n\n        if expiration_time is None:\n            expiration_time = self.expiration_time\n\n        if expiration_time == -1:\n            expiration_time = None\n\n        sorted_unique_keys = sorted(set(keys))\n\n        if self.key_mangler:\n            mangled_keys = [self.key_mangler(k) for k in sorted_unique_keys]\n        else:\n            mangled_keys = sorted_unique_keys\n\n        orig_to_mangled = dict(zip(sorted_unique_keys, mangled_keys))\n\n        values = dict(\n            zip(mangled_keys, self._get_multi_from_backend(mangled_keys))\n        )\n\n        mutexes: Mapping[KeyType, Any] = {}\n\n        for orig_key, mangled_key in orig_to_mangled.items():\n            with Lock(\n                self._mutex(mangled_key),\n                gen_value,\n                lambda: get_value(mangled_key),\n                expiration_time,\n                async_creator=lambda mutex: async_creator(\n                    mutexes, orig_key, mutex\n                ),\n            ):\n                pass\n        try:\n            if mutexes:\n                # sort the keys, the idea is to prevent deadlocks.\n                # though haven't been able to simulate one anyway.\n                keys_to_get = sorted(mutexes)\n\n                with self._log_time(keys_to_get):\n                    new_values = creator(*keys_to_get)\n\n                values_w_created = {\n                    orig_to_mangled[k]: self._value(v)\n                    for k, v in zip(keys_to_get, new_values)\n                }\n\n                if (\n                    expiration_time is None\n                    and self.region_invalidator.was_soft_invalidated()\n                ):\n                    raise exception.DogpileCacheException(\n                        \"Non-None expiration time required \"\n                        \"for soft invalidation\"\n                    )\n\n                if not should_cache_fn:\n                    self._set_multi_cached_value_to_backend(values_w_created)\n\n                else:\n                    self._set_multi_cached_value_to_backend(\n                        {\n                            k: v\n                            for k, v in values_w_created.items()\n                            if should_cache_fn(v.payload)\n                        }\n                    )\n\n                values.update(values_w_created)\n            return [values[orig_to_mangled[k]].payload for k in keys]\n        finally:\n            for mutex in mutexes.values():\n                mutex.release()\n\n    def _value(\n        self, value: Any, metadata: Optional[MetaDataType] = None\n    ) -> CachedValue:\n        \"\"\"Return a :class:`.CachedValue` given a value.\"\"\"\n\n        if metadata is None:\n            metadata = self._gen_metadata()\n        return CachedValue(value, metadata)\n\n    def _parse_serialized_from_backend(\n        self, value: SerializedReturnType\n    ) -> CacheReturnType:\n        if value in (None, NO_VALUE):\n            return NO_VALUE\n\n        assert self.deserializer\n        byte_value = cast(bytes, value)\n\n        bytes_metadata, _, bytes_payload = byte_value.partition(b\"|\")\n        metadata = json.loads(bytes_metadata)\n        try:\n            payload = self.deserializer(bytes_payload)\n        except CantDeserializeException:\n            return NO_VALUE\n        else:\n            return CachedValue(payload, metadata)\n\n    def _serialize_cached_value_elements(\n        self, payload: ValuePayload, metadata: MetaDataType\n    ) -> bytes:\n        serializer = cast(Serializer, self.serializer)\n\n        return b\"%b|%b\" % (\n            json.dumps(metadata).encode(\"ascii\"),\n            serializer(payload),\n        )\n\n    def _serialized_payload(\n        self, payload: ValuePayload, metadata: Optional[MetaDataType] = None\n    ) -> BackendFormatted:\n        \"\"\"Return a backend formatted representation of a value.\n\n        If a serializer is in use then this will return a string representation\n        with the value formatted by the serializer.\n\n        \"\"\"\n        if metadata is None:\n            metadata = self._gen_metadata()\n\n        return self._serialize_cached_value_elements(payload, metadata)\n\n    def _serialized_cached_value(self, value: CachedValue) -> BackendFormatted:\n        \"\"\"Return a backend formatted representation of a\n        :class:`.CachedValue`.\n\n        If a serializer is in use then this will return a string representation\n        with the value formatted by the serializer.\n\n        \"\"\"\n\n        assert self.serializer\n        return self._serialize_cached_value_elements(\n            value.payload, value.metadata\n        )\n\n    def _get_from_backend(self, key: KeyType) -> CacheReturnType:\n        if self.deserializer:\n            return self._parse_serialized_from_backend(\n                self.backend.get_serialized(key)\n            )\n        else:\n            return cast(CacheReturnType, self.backend.get(key))\n\n    def _get_multi_from_backend(\n        self, keys: Sequence[KeyType]\n    ) -> Sequence[CacheReturnType]:\n        if self.deserializer:\n            return [\n                self._parse_serialized_from_backend(v)\n                for v in self.backend.get_serialized_multi(keys)\n            ]\n        else:\n            return cast(\n                Sequence[CacheReturnType], self.backend.get_multi(keys)\n            )\n\n    def _set_cached_value_to_backend(\n        self, key: KeyType, value: CachedValue\n    ) -> None:\n        if self.serializer:\n            self.backend.set_serialized(\n                key, self._serialized_cached_value(value)\n            )\n        else:\n            self.backend.set(key, value)\n\n    def _set_multi_cached_value_to_backend(\n        self, mapping: Mapping[KeyType, CachedValue]\n    ) -> None:\n        if not mapping:\n            return\n\n        if self.serializer:\n            self.backend.set_serialized_multi(\n                {\n                    k: self._serialized_cached_value(v)\n                    for k, v in mapping.items()\n                }\n            )\n        else:\n            self.backend.set_multi(mapping)\n\n    def _gen_metadata(self) -> MetaDataType:\n        return {\"ct\": time.time(), \"v\": value_version}\n\n    def set(self, key: KeyType, value: ValuePayload) -> None:\n        \"\"\"Place a new value in the cache under the given key.\"\"\"\n\n        if self.key_mangler:\n            key = self.key_mangler(key)\n\n        if self.serializer:\n            self.backend.set_serialized(key, self._serialized_payload(value))\n        else:\n            self.backend.set(key, self._value(value))\n\n    def set_multi(self, mapping: Mapping[KeyType, ValuePayload]) -> None:\n        \"\"\"Place new values in the cache under the given keys.\"\"\"\n        if not mapping:\n            return\n\n        metadata = self._gen_metadata()\n\n        if self.serializer:\n            if self.key_mangler:\n                mapping = {\n                    self.key_mangler(k): self._serialized_payload(\n                        v, metadata=metadata\n                    )\n                    for k, v in mapping.items()\n                }\n            else:\n                mapping = {\n                    k: self._serialized_payload(v, metadata=metadata)\n                    for k, v in mapping.items()\n                }\n            self.backend.set_serialized_multi(mapping)\n        else:\n            if self.key_mangler:\n                mapping = {\n                    self.key_mangler(k): self._value(v, metadata=metadata)\n                    for k, v in mapping.items()\n                }\n            else:\n                mapping = {\n                    k: self._value(v, metadata=metadata)\n                    for k, v in mapping.items()\n                }\n            self.backend.set_multi(mapping)\n\n    def delete(self, key: KeyType) -> None:\n        \"\"\"Remove a value from the cache.\n\n        This operation is idempotent (can be called multiple times, or on a\n        non-existent key, safely)\n        \"\"\"\n\n        if self.key_mangler:\n            key = self.key_mangler(key)\n\n        self.backend.delete(key)\n\n    def delete_multi(self, keys: Sequence[KeyType]) -> None:\n        \"\"\"Remove multiple values from the cache.\n\n        This operation is idempotent (can be called multiple times, or on a\n        non-existent key, safely)\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n\n        if self.key_mangler:\n            km = self.key_mangler\n            keys = [km(key) for key in keys]\n\n        self.backend.delete_multi(keys)\n\n    def cache_on_arguments(\n        self,\n        namespace: Optional[str] = None,\n        expiration_time: Union[float, ExpirationTimeCallable, None] = None,\n        should_cache_fn: Optional[Callable[[ValuePayload], bool]] = None,\n        to_str: Callable[[Any], str] = str,\n        function_key_generator: Optional[FunctionKeyGenerator] = None,\n    ) -> Callable[[Callable[..., ValuePayload]], Callable[..., ValuePayload]]:\n        \"\"\"A function decorator that will cache the return\n        value of the function using a key derived from the\n        function itself and its arguments.\n\n        The decorator internally makes use of the\n        :meth:`.CacheRegion.get_or_create` method to access the\n        cache and conditionally call the function.  See that\n        method for additional behavioral details.\n\n        E.g.::\n\n            @someregion.cache_on_arguments()\n            def generate_something(x, y):\n                return somedatabase.query(x, y)\n\n        The decorated function can then be called normally, where\n        data will be pulled from the cache region unless a new\n        value is needed::\n\n            result = generate_something(5, 6)\n\n        The function is also given an attribute ``invalidate()``, which\n        provides for invalidation of the value.  Pass to ``invalidate()``\n        the same arguments you'd pass to the function itself to represent\n        a particular value::\n\n            generate_something.invalidate(5, 6)\n\n        Another attribute ``set()`` is added to provide extra caching\n        possibilities relative to the function.   This is a convenience\n        method for :meth:`.CacheRegion.set` which will store a given\n        value directly without calling the decorated function.\n        The value to be cached is passed as the first argument, and the\n        arguments which would normally be passed to the function\n        should follow::\n\n            generate_something.set(3, 5, 6)\n\n        The above example is equivalent to calling\n        ``generate_something(5, 6)``, if the function were to produce\n        the value ``3`` as the value to be cached.\n\n        .. versionadded:: 0.4.1 Added ``set()`` method to decorated function.\n\n        Similar to ``set()`` is ``refresh()``.   This attribute will\n        invoke the decorated function and populate a new value into\n        the cache with the new value, as well as returning that value::\n\n            newvalue = generate_something.refresh(5, 6)\n\n        .. versionadded:: 0.5.0 Added ``refresh()`` method to decorated\n           function.\n\n        ``original()`` on other hand will invoke the decorated function\n        without any caching::\n\n            newvalue = generate_something.original(5, 6)\n\n        .. versionadded:: 0.6.0 Added ``original()`` method to decorated\n           function.\n\n        Lastly, the ``get()`` method returns either the value cached\n        for the given key, or the token ``NO_VALUE`` if no such key\n        exists::\n\n            value = generate_something.get(5, 6)\n\n        .. versionadded:: 0.5.3 Added ``get()`` method to decorated\n           function.\n\n        The default key generation will use the name\n        of the function, the module name for the function,\n        the arguments passed, as well as an optional \"namespace\"\n        parameter in order to generate a cache key.\n\n        Given a function ``one`` inside the module\n        ``myapp.tools``::\n\n            @region.cache_on_arguments(namespace=\"foo\")\n            def one(a, b):\n                return a + b\n\n        Above, calling ``one(3, 4)`` will produce a\n        cache key as follows::\n\n            myapp.tools:one|foo|3 4\n\n        The key generator will ignore an initial argument\n        of ``self`` or ``cls``, making the decorator suitable\n        (with caveats) for use with instance or class methods.\n        Given the example::\n\n            class MyClass:\n                @region.cache_on_arguments(namespace=\"foo\")\n                def one(self, a, b):\n                    return a + b\n\n        The cache key above for ``MyClass().one(3, 4)`` will\n        again produce the same cache key of ``myapp.tools:one|foo|3 4`` -\n        the name ``self`` is skipped.\n\n        The ``namespace`` parameter is optional, and is used\n        normally to disambiguate two functions of the same\n        name within the same module, as can occur when decorating\n        instance or class methods as below::\n\n            class MyClass:\n                @region.cache_on_arguments(namespace='MC')\n                def somemethod(self, x, y):\n                    \"\"\n\n            class MyOtherClass:\n                @region.cache_on_arguments(namespace='MOC')\n                def somemethod(self, x, y):\n                    \"\"\n\n        Above, the ``namespace`` parameter disambiguates\n        between ``somemethod`` on ``MyClass`` and ``MyOtherClass``.\n        Python class declaration mechanics otherwise prevent\n        the decorator from having awareness of the ``MyClass``\n        and ``MyOtherClass`` names, as the function is received\n        by the decorator before it becomes an instance method.\n\n        The function key generation can be entirely replaced\n        on a per-region basis using the ``function_key_generator``\n        argument present on :func:`.make_region` and\n        :class:`.CacheRegion`. If defaults to\n        :func:`.function_key_generator`.\n\n        :param namespace: optional string argument which will be\n         established as part of the cache key.   This may be needed\n         to disambiguate functions of the same name within the same\n         source file, such as those\n         associated with classes - note that the decorator itself\n         can't see the parent class on a function as the class is\n         being declared.\n\n        :param expiration_time: if not None, will override the normal\n         expiration time.\n\n         May be specified as a callable, taking no arguments, that\n         returns a value to be used as the ``expiration_time``. This callable\n         will be called whenever the decorated function itself is called, in\n         caching or retrieving. Thus, this can be used to\n         determine a *dynamic* expiration time for the cached function\n         result.  Example use cases include \"cache the result until the\n         end of the day, week or time period\" and \"cache until a certain date\n         or time passes\".\n\n        :param should_cache_fn: passed to :meth:`.CacheRegion.get_or_create`.\n\n        :param to_str: callable, will be called on each function argument\n         in order to convert to a string.  Defaults to ``str()``.  If the\n         function accepts non-ascii unicode arguments on Python 2.x, the\n         ``unicode()`` builtin can be substituted, but note this will\n         produce unicode cache keys which may require key mangling before\n         reaching the cache.\n\n        :param function_key_generator: a function that will produce a\n         \"cache key\". This function will supersede the one configured on the\n         :class:`.CacheRegion` itself.\n\n        .. seealso::\n\n            :meth:`.CacheRegion.cache_multi_on_arguments`\n\n            :meth:`.CacheRegion.get_or_create`\n\n        \"\"\"\n        expiration_time_is_callable = callable(expiration_time)\n\n        if function_key_generator is None:\n            _function_key_generator = self.function_key_generator\n        else:\n            _function_key_generator = function_key_generator\n\n        def get_or_create_for_user_func(key_generator, user_func, *arg, **kw):\n            key = key_generator(*arg, **kw)\n\n            timeout: Optional[float] = (\n                cast(ExpirationTimeCallable, expiration_time)()\n                if expiration_time_is_callable\n                else cast(Optional[float], expiration_time)\n            )\n            return self.get_or_create(\n                key, user_func, timeout, should_cache_fn, (arg, kw)\n            )\n\n        def cache_decorator(user_func):\n            if to_str is cast(Callable[[Any], str], str):\n                # backwards compatible\n                key_generator = _function_key_generator(\n                    namespace, user_func\n                )  # type: ignore\n            else:\n                key_generator = _function_key_generator(\n                    namespace, user_func, to_str\n                )\n\n            def refresh(*arg, **kw):\n                \"\"\"\n                Like invalidate, but regenerates the value instead\n                \"\"\"\n                key = key_generator(*arg, **kw)\n                value = user_func(*arg, **kw)\n                self.set(key, value)\n                return value\n\n            def invalidate(*arg, **kw):\n                key = key_generator(*arg, **kw)\n                self.delete(key)\n\n            def set_(value, *arg, **kw):\n                key = key_generator(*arg, **kw)\n                self.set(key, value)\n\n            def get(*arg, **kw):\n                key = key_generator(*arg, **kw)\n                return self.get(key)\n\n            user_func.set = set_\n            user_func.invalidate = invalidate\n            user_func.get = get\n            user_func.refresh = refresh\n            user_func.original = user_func\n\n            # Use `decorate` to preserve the signature of :param:`user_func`.\n\n            return decorate(\n                user_func, partial(get_or_create_for_user_func, key_generator)\n            )\n\n        return cache_decorator\n\n    def cache_multi_on_arguments(\n        self,\n        namespace: Optional[str] = None,\n        expiration_time: Union[float, ExpirationTimeCallable, None] = None,\n        should_cache_fn: Optional[Callable[[ValuePayload], bool]] = None,\n        asdict: bool = False,\n        to_str: ToStr = str,\n        function_multi_key_generator: Optional[\n            FunctionMultiKeyGenerator\n        ] = None,\n    ) -> Callable[\n        [Callable[..., Sequence[ValuePayload]]],\n        Callable[\n            ..., Union[Sequence[ValuePayload], Mapping[KeyType, ValuePayload]]\n        ],\n    ]:\n        \"\"\"A function decorator that will cache multiple return\n        values from the function using a sequence of keys derived from the\n        function itself and the arguments passed to it.\n\n        This method is the \"multiple key\" analogue to the\n        :meth:`.CacheRegion.cache_on_arguments` method.\n\n        Example::\n\n            @someregion.cache_multi_on_arguments()\n            def generate_something(*keys):\n                return [\n                    somedatabase.query(key)\n                    for key in keys\n                ]\n\n        The decorated function can be called normally.  The decorator\n        will produce a list of cache keys using a mechanism similar to\n        that of :meth:`.CacheRegion.cache_on_arguments`, combining the\n        name of the function with the optional namespace and with the\n        string form of each key.  It will then consult the cache using\n        the same mechanism as that of :meth:`.CacheRegion.get_multi`\n        to retrieve all current values; the originally passed keys\n        corresponding to those values which aren't generated or need\n        regeneration will be assembled into a new argument list, and\n        the decorated function is then called with that subset of\n        arguments.\n\n        The returned result is a list::\n\n            result = generate_something(\"key1\", \"key2\", \"key3\")\n\n        The decorator internally makes use of the\n        :meth:`.CacheRegion.get_or_create_multi` method to access the\n        cache and conditionally call the function.  See that\n        method for additional behavioral details.\n\n        Unlike the :meth:`.CacheRegion.cache_on_arguments` method,\n        :meth:`.CacheRegion.cache_multi_on_arguments` works only with\n        a single function signature, one which takes a simple list of\n        keys as arguments.\n\n        Like :meth:`.CacheRegion.cache_on_arguments`, the decorated function\n        is also provided with a ``set()`` method, which here accepts a\n        mapping of keys and values to set in the cache::\n\n            generate_something.set({\"k1\": \"value1\",\n                                    \"k2\": \"value2\", \"k3\": \"value3\"})\n\n        ...an ``invalidate()`` method, which has the effect of deleting\n        the given sequence of keys using the same mechanism as that of\n        :meth:`.CacheRegion.delete_multi`::\n\n            generate_something.invalidate(\"k1\", \"k2\", \"k3\")\n\n        ...a ``refresh()`` method, which will call the creation\n        function, cache the new values, and return them::\n\n            values = generate_something.refresh(\"k1\", \"k2\", \"k3\")\n\n        ...and a ``get()`` method, which will return values\n        based on the given arguments::\n\n            values = generate_something.get(\"k1\", \"k2\", \"k3\")\n\n        .. versionadded:: 0.5.3 Added ``get()`` method to decorated\n           function.\n\n        Parameters passed to :meth:`.CacheRegion.cache_multi_on_arguments`\n        have the same meaning as those passed to\n        :meth:`.CacheRegion.cache_on_arguments`.\n\n        :param namespace: optional string argument which will be\n         established as part of each cache key.\n\n        :param expiration_time: if not None, will override the normal\n         expiration time.  May be passed as an integer or a\n         callable.\n\n        :param should_cache_fn: passed to\n         :meth:`.CacheRegion.get_or_create_multi`. This function is given a\n         value as returned by the creator, and only if it returns True will\n         that value be placed in the cache.\n\n        :param asdict: if ``True``, the decorated function should return\n         its result as a dictionary of keys->values, and the final result\n         of calling the decorated function will also be a dictionary.\n         If left at its default value of ``False``, the decorated function\n         should return its result as a list of values, and the final\n         result of calling the decorated function will also be a list.\n\n         When ``asdict==True`` if the dictionary returned by the decorated\n         function is missing keys, those keys will not be cached.\n\n        :param to_str: callable, will be called on each function argument\n         in order to convert to a string.  Defaults to ``str()``.  If the\n         function accepts non-ascii unicode arguments on Python 2.x, the\n         ``unicode()`` builtin can be substituted, but note this will\n         produce unicode cache keys which may require key mangling before\n         reaching the cache.\n\n        .. versionadded:: 0.5.0\n\n        :param function_multi_key_generator: a function that will produce a\n         list of keys. This function will supersede the one configured on the\n         :class:`.CacheRegion` itself.\n\n         .. versionadded:: 0.5.5\n\n        .. seealso::\n\n            :meth:`.CacheRegion.cache_on_arguments`\n\n            :meth:`.CacheRegion.get_or_create_multi`\n\n        \"\"\"\n        expiration_time_is_callable = callable(expiration_time)\n\n        if function_multi_key_generator is None:\n            _function_multi_key_generator = self.function_multi_key_generator\n        else:\n            _function_multi_key_generator = function_multi_key_generator\n\n        def get_or_create_for_user_func(\n            key_generator: Callable[..., Sequence[KeyType]],\n            user_func: Callable[..., Sequence[ValuePayload]],\n            *arg: Any,\n            **kw: Any,\n        ) -> Union[Sequence[ValuePayload], Mapping[KeyType, ValuePayload]]:\n            cache_keys = arg\n            keys = key_generator(*arg, **kw)\n            key_lookup = dict(zip(keys, cache_keys))\n\n            @wraps(user_func)\n            def creator(*keys_to_create):\n                return user_func(*[key_lookup[k] for k in keys_to_create])\n\n            timeout: Optional[float] = (\n                cast(ExpirationTimeCallable, expiration_time)()\n                if expiration_time_is_callable\n                else cast(Optional[float], expiration_time)\n            )\n\n            result: Union[\n                Sequence[ValuePayload], Mapping[KeyType, ValuePayload]\n            ]\n\n            if asdict:\n\n                def dict_create(*keys):\n                    d_values = creator(*keys)\n                    return [\n                        d_values.get(key_lookup[k], NO_VALUE) for k in keys\n                    ]\n\n                def wrap_cache_fn(value):\n                    if value is NO_VALUE:\n                        return False\n                    elif not should_cache_fn:\n                        return True\n                    else:\n                        return should_cache_fn(value)\n\n                result = self.get_or_create_multi(\n                    keys, dict_create, timeout, wrap_cache_fn\n                )\n                result = dict(\n                    (k, v)\n                    for k, v in zip(cache_keys, result)\n                    if v is not NO_VALUE\n                )\n            else:\n                result = self.get_or_create_multi(\n                    keys, creator, timeout, should_cache_fn\n                )\n\n            return result\n\n        def cache_decorator(user_func):\n            key_generator = _function_multi_key_generator(\n                namespace, user_func, to_str=to_str\n            )\n\n            def invalidate(*arg):\n                keys = key_generator(*arg)\n                self.delete_multi(keys)\n\n            def set_(mapping):\n                keys = list(mapping)\n                gen_keys = key_generator(*keys)\n                self.set_multi(\n                    dict(\n                        (gen_key, mapping[key])\n                        for gen_key, key in zip(gen_keys, keys)\n                    )\n                )\n\n            def get(*arg):\n                keys = key_generator(*arg)\n                return self.get_multi(keys)\n\n            def refresh(*arg):\n                keys = key_generator(*arg)\n                values = user_func(*arg)\n                if asdict:\n                    self.set_multi(dict(zip(keys, [values[a] for a in arg])))\n                    return values\n                else:\n                    self.set_multi(dict(zip(keys, values)))\n                    return values\n\n            user_func.set = set_\n            user_func.invalidate = invalidate\n            user_func.refresh = refresh\n            user_func.get = get\n\n            # Use `decorate` to preserve the signature of :param:`user_func`.\n\n            return decorate(\n                user_func, partial(get_or_create_for_user_func, key_generator)\n            )\n\n        return cache_decorator\n\n\ndef make_region(*arg: Any, **kw: Any) -> CacheRegion:\n    \"\"\"Instantiate a new :class:`.CacheRegion`.\n\n    Currently, :func:`.make_region` is a passthrough\n    to :class:`.CacheRegion`.  See that class for\n    constructor arguments.\n\n    \"\"\"\n    return CacheRegion(*arg, **kw)\n",
    "dogpile/testing/fixtures.py": "# mypy: ignore-errors\n\nimport collections\nimport itertools\nimport json\nimport random\nfrom threading import Lock\nfrom threading import Thread\nimport time\nimport uuid\n\nimport pytest\n\nfrom dogpile.cache import CacheRegion\nfrom dogpile.cache import register_backend\nfrom dogpile.cache.api import CacheBackend\nfrom dogpile.cache.api import CacheMutex\nfrom dogpile.cache.api import CantDeserializeException\nfrom dogpile.cache.api import NO_VALUE\nfrom dogpile.cache.region import _backend_loader\nfrom .assertions import assert_raises_message\nfrom .assertions import eq_\n\n\ndef gen_some_key():\n    return f\"some_key_{random.randint(1, 100000)}\"\n\n\nclass _GenericBackendFixture:\n    @classmethod\n    def setup_class(cls):\n        backend_cls = _backend_loader.load(cls.backend)\n        try:\n            arguments = cls.config_args.get(\"arguments\", {})\n            backend = backend_cls(arguments)\n        except ImportError:\n            pytest.skip(\"Backend %s not installed\" % cls.backend)\n        cls._check_backend_available(backend)\n\n    def teardown_method(self, method):\n        some_key = gen_some_key()\n        if self._region_inst:\n            for key in self._keys:\n                self._region_inst.delete(key)\n            self._keys.clear()\n        elif self._backend_inst:\n            self._backend_inst.delete(some_key)\n\n    @classmethod\n    def _check_backend_available(cls, backend):\n        pass\n\n    region_args = {}\n    config_args = {}\n    extra_arguments = {}\n\n    _region_inst = None\n    _backend_inst = None\n\n    _keys = set()\n\n    def _region(self, backend=None, region_args={}, config_args={}):\n        _region_args = {}\n\n        # TODO: maybe we use a class-level naming convention instead\n        # of a dict here so that arguments merge naturally\n\n        for cls in reversed(self.__class__.__mro__):\n            if \"region_args\" in cls.__dict__:\n                _region_args.update(cls.__dict__[\"region_args\"])\n\n        _region_args.update(**region_args)\n        _config_args = self.config_args.copy()\n        _config_args.update(config_args)\n\n        def _store_keys(key):\n            if existing_key_mangler:\n                key = existing_key_mangler(key)\n            self._keys.add(key)\n            return key\n\n        self._region_inst = reg = CacheRegion(**_region_args)\n\n        existing_key_mangler = self._region_inst.key_mangler\n        self._region_inst.key_mangler = _store_keys\n        self._region_inst._user_defined_key_mangler = _store_keys\n\n        reg.configure(backend or self.backend, **_config_args)\n        return reg\n\n    def _backend(self):\n        backend_cls = _backend_loader.load(self.backend)\n        _config_args = self.config_args.copy()\n        arguments = _config_args.get(\"arguments\", {})\n        arguments = {**arguments, **self.extra_arguments}\n        self._backend_inst = backend_cls(arguments)\n        return self._backend_inst\n\n\nclass _GenericBackendTestSuite(_GenericBackendFixture):\n    def test_backend_get_nothing(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        eq_(backend.get_serialized(some_key), NO_VALUE)\n\n    def test_backend_delete_nothing(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        backend.delete(some_key)\n\n    def test_backend_set_get_value(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        backend.set_serialized(some_key, b\"some value\")\n        eq_(backend.get_serialized(some_key), b\"some value\")\n\n    def test_backend_delete(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        backend.set_serialized(some_key, b\"some value\")\n        backend.delete(some_key)\n        eq_(backend.get_serialized(some_key), NO_VALUE)\n\n    def test_region_is_key_locked(self):\n        reg = self._region()\n        random_key = str(uuid.uuid1())\n        assert not reg.get(random_key)\n        eq_(reg.key_is_locked(random_key), False)\n        # ensures that calling key_is_locked doesn't acquire the lock\n        eq_(reg.key_is_locked(random_key), False)\n\n        mutex = reg.backend.get_mutex(random_key)\n        if mutex:\n            mutex.acquire()\n            eq_(reg.key_is_locked(random_key), True)\n            mutex.release()\n            eq_(reg.key_is_locked(random_key), False)\n\n    def test_region_set_get_value(self):\n        reg = self._region()\n        some_key = gen_some_key()\n        reg.set(some_key, \"some value\")\n        eq_(reg.get(some_key), \"some value\")\n\n    def test_region_set_multiple_values(self):\n        reg = self._region()\n        values = {\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}\n        reg.set_multi(values)\n        eq_(values[\"key1\"], reg.get(\"key1\"))\n        eq_(values[\"key2\"], reg.get(\"key2\"))\n        eq_(values[\"key3\"], reg.get(\"key3\"))\n\n    def test_region_get_zero_multiple_values(self):\n        reg = self._region()\n        eq_(reg.get_multi([]), [])\n\n    def test_region_set_zero_multiple_values(self):\n        reg = self._region()\n        reg.set_multi({})\n\n    def test_region_set_zero_multiple_values_w_decorator(self):\n        reg = self._region()\n        values = reg.get_or_create_multi([], lambda: 0)\n        eq_(values, [])\n\n    def test_region_get_or_create_multi_w_should_cache_none(self):\n        reg = self._region()\n        values = reg.get_or_create_multi(\n            [\"key1\", \"key2\", \"key3\"],\n            lambda *k: [None, None, None],\n            should_cache_fn=lambda v: v is not None,\n        )\n        eq_(values, [None, None, None])\n\n    def test_region_get_multiple_values(self):\n        reg = self._region()\n        key1 = \"value1\"\n        key2 = \"value2\"\n        key3 = \"value3\"\n        reg.set(\"key1\", key1)\n        reg.set(\"key2\", key2)\n        reg.set(\"key3\", key3)\n        values = reg.get_multi([\"key1\", \"key2\", \"key3\"])\n        eq_([key1, key2, key3], values)\n\n    def test_region_get_nothing_multiple(self):\n        reg = self._region()\n        reg.delete_multi([\"key1\", \"key2\", \"key3\", \"key4\", \"key5\"])\n        values = {\"key1\": \"value1\", \"key3\": \"value3\", \"key5\": \"value5\"}\n        reg.set_multi(values)\n        reg_values = reg.get_multi(\n            [\"key1\", \"key2\", \"key3\", \"key4\", \"key5\", \"key6\"]\n        )\n        eq_(\n            reg_values,\n            [\"value1\", NO_VALUE, \"value3\", NO_VALUE, \"value5\", NO_VALUE],\n        )\n\n    def test_region_get_empty_multiple(self):\n        reg = self._region()\n        reg_values = reg.get_multi([])\n        eq_(reg_values, [])\n\n    def test_region_delete_multiple(self):\n        reg = self._region()\n        values = {\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}\n        reg.set_multi(values)\n        reg.delete_multi([\"key2\", \"key10\"])\n        eq_(values[\"key1\"], reg.get(\"key1\"))\n        eq_(NO_VALUE, reg.get(\"key2\"))\n        eq_(values[\"key3\"], reg.get(\"key3\"))\n        eq_(NO_VALUE, reg.get(\"key10\"))\n\n    def test_region_set_get_nothing(self):\n        reg = self._region()\n        some_key = gen_some_key()\n        reg.delete_multi([some_key])\n        eq_(reg.get(some_key), NO_VALUE)\n\n    def test_region_creator(self):\n        reg = self._region()\n\n        def creator():\n            return \"some value\"\n\n        some_key = gen_some_key()\n        eq_(reg.get_or_create(some_key, creator), \"some value\")\n\n    @pytest.mark.time_intensive\n    def test_threaded_dogpile(self):\n        # run a basic dogpile concurrency test.\n        # note the concurrency of dogpile itself\n        # is intensively tested as part of dogpile.\n        reg = self._region(config_args={\"expiration_time\": 0.25})\n        lock = Lock()\n        canary = []\n        some_key = gen_some_key()\n\n        def creator():\n            ack = lock.acquire(False)\n            canary.append(ack)\n            time.sleep(0.25)\n            if ack:\n                lock.release()\n            return \"some value\"\n\n        def f():\n            for x in range(5):\n                reg.get_or_create(some_key, creator)\n                time.sleep(0.5)\n\n        threads = [Thread(target=f) for i in range(10)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n        assert len(canary) > 2\n        if not reg.backend.has_lock_timeout():\n            assert False not in canary\n\n    @pytest.mark.time_intensive\n    def test_threaded_get_multi(self):\n        \"\"\"This test is testing that when we get inside the \"creator\" for\n        a certain key, there are no other \"creators\" running at all for\n        that key.\n\n        With \"distributed\" locks, this is not 100% the case.\n\n        \"\"\"\n        some_key = gen_some_key()\n        reg = self._region(config_args={\"expiration_time\": 0.25})\n        backend_mutex = reg.backend.get_mutex(some_key)\n        is_custom_mutex = backend_mutex is not None\n\n        locks = dict((str(i), Lock()) for i in range(11))\n\n        canary = collections.defaultdict(list)\n\n        def creator(*keys):\n            assert keys\n            ack = [locks[key].acquire(False) for key in keys]\n\n            # print(\n            #        (\"%s \" % thread.get_ident()) + \\\n            #        \", \".join(sorted(\"%s=%s\" % (key, acq)\n            #                    for acq, key in zip(ack, keys)))\n            #    )\n\n            for acq, key in zip(ack, keys):\n                canary[key].append(acq)\n\n            time.sleep(0.5)\n\n            for acq, key in zip(ack, keys):\n                if acq:\n                    locks[key].release()\n            return [\"some value %s\" % k for k in keys]\n\n        def f():\n            for x in range(5):\n                reg.get_or_create_multi(\n                    [\n                        str(random.randint(1, 10))\n                        for i in range(random.randint(1, 5))\n                    ],\n                    creator,\n                )\n                time.sleep(0.5)\n\n        f()\n\n        threads = [Thread(target=f) for i in range(5)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n\n        assert sum([len(v) for v in canary.values()]) > 10\n\n        # for non-custom mutex, check that we never had two creators\n        # running at once\n        if not is_custom_mutex:\n            for l in canary.values():\n                assert False not in l\n\n    def test_region_delete(self):\n        reg = self._region()\n        some_key = gen_some_key()\n        reg.set(some_key, \"some value\")\n        reg.delete(some_key)\n        reg.delete(some_key)\n        eq_(reg.get(some_key), NO_VALUE)\n\n    @pytest.mark.time_intensive\n    def test_region_expire(self):\n        # TODO: ideally tests like these would not be using actual\n        # time(); instead, an artificial function where the increment\n        # can be controlled would be preferred.  this way tests need not\n        # have any delay in running and additionally there is no issue\n        # with very slow processing missing a timeout, as is often the\n        # case with this particular test\n\n        some_key = gen_some_key()\n        expire_time = 1.00\n\n        reg = self._region(config_args={\"expiration_time\": expire_time})\n        counter = itertools.count(1)\n\n        def creator():\n            return \"some value %d\" % next(counter)\n\n        eq_(reg.get_or_create(some_key, creator), \"some value 1\")\n        time.sleep(expire_time + (0.2 * expire_time))\n        # expiration is definitely hit\n        post_expiration = reg.get(some_key, ignore_expiration=True)\n        if post_expiration is not NO_VALUE:\n            eq_(post_expiration, \"some value 1\")\n\n        eq_(reg.get_or_create(some_key, creator), \"some value 2\")\n\n        # this line needs to run less the expire_time sec before the previous\n        # two or it hits the expiration\n        eq_(reg.get(some_key), \"some value 2\")\n\n    def test_decorated_fn_functionality(self):\n        # test for any quirks in the fn decoration that interact\n        # with the backend.\n\n        reg = self._region()\n\n        counter = itertools.count(1)\n\n        @reg.cache_on_arguments()\n        def my_function(x, y):\n            return next(counter) + x + y\n\n        # Start with a clean slate\n        my_function.invalidate(3, 4)\n        my_function.invalidate(5, 6)\n        my_function.invalidate(4, 3)\n\n        eq_(my_function(3, 4), 8)\n        eq_(my_function(5, 6), 13)\n        eq_(my_function(3, 4), 8)\n        eq_(my_function(4, 3), 10)\n\n        my_function.invalidate(4, 3)\n        eq_(my_function(4, 3), 11)\n\n    def test_exploding_value_fn(self):\n        some_key = gen_some_key()\n        reg = self._region()\n\n        def boom():\n            raise Exception(\"boom\")\n\n        assert_raises_message(\n            Exception, \"boom\", reg.get_or_create, some_key, boom\n        )\n\n\ndef raise_cant_deserialize_exception(v):\n    raise CantDeserializeException()\n\n\nclass _GenericSerializerTestSuite:\n    # Inheriting from this class will make test cases\n    # use these serialization arguments\n    region_args = {\n        \"serializer\": lambda v: json.dumps(v).encode(\"ascii\"),\n        \"deserializer\": json.loads,\n    }\n\n    def test_serializer_cant_deserialize(self):\n        region = self._region(\n            region_args={\n                \"serializer\": self.region_args[\"serializer\"],\n                \"deserializer\": raise_cant_deserialize_exception,\n            }\n        )\n\n        value = {\"foo\": [\"bar\", 1, False, None]}\n        region.set(\"k\", value)\n        asserted = region.get(\"k\")\n        eq_(asserted, NO_VALUE)\n\n    def test_uses_serializer(self):\n        region = self._region()\n\n        backend = region.backend\n        value = {\"foo\": [\"bar\", 1, False, None]}\n        region.set(\"k\", value)\n\n        raw = backend.get_serialized(\"k\")\n\n        assert isinstance(raw, bytes)\n\n        pipe = raw.find(b\"|\")\n        payload = raw[pipe + 1 :]\n        eq_(payload, self.region_args[\"serializer\"](value))\n        eq_(region._parse_serialized_from_backend(raw).payload, value)\n\n    def test_uses_deserializer(self):\n        region = self._region()\n\n        value = {\"foo\": [\"bar\", 1, False, None]}\n        region.set(\"k\", value)\n\n        asserted = region.get(\"k\")\n\n        eq_(asserted, value)\n\n    # TODO: test set_multi, get_multi\n\n\nclass _GenericMutexTestSuite(_GenericBackendFixture):\n    def test_mutex(self):\n        backend = self._backend()\n        mutex = backend.get_mutex(\"foo\")\n\n        assert not mutex.locked()\n        ac = mutex.acquire()\n        assert ac\n        ac2 = mutex.acquire(False)\n        assert mutex.locked()\n        assert not ac2\n        mutex.release()\n        assert not mutex.locked()\n\n        ac3 = mutex.acquire()\n        assert ac3\n        mutex.release()\n\n    def test_subclass_match(self):\n        backend = self._backend()\n        mutex = backend.get_mutex(\"foo\")\n\n        assert isinstance(mutex, CacheMutex)\n\n    @pytest.mark.time_intensive\n    def test_mutex_threaded(self):\n        backend = self._backend()\n        backend.get_mutex(\"foo\")\n\n        lock = Lock()\n        canary = []\n\n        def f():\n            for x in range(5):\n                mutex = backend.get_mutex(\"foo\")\n                mutex.acquire()\n                for y in range(5):\n                    ack = lock.acquire(False)\n                    canary.append(ack)\n                    time.sleep(0.002)\n                    if ack:\n                        lock.release()\n                mutex.release()\n                time.sleep(0.02)\n\n        threads = [Thread(target=f) for i in range(5)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n        assert False not in canary\n\n    def test_mutex_reentrant_across_keys(self):\n        backend = self._backend()\n        for x in range(3):\n            m1 = backend.get_mutex(\"foo\")\n            m2 = backend.get_mutex(\"bar\")\n            try:\n                m1.acquire()\n                assert m2.acquire(False)\n                assert not m2.acquire(False)\n                m2.release()\n\n                assert m2.acquire(False)\n                assert not m2.acquire(False)\n                m2.release()\n            finally:\n                m1.release()\n\n    def test_reentrant_dogpile(self):\n        reg = self._region()\n\n        def create_foo():\n            return \"foo\" + reg.get_or_create(\"bar\", create_bar)\n\n        def create_bar():\n            return \"bar\"\n\n        eq_(reg.get_or_create(\"foo\", create_foo), \"foobar\")\n        eq_(reg.get_or_create(\"foo\", create_foo), \"foobar\")\n\n\nclass MockMutex(object):\n    def __init__(self, key):\n        self.key = key\n\n    def acquire(self, blocking=True):\n        return True\n\n    def release(self):\n        return\n\n    def locked(self):\n        return False\n\n\nclass MockBackend(CacheBackend):\n    def __init__(self, arguments):\n        self.arguments = arguments\n        self._cache = {}\n\n    def get_mutex(self, key):\n        return MockMutex(key)\n\n    def get(self, key):\n        try:\n            return self._cache[key]\n        except KeyError:\n            return NO_VALUE\n\n    def get_multi(self, keys):\n        return [self.get(key) for key in keys]\n\n    def set(self, key, value):\n        self._cache[key] = value\n\n    def set_multi(self, mapping):\n        for key, value in mapping.items():\n            self.set(key, value)\n\n    def delete(self, key):\n        self._cache.pop(key, None)\n\n    def delete_multi(self, keys):\n        for key in keys:\n            self.delete(key)\n\n\nregister_backend(\"mock\", __name__, \"MockBackend\")\n",
    "dogpile/cache/backends/null.py": "\"\"\"\nNull Backend\n-------------\n\nThe Null backend does not do any caching at all.  It can be\nused to test behavior without caching, or as a means of disabling\ncaching for a region that is otherwise used normally.\n\n.. versionadded:: 0.5.4\n\n\"\"\"\n\nfrom ..api import CacheBackend\nfrom ..api import NO_VALUE\n\n\n__all__ = [\"NullBackend\"]\n\n\nclass NullLock(object):\n    def acquire(self, wait=True):\n        return True\n\n    def release(self):\n        pass\n\n    def locked(self):\n        return False\n\n\nclass NullBackend(CacheBackend):\n    \"\"\"A \"null\" backend that effectively disables all cache operations.\n\n    Basic usage::\n\n        from dogpile.cache import make_region\n\n        region = make_region().configure(\n            'dogpile.cache.null'\n        )\n\n    \"\"\"\n\n    def __init__(self, arguments):\n        pass\n\n    def get_mutex(self, key):\n        return NullLock()\n\n    def get(self, key):\n        return NO_VALUE\n\n    def get_multi(self, keys):\n        return [NO_VALUE for k in keys]\n\n    def set(self, key, value):\n        pass\n\n    def set_multi(self, mapping):\n        pass\n\n    def delete(self, key):\n        pass\n\n    def delete_multi(self, keys):\n        pass\n",
    "dogpile/cache/api.py": "from __future__ import annotations\n\nimport abc\nimport enum\nimport pickle\nimport time\nfrom typing import Any\nfrom typing import Callable\nfrom typing import cast\nfrom typing import Literal\nfrom typing import Mapping\nfrom typing import NamedTuple\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Union\n\nfrom ..util.typing import Self\n\n\nclass NoValue(enum.Enum):\n    \"\"\"Describe a missing cache value.\n\n    The :data:`.NO_VALUE` constant should be used.\n\n    \"\"\"\n\n    @property\n    def payload(self) -> Self:\n        return self\n\n    def __repr__(self):\n        \"\"\"Ensure __repr__ is a consistent value in case NoValue is used to\n        fill another cache key.\n\n        \"\"\"\n        return \"<dogpile.cache.api.NoValue object>\"\n\n    def __bool__(self) -> Literal[False]:  # pragma NO COVERAGE\n        return False\n\n    NO_VALUE = \"NoValue\"\n\n\nNoValueType = Literal[NoValue.NO_VALUE]\n\nNO_VALUE = NoValue.NO_VALUE\n\"\"\"Value returned from :meth:`.CacheRegion.get` that describes\na  key not present.\"\"\"\n\nMetaDataType = Mapping[str, Any]\n\n\nKeyType = str\n\"\"\"A cache key.\"\"\"\n\nValuePayload = Any\n\"\"\"An object to be placed in the cache against a key.\"\"\"\n\n\nKeyManglerType = Callable[[KeyType], KeyType]\nSerializer = Callable[[ValuePayload], bytes]\nDeserializer = Callable[[bytes], ValuePayload]\n\n\nclass CantDeserializeException(Exception):\n    \"\"\"Exception indicating deserialization failed, and that caching\n    should proceed to re-generate a value\n\n    .. versionadded:: 1.2.0\n\n    \"\"\"\n\n\nclass CacheMutex(abc.ABC):\n    \"\"\"Describes a mutexing object with acquire and release methods.\n\n    This is an abstract base class; any object that has acquire/release\n    methods may be used.\n\n    .. versionadded:: 1.1\n\n\n    .. seealso::\n\n        :meth:`.CacheBackend.get_mutex` - the backend method that optionally\n        returns this locking object.\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def acquire(self, wait: bool = True) -> bool:\n        \"\"\"Acquire the mutex.\n\n        :param wait: if True, block until available, else return True/False\n         immediately.\n\n        :return: True if the lock succeeded.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def release(self) -> None:\n        \"\"\"Release the mutex.\"\"\"\n\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def locked(self) -> bool:\n        \"\"\"Check if the mutex was acquired.\n\n        :return: true if the lock is acquired.\n\n        .. versionadded:: 1.1.2\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        return hasattr(C, \"acquire\") and hasattr(C, \"release\")\n\n\nclass CachedValue(NamedTuple):\n    \"\"\"Represent a value stored in the cache.\n\n    :class:`.CachedValue` is a two-tuple of\n    ``(payload, metadata)``, where ``metadata``\n    is dogpile.cache's tracking information (\n    currently the creation time).\n\n    \"\"\"\n\n    payload: ValuePayload\n    \"\"\"the actual cached value.\"\"\"\n\n    metadata: MetaDataType\n    \"\"\"Metadata dictionary for the cached value.\n\n    Prefer using accessors such as :attr:`.CachedValue.cached_time` rather\n    than accessing this mapping directly.\n\n    \"\"\"\n\n    @property\n    def cached_time(self) -> float:\n        \"\"\"The epoch (floating point time value) stored when this payload was\n        cached.\n\n        .. versionadded:: 1.3\n\n        \"\"\"\n        return cast(float, self.metadata[\"ct\"])\n\n    @property\n    def age(self) -> float:\n        \"\"\"Returns the elapsed time in seconds as a `float` since the insertion\n        of the value in the cache.\n\n        This value is computed **dynamically** by subtracting the cached\n        floating point epoch value from the value of ``time.time()``.\n\n        .. versionadded:: 1.3\n\n        \"\"\"\n        return time.time() - self.cached_time\n\n\nCacheReturnType = Union[CachedValue, NoValueType]\n\"\"\"The non-serialized form of what may be returned from a backend\nget method.\n\n\"\"\"\n\nSerializedReturnType = Union[bytes, NoValueType]\n\"\"\"the serialized form of what may be returned from a backend get method.\"\"\"\n\nBackendFormatted = Union[CacheReturnType, SerializedReturnType]\n\"\"\"Describes the type returned from the :meth:`.CacheBackend.get` method.\"\"\"\n\nBackendSetType = Union[CachedValue, bytes]\n\"\"\"Describes the value argument passed to the :meth:`.CacheBackend.set`\nmethod.\"\"\"\n\nBackendArguments = Mapping[str, Any]\n\n\nclass CacheBackend:\n    \"\"\"Base class for backend implementations.\n\n    Backends which set and get Python object values should subclass this\n    backend.   For backends in which the value that's stored is ultimately\n    a stream of bytes, the :class:`.BytesBackend` should be used.\n\n    \"\"\"\n\n    key_mangler: Optional[Callable[[KeyType], KeyType]] = None\n    \"\"\"Key mangling function.\n\n    May be None, or otherwise declared\n    as an ordinary instance method.\n\n    \"\"\"\n\n    serializer: Union[None, Serializer] = None\n    \"\"\"Serializer function that will be used by default if not overridden\n    by the region.\n\n    .. versionadded:: 1.1\n\n    \"\"\"\n\n    deserializer: Union[None, Deserializer] = None\n    \"\"\"deserializer function that will be used by default if not overridden\n    by the region.\n\n    .. versionadded:: 1.1\n\n    \"\"\"\n\n    def __init__(self, arguments: BackendArguments):  # pragma NO COVERAGE\n        \"\"\"Construct a new :class:`.CacheBackend`.\n\n        Subclasses should override this to\n        handle the given arguments.\n\n        :param arguments: The ``arguments`` parameter\n         passed to :func:`.make_registry`.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def from_config_dict(\n        cls, config_dict: Mapping[str, Any], prefix: str\n    ) -> Self:\n        prefix_len = len(prefix)\n        return cls(\n            dict(\n                (key[prefix_len:], config_dict[key])\n                for key in config_dict\n                if key.startswith(prefix)\n            )\n        )\n\n    def has_lock_timeout(self) -> bool:\n        return False\n\n    def get_mutex(self, key: KeyType) -> Optional[CacheMutex]:\n        \"\"\"Return an optional mutexing object for the given key.\n\n        This object need only provide an ``acquire()``\n        and ``release()`` method.\n\n        May return ``None``, in which case the dogpile\n        lock will use a regular ``threading.Lock``\n        object to mutex concurrent threads for\n        value creation.   The default implementation\n        returns ``None``.\n\n        Different backends may want to provide various\n        kinds of \"mutex\" objects, such as those which\n        link to lock files, distributed mutexes,\n        memcached semaphores, etc.  Whatever\n        kind of system is best suited for the scope\n        and behavior of the caching backend.\n\n        A mutex that takes the key into account will\n        allow multiple regenerate operations across\n        keys to proceed simultaneously, while a mutex\n        that does not will serialize regenerate operations\n        to just one at a time across all keys in the region.\n        The latter approach, or a variant that involves\n        a modulus of the given key's hash value,\n        can be used as a means of throttling the total\n        number of value recreation operations that may\n        proceed at one time.\n\n        \"\"\"\n        return None\n\n    def get(self, key: KeyType) -> BackendFormatted:  # pragma NO COVERAGE\n        \"\"\"Retrieve an optionally serialized value from the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.get`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :return: the Python object that corresponds to\n         what was established via the :meth:`.CacheBackend.set` method,\n         or the :data:`.NO_VALUE` constant if not present.\n\n        If a serializer is in use, this method will only be called if the\n        :meth:`.CacheBackend.get_serialized` method is not overridden.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_multi(\n        self, keys: Sequence[KeyType]\n    ) -> Sequence[BackendFormatted]:  # pragma NO COVERAGE\n        \"\"\"Retrieve multiple optionally serialized values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.get_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        :return a list of values as would be returned\n         individually via the :meth:`.CacheBackend.get` method, corresponding\n         to the list of keys given.\n\n        If a serializer is in use, this method will only be called if the\n        :meth:`.CacheBackend.get_serialized_multi` method is not overridden.\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_serialized(self, key: KeyType) -> SerializedReturnType:\n        \"\"\"Retrieve a serialized value from the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.get`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :return: a bytes object, or :data:`.NO_VALUE`\n         constant if not present.\n\n        The default implementation of this method for :class:`.CacheBackend`\n        returns the value of the :meth:`.CacheBackend.get` method.\n\n        .. versionadded:: 1.1\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n        \"\"\"\n        return cast(SerializedReturnType, self.get(key))\n\n    def get_serialized_multi(\n        self, keys: Sequence[KeyType]\n    ) -> Sequence[SerializedReturnType]:  # pragma NO COVERAGE\n        \"\"\"Retrieve multiple serialized values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.get_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        :return: list of bytes objects\n\n        The default implementation of this method for :class:`.CacheBackend`\n        returns the value of the :meth:`.CacheBackend.get_multi` method.\n\n        .. versionadded:: 1.1\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n        \"\"\"\n        return cast(Sequence[SerializedReturnType], self.get_multi(keys))\n\n    def set(\n        self, key: KeyType, value: BackendSetType\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Set an optionally serialized value in the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.set`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :param value: The optionally serialized :class:`.CachedValue` object.\n         May be an instance of :class:`.CachedValue` or a bytes object\n         depending on if a serializer is in use with the region and if the\n         :meth:`.CacheBackend.set_serialized` method is not overridden.\n\n        .. seealso::\n\n            :meth:`.CacheBackend.set_serialized`\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized(\n        self, key: KeyType, value: bytes\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Set a serialized value in the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.set`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :param value: a bytes object to be stored.\n\n        The default implementation of this method for :class:`.CacheBackend`\n        calls upon the :meth:`.CacheBackend.set` method.\n\n        .. versionadded:: 1.1\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n        \"\"\"\n        self.set(key, value)\n\n    def set_multi(\n        self, mapping: Mapping[KeyType, BackendSetType]\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Set multiple values in the cache.\n\n        :param mapping: a dict in which the key will be whatever was passed to\n         the :meth:`.CacheRegion.set_multi` method, processed by the \"key\n         mangling\" function, if any.\n\n        When implementing a new :class:`.CacheBackend` or cutomizing via\n        :class:`.ProxyBackend`, be aware that when this method is invoked by\n        :meth:`.Region.get_or_create_multi`, the ``mapping`` values are the\n        same ones returned to the upstream caller. If the subclass alters the\n        values in any way, it must not do so 'in-place' on the ``mapping`` dict\n        -- that will have the undesirable effect of modifying the returned\n        values as well.\n\n        If a serializer is in use, this method will only be called if the\n        :meth:`.CacheBackend.set_serialized_multi` method is not overridden.\n\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized_multi(\n        self, mapping: Mapping[KeyType, bytes]\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Set multiple serialized values in the cache.\n\n        :param mapping: a dict in which the key will be whatever was passed to\n         the :meth:`.CacheRegion.set_multi` method, processed by the \"key\n         mangling\" function, if any.\n\n        When implementing a new :class:`.CacheBackend` or cutomizing via\n        :class:`.ProxyBackend`, be aware that when this method is invoked by\n        :meth:`.Region.get_or_create_multi`, the ``mapping`` values are the\n        same ones returned to the upstream caller. If the subclass alters the\n        values in any way, it must not do so 'in-place' on the ``mapping`` dict\n        -- that will have the undesirable effect of modifying the returned\n        values as well.\n\n        .. versionadded:: 1.1\n\n        The default implementation of this method for :class:`.CacheBackend`\n        calls upon the :meth:`.CacheBackend.set_multi` method.\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n\n        \"\"\"\n        self.set_multi(mapping)\n\n    def delete(self, key: KeyType) -> None:  # pragma NO COVERAGE\n        \"\"\"Delete a value from the cache.\n\n        :param key: String key that was passed to the\n         :meth:`.CacheRegion.delete`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        The behavior here should be idempotent,\n        that is, can be called any number of times\n        regardless of whether or not the\n        key exists.\n        \"\"\"\n        raise NotImplementedError()\n\n    def delete_multi(\n        self, keys: Sequence[KeyType]\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Delete multiple values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.delete_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        The behavior here should be idempotent,\n        that is, can be called any number of times\n        regardless of whether or not the\n        key exists.\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        raise NotImplementedError()\n\n\nclass DefaultSerialization:\n    serializer: Union[None, Serializer] = staticmethod(  # type: ignore\n        pickle.dumps\n    )\n    deserializer: Union[None, Deserializer] = staticmethod(  # type: ignore\n        pickle.loads\n    )\n\n\nclass BytesBackend(DefaultSerialization, CacheBackend):\n    \"\"\"A cache backend that receives and returns series of bytes.\n\n    This backend only supports the \"serialized\" form of values; subclasses\n    should implement :meth:`.BytesBackend.get_serialized`,\n    :meth:`.BytesBackend.get_serialized_multi`,\n    :meth:`.BytesBackend.set_serialized`,\n    :meth:`.BytesBackend.set_serialized_multi`.\n\n    .. versionadded:: 1.1\n\n    \"\"\"\n\n    def get_serialized(self, key: KeyType) -> SerializedReturnType:\n        \"\"\"Retrieve a serialized value from the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.get`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :return: a bytes object, or :data:`.NO_VALUE`\n         constant if not present.\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_serialized_multi(\n        self, keys: Sequence[KeyType]\n    ) -> Sequence[SerializedReturnType]:  # pragma NO COVERAGE\n        \"\"\"Retrieve multiple serialized values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.get_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        :return: list of bytes objects\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized(\n        self, key: KeyType, value: bytes\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Set a serialized value in the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.set`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :param value: a bytes object to be stored.\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized_multi(\n        self, mapping: Mapping[KeyType, bytes]\n    ) -> None:  # pragma NO COVERAGE\n        \"\"\"Set multiple serialized values in the cache.\n\n        :param mapping: a dict in which the key will be whatever was passed to\n         the :meth:`.CacheRegion.set_multi` method, processed by the \"key\n         mangling\" function, if any.\n\n        When implementing a new :class:`.CacheBackend` or cutomizing via\n        :class:`.ProxyBackend`, be aware that when this method is invoked by\n        :meth:`.Region.get_or_create_multi`, the ``mapping`` values are the\n        same ones returned to the upstream caller. If the subclass alters the\n        values in any way, it must not do so 'in-place' on the ``mapping`` dict\n        -- that will have the undesirable effect of modifying the returned\n        values as well.\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n",
    "dogpile/testing/assertions.py": "import re\nimport sys\nimport time\n\n\ndef eq_(a, b, msg=None):\n    \"\"\"Assert a == b, with repr messaging on failure.\"\"\"\n    assert a == b, msg or \"%r != %r\" % (a, b)\n\n\ndef is_(a, b, msg=None):\n    \"\"\"Assert a is b, with repr messaging on failure.\"\"\"\n    assert a is b, msg or \"%r is not %r\" % (a, b)\n\n\ndef ne_(a, b, msg=None):\n    \"\"\"Assert a != b, with repr messaging on failure.\"\"\"\n    assert a != b, msg or \"%r == %r\" % (a, b)\n\n\ndef assert_raises_message(except_cls, msg, callable_, *args, **kwargs):\n    try:\n        callable_(*args, **kwargs)\n        assert False, \"Callable did not raise an exception\"\n    except except_cls as e:\n        assert re.search(msg, str(e)), \"%r !~ %s\" % (msg, e)\n\n\ndef winsleep():\n    # sleep a for an amount of time\n    # sufficient for windows time.time()\n    # to change\n    if sys.platform.startswith(\"win\"):\n        time.sleep(0.001)\n",
    "dogpile/cache/proxy.py": "\"\"\"\nProxy Backends\n------------------\n\nProvides a utility and a decorator class that allow for modifying the behavior\nof different backends without altering the class itself or having to extend the\nbase backend.\n\n.. versionadded:: 0.5.0  Added support for the :class:`.ProxyBackend` class.\n\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\n\nfrom .api import BackendFormatted\nfrom .api import BackendSetType\nfrom .api import CacheBackend\nfrom .api import CacheMutex\nfrom .api import KeyType\nfrom .api import SerializedReturnType\nfrom ..util.typing import Self\n\n\nclass ProxyBackend(CacheBackend):\n    \"\"\"A decorator class for altering the functionality of backends.\n\n    Basic usage::\n\n        from dogpile.cache import make_region\n        from dogpile.cache.proxy import ProxyBackend\n\n        class MyFirstProxy(ProxyBackend):\n            def get_serialized(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get_serialized(key)\n\n            def get(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get(key)\n\n            def set(self, key, value):\n                # ... custom code goes here ...\n                self.proxied.set(key)\n\n        class MySecondProxy(ProxyBackend):\n            def get_serialized(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get_serialized(key)\n\n            def get(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get(key)\n\n\n        region = make_region().configure(\n            'dogpile.cache.dbm',\n            expiration_time = 3600,\n            arguments = {\n                \"filename\":\"/path/to/cachefile.dbm\"\n            },\n            wrap = [ MyFirstProxy, MySecondProxy ]\n        )\n\n    Classes that extend :class:`.ProxyBackend` can be stacked\n    together.  The ``.proxied`` property will always\n    point to either the concrete backend instance or\n    the next proxy in the chain that a method can be\n    delegated towards.\n\n    .. versionadded:: 0.5.0\n\n    \"\"\"\n\n    def __init__(self, *arg, **kw):\n        pass\n\n    def wrap(self, backend: CacheBackend) -> Self:\n        \"\"\"Take a backend as an argument and setup the self.proxied property.\n        Return an object that be used as a backend by a :class:`.CacheRegion`\n        object.\n        \"\"\"\n        assert isinstance(backend, CacheBackend) or isinstance(\n            backend, ProxyBackend\n        )\n        self.proxied = backend\n        return self\n\n    #\n    # Delegate any functions that are not already overridden to\n    # the proxies backend\n    #\n    def get(self, key: KeyType) -> BackendFormatted:\n        return self.proxied.get(key)\n\n    def set(self, key: KeyType, value: BackendSetType) -> None:\n        self.proxied.set(key, value)\n\n    def delete(self, key: KeyType) -> None:\n        self.proxied.delete(key)\n\n    def get_multi(self, keys: Sequence[KeyType]) -> Sequence[BackendFormatted]:\n        return self.proxied.get_multi(keys)\n\n    def set_multi(self, mapping: Mapping[KeyType, BackendSetType]) -> None:\n        self.proxied.set_multi(mapping)\n\n    def delete_multi(self, keys: Sequence[KeyType]) -> None:\n        self.proxied.delete_multi(keys)\n\n    def get_mutex(self, key: KeyType) -> Optional[CacheMutex]:\n        return self.proxied.get_mutex(key)\n\n    def get_serialized(self, key: KeyType) -> SerializedReturnType:\n        return self.proxied.get_serialized(key)\n\n    def get_serialized_multi(\n        self, keys: Sequence[KeyType]\n    ) -> Sequence[SerializedReturnType]:\n        return self.proxied.get_serialized_multi(keys)\n\n    def set_serialized(self, key: KeyType, value: bytes) -> None:\n        self.proxied.set_serialized(key, value)\n\n    def set_serialized_multi(self, mapping: Mapping[KeyType, bytes]) -> None:\n        self.proxied.set_serialized_multi(mapping)\n"
  },
  "GT_src_dict": {
    "dogpile/cache/region.py": {},
    "dogpile/testing/fixtures.py": {
      "_GenericBackendFixture._region": {
        "code": "    def _region(self, backend=None, region_args={}, config_args={}):\n        \"\"\"Creates and configures a cache region for the backend caching system.\n\nParameters:\n- backend (str, optional): The name of the backend to use. If not provided, defaults to the class-level `backend` attribute.\n- region_args (dict, optional): Additional arguments for the cache region configuration, which will override class-level `region_args`.\n- config_args (dict, optional): Configuration arguments for the backend, merging with class-level `config_args`.\n\nReturns:\n- CacheRegion: An instance of the configured cache region.\n\nSide Effects:\n- Updates the `_region_inst` attribute with the new CacheRegion instance.\n- The `_keys` set is updated with keys passed to the region, facilitating key management.\n\nDependencies:\n- Uses `self.backend` to determine the caching backend.\n- Relies on the class-level attributes `region_args` and `config_args` which are dictionaries used to manage configuration options for cache regions and backends. These attributes are meant to be populated by subclasses, enhancing extensibility for various caching use cases.\"\"\"\n        _region_args = {}\n        for cls in reversed(self.__class__.__mro__):\n            if 'region_args' in cls.__dict__:\n                _region_args.update(cls.__dict__['region_args'])\n        _region_args.update(**region_args)\n        _config_args = self.config_args.copy()\n        _config_args.update(config_args)\n\n        def _store_keys(key):\n            if existing_key_mangler:\n                key = existing_key_mangler(key)\n            self._keys.add(key)\n            return key\n        self._region_inst = reg = CacheRegion(**_region_args)\n        existing_key_mangler = self._region_inst.key_mangler\n        self._region_inst.key_mangler = _store_keys\n        self._region_inst._user_defined_key_mangler = _store_keys\n        reg.configure(backend or self.backend, **_config_args)\n        return reg",
        "docstring": "Creates and configures a cache region for the backend caching system.\n\nParameters:\n- backend (str, optional): The name of the backend to use. If not provided, defaults to the class-level `backend` attribute.\n- region_args (dict, optional): Additional arguments for the cache region configuration, which will override class-level `region_args`.\n- config_args (dict, optional): Configuration arguments for the backend, merging with class-level `config_args`.\n\nReturns:\n- CacheRegion: An instance of the configured cache region.\n\nSide Effects:\n- Updates the `_region_inst` attribute with the new CacheRegion instance.\n- The `_keys` set is updated with keys passed to the region, facilitating key management.\n\nDependencies:\n- Uses `self.backend` to determine the caching backend.\n- Relies on the class-level attributes `region_args` and `config_args` which are dictionaries used to manage configuration options for cache regions and backends. These attributes are meant to be populated by subclasses, enhancing extensibility for various caching use cases.",
        "signature": "def _region(self, backend=None, region_args={}, config_args={}):",
        "type": "Method",
        "class_signature": "class _GenericBackendFixture:"
      },
      "_GenericBackendFixture._backend": {
        "code": "    def _backend(self):\n        \"\"\"Retrieves an instance of the backend class defined for the cache region.\n\nThis method dynamically loads the backend class specified by `self.backend` and initializes it with configuration arguments. It combines `self.config_args` with `self.extra_arguments` to form the full set of arguments used during the backend's instantiation. The created backend instance is stored in `self._backend_inst`.\n\nParameters:\n- self: The instance of the _GenericBackendFixture class.\n\nReturns:\n- An instance of the backend class specified by `self.backend`.\n\nDependencies:\n- Relies on `_backend_loader` for loading the backend class, which is expected to handle cases where the specified backend might not be installed.\n- Assumes the existence of `self.config_args` and `self.extra_arguments`, which should provide necessary initialization parameters for the backend.\n- The backend instance is stored in `self._backend_inst` for later use within tests.\"\"\"\n        backend_cls = _backend_loader.load(self.backend)\n        _config_args = self.config_args.copy()\n        arguments = _config_args.get('arguments', {})\n        arguments = {**arguments, **self.extra_arguments}\n        self._backend_inst = backend_cls(arguments)\n        return self._backend_inst",
        "docstring": "Retrieves an instance of the backend class defined for the cache region.\n\nThis method dynamically loads the backend class specified by `self.backend` and initializes it with configuration arguments. It combines `self.config_args` with `self.extra_arguments` to form the full set of arguments used during the backend's instantiation. The created backend instance is stored in `self._backend_inst`.\n\nParameters:\n- self: The instance of the _GenericBackendFixture class.\n\nReturns:\n- An instance of the backend class specified by `self.backend`.\n\nDependencies:\n- Relies on `_backend_loader` for loading the backend class, which is expected to handle cases where the specified backend might not be installed.\n- Assumes the existence of `self.config_args` and `self.extra_arguments`, which should provide necessary initialization parameters for the backend.\n- The backend instance is stored in `self._backend_inst` for later use within tests.",
        "signature": "def _backend(self):",
        "type": "Method",
        "class_signature": "class _GenericBackendFixture:"
      }
    },
    "dogpile/cache/backends/null.py": {
      "NullLock.acquire": {
        "code": "    def acquire(self, wait=True):\n        \"\"\"Acquire a lock, simulating the behavior of a lock acquisition.\n\nParameters:\n- wait (bool): This parameter indicates whether the function should wait for the lock to be acquired. However, in this implementation, it is ignored.\n\nReturns:\n- bool: Always returns True, indicating that the lock acquisition is successful. This is a characteristic of the NullLock, which does not implement actual locking behavior.\n\nThis method is part of the NullLock class, which serves as a placeholder for lock operations in the NullBackend cache. In the context of the larger code, the NullBackend effectively disables all caching operations, making this lock functionality irrelevant intentionally.\"\"\"\n        return True",
        "docstring": "Acquire a lock, simulating the behavior of a lock acquisition.\n\nParameters:\n- wait (bool): This parameter indicates whether the function should wait for the lock to be acquired. However, in this implementation, it is ignored.\n\nReturns:\n- bool: Always returns True, indicating that the lock acquisition is successful. This is a characteristic of the NullLock, which does not implement actual locking behavior.\n\nThis method is part of the NullLock class, which serves as a placeholder for lock operations in the NullBackend cache. In the context of the larger code, the NullBackend effectively disables all caching operations, making this lock functionality irrelevant intentionally.",
        "signature": "def acquire(self, wait=True):",
        "type": "Method",
        "class_signature": "class NullLock(object):"
      },
      "NullLock.release": {
        "code": "    def release(self):\n        \"\"\"Release the lock. This method is a placeholder and does not perform any action, as the NullLock is designed to simulate lock behavior without actual locking mechanisms. It is always safe to call, as it does not raise exceptions or alter state.\n\nThis method does not take any parameters and does not return any value. It is intended for compatibility with interfaces that require a release method.\"\"\"\n        pass",
        "docstring": "Release the lock. This method is a placeholder and does not perform any action, as the NullLock is designed to simulate lock behavior without actual locking mechanisms. It is always safe to call, as it does not raise exceptions or alter state.\n\nThis method does not take any parameters and does not return any value. It is intended for compatibility with interfaces that require a release method.",
        "signature": "def release(self):",
        "type": "Method",
        "class_signature": "class NullLock(object):"
      },
      "NullBackend.get_mutex": {
        "code": "    def get_mutex(self, key):\n        \"\"\"Return a mutex lock for the specified key.\n\nThis method provides a locking mechanism, although in the case of the\nNullBackend, it returns an instance of NullLock, which does not actually\nimplement any locking behavior. This can be useful for testing purposes\nor when no caching is to occur, as it effectively behaves like a no-op.\n\nParameters\n----------\nkey : str\n    The key for which to retrieve the mutex. It is not used within this\n    implementation as the locking behavior is effectively non-existent.\n\nReturns\n-------\nNullLock\n    An instance of the NullLock class, which allows all acquire and release\n    operations to succeed without any actual concurrency control.\n\nNotes\n-----\nThe NullLock class methods acquire, release, and locked are implemented\nto return predetermined values that allow operations to succeed without\nperforming any real locks. This is integral to the NullBackend's role of \ndisabling caching behavior.\"\"\"\n        return NullLock()",
        "docstring": "Return a mutex lock for the specified key.\n\nThis method provides a locking mechanism, although in the case of the\nNullBackend, it returns an instance of NullLock, which does not actually\nimplement any locking behavior. This can be useful for testing purposes\nor when no caching is to occur, as it effectively behaves like a no-op.\n\nParameters\n----------\nkey : str\n    The key for which to retrieve the mutex. It is not used within this\n    implementation as the locking behavior is effectively non-existent.\n\nReturns\n-------\nNullLock\n    An instance of the NullLock class, which allows all acquire and release\n    operations to succeed without any actual concurrency control.\n\nNotes\n-----\nThe NullLock class methods acquire, release, and locked are implemented\nto return predetermined values that allow operations to succeed without\nperforming any real locks. This is integral to the NullBackend's role of \ndisabling caching behavior.",
        "signature": "def get_mutex(self, key):",
        "type": "Method",
        "class_signature": "class NullBackend(CacheBackend):"
      }
    },
    "dogpile/cache/api.py": {},
    "dogpile/testing/assertions.py": {
      "eq_": {
        "code": "def eq_(a, b, msg=None):\n    \"\"\"Assert that two values are equal (a == b). If they are not equal, raises an AssertionError with a message that indicates the failure. The function takes three parameters: `a` (the first value to compare), `b` (the second value to compare), and an optional `msg` (a custom error message). If `msg` is not provided, the default message includes the string representation of both values. The function does not return a value; instead, it enforces an assertion check that can halt program execution upon failure.\"\"\"\n    'Assert a == b, with repr messaging on failure.'\n    assert a == b, msg or '%r != %r' % (a, b)",
        "docstring": "Assert that two values are equal (a == b). If they are not equal, raises an AssertionError with a message that indicates the failure. The function takes three parameters: `a` (the first value to compare), `b` (the second value to compare), and an optional `msg` (a custom error message). If `msg` is not provided, the default message includes the string representation of both values. The function does not return a value; instead, it enforces an assertion check that can halt program execution upon failure.",
        "signature": "def eq_(a, b, msg=None):",
        "type": "Function",
        "class_signature": null
      }
    },
    "dogpile/cache/proxy.py": {}
  },
  "dependency_dict": {
    "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
      "dogpile/cache/region.py": {
        "_LockWrapper.__init__": {
          "code": "        def __init__(self):\n            self.lock = threading.Lock()",
          "docstring": "",
          "signature": "def __init__(self):",
          "type": "Method",
          "class_signature": "class _LockWrapper(CacheMutex):"
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:get": {
      "dogpile/cache/api.py": {
        "NoValue.payload": {
          "code": "    def payload(self) -> Self:\n        return self",
          "docstring": "",
          "signature": "def payload(self) -> Self:",
          "type": "Method",
          "class_signature": "class NoValue(enum.Enum):"
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:set": {
      "dogpile/cache/backends/null.py": {
        "NullBackend.set": {
          "code": "    def set(self, key, value):\n        pass",
          "docstring": "",
          "signature": "def set(self, key, value):",
          "type": "Method",
          "class_signature": "class NullBackend(CacheBackend):"
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:delete": {
      "dogpile/cache/backends/null.py": {
        "NullBackend.delete": {
          "code": "    def delete(self, key):\n        pass",
          "docstring": "",
          "signature": "def delete(self, key):",
          "type": "Method",
          "class_signature": "class NullBackend(CacheBackend):"
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:get_multi": {},
    "dogpile/cache/region.py:_LockWrapper:set_multi": {
      "dogpile/cache/backends/null.py": {
        "NullBackend.set_multi": {
          "code": "    def set_multi(self, mapping):\n        pass",
          "docstring": "",
          "signature": "def set_multi(self, mapping):",
          "type": "Method",
          "class_signature": "class NullBackend(CacheBackend):"
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:delete_multi": {
      "dogpile/cache/backends/null.py": {
        "NullBackend.delete_multi": {
          "code": "    def delete_multi(self, keys):\n        pass",
          "docstring": "",
          "signature": "def delete_multi(self, keys):",
          "type": "Method",
          "class_signature": "class NullBackend(CacheBackend):"
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:cache_decorator": {
      "dogpile/cache/util.py": {
        "function_key_generator": {
          "code": "def function_key_generator(namespace, fn, to_str=str):\n    \"\"\"Return a function that generates a string\n    key, based on a given function as well as\n    arguments to the returned function itself.\n\n    This is used by :meth:`.CacheRegion.cache_on_arguments`\n    to generate a cache key from a decorated function.\n\n    An alternate function may be used by specifying\n    the :paramref:`.CacheRegion.function_key_generator` argument\n    for :class:`.CacheRegion`.\n\n    .. seealso::\n\n        :func:`.kwarg_function_key_generator` - similar function that also\n        takes keyword arguments into account\n\n    \"\"\"\n\n    if namespace is None:\n        namespace = \"%s:%s\" % (fn.__module__, fn.__name__)\n    else:\n        namespace = \"%s:%s|%s\" % (fn.__module__, fn.__name__, namespace)\n\n    args = compat.inspect_getargspec(fn)\n    has_self = args[0] and args[0][0] in (\"self\", \"cls\")\n\n    def generate_key(*args, **kw):\n        if kw:\n            raise ValueError(\n                \"dogpile.cache's default key creation \"\n                \"function does not accept keyword arguments.\"\n            )\n        if has_self:\n            args = args[1:]\n\n        return namespace + \"|\" + \" \".join(map(to_str, args))\n\n    return generate_key",
          "docstring": "Return a function that generates a string\nkey, based on a given function as well as\narguments to the returned function itself.\n\nThis is used by :meth:`.CacheRegion.cache_on_arguments`\nto generate a cache key from a decorated function.\n\nAn alternate function may be used by specifying\nthe :paramref:`.CacheRegion.function_key_generator` argument\nfor :class:`.CacheRegion`.\n\n.. seealso::\n\n    :func:`.kwarg_function_key_generator` - similar function that also\n    takes keyword arguments into account",
          "signature": "def function_key_generator(namespace, fn, to_str=str):",
          "type": "Function",
          "class_signature": null
        }
      }
    },
    "dogpile/cache/region.py:_LockWrapper:get_or_create_for_user_func": {
      "dogpile/cache/util.py": {
        "generate_key": {
          "code": "    def generate_key(*args, **kwargs):\n        as_kwargs = dict(\n            [\n                (argspec.args[idx], arg)\n                for idx, arg in enumerate(\n                    args[arg_index_start:], arg_index_start\n                )\n            ]\n        )\n        as_kwargs.update(kwargs)\n        for arg, val in args_with_defaults.items():\n            if arg not in as_kwargs:\n                as_kwargs[arg] = val\n\n        argument_values = [as_kwargs[key] for key in sorted(as_kwargs.keys())]\n        return namespace + \"|\" + \" \".join(map(to_str, argument_values))",
          "docstring": "",
          "signature": "def generate_key(*args, **kwargs):",
          "type": "Function",
          "class_signature": null
        }
      }
    },
    "dogpile/testing/fixtures.py:_GenericBackendFixture:_backend": {
      "dogpile/cache/backends/null.py": {
        "NullBackend.__init__": {
          "code": "    def __init__(self, arguments):\n        pass",
          "docstring": "",
          "signature": "def __init__(self, arguments):",
          "type": "Method",
          "class_signature": "class NullBackend(CacheBackend):"
        }
      }
    }
  },
  "call_tree": {
    "tests/cache/test_null_backend.py:NullBackendTest:test_get": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:get": {
        "dogpile/cache/region.py:_LockWrapper:_get_cache_value": {
          "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
          "dogpile/cache/region.py:_LockWrapper:_get_from_backend": {
            "dogpile/cache/backends/null.py:NullBackend:get": {}
          },
          "dogpile/cache/region.py:_LockWrapper:_unexpired_value_fn": {},
          "dogpile/cache/region.py:_LockWrapper:value_fn": {}
        },
        "dogpile/cache/api.py:NoValue:payload": {}
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_set": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:set": {
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/region.py:_LockWrapper:_value": {
          "dogpile/cache/region.py:_LockWrapper:_gen_metadata": {}
        },
        "dogpile/cache/backends/null.py:NullBackend:set": {}
      },
      "dogpile/cache/region.py:_LockWrapper:get": {
        "dogpile/cache/region.py:_LockWrapper:_get_cache_value": {
          "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
          "dogpile/cache/region.py:_LockWrapper:_get_from_backend": {
            "dogpile/cache/backends/null.py:NullBackend:get": {}
          },
          "dogpile/cache/region.py:_LockWrapper:_unexpired_value_fn": {},
          "dogpile/cache/region.py:_LockWrapper:value_fn": {}
        },
        "dogpile/cache/api.py:NoValue:payload": {}
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_delete": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:delete": {
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/backends/null.py:NullBackend:delete": {}
      },
      "dogpile/cache/region.py:_LockWrapper:get": {
        "dogpile/cache/region.py:_LockWrapper:_get_cache_value": {
          "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
          "dogpile/cache/region.py:_LockWrapper:_get_from_backend": {
            "dogpile/cache/backends/null.py:NullBackend:get": {}
          },
          "dogpile/cache/region.py:_LockWrapper:_unexpired_value_fn": {},
          "dogpile/cache/region.py:_LockWrapper:value_fn": {}
        },
        "dogpile/cache/api.py:NoValue:payload": {}
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_get_multi": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:get_multi": {
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/region.py:_LockWrapper:_get_multi_from_backend": {
          "dogpile/cache/backends/null.py:NullBackend:get_multi": {}
        },
        "dogpile/cache/region.py:_LockWrapper:_unexpired_value_fn": {},
        "dogpile/cache/region.py:_LockWrapper:value_fn": {}
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_set_multi": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:set_multi": {
        "dogpile/cache/region.py:_LockWrapper:_gen_metadata": {},
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/region.py:_LockWrapper:_value": {},
        "dogpile/cache/backends/null.py:NullBackend:set_multi": {}
      },
      "dogpile/cache/region.py:_LockWrapper:get_multi": {
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/region.py:_LockWrapper:_get_multi_from_backend": {
          "dogpile/cache/backends/null.py:NullBackend:get_multi": {}
        },
        "dogpile/cache/region.py:_LockWrapper:_unexpired_value_fn": {},
        "dogpile/cache/region.py:_LockWrapper:value_fn": {}
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_delete_multi": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:delete_multi": {
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/backends/null.py:NullBackend:delete_multi": {}
      },
      "dogpile/cache/region.py:_LockWrapper:get_multi": {
        "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
        "dogpile/cache/region.py:_LockWrapper:_get_multi_from_backend": {
          "dogpile/cache/backends/null.py:NullBackend:get_multi": {}
        },
        "dogpile/cache/region.py:_LockWrapper:_unexpired_value_fn": {},
        "dogpile/cache/region.py:_LockWrapper:value_fn": {}
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_decorator": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_region": {
        "dogpile/cache/region.py:_LockWrapper:__init__": {
          "dogpile/cache/region.py:DefaultInvalidationStrategy:__init__": {}
        },
        "dogpile/cache/region.py:_LockWrapper:configure": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "dogpile/util/langhelpers.py:NotFound:load": {
              "[ignored_or_cut_off]": "..."
            }
          },
          "dogpile/cache/backends/null.py:NullBackend:__init__": {},
          "dogpile/util/nameregistry.py:NameRegistry:__init__": {}
        }
      },
      "dogpile/cache/region.py:_LockWrapper:cache_on_arguments": {},
      "dogpile/cache/region.py:_LockWrapper:cache_decorator": {
        "dogpile/cache/util.py:function_key_generator": {
          "dogpile/util/compat.py:inspect_getargspec": {
            "dogpile/util/compat.py:inspect_getfullargspec": {}
          }
        }
      },
      "dogpile/cache/region.py:_LockWrapper:get_or_create_for_user_func": {
        "dogpile/cache/util.py:generate_key": {},
        "dogpile/cache/region.py:_LockWrapper:get_or_create": {
          "dogpile/testing/fixtures.py:_GenericBackendFixture:_store_keys": {},
          "dogpile/cache/region.py:_LockWrapper:_mutex": {
            "dogpile/util/nameregistry.py:NameRegistry:get": {
              "dogpile/util/nameregistry.py:NameRegistry:_sync_get": {
                "dogpile/cache/region.py:_LockWrapper:_create_mutex": {
                  "dogpile/cache/backends/null.py:NullBackend:get_mutex": {}
                }
              }
            }
          },
          "dogpile/lock.py:Lock:__init__": {},
          "dogpile/lock.py:Lock:__enter__": {
            "dogpile/lock.py:Lock:_enter": {
              "dogpile/cache/region.py:_LockWrapper:get_value": {
                "dogpile/cache/region.py:_LockWrapper:_get_from_backend": {
                  "dogpile/cache/backends/null.py:NullBackend:get": {}
                },
                "dogpile/cache/region.py:_LockWrapper:_is_cache_miss": {}
              },
              "dogpile/lock.py:Lock:_enter_create": {
                "dogpile/lock.py:Lock:_is_expired": {
                  "dogpile/lock.py:Lock:_has_value": {}
                },
                "dogpile/lock.py:Lock:_has_value": {},
                "dogpile/cache/backends/null.py:NullLock:acquire": {},
                "dogpile/cache/region.py:_LockWrapper:get_value": {
                  "dogpile/cache/region.py:_LockWrapper:_get_from_backend": {
                    "dogpile/cache/backends/null.py:NullBackend:get": {}
                  },
                  "dogpile/cache/region.py:_LockWrapper:_is_cache_miss": {}
                },
                "dogpile/cache/region.py:_LockWrapper:gen_value": {
                  "dogpile/cache/region.py:_LockWrapper:_log_time": {
                    "dogpile/cache/util.py:repr_obj:__init__": {}
                  },
                  "tests/cache/test_null_backend.py:NullBackendTest:go": {},
                  "dogpile/cache/region.py:_LockWrapper:_value": {
                    "dogpile/cache/region.py:_LockWrapper:_gen_metadata": {}
                  },
                  "dogpile/cache/region.py:DefaultInvalidationStrategy:was_soft_invalidated": {},
                  "dogpile/cache/region.py:_LockWrapper:_set_cached_value_to_backend": {
                    "dogpile/cache/backends/null.py:NullBackend:set": {}
                  }
                },
                "dogpile/cache/backends/null.py:NullLock:release": {}
              }
            }
          },
          "dogpile/lock.py:Lock:__exit__": {}
        }
      },
      "dogpile/testing/assertions.py:eq_": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_mutex": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_backend": {
        "dogpile/util/langhelpers.py:NotFound:load": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "[ignored_or_cut_off]": "..."
          }
        },
        "dogpile/cache/backends/null.py:NullBackend:__init__": {}
      },
      "dogpile/cache/backends/null.py:NullBackend:get_mutex": {},
      "dogpile/cache/backends/null.py:NullLock:acquire": {},
      "dogpile/cache/backends/null.py:NullLock:release": {}
    },
    "tests/cache/test_null_backend.py:NullBackendTest:test_mutex_doesnt_actually_lock": {
      "dogpile/testing/fixtures.py:_GenericBackendFixture:_backend": {
        "dogpile/util/langhelpers.py:NotFound:load": {
          "dogpile/util/langhelpers.py:NotFound:load": {
            "[ignored_or_cut_off]": "..."
          }
        },
        "dogpile/cache/backends/null.py:NullBackend:__init__": {}
      },
      "dogpile/cache/backends/null.py:NullBackend:get_mutex": {},
      "dogpile/cache/backends/null.py:NullLock:acquire": {},
      "dogpile/cache/backends/null.py:NullLock:release": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:RegionTest:test_instance_from_dict": {
      "dogpile/testing/fixtures.py:MockBackend:MockBackend": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:RegionTest:test_instance_from_config_string": {
      "dogpile/testing/fixtures.py:MockBackend:MockBackend": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:RegionTest:test_replace_backend_config": {
      "dogpile/testing/fixtures.py:MockBackend:MockBackend": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:MutexAPITest:test_mutex_non_match": {
      "dogpile/cache/api.py:CacheMutex:CacheMutex": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:MutexAPITest:test_mutex_match": {
      "dogpile/cache/api.py:CacheMutex:CacheMutex": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:CanModifyCachedValueProxy:test_actual_backend_proxied": {
      "dogpile/cache/proxy.py:ProxyBackend:ProxyBackend": {},
      "dogpile/cache/api.py:CacheBackend:CacheBackend": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/tests/cache/test_region.py:CanModifyCachedValueProxy:test_actual_backend_noproxy": {
      "dogpile/cache/api.py:CacheBackend:CacheBackend": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/dogpile_cache-image-test_null_backend/dogpile_cache-test_null_backend/dogpile/testing/fixtures.py:_GenericMutexTestSuite:test_subclass_match": {
      "dogpile/cache/api.py:CacheMutex:CacheMutex": {}
    }
  },
  "PRD": "# PROJECT NAME: dogpile_cache-test_null_backend\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 dogpile/\n    \u251c\u2500\u2500 cache/\n    \u2502   \u251c\u2500\u2500 api.py\n    \u2502   \u2502   \u251c\u2500\u2500 CacheBackend.CacheBackend\n    \u2502   \u2502   \u2514\u2500\u2500 CacheMutex.CacheMutex\n    \u2502   \u251c\u2500\u2500 backends/\n    \u2502   \u2502   \u2514\u2500\u2500 null.py\n    \u2502   \u2502       \u251c\u2500\u2500 NullBackend.get_mutex\n    \u2502   \u2502       \u251c\u2500\u2500 NullLock.acquire\n    \u2502   \u2502       \u2514\u2500\u2500 NullLock.release\n    \u2502   \u251c\u2500\u2500 proxy.py\n    \u2502   \u2502   \u2514\u2500\u2500 ProxyBackend.ProxyBackend\n    \u2502   \u2514\u2500\u2500 region.py\n    \u2502       \u251c\u2500\u2500 _LockWrapper.cache_decorator\n    \u2502       \u251c\u2500\u2500 _LockWrapper.cache_on_arguments\n    \u2502       \u251c\u2500\u2500 _LockWrapper.delete\n    \u2502       \u251c\u2500\u2500 _LockWrapper.delete_multi\n    \u2502       \u251c\u2500\u2500 _LockWrapper.get\n    \u2502       \u251c\u2500\u2500 _LockWrapper.get_multi\n    \u2502       \u251c\u2500\u2500 _LockWrapper.get_or_create_for_user_func\n    \u2502       \u251c\u2500\u2500 _LockWrapper.set\n    \u2502       \u2514\u2500\u2500 _LockWrapper.set_multi\n    \u2514\u2500\u2500 testing/\n        \u251c\u2500\u2500 assertions.py\n        \u2502   \u2514\u2500\u2500 eq_\n        \u2514\u2500\u2500 fixtures.py\n            \u251c\u2500\u2500 MockBackend.MockBackend\n            \u251c\u2500\u2500 _GenericBackendFixture._backend\n            \u2514\u2500\u2500 _GenericBackendFixture._region\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThe module serves as a test suite for validating the functionality of the \"dogpile.cache.null\" backend, a caching solution that simulates a non-persistent, no-op cache implementation. It ensures that all caching operations\u2014such as `get`, `set`, `delete`, single, and multi-key operations\u2014consistently return `NO_VALUE`, confirming the backend's adherence to its intended behavior of not storing any data. Additionally, the module verifies other backend features, such as mutex acquisition, cache decorators, and locking mechanisms, ensuring they work predictably without enforcing actual persistence or synchronization. This module addresses the need for developers to confirm that specific cache backends, particularly null or placeholder implementations, behave correctly within the broader caching framework, thus preventing unintended side effects during use.\n\n## FILE 1: dogpile/cache/region.py\n\n## FILE 2: dogpile/testing/fixtures.py\n\n- CLASS METHOD: _GenericBackendFixture._region\n  - CLASS SIGNATURE: class _GenericBackendFixture:\n  - SIGNATURE: def _region(self, backend=None, region_args={}, config_args={}):\n  - DOCSTRING: \n```python\n\"\"\"\nCreates and configures a cache region for the backend caching system.\n\nParameters:\n- backend (str, optional): The name of the backend to use. If not provided, defaults to the class-level `backend` attribute.\n- region_args (dict, optional): Additional arguments for the cache region configuration, which will override class-level `region_args`.\n- config_args (dict, optional): Configuration arguments for the backend, merging with class-level `config_args`.\n\nReturns:\n- CacheRegion: An instance of the configured cache region.\n\nSide Effects:\n- Updates the `_region_inst` attribute with the new CacheRegion instance.\n- The `_keys` set is updated with keys passed to the region, facilitating key management.\n\nDependencies:\n- Uses `self.backend` to determine the caching backend.\n- Relies on the class-level attributes `region_args` and `config_args` which are dictionaries used to manage configuration options for cache regions and backends. These attributes are meant to be populated by subclasses, enhancing extensibility for various caching use cases.\n\"\"\"\n```\n\n- CLASS METHOD: _GenericBackendFixture._backend\n  - CLASS SIGNATURE: class _GenericBackendFixture:\n  - SIGNATURE: def _backend(self):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieves an instance of the backend class defined for the cache region.\n\nThis method dynamically loads the backend class specified by `self.backend` and initializes it with configuration arguments. It combines `self.config_args` with `self.extra_arguments` to form the full set of arguments used during the backend's instantiation. The created backend instance is stored in `self._backend_inst`.\n\nParameters:\n- self: The instance of the _GenericBackendFixture class.\n\nReturns:\n- An instance of the backend class specified by `self.backend`.\n\nDependencies:\n- Relies on `_backend_loader` for loading the backend class, which is expected to handle cases where the specified backend might not be installed.\n- Assumes the existence of `self.config_args` and `self.extra_arguments`, which should provide necessary initialization parameters for the backend.\n- The backend instance is stored in `self._backend_inst` for later use within tests.\n\"\"\"\n```\n\n## FILE 3: dogpile/cache/backends/null.py\n\n- CLASS METHOD: NullLock.release\n  - CLASS SIGNATURE: class NullLock(object):\n  - SIGNATURE: def release(self):\n  - DOCSTRING: \n```python\n\"\"\"\nRelease the lock. This method is a placeholder and does not perform any action, as the NullLock is designed to simulate lock behavior without actual locking mechanisms. It is always safe to call, as it does not raise exceptions or alter state.\n\nThis method does not take any parameters and does not return any value. It is intended for compatibility with interfaces that require a release method.\n\"\"\"\n```\n\n- CLASS METHOD: NullLock.acquire\n  - CLASS SIGNATURE: class NullLock(object):\n  - SIGNATURE: def acquire(self, wait=True):\n  - DOCSTRING: \n```python\n\"\"\"\nAcquire a lock, simulating the behavior of a lock acquisition.\n\nParameters:\n- wait (bool): This parameter indicates whether the function should wait for the lock to be acquired. However, in this implementation, it is ignored.\n\nReturns:\n- bool: Always returns True, indicating that the lock acquisition is successful. This is a characteristic of the NullLock, which does not implement actual locking behavior.\n\nThis method is part of the NullLock class, which serves as a placeholder for lock operations in the NullBackend cache. In the context of the larger code, the NullBackend effectively disables all caching operations, making this lock functionality irrelevant intentionally.\n\"\"\"\n```\n\n- CLASS METHOD: NullBackend.get_mutex\n  - CLASS SIGNATURE: class NullBackend(CacheBackend):\n  - SIGNATURE: def get_mutex(self, key):\n  - DOCSTRING: \n```python\n\"\"\"\nReturn a mutex lock for the specified key.\n\nThis method provides a locking mechanism, although in the case of the\nNullBackend, it returns an instance of NullLock, which does not actually\nimplement any locking behavior. This can be useful for testing purposes\nor when no caching is to occur, as it effectively behaves like a no-op.\n\nParameters\n----------\nkey : str\n    The key for which to retrieve the mutex. It is not used within this\n    implementation as the locking behavior is effectively non-existent.\n\nReturns\n-------\nNullLock\n    An instance of the NullLock class, which allows all acquire and release\n    operations to succeed without any actual concurrency control.\n\nNotes\n-----\nThe NullLock class methods acquire, release, and locked are implemented\nto return predetermined values that allow operations to succeed without\nperforming any real locks. This is integral to the NullBackend's role of \ndisabling caching behavior.\n\"\"\"\n```\n\n## FILE 4: dogpile/cache/api.py\n\n## FILE 5: dogpile/testing/assertions.py\n\n- FUNCTION NAME: eq_\n  - SIGNATURE: def eq_(a, b, msg=None):\n  - DOCSTRING: \n```python\n\"\"\"\nAssert that two values are equal (a == b). If they are not equal, raises an AssertionError with a message that indicates the failure. The function takes three parameters: `a` (the first value to compare), `b` (the second value to compare), and an optional `msg` (a custom error message). If `msg` is not provided, the default message includes the string representation of both values. The function does not return a value; instead, it enforces an assertion check that can halt program execution upon failure.\n\"\"\"\n```\n\n## FILE 6: dogpile/cache/proxy.py\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "dogpile/cache/region.py": "from __future__ import annotations\nimport contextlib\nimport datetime\nfrom functools import partial\nfrom functools import wraps\nimport json\nimport logging\nfrom numbers import Number\nimport threading\nimport time\nfrom typing import Any\nfrom typing import Callable\nfrom typing import cast\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Tuple\nfrom typing import Type\nfrom typing import TYPE_CHECKING\nfrom typing import Union\nfrom decorator import decorate\nfrom . import exception\nfrom .api import BackendArguments\nfrom .api import BackendFormatted\nfrom .api import CachedValue\nfrom .api import CacheMutex\nfrom .api import CacheReturnType\nfrom .api import CantDeserializeException\nfrom .api import KeyType\nfrom .api import MetaDataType\nfrom .api import NO_VALUE\nfrom .api import NoValueType\nfrom .api import SerializedReturnType\nfrom .api import Serializer\nfrom .api import ValuePayload\nfrom .backends import _backend_loader\nfrom .backends import register_backend\nfrom .proxy import ProxyBackend\nfrom .util import function_key_generator\nfrom .util import function_multi_key_generator\nfrom .util import repr_obj\nfrom .. import Lock\nfrom .. import NeedRegenerationException\nfrom ..util import coerce_string_conf\nfrom ..util import memoized_property\nfrom ..util import NameRegistry\nfrom ..util import PluginLoader\nfrom ..util.typing import Self\nvalue_version = 2\n'An integer placed in the :class:`.CachedValue`\\nso that new versions of dogpile.cache can detect cached\\nvalues from a previous, backwards-incompatible version.\\n\\n'\nlog = logging.getLogger(__name__)\nAsyncCreator = Callable[['CacheRegion', KeyType, Callable[[], ValuePayload], CacheMutex], None]\nExpirationTimeCallable = Callable[[], float]\nToStr = Callable[[Any], str]\nFunctionKeyGenerator = Callable[..., Callable[..., KeyType]]\nFunctionMultiKeyGenerator = Callable[..., Callable[..., Sequence[KeyType]]]\n\nclass RegionInvalidationStrategy:\n    \"\"\"Region invalidation strategy interface\n\n    Implement this interface and pass implementation instance\n    to :meth:`.CacheRegion.configure` to override default region invalidation.\n\n    Example::\n\n        class CustomInvalidationStrategy(RegionInvalidationStrategy):\n\n            def __init__(self):\n                self._soft_invalidated = None\n                self._hard_invalidated = None\n\n            def invalidate(self, hard=None):\n                if hard:\n                    self._soft_invalidated = None\n                    self._hard_invalidated = time.time()\n                else:\n                    self._soft_invalidated = time.time()\n                    self._hard_invalidated = None\n\n            def is_invalidated(self, timestamp):\n                return ((self._soft_invalidated and\n                         timestamp < self._soft_invalidated) or\n                        (self._hard_invalidated and\n                         timestamp < self._hard_invalidated))\n\n            def was_hard_invalidated(self):\n                return bool(self._hard_invalidated)\n\n            def is_hard_invalidated(self, timestamp):\n                return (self._hard_invalidated and\n                        timestamp < self._hard_invalidated)\n\n            def was_soft_invalidated(self):\n                return bool(self._soft_invalidated)\n\n            def is_soft_invalidated(self, timestamp):\n                return (self._soft_invalidated and\n                        timestamp < self._soft_invalidated)\n\n    The custom implementation is injected into a :class:`.CacheRegion`\n    at configure time using the\n    :paramref:`.CacheRegion.configure.region_invalidator` parameter::\n\n        region = CacheRegion()\n\n        region = region.configure(region_invalidator=CustomInvalidationStrategy())  # noqa\n\n    Invalidation strategies that wish to have access to the\n    :class:`.CacheRegion` itself should construct the invalidator given the\n    region as an argument::\n\n        class MyInvalidator(RegionInvalidationStrategy):\n            def __init__(self, region):\n                self.region = region\n                # ...\n\n            # ...\n\n        region = CacheRegion()\n        region = region.configure(region_invalidator=MyInvalidator(region))\n\n    .. versionadded:: 0.6.2\n\n    .. seealso::\n\n        :paramref:`.CacheRegion.configure.region_invalidator`\n\n    \"\"\"\n\n    def invalidate(self, hard: bool=True) -> None:\n        \"\"\"Region invalidation.\n\n        :class:`.CacheRegion` propagated call.\n        The default invalidation system works by setting\n        a current timestamp (using ``time.time()``) to consider all older\n        timestamps effectively invalidated.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def is_hard_invalidated(self, timestamp: float) -> bool:\n        \"\"\"Check timestamp to determine if it was hard invalidated.\n\n        :return: Boolean. True if ``timestamp`` is older than\n         the last region invalidation time and region is invalidated\n         in hard mode.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def is_soft_invalidated(self, timestamp: float) -> bool:\n        \"\"\"Check timestamp to determine if it was soft invalidated.\n\n        :return: Boolean. True if ``timestamp`` is older than\n         the last region invalidation time and region is invalidated\n         in soft mode.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def is_invalidated(self, timestamp: float) -> bool:\n        \"\"\"Check timestamp to determine if it was invalidated.\n\n        :return: Boolean. True if ``timestamp`` is older than\n         the last region invalidation time.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def was_soft_invalidated(self) -> bool:\n        \"\"\"Indicate the region was invalidated in soft mode.\n\n        :return: Boolean. True if region was invalidated in soft mode.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def was_hard_invalidated(self) -> bool:\n        \"\"\"Indicate the region was invalidated in hard mode.\n\n        :return: Boolean. True if region was invalidated in hard mode.\n\n        \"\"\"\n        raise NotImplementedError()\n\nclass DefaultInvalidationStrategy(RegionInvalidationStrategy):\n\n    def __init__(self):\n        self._is_hard_invalidated = None\n        self._invalidated = None\n\n    def invalidate(self, hard: bool=True) -> None:\n        self._is_hard_invalidated = bool(hard)\n        self._invalidated = time.time()\n\n    def is_invalidated(self, timestamp: float) -> bool:\n        return self._invalidated is not None and timestamp < self._invalidated\n\n    def was_hard_invalidated(self) -> bool:\n        return self._is_hard_invalidated is True\n\n    def is_hard_invalidated(self, timestamp: float) -> bool:\n        return self.was_hard_invalidated() and self.is_invalidated(timestamp)\n\n    def was_soft_invalidated(self) -> bool:\n        return self._is_hard_invalidated is False\n\n    def is_soft_invalidated(self, timestamp: float) -> bool:\n        return self.was_soft_invalidated() and self.is_invalidated(timestamp)\n\nclass CacheRegion:\n    \"\"\"A front end to a particular cache backend.\n\n    :param name: Optional, a string name for the region.\n     This isn't used internally\n     but can be accessed via the ``.name`` parameter, helpful\n     for configuring a region from a config file.\n    :param function_key_generator:  Optional.  A\n     function that will produce a \"cache key\" given\n     a data creation function and arguments, when using\n     the :meth:`.CacheRegion.cache_on_arguments` method.\n     The structure of this function\n     should be two levels: given the data creation function,\n     return a new function that generates the key based on\n     the given arguments.  Such as::\n\n        def my_key_generator(namespace, fn, **kw):\n            fname = fn.__name__\n            def generate_key(*arg):\n                return namespace + \"_\" + fname + \"_\".join(str(s) for s in arg)\n            return generate_key\n\n\n        region = make_region(\n            function_key_generator = my_key_generator\n        ).configure(\n            \"dogpile.cache.dbm\",\n            expiration_time=300,\n            arguments={\n                \"filename\":\"file.dbm\"\n            }\n        )\n\n     The ``namespace`` is that passed to\n     :meth:`.CacheRegion.cache_on_arguments`.  It's not consulted\n     outside this function, so in fact can be of any form.\n     For example, it can be passed as a tuple, used to specify\n     arguments to pluck from \\\\**kw::\n\n        def my_key_generator(namespace, fn):\n            def generate_key(*arg, **kw):\n                return \":\".join(\n                        [kw[k] for k in namespace] +\n                        [str(x) for x in arg]\n                    )\n            return generate_key\n\n\n     Where the decorator might be used as::\n\n        @my_region.cache_on_arguments(namespace=('x', 'y'))\n        def my_function(a, b, **kw):\n            return my_data()\n\n     .. seealso::\n\n        :func:`.function_key_generator` - default key generator\n\n        :func:`.kwarg_function_key_generator` - optional gen that also\n        uses keyword arguments\n\n    :param function_multi_key_generator: Optional.\n     Similar to ``function_key_generator`` parameter, but it's used in\n     :meth:`.CacheRegion.cache_multi_on_arguments`. Generated function\n     should return list of keys. For example::\n\n        def my_multi_key_generator(namespace, fn, **kw):\n            namespace = fn.__name__ + (namespace or '')\n\n            def generate_keys(*args):\n                return [namespace + ':' + str(a) for a in args]\n\n            return generate_keys\n\n    :param key_mangler: Function which will be used on all incoming\n     keys before passing to the backend.  Defaults to ``None``,\n     in which case the key mangling function recommended by\n     the cache backend will be used.    A typical mangler\n     is the SHA1 mangler found at :func:`.sha1_mangle_key`\n     which coerces keys into a SHA1\n     hash, so that the string length is fixed.  To\n     disable all key mangling, set to ``False``.   Another typical\n     mangler is the built-in Python function ``str``, which can be used\n     to convert non-string or Unicode keys to bytestrings, which is\n     needed when using a backend such as bsddb or dbm under Python 2.x\n     in conjunction with Unicode keys.\n\n    :param serializer: function which will be applied to all values before\n     passing to the backend.  Defaults to ``None``, in which case the\n     serializer recommended by the backend will be used.   Typical\n     serializers include ``pickle.dumps`` and ``json.dumps``.\n\n     .. versionadded:: 1.1.0\n\n    :param deserializer: function which will be applied to all values returned\n     by the backend.  Defaults to ``None``, in which case the\n     deserializer recommended by the backend will be used.   Typical\n     deserializers include ``pickle.dumps`` and ``json.dumps``.\n\n     Deserializers can raise a :class:`.api.CantDeserializeException` if they\n     are unable to deserialize the value from the backend, indicating\n     deserialization failed and that caching should proceed to re-generate\n     a value.  This allows an application that has been updated to gracefully\n     re-cache old items which were persisted by a previous version of the\n     application and can no longer be successfully deserialized.\n\n     .. versionadded:: 1.1.0 added \"deserializer\" parameter\n\n     .. versionadded:: 1.2.0 added support for\n        :class:`.api.CantDeserializeException`\n\n    :param async_creation_runner:  A callable that, when specified,\n     will be passed to and called by dogpile.lock when\n     there is a stale value present in the cache.  It will be passed the\n     mutex and is responsible releasing that mutex when finished.\n     This can be used to defer the computation of expensive creator\n     functions to later points in the future by way of, for example, a\n     background thread, a long-running queue, or a task manager system\n     like Celery.\n\n     For a specific example using async_creation_runner, new values can\n     be created in a background thread like so::\n\n        import threading\n\n        def async_creation_runner(cache, somekey, creator, mutex):\n            ''' Used by dogpile.core:Lock when appropriate  '''\n            def runner():\n                try:\n                    value = creator()\n                    cache.set(somekey, value)\n                finally:\n                    mutex.release()\n\n            thread = threading.Thread(target=runner)\n            thread.start()\n\n\n        region = make_region(\n            async_creation_runner=async_creation_runner,\n        ).configure(\n            'dogpile.cache.memcached',\n            expiration_time=5,\n            arguments={\n                'url': '127.0.0.1:11211',\n                'distributed_lock': True,\n            }\n        )\n\n     Remember that the first request for a key with no associated\n     value will always block; async_creator will not be invoked.\n     However, subsequent requests for cached-but-expired values will\n     still return promptly.  They will be refreshed by whatever\n     asynchronous means the provided async_creation_runner callable\n     implements.\n\n     By default the async_creation_runner is disabled and is set\n     to ``None``.\n\n     .. versionadded:: 0.4.2 added the async_creation_runner\n        feature.\n\n    \"\"\"\n\n    def __init__(self, name: Optional[str]=None, function_key_generator: FunctionKeyGenerator=function_key_generator, function_multi_key_generator: FunctionMultiKeyGenerator=function_multi_key_generator, key_mangler: Optional[Callable[[KeyType], KeyType]]=None, serializer: Optional[Callable[[ValuePayload], bytes]]=None, deserializer: Optional[Callable[[bytes], ValuePayload]]=None, async_creation_runner: Optional[AsyncCreator]=None):\n        \"\"\"Construct a new :class:`.CacheRegion`.\"\"\"\n        self.name = name\n        self.function_key_generator = function_key_generator\n        self.function_multi_key_generator = function_multi_key_generator\n        self.key_mangler = self._user_defined_key_mangler = key_mangler\n        self.serializer = self._user_defined_serializer = serializer\n        self.deserializer = self._user_defined_deserializer = deserializer\n        self.async_creation_runner = async_creation_runner\n        self.region_invalidator: RegionInvalidationStrategy = DefaultInvalidationStrategy()\n\n    def configure(self, backend: str, expiration_time: Optional[Union[float, datetime.timedelta]]=None, arguments: Optional[BackendArguments]=None, _config_argument_dict: Optional[Mapping[str, Any]]=None, _config_prefix: Optional[str]=None, wrap: Sequence[Union[ProxyBackend, Type[ProxyBackend]]]=(), replace_existing_backend: bool=False, region_invalidator: Optional[RegionInvalidationStrategy]=None) -> Self:\n        \"\"\"Configure a :class:`.CacheRegion`.\n\n        The :class:`.CacheRegion` itself\n        is returned.\n\n        :param backend:   Required.  This is the name of the\n         :class:`.CacheBackend` to use, and is resolved by loading\n         the class from the ``dogpile.cache`` entrypoint.\n\n        :param expiration_time:   Optional.  The expiration time passed\n         to the dogpile system.  May be passed as an integer number\n         of seconds, or as a ``datetime.timedelta`` value.\n\n         .. versionadded 0.5.0\n            ``expiration_time`` may be optionally passed as a\n            ``datetime.timedelta`` value.\n\n         The :meth:`.CacheRegion.get_or_create`\n         method as well as the :meth:`.CacheRegion.cache_on_arguments`\n         decorator (though note:  **not** the :meth:`.CacheRegion.get`\n         method) will call upon the value creation function after this\n         time period has passed since the last generation.\n\n        :param arguments: Optional.  The structure here is passed\n         directly to the constructor of the :class:`.CacheBackend`\n         in use, though is typically a dictionary.\n\n        :param wrap: Optional.  A list of :class:`.ProxyBackend`\n         classes and/or instances, each of which will be applied\n         in a chain to ultimately wrap the original backend,\n         so that custom functionality augmentation can be applied.\n\n         .. versionadded:: 0.5.0\n\n         .. seealso::\n\n            :ref:`changing_backend_behavior`\n\n        :param replace_existing_backend: if True, the existing cache backend\n         will be replaced.  Without this flag, an exception is raised if\n         a backend is already configured.\n\n         .. versionadded:: 0.5.7\n\n        :param region_invalidator: Optional. Override default invalidation\n         strategy with custom implementation of\n         :class:`.RegionInvalidationStrategy`.\n\n         .. versionadded:: 0.6.2\n\n        \"\"\"\n        if 'backend' in self.__dict__ and (not replace_existing_backend):\n            raise exception.RegionAlreadyConfigured('This region is already configured with backend: %s.  Specify replace_existing_backend=True to replace.' % self.backend)\n        try:\n            backend_cls = _backend_loader.load(backend)\n        except PluginLoader.NotFound:\n            raise exception.PluginNotFound(\"Couldn't find cache plugin to load: %s\" % backend)\n        if _config_argument_dict:\n            self.backend = backend_cls.from_config_dict(_config_argument_dict, _config_prefix)\n        else:\n            self.backend = backend_cls(arguments or {})\n        self.expiration_time: Union[float, None]\n        if not expiration_time or isinstance(expiration_time, Number):\n            self.expiration_time = cast(Union[None, float], expiration_time)\n        elif isinstance(expiration_time, datetime.timedelta):\n            self.expiration_time = int(expiration_time.total_seconds())\n        else:\n            raise exception.ValidationError('expiration_time is not a number or timedelta.')\n        if not self._user_defined_key_mangler:\n            self.key_mangler = self.backend.key_mangler\n        if not self._user_defined_serializer:\n            self.serializer = self.backend.serializer\n        if not self._user_defined_deserializer:\n            self.deserializer = self.backend.deserializer\n        self._lock_registry = NameRegistry(self._create_mutex)\n        if getattr(wrap, '__iter__', False):\n            for wrapper in reversed(wrap):\n                self.wrap(wrapper)\n        if region_invalidator:\n            self.region_invalidator = region_invalidator\n        return self\n\n    def wrap(self, proxy: Union[ProxyBackend, Type[ProxyBackend]]) -> None:\n        \"\"\"Takes a ProxyBackend instance or class and wraps the\n        attached backend.\"\"\"\n        if isinstance(proxy, type):\n            proxy_instance = proxy()\n        else:\n            proxy_instance = proxy\n        if not isinstance(proxy_instance, ProxyBackend):\n            raise TypeError('%r is not a valid ProxyBackend' % (proxy_instance,))\n        self.backend = proxy_instance.wrap(self.backend)\n\n    def _mutex(self, key):\n        return self._lock_registry.get(key)\n\n    class _LockWrapper(CacheMutex):\n        \"\"\"weakref-capable wrapper for threading.Lock\"\"\"\n\n        def __init__(self):\n            self.lock = threading.Lock()\n\n        def acquire(self, wait=True):\n            return self.lock.acquire(wait)\n\n        def release(self):\n            self.lock.release()\n\n        def locked(self):\n            return self.lock.locked()\n\n    def _create_mutex(self, key):\n        mutex = self.backend.get_mutex(key)\n        if mutex is not None:\n            return mutex\n        else:\n            return self._LockWrapper()\n    _actual_backend = None\n\n    @property\n    def actual_backend(self):\n        \"\"\"Return the ultimate backend underneath any proxies.\n\n        The backend might be the result of one or more ``proxy.wrap``\n        applications. If so, derive the actual underlying backend.\n\n        .. versionadded:: 0.6.6\n\n        \"\"\"\n        if self._actual_backend is None:\n            _backend = self.backend\n            while hasattr(_backend, 'proxied'):\n                _backend = _backend.proxied\n            self._actual_backend = _backend\n        return self._actual_backend\n\n    def invalidate(self, hard=True):\n        \"\"\"Invalidate this :class:`.CacheRegion`.\n\n        The default invalidation system works by setting\n        a current timestamp (using ``time.time()``)\n        representing the \"minimum creation time\" for\n        a value.  Any retrieved value whose creation\n        time is prior to this timestamp\n        is considered to be stale.  It does not\n        affect the data in the cache in any way, and is\n        **local to this instance of :class:`.CacheRegion`.**\n\n        .. warning::\n\n            The :meth:`.CacheRegion.invalidate` method's default mode of\n            operation is to set a timestamp **local to this CacheRegion\n            in this Python process only**.   It does not impact other Python\n            processes or regions as the timestamp is **only stored locally in\n            memory**.  To implement invalidation where the\n            timestamp is stored in the cache or similar so that all Python\n            processes can be affected by an invalidation timestamp, implement a\n            custom :class:`.RegionInvalidationStrategy`.\n\n        Once set, the invalidation time is honored by\n        the :meth:`.CacheRegion.get_or_create`,\n        :meth:`.CacheRegion.get_or_create_multi` and\n        :meth:`.CacheRegion.get` methods.\n\n        The method supports both \"hard\" and \"soft\" invalidation\n        options.  With \"hard\" invalidation,\n        :meth:`.CacheRegion.get_or_create` will force an immediate\n        regeneration of the value which all getters will wait for.\n        With \"soft\" invalidation, subsequent getters will return the\n        \"old\" value until the new one is available.\n\n        Usage of \"soft\" invalidation requires that the region or the method\n        is given a non-None expiration time.\n\n        .. versionadded:: 0.3.0\n\n        :param hard: if True, cache values will all require immediate\n         regeneration; dogpile logic won't be used.  If False, the\n         creation time of existing values will be pushed back before\n         the expiration time so that a return+regen will be invoked.\n\n         .. versionadded:: 0.5.1\n\n        \"\"\"\n        self.region_invalidator.invalidate(hard)\n\n    def configure_from_config(self, config_dict, prefix):\n        \"\"\"Configure from a configuration dictionary\n        and a prefix.\n\n        Example::\n\n            local_region = make_region()\n            memcached_region = make_region()\n\n            # regions are ready to use for function\n            # decorators, but not yet for actual caching\n\n            # later, when config is available\n            myconfig = {\n                \"cache.local.backend\":\"dogpile.cache.dbm\",\n                \"cache.local.arguments.filename\":\"/path/to/dbmfile.dbm\",\n                \"cache.memcached.backend\":\"dogpile.cache.pylibmc\",\n                \"cache.memcached.arguments.url\":\"127.0.0.1, 10.0.0.1\",\n            }\n            local_region.configure_from_config(myconfig, \"cache.local.\")\n            memcached_region.configure_from_config(myconfig,\n                                                \"cache.memcached.\")\n\n        \"\"\"\n        config_dict = coerce_string_conf(config_dict)\n        return self.configure(config_dict['%sbackend' % prefix], expiration_time=config_dict.get('%sexpiration_time' % prefix, None), _config_argument_dict=config_dict, _config_prefix='%sarguments.' % prefix, wrap=config_dict.get('%swrap' % prefix, None), replace_existing_backend=config_dict.get('%sreplace_existing_backend' % prefix, False))\n\n    @memoized_property\n    def backend(self):\n        raise exception.RegionNotConfigured('No backend is configured on this region.')\n\n    @property\n    def is_configured(self):\n        \"\"\"Return True if the backend has been configured via the\n        :meth:`.CacheRegion.configure` method already.\n\n        .. versionadded:: 0.5.1\n\n        \"\"\"\n        return 'backend' in self.__dict__\n\n    def get(self, key: KeyType, expiration_time: Optional[float]=None, ignore_expiration: bool=False) -> Union[ValuePayload, NoValueType]:\n        \"\"\"Return a value from the cache, based on the given key.\n\n        If the value is not present, the method returns the token\n        :data:`.api.NO_VALUE`. :data:`.api.NO_VALUE` evaluates to False, but is\n        separate from ``None`` to distinguish between a cached value of\n        ``None``.\n\n        By default, the configured expiration time of the\n        :class:`.CacheRegion`, or alternatively the expiration\n        time supplied by the ``expiration_time`` argument,\n        is tested against the creation time of the retrieved\n        value versus the current time (as reported by ``time.time()``).\n        If stale, the cached value is ignored and the :data:`.api.NO_VALUE`\n        token is returned.  Passing the flag ``ignore_expiration=True``\n        bypasses the expiration time check.\n\n        .. versionchanged:: 0.3.0\n           :meth:`.CacheRegion.get` now checks the value's creation time\n           against the expiration time, rather than returning\n           the value unconditionally.\n\n        The method also interprets the cached value in terms\n        of the current \"invalidation\" time as set by\n        the :meth:`.invalidate` method.   If a value is present,\n        but its creation time is older than the current\n        invalidation time, the :data:`.api.NO_VALUE` token is returned.\n        Passing the flag ``ignore_expiration=True`` bypasses\n        the invalidation time check.\n\n        .. versionadded:: 0.3.0\n           Support for the :meth:`.CacheRegion.invalidate`\n           method.\n\n        :param key: Key to be retrieved. While it's typical for a key to be a\n         string, it is ultimately passed directly down to the cache backend,\n         before being optionally processed by the key_mangler function, so can\n         be of any type recognized by the backend or by the key_mangler\n         function, if present.\n\n        :param expiration_time: Optional expiration time value\n         which will supersede that configured on the :class:`.CacheRegion`\n         itself.\n\n         .. note:: The :paramref:`.CacheRegion.get.expiration_time`\n            argument is **not persisted in the cache** and is relevant\n            only to **this specific cache retrieval operation**, relative to\n            the creation time stored with the existing cached value.\n            Subsequent calls to :meth:`.CacheRegion.get` are **not** affected\n            by this value.\n\n         .. versionadded:: 0.3.0\n\n        :param ignore_expiration: if ``True``, the value is returned\n         from the cache if present, regardless of configured\n         expiration times or whether or not :meth:`.invalidate`\n         was called.\n\n         .. versionadded:: 0.3.0\n\n        .. seealso::\n\n            :meth:`.CacheRegion.get_multi`\n\n            :meth:`.CacheRegion.get_or_create`\n\n            :meth:`.CacheRegion.set`\n\n            :meth:`.CacheRegion.delete`\n\n\n        \"\"\"\n        value = self._get_cache_value(key, expiration_time, ignore_expiration)\n        return value.payload\n\n    def get_value_metadata(self, key: KeyType, expiration_time: Optional[float]=None, ignore_expiration: bool=False) -> Optional[CachedValue]:\n        \"\"\"Return the :class:`.CachedValue` object directly from the cache.\n\n        This is the enclosing datastructure that includes the value as well as\n        the metadata, including the timestamp when the value was cached.\n        Convenience accessors on :class:`.CachedValue` also provide for common\n        data such as :attr:`.CachedValue.cached_time` and\n        :attr:`.CachedValue.age`.\n\n\n        .. versionadded:: 1.3. Added :meth:`.CacheRegion.get_value_metadata`\n        \"\"\"\n        cache_value = self._get_cache_value(key, expiration_time, ignore_expiration)\n        if cache_value is NO_VALUE:\n            return None\n        else:\n            if TYPE_CHECKING:\n                assert isinstance(cache_value, CachedValue)\n            return cache_value\n\n    def _get_cache_value(self, key: KeyType, expiration_time: Optional[float]=None, ignore_expiration: bool=False) -> CacheReturnType:\n        if self.key_mangler:\n            key = self.key_mangler(key)\n        value = self._get_from_backend(key)\n        value = self._unexpired_value_fn(expiration_time, ignore_expiration)(value)\n        return value\n\n    def _unexpired_value_fn(self, expiration_time, ignore_expiration):\n        if ignore_expiration:\n            return lambda value: value\n        else:\n            if expiration_time is None:\n                expiration_time = self.expiration_time\n            current_time = time.time()\n\n            def value_fn(value):\n                if value is NO_VALUE:\n                    return value\n                elif expiration_time is not None and current_time - value.metadata['ct'] > expiration_time:\n                    return NO_VALUE\n                elif self.region_invalidator.is_invalidated(value.metadata['ct']):\n                    return NO_VALUE\n                else:\n                    return value\n            return value_fn\n\n    def get_multi(self, keys, expiration_time=None, ignore_expiration=False):\n        \"\"\"Return multiple values from the cache, based on the given keys.\n\n        Returns values as a list matching the keys given.\n\n        E.g.::\n\n            values = region.get_multi([\"one\", \"two\", \"three\"])\n\n        To convert values to a dictionary, use ``zip()``::\n\n            keys = [\"one\", \"two\", \"three\"]\n            values = region.get_multi(keys)\n            dictionary = dict(zip(keys, values))\n\n        Keys which aren't present in the list are returned as\n        the ``NO_VALUE`` token.  ``NO_VALUE`` evaluates to False,\n        but is separate from\n        ``None`` to distinguish between a cached value of ``None``.\n\n        By default, the configured expiration time of the\n        :class:`.CacheRegion`, or alternatively the expiration\n        time supplied by the ``expiration_time`` argument,\n        is tested against the creation time of the retrieved\n        value versus the current time (as reported by ``time.time()``).\n        If stale, the cached value is ignored and the ``NO_VALUE``\n        token is returned.  Passing the flag ``ignore_expiration=True``\n        bypasses the expiration time check.\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        if not keys:\n            return []\n        if self.key_mangler is not None:\n            keys = [self.key_mangler(key) for key in keys]\n        backend_values = self._get_multi_from_backend(keys)\n        _unexpired_value_fn = self._unexpired_value_fn(expiration_time, ignore_expiration)\n        return [value.payload if value is not NO_VALUE else value for value in (_unexpired_value_fn(value) for value in backend_values)]\n\n    @contextlib.contextmanager\n    def _log_time(self, keys):\n        start_time = time.time()\n        yield\n        seconds = time.time() - start_time\n        log.debug('Cache value generated in %(seconds).3f seconds for key(s): %(keys)r', {'seconds': seconds, 'keys': repr_obj(keys)})\n\n    def _is_cache_miss(self, value, orig_key):\n        if value is NO_VALUE:\n            log.debug('No value present for key: %r', orig_key)\n        elif value.metadata['v'] != value_version:\n            log.debug('Dogpile version update for key: %r', orig_key)\n        elif self.region_invalidator.is_hard_invalidated(value.metadata['ct']):\n            log.debug('Hard invalidation detected for key: %r', orig_key)\n        else:\n            return False\n        return True\n\n    def key_is_locked(self, key: KeyType) -> bool:\n        \"\"\"Return True if a particular cache key is currently being generated\n        within the dogpile lock.\n\n        .. versionadded:: 1.1.2\n\n        \"\"\"\n        mutex = self._mutex(key)\n        locked: bool = mutex.locked()\n        return locked\n\n    def get_or_create(self, key: KeyType, creator: Callable[..., ValuePayload], expiration_time: Optional[float]=None, should_cache_fn: Optional[Callable[[ValuePayload], bool]]=None, creator_args: Optional[Tuple[Any, Mapping[str, Any]]]=None) -> ValuePayload:\n        \"\"\"Return a cached value based on the given key.\n\n        If the value does not exist or is considered to be expired\n        based on its creation time, the given\n        creation function may or may not be used to recreate the value\n        and persist the newly generated value in the cache.\n\n        Whether or not the function is used depends on if the\n        *dogpile lock* can be acquired or not.  If it can't, it means\n        a different thread or process is already running a creation\n        function for this key against the cache.  When the dogpile\n        lock cannot be acquired, the method will block if no\n        previous value is available, until the lock is released and\n        a new value available.  If a previous value\n        is available, that value is returned immediately without blocking.\n\n        If the :meth:`.invalidate` method has been called, and\n        the retrieved value's timestamp is older than the invalidation\n        timestamp, the value is unconditionally prevented from\n        being returned.  The method will attempt to acquire the dogpile\n        lock to generate a new value, or will wait\n        until the lock is released to return the new value.\n\n        .. versionchanged:: 0.3.0\n          The value is unconditionally regenerated if the creation\n          time is older than the last call to :meth:`.invalidate`.\n\n        :param key: Key to be retrieved. While it's typical for a key to be a\n         string, it is ultimately passed directly down to the cache backend,\n         before being optionally processed by the key_mangler function, so can\n         be of any type recognized by the backend or by the key_mangler\n         function, if present.\n\n        :param creator: function which creates a new value.\n\n        :param creator_args: optional tuple of (args, kwargs) that will be\n         passed to the creator function if present.\n\n         .. versionadded:: 0.7.0\n\n        :param expiration_time: optional expiration time which will override\n         the expiration time already configured on this :class:`.CacheRegion`\n         if not None.   To set no expiration, use the value -1.\n\n         .. note:: The :paramref:`.CacheRegion.get_or_create.expiration_time`\n            argument is **not persisted in the cache** and is relevant\n            only to **this specific cache retrieval operation**, relative to\n            the creation time stored with the existing cached value.\n            Subsequent calls to :meth:`.CacheRegion.get_or_create` are **not**\n            affected by this value.\n\n        :param should_cache_fn: optional callable function which will receive\n         the value returned by the \"creator\", and will then return True or\n         False, indicating if the value should actually be cached or not.  If\n         it returns False, the value is still returned, but isn't cached.\n         E.g.::\n\n            def dont_cache_none(value):\n                return value is not None\n\n            value = region.get_or_create(\"some key\",\n                                create_value,\n                                should_cache_fn=dont_cache_none)\n\n         Above, the function returns the value of create_value() if\n         the cache is invalid, however if the return value is None,\n         it won't be cached.\n\n         .. versionadded:: 0.4.3\n\n        .. seealso::\n\n            :meth:`.CacheRegion.get`\n\n            :meth:`.CacheRegion.cache_on_arguments` - applies\n            :meth:`.get_or_create` to any function using a decorator.\n\n            :meth:`.CacheRegion.get_or_create_multi` - multiple key/value\n            version\n\n        \"\"\"\n        orig_key = key\n        if self.key_mangler:\n            key = self.key_mangler(key)\n\n        def get_value():\n            value = self._get_from_backend(key)\n            if self._is_cache_miss(value, orig_key):\n                raise NeedRegenerationException()\n            ct = cast(CachedValue, value).metadata['ct']\n            if self.region_invalidator.is_soft_invalidated(ct):\n                if expiration_time is None:\n                    raise exception.DogpileCacheException('Non-None expiration time required for soft invalidation')\n                ct = time.time() - expiration_time - 0.0001\n            return (value.payload, ct)\n\n        def gen_value():\n            with self._log_time(orig_key):\n                if creator_args:\n                    created_value = creator(*creator_args[0], **creator_args[1])\n                else:\n                    created_value = creator()\n            value = self._value(created_value)\n            if expiration_time is None and self.region_invalidator.was_soft_invalidated():\n                raise exception.DogpileCacheException('Non-None expiration time required for soft invalidation')\n            if not should_cache_fn or should_cache_fn(created_value):\n                self._set_cached_value_to_backend(key, value)\n            return (value.payload, value.metadata['ct'])\n        if expiration_time is None:\n            expiration_time = self.expiration_time\n        if expiration_time == -1:\n            expiration_time = None\n        async_creator: Optional[Callable[[CacheMutex], AsyncCreator]]\n        if self.async_creation_runner:\n            acr = self.async_creation_runner\n\n            def async_creator(mutex):\n                if creator_args:\n                    ca = creator_args\n\n                    @wraps(creator)\n                    def go():\n                        return creator(*ca[0], **ca[1])\n                else:\n                    go = creator\n                return acr(self, orig_key, go, mutex)\n        else:\n            async_creator = None\n        with Lock(self._mutex(key), gen_value, get_value, expiration_time, async_creator) as value:\n            return value\n\n    def get_or_create_multi(self, keys: Sequence[KeyType], creator: Callable[[], ValuePayload], expiration_time: Optional[float]=None, should_cache_fn: Optional[Callable[[ValuePayload], bool]]=None) -> Sequence[ValuePayload]:\n        \"\"\"Return a sequence of cached values based on a sequence of keys.\n\n        The behavior for generation of values based on keys corresponds\n        to that of :meth:`.Region.get_or_create`, with the exception that\n        the ``creator()`` function may be asked to generate any subset of\n        the given keys.   The list of keys to be generated is passed to\n        ``creator()``, and ``creator()`` should return the generated values\n        as a sequence corresponding to the order of the keys.\n\n        The method uses the same approach as :meth:`.Region.get_multi`\n        and :meth:`.Region.set_multi` to get and set values from the\n        backend.\n\n        If you are using a :class:`.CacheBackend` or :class:`.ProxyBackend`\n        that modifies values, take note this function invokes\n        ``.set_multi()`` for newly generated values using the same values it\n        returns to the calling function. A correct implementation of\n        ``.set_multi()`` will not modify values in-place on the submitted\n        ``mapping`` dict.\n\n        :param keys: Sequence of keys to be retrieved.\n\n        :param creator: function which accepts a sequence of keys and\n         returns a sequence of new values.\n\n        :param expiration_time: optional expiration time which will override\n         the expiration time already configured on this :class:`.CacheRegion`\n         if not None.   To set no expiration, use the value -1.\n\n        :param should_cache_fn: optional callable function which will receive\n         each value returned by the \"creator\", and will then return True or\n         False, indicating if the value should actually be cached or not.  If\n         it returns False, the value is still returned, but isn't cached.\n\n        .. versionadded:: 0.5.0\n\n        .. seealso::\n\n\n            :meth:`.CacheRegion.cache_multi_on_arguments`\n\n            :meth:`.CacheRegion.get_or_create`\n\n        \"\"\"\n\n        def get_value(key):\n            value = values.get(key, NO_VALUE)\n            if self._is_cache_miss(value, orig_key):\n                return (value.payload, 0)\n            else:\n                ct = cast(CachedValue, value).metadata['ct']\n                if self.region_invalidator.is_soft_invalidated(ct):\n                    if expiration_time is None:\n                        raise exception.DogpileCacheException('Non-None expiration time required for soft invalidation')\n                    ct = time.time() - expiration_time - 0.0001\n                return (value.payload, ct)\n\n        def gen_value() -> ValuePayload:\n            raise NotImplementedError()\n\n        def async_creator(mutexes, key, mutex):\n            mutexes[key] = mutex\n        if expiration_time is None:\n            expiration_time = self.expiration_time\n        if expiration_time == -1:\n            expiration_time = None\n        sorted_unique_keys = sorted(set(keys))\n        if self.key_mangler:\n            mangled_keys = [self.key_mangler(k) for k in sorted_unique_keys]\n        else:\n            mangled_keys = sorted_unique_keys\n        orig_to_mangled = dict(zip(sorted_unique_keys, mangled_keys))\n        values = dict(zip(mangled_keys, self._get_multi_from_backend(mangled_keys)))\n        mutexes: Mapping[KeyType, Any] = {}\n        for orig_key, mangled_key in orig_to_mangled.items():\n            with Lock(self._mutex(mangled_key), gen_value, lambda: get_value(mangled_key), expiration_time, async_creator=lambda mutex: async_creator(mutexes, orig_key, mutex)):\n                pass\n        try:\n            if mutexes:\n                keys_to_get = sorted(mutexes)\n                with self._log_time(keys_to_get):\n                    new_values = creator(*keys_to_get)\n                values_w_created = {orig_to_mangled[k]: self._value(v) for k, v in zip(keys_to_get, new_values)}\n                if expiration_time is None and self.region_invalidator.was_soft_invalidated():\n                    raise exception.DogpileCacheException('Non-None expiration time required for soft invalidation')\n                if not should_cache_fn:\n                    self._set_multi_cached_value_to_backend(values_w_created)\n                else:\n                    self._set_multi_cached_value_to_backend({k: v for k, v in values_w_created.items() if should_cache_fn(v.payload)})\n                values.update(values_w_created)\n            return [values[orig_to_mangled[k]].payload for k in keys]\n        finally:\n            for mutex in mutexes.values():\n                mutex.release()\n\n    def _value(self, value: Any, metadata: Optional[MetaDataType]=None) -> CachedValue:\n        \"\"\"Return a :class:`.CachedValue` given a value.\"\"\"\n        if metadata is None:\n            metadata = self._gen_metadata()\n        return CachedValue(value, metadata)\n\n    def _parse_serialized_from_backend(self, value: SerializedReturnType) -> CacheReturnType:\n        if value in (None, NO_VALUE):\n            return NO_VALUE\n        assert self.deserializer\n        byte_value = cast(bytes, value)\n        bytes_metadata, _, bytes_payload = byte_value.partition(b'|')\n        metadata = json.loads(bytes_metadata)\n        try:\n            payload = self.deserializer(bytes_payload)\n        except CantDeserializeException:\n            return NO_VALUE\n        else:\n            return CachedValue(payload, metadata)\n\n    def _serialize_cached_value_elements(self, payload: ValuePayload, metadata: MetaDataType) -> bytes:\n        serializer = cast(Serializer, self.serializer)\n        return b'%b|%b' % (json.dumps(metadata).encode('ascii'), serializer(payload))\n\n    def _serialized_payload(self, payload: ValuePayload, metadata: Optional[MetaDataType]=None) -> BackendFormatted:\n        \"\"\"Return a backend formatted representation of a value.\n\n        If a serializer is in use then this will return a string representation\n        with the value formatted by the serializer.\n\n        \"\"\"\n        if metadata is None:\n            metadata = self._gen_metadata()\n        return self._serialize_cached_value_elements(payload, metadata)\n\n    def _serialized_cached_value(self, value: CachedValue) -> BackendFormatted:\n        \"\"\"Return a backend formatted representation of a\n        :class:`.CachedValue`.\n\n        If a serializer is in use then this will return a string representation\n        with the value formatted by the serializer.\n\n        \"\"\"\n        assert self.serializer\n        return self._serialize_cached_value_elements(value.payload, value.metadata)\n\n    def _get_from_backend(self, key: KeyType) -> CacheReturnType:\n        if self.deserializer:\n            return self._parse_serialized_from_backend(self.backend.get_serialized(key))\n        else:\n            return cast(CacheReturnType, self.backend.get(key))\n\n    def _get_multi_from_backend(self, keys: Sequence[KeyType]) -> Sequence[CacheReturnType]:\n        if self.deserializer:\n            return [self._parse_serialized_from_backend(v) for v in self.backend.get_serialized_multi(keys)]\n        else:\n            return cast(Sequence[CacheReturnType], self.backend.get_multi(keys))\n\n    def _set_cached_value_to_backend(self, key: KeyType, value: CachedValue) -> None:\n        if self.serializer:\n            self.backend.set_serialized(key, self._serialized_cached_value(value))\n        else:\n            self.backend.set(key, value)\n\n    def _set_multi_cached_value_to_backend(self, mapping: Mapping[KeyType, CachedValue]) -> None:\n        if not mapping:\n            return\n        if self.serializer:\n            self.backend.set_serialized_multi({k: self._serialized_cached_value(v) for k, v in mapping.items()})\n        else:\n            self.backend.set_multi(mapping)\n\n    def _gen_metadata(self) -> MetaDataType:\n        return {'ct': time.time(), 'v': value_version}\n\n    def set(self, key: KeyType, value: ValuePayload) -> None:\n        \"\"\"Place a new value in the cache under the given key.\"\"\"\n        if self.key_mangler:\n            key = self.key_mangler(key)\n        if self.serializer:\n            self.backend.set_serialized(key, self._serialized_payload(value))\n        else:\n            self.backend.set(key, self._value(value))\n\n    def set_multi(self, mapping: Mapping[KeyType, ValuePayload]) -> None:\n        \"\"\"Place new values in the cache under the given keys.\"\"\"\n        if not mapping:\n            return\n        metadata = self._gen_metadata()\n        if self.serializer:\n            if self.key_mangler:\n                mapping = {self.key_mangler(k): self._serialized_payload(v, metadata=metadata) for k, v in mapping.items()}\n            else:\n                mapping = {k: self._serialized_payload(v, metadata=metadata) for k, v in mapping.items()}\n            self.backend.set_serialized_multi(mapping)\n        else:\n            if self.key_mangler:\n                mapping = {self.key_mangler(k): self._value(v, metadata=metadata) for k, v in mapping.items()}\n            else:\n                mapping = {k: self._value(v, metadata=metadata) for k, v in mapping.items()}\n            self.backend.set_multi(mapping)\n\n    def delete(self, key: KeyType) -> None:\n        \"\"\"Remove a value from the cache.\n\n        This operation is idempotent (can be called multiple times, or on a\n        non-existent key, safely)\n        \"\"\"\n        if self.key_mangler:\n            key = self.key_mangler(key)\n        self.backend.delete(key)\n\n    def delete_multi(self, keys: Sequence[KeyType]) -> None:\n        \"\"\"Remove multiple values from the cache.\n\n        This operation is idempotent (can be called multiple times, or on a\n        non-existent key, safely)\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        if self.key_mangler:\n            km = self.key_mangler\n            keys = [km(key) for key in keys]\n        self.backend.delete_multi(keys)\n\n    def cache_on_arguments(self, namespace: Optional[str]=None, expiration_time: Union[float, ExpirationTimeCallable, None]=None, should_cache_fn: Optional[Callable[[ValuePayload], bool]]=None, to_str: Callable[[Any], str]=str, function_key_generator: Optional[FunctionKeyGenerator]=None) -> Callable[[Callable[..., ValuePayload]], Callable[..., ValuePayload]]:\n        \"\"\"A function decorator that will cache the return\n        value of the function using a key derived from the\n        function itself and its arguments.\n\n        The decorator internally makes use of the\n        :meth:`.CacheRegion.get_or_create` method to access the\n        cache and conditionally call the function.  See that\n        method for additional behavioral details.\n\n        E.g.::\n\n            @someregion.cache_on_arguments()\n            def generate_something(x, y):\n                return somedatabase.query(x, y)\n\n        The decorated function can then be called normally, where\n        data will be pulled from the cache region unless a new\n        value is needed::\n\n            result = generate_something(5, 6)\n\n        The function is also given an attribute ``invalidate()``, which\n        provides for invalidation of the value.  Pass to ``invalidate()``\n        the same arguments you'd pass to the function itself to represent\n        a particular value::\n\n            generate_something.invalidate(5, 6)\n\n        Another attribute ``set()`` is added to provide extra caching\n        possibilities relative to the function.   This is a convenience\n        method for :meth:`.CacheRegion.set` which will store a given\n        value directly without calling the decorated function.\n        The value to be cached is passed as the first argument, and the\n        arguments which would normally be passed to the function\n        should follow::\n\n            generate_something.set(3, 5, 6)\n\n        The above example is equivalent to calling\n        ``generate_something(5, 6)``, if the function were to produce\n        the value ``3`` as the value to be cached.\n\n        .. versionadded:: 0.4.1 Added ``set()`` method to decorated function.\n\n        Similar to ``set()`` is ``refresh()``.   This attribute will\n        invoke the decorated function and populate a new value into\n        the cache with the new value, as well as returning that value::\n\n            newvalue = generate_something.refresh(5, 6)\n\n        .. versionadded:: 0.5.0 Added ``refresh()`` method to decorated\n           function.\n\n        ``original()`` on other hand will invoke the decorated function\n        without any caching::\n\n            newvalue = generate_something.original(5, 6)\n\n        .. versionadded:: 0.6.0 Added ``original()`` method to decorated\n           function.\n\n        Lastly, the ``get()`` method returns either the value cached\n        for the given key, or the token ``NO_VALUE`` if no such key\n        exists::\n\n            value = generate_something.get(5, 6)\n\n        .. versionadded:: 0.5.3 Added ``get()`` method to decorated\n           function.\n\n        The default key generation will use the name\n        of the function, the module name for the function,\n        the arguments passed, as well as an optional \"namespace\"\n        parameter in order to generate a cache key.\n\n        Given a function ``one`` inside the module\n        ``myapp.tools``::\n\n            @region.cache_on_arguments(namespace=\"foo\")\n            def one(a, b):\n                return a + b\n\n        Above, calling ``one(3, 4)`` will produce a\n        cache key as follows::\n\n            myapp.tools:one|foo|3 4\n\n        The key generator will ignore an initial argument\n        of ``self`` or ``cls``, making the decorator suitable\n        (with caveats) for use with instance or class methods.\n        Given the example::\n\n            class MyClass:\n                @region.cache_on_arguments(namespace=\"foo\")\n                def one(self, a, b):\n                    return a + b\n\n        The cache key above for ``MyClass().one(3, 4)`` will\n        again produce the same cache key of ``myapp.tools:one|foo|3 4`` -\n        the name ``self`` is skipped.\n\n        The ``namespace`` parameter is optional, and is used\n        normally to disambiguate two functions of the same\n        name within the same module, as can occur when decorating\n        instance or class methods as below::\n\n            class MyClass:\n                @region.cache_on_arguments(namespace='MC')\n                def somemethod(self, x, y):\n                    \"\"\n\n            class MyOtherClass:\n                @region.cache_on_arguments(namespace='MOC')\n                def somemethod(self, x, y):\n                    \"\"\n\n        Above, the ``namespace`` parameter disambiguates\n        between ``somemethod`` on ``MyClass`` and ``MyOtherClass``.\n        Python class declaration mechanics otherwise prevent\n        the decorator from having awareness of the ``MyClass``\n        and ``MyOtherClass`` names, as the function is received\n        by the decorator before it becomes an instance method.\n\n        The function key generation can be entirely replaced\n        on a per-region basis using the ``function_key_generator``\n        argument present on :func:`.make_region` and\n        :class:`.CacheRegion`. If defaults to\n        :func:`.function_key_generator`.\n\n        :param namespace: optional string argument which will be\n         established as part of the cache key.   This may be needed\n         to disambiguate functions of the same name within the same\n         source file, such as those\n         associated with classes - note that the decorator itself\n         can't see the parent class on a function as the class is\n         being declared.\n\n        :param expiration_time: if not None, will override the normal\n         expiration time.\n\n         May be specified as a callable, taking no arguments, that\n         returns a value to be used as the ``expiration_time``. This callable\n         will be called whenever the decorated function itself is called, in\n         caching or retrieving. Thus, this can be used to\n         determine a *dynamic* expiration time for the cached function\n         result.  Example use cases include \"cache the result until the\n         end of the day, week or time period\" and \"cache until a certain date\n         or time passes\".\n\n        :param should_cache_fn: passed to :meth:`.CacheRegion.get_or_create`.\n\n        :param to_str: callable, will be called on each function argument\n         in order to convert to a string.  Defaults to ``str()``.  If the\n         function accepts non-ascii unicode arguments on Python 2.x, the\n         ``unicode()`` builtin can be substituted, but note this will\n         produce unicode cache keys which may require key mangling before\n         reaching the cache.\n\n        :param function_key_generator: a function that will produce a\n         \"cache key\". This function will supersede the one configured on the\n         :class:`.CacheRegion` itself.\n\n        .. seealso::\n\n            :meth:`.CacheRegion.cache_multi_on_arguments`\n\n            :meth:`.CacheRegion.get_or_create`\n\n        \"\"\"\n        expiration_time_is_callable = callable(expiration_time)\n        if function_key_generator is None:\n            _function_key_generator = self.function_key_generator\n        else:\n            _function_key_generator = function_key_generator\n\n        def get_or_create_for_user_func(key_generator, user_func, *arg, **kw):\n            key = key_generator(*arg, **kw)\n            timeout: Optional[float] = cast(ExpirationTimeCallable, expiration_time)() if expiration_time_is_callable else cast(Optional[float], expiration_time)\n            return self.get_or_create(key, user_func, timeout, should_cache_fn, (arg, kw))\n\n        def cache_decorator(user_func):\n            if to_str is cast(Callable[[Any], str], str):\n                key_generator = _function_key_generator(namespace, user_func)\n            else:\n                key_generator = _function_key_generator(namespace, user_func, to_str)\n\n            def refresh(*arg, **kw):\n                \"\"\"\n                Like invalidate, but regenerates the value instead\n                \"\"\"\n                key = key_generator(*arg, **kw)\n                value = user_func(*arg, **kw)\n                self.set(key, value)\n                return value\n\n            def invalidate(*arg, **kw):\n                key = key_generator(*arg, **kw)\n                self.delete(key)\n\n            def set_(value, *arg, **kw):\n                key = key_generator(*arg, **kw)\n                self.set(key, value)\n\n            def get(*arg, **kw):\n                key = key_generator(*arg, **kw)\n                return self.get(key)\n            user_func.set = set_\n            user_func.invalidate = invalidate\n            user_func.get = get\n            user_func.refresh = refresh\n            user_func.original = user_func\n            return decorate(user_func, partial(get_or_create_for_user_func, key_generator))\n        return cache_decorator\n\n    def cache_multi_on_arguments(self, namespace: Optional[str]=None, expiration_time: Union[float, ExpirationTimeCallable, None]=None, should_cache_fn: Optional[Callable[[ValuePayload], bool]]=None, asdict: bool=False, to_str: ToStr=str, function_multi_key_generator: Optional[FunctionMultiKeyGenerator]=None) -> Callable[[Callable[..., Sequence[ValuePayload]]], Callable[..., Union[Sequence[ValuePayload], Mapping[KeyType, ValuePayload]]]]:\n        \"\"\"A function decorator that will cache multiple return\n        values from the function using a sequence of keys derived from the\n        function itself and the arguments passed to it.\n\n        This method is the \"multiple key\" analogue to the\n        :meth:`.CacheRegion.cache_on_arguments` method.\n\n        Example::\n\n            @someregion.cache_multi_on_arguments()\n            def generate_something(*keys):\n                return [\n                    somedatabase.query(key)\n                    for key in keys\n                ]\n\n        The decorated function can be called normally.  The decorator\n        will produce a list of cache keys using a mechanism similar to\n        that of :meth:`.CacheRegion.cache_on_arguments`, combining the\n        name of the function with the optional namespace and with the\n        string form of each key.  It will then consult the cache using\n        the same mechanism as that of :meth:`.CacheRegion.get_multi`\n        to retrieve all current values; the originally passed keys\n        corresponding to those values which aren't generated or need\n        regeneration will be assembled into a new argument list, and\n        the decorated function is then called with that subset of\n        arguments.\n\n        The returned result is a list::\n\n            result = generate_something(\"key1\", \"key2\", \"key3\")\n\n        The decorator internally makes use of the\n        :meth:`.CacheRegion.get_or_create_multi` method to access the\n        cache and conditionally call the function.  See that\n        method for additional behavioral details.\n\n        Unlike the :meth:`.CacheRegion.cache_on_arguments` method,\n        :meth:`.CacheRegion.cache_multi_on_arguments` works only with\n        a single function signature, one which takes a simple list of\n        keys as arguments.\n\n        Like :meth:`.CacheRegion.cache_on_arguments`, the decorated function\n        is also provided with a ``set()`` method, which here accepts a\n        mapping of keys and values to set in the cache::\n\n            generate_something.set({\"k1\": \"value1\",\n                                    \"k2\": \"value2\", \"k3\": \"value3\"})\n\n        ...an ``invalidate()`` method, which has the effect of deleting\n        the given sequence of keys using the same mechanism as that of\n        :meth:`.CacheRegion.delete_multi`::\n\n            generate_something.invalidate(\"k1\", \"k2\", \"k3\")\n\n        ...a ``refresh()`` method, which will call the creation\n        function, cache the new values, and return them::\n\n            values = generate_something.refresh(\"k1\", \"k2\", \"k3\")\n\n        ...and a ``get()`` method, which will return values\n        based on the given arguments::\n\n            values = generate_something.get(\"k1\", \"k2\", \"k3\")\n\n        .. versionadded:: 0.5.3 Added ``get()`` method to decorated\n           function.\n\n        Parameters passed to :meth:`.CacheRegion.cache_multi_on_arguments`\n        have the same meaning as those passed to\n        :meth:`.CacheRegion.cache_on_arguments`.\n\n        :param namespace: optional string argument which will be\n         established as part of each cache key.\n\n        :param expiration_time: if not None, will override the normal\n         expiration time.  May be passed as an integer or a\n         callable.\n\n        :param should_cache_fn: passed to\n         :meth:`.CacheRegion.get_or_create_multi`. This function is given a\n         value as returned by the creator, and only if it returns True will\n         that value be placed in the cache.\n\n        :param asdict: if ``True``, the decorated function should return\n         its result as a dictionary of keys->values, and the final result\n         of calling the decorated function will also be a dictionary.\n         If left at its default value of ``False``, the decorated function\n         should return its result as a list of values, and the final\n         result of calling the decorated function will also be a list.\n\n         When ``asdict==True`` if the dictionary returned by the decorated\n         function is missing keys, those keys will not be cached.\n\n        :param to_str: callable, will be called on each function argument\n         in order to convert to a string.  Defaults to ``str()``.  If the\n         function accepts non-ascii unicode arguments on Python 2.x, the\n         ``unicode()`` builtin can be substituted, but note this will\n         produce unicode cache keys which may require key mangling before\n         reaching the cache.\n\n        .. versionadded:: 0.5.0\n\n        :param function_multi_key_generator: a function that will produce a\n         list of keys. This function will supersede the one configured on the\n         :class:`.CacheRegion` itself.\n\n         .. versionadded:: 0.5.5\n\n        .. seealso::\n\n            :meth:`.CacheRegion.cache_on_arguments`\n\n            :meth:`.CacheRegion.get_or_create_multi`\n\n        \"\"\"\n        expiration_time_is_callable = callable(expiration_time)\n        if function_multi_key_generator is None:\n            _function_multi_key_generator = self.function_multi_key_generator\n        else:\n            _function_multi_key_generator = function_multi_key_generator\n\n        def get_or_create_for_user_func(key_generator: Callable[..., Sequence[KeyType]], user_func: Callable[..., Sequence[ValuePayload]], *arg: Any, **kw: Any) -> Union[Sequence[ValuePayload], Mapping[KeyType, ValuePayload]]:\n            cache_keys = arg\n            keys = key_generator(*arg, **kw)\n            key_lookup = dict(zip(keys, cache_keys))\n\n            @wraps(user_func)\n            def creator(*keys_to_create):\n                return user_func(*[key_lookup[k] for k in keys_to_create])\n            timeout: Optional[float] = cast(ExpirationTimeCallable, expiration_time)() if expiration_time_is_callable else cast(Optional[float], expiration_time)\n            result: Union[Sequence[ValuePayload], Mapping[KeyType, ValuePayload]]\n            if asdict:\n\n                def dict_create(*keys):\n                    d_values = creator(*keys)\n                    return [d_values.get(key_lookup[k], NO_VALUE) for k in keys]\n\n                def wrap_cache_fn(value):\n                    if value is NO_VALUE:\n                        return False\n                    elif not should_cache_fn:\n                        return True\n                    else:\n                        return should_cache_fn(value)\n                result = self.get_or_create_multi(keys, dict_create, timeout, wrap_cache_fn)\n                result = dict(((k, v) for k, v in zip(cache_keys, result) if v is not NO_VALUE))\n            else:\n                result = self.get_or_create_multi(keys, creator, timeout, should_cache_fn)\n            return result\n\n        def cache_decorator(user_func):\n            key_generator = _function_multi_key_generator(namespace, user_func, to_str=to_str)\n\n            def invalidate(*arg):\n                keys = key_generator(*arg)\n                self.delete_multi(keys)\n\n            def set_(mapping):\n                keys = list(mapping)\n                gen_keys = key_generator(*keys)\n                self.set_multi(dict(((gen_key, mapping[key]) for gen_key, key in zip(gen_keys, keys))))\n\n            def get(*arg):\n                keys = key_generator(*arg)\n                return self.get_multi(keys)\n\n            def refresh(*arg):\n                keys = key_generator(*arg)\n                values = user_func(*arg)\n                if asdict:\n                    self.set_multi(dict(zip(keys, [values[a] for a in arg])))\n                    return values\n                else:\n                    self.set_multi(dict(zip(keys, values)))\n                    return values\n            user_func.set = set_\n            user_func.invalidate = invalidate\n            user_func.refresh = refresh\n            user_func.get = get\n            return decorate(user_func, partial(get_or_create_for_user_func, key_generator))\n        return cache_decorator\n\ndef make_region(*arg: Any, **kw: Any) -> CacheRegion:\n    \"\"\"Instantiate a new :class:`.CacheRegion`.\n\n    Currently, :func:`.make_region` is a passthrough\n    to :class:`.CacheRegion`.  See that class for\n    constructor arguments.\n\n    \"\"\"\n    return CacheRegion(*arg, **kw)",
    "dogpile/testing/fixtures.py": "import collections\nimport itertools\nimport json\nimport random\nfrom threading import Lock\nfrom threading import Thread\nimport time\nimport uuid\nimport pytest\nfrom dogpile.cache import CacheRegion\nfrom dogpile.cache import register_backend\nfrom dogpile.cache.api import CacheBackend\nfrom dogpile.cache.api import CacheMutex\nfrom dogpile.cache.api import CantDeserializeException\nfrom dogpile.cache.api import NO_VALUE\nfrom dogpile.cache.region import _backend_loader\nfrom .assertions import assert_raises_message\nfrom .assertions import eq_\n\ndef gen_some_key():\n    return f'some_key_{random.randint(1, 100000)}'\n\nclass _GenericBackendFixture:\n\n    @classmethod\n    def setup_class(cls):\n        backend_cls = _backend_loader.load(cls.backend)\n        try:\n            arguments = cls.config_args.get('arguments', {})\n            backend = backend_cls(arguments)\n        except ImportError:\n            pytest.skip('Backend %s not installed' % cls.backend)\n        cls._check_backend_available(backend)\n\n    def teardown_method(self, method):\n        some_key = gen_some_key()\n        if self._region_inst:\n            for key in self._keys:\n                self._region_inst.delete(key)\n            self._keys.clear()\n        elif self._backend_inst:\n            self._backend_inst.delete(some_key)\n\n    @classmethod\n    def _check_backend_available(cls, backend):\n        pass\n    region_args = {}\n    config_args = {}\n    extra_arguments = {}\n    _region_inst = None\n    _backend_inst = None\n    _keys = set()\n\nclass _GenericBackendTestSuite(_GenericBackendFixture):\n\n    def test_backend_get_nothing(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        eq_(backend.get_serialized(some_key), NO_VALUE)\n\n    def test_backend_delete_nothing(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        backend.delete(some_key)\n\n    def test_backend_set_get_value(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        backend.set_serialized(some_key, b'some value')\n        eq_(backend.get_serialized(some_key), b'some value')\n\n    def test_backend_delete(self):\n        backend = self._backend()\n        some_key = gen_some_key()\n        backend.set_serialized(some_key, b'some value')\n        backend.delete(some_key)\n        eq_(backend.get_serialized(some_key), NO_VALUE)\n\n    def test_region_is_key_locked(self):\n        reg = self._region()\n        random_key = str(uuid.uuid1())\n        assert not reg.get(random_key)\n        eq_(reg.key_is_locked(random_key), False)\n        eq_(reg.key_is_locked(random_key), False)\n        mutex = reg.backend.get_mutex(random_key)\n        if mutex:\n            mutex.acquire()\n            eq_(reg.key_is_locked(random_key), True)\n            mutex.release()\n            eq_(reg.key_is_locked(random_key), False)\n\n    def test_region_set_get_value(self):\n        reg = self._region()\n        some_key = gen_some_key()\n        reg.set(some_key, 'some value')\n        eq_(reg.get(some_key), 'some value')\n\n    def test_region_set_multiple_values(self):\n        reg = self._region()\n        values = {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}\n        reg.set_multi(values)\n        eq_(values['key1'], reg.get('key1'))\n        eq_(values['key2'], reg.get('key2'))\n        eq_(values['key3'], reg.get('key3'))\n\n    def test_region_get_zero_multiple_values(self):\n        reg = self._region()\n        eq_(reg.get_multi([]), [])\n\n    def test_region_set_zero_multiple_values(self):\n        reg = self._region()\n        reg.set_multi({})\n\n    def test_region_set_zero_multiple_values_w_decorator(self):\n        reg = self._region()\n        values = reg.get_or_create_multi([], lambda: 0)\n        eq_(values, [])\n\n    def test_region_get_or_create_multi_w_should_cache_none(self):\n        reg = self._region()\n        values = reg.get_or_create_multi(['key1', 'key2', 'key3'], lambda *k: [None, None, None], should_cache_fn=lambda v: v is not None)\n        eq_(values, [None, None, None])\n\n    def test_region_get_multiple_values(self):\n        reg = self._region()\n        key1 = 'value1'\n        key2 = 'value2'\n        key3 = 'value3'\n        reg.set('key1', key1)\n        reg.set('key2', key2)\n        reg.set('key3', key3)\n        values = reg.get_multi(['key1', 'key2', 'key3'])\n        eq_([key1, key2, key3], values)\n\n    def test_region_get_nothing_multiple(self):\n        reg = self._region()\n        reg.delete_multi(['key1', 'key2', 'key3', 'key4', 'key5'])\n        values = {'key1': 'value1', 'key3': 'value3', 'key5': 'value5'}\n        reg.set_multi(values)\n        reg_values = reg.get_multi(['key1', 'key2', 'key3', 'key4', 'key5', 'key6'])\n        eq_(reg_values, ['value1', NO_VALUE, 'value3', NO_VALUE, 'value5', NO_VALUE])\n\n    def test_region_get_empty_multiple(self):\n        reg = self._region()\n        reg_values = reg.get_multi([])\n        eq_(reg_values, [])\n\n    def test_region_delete_multiple(self):\n        reg = self._region()\n        values = {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}\n        reg.set_multi(values)\n        reg.delete_multi(['key2', 'key10'])\n        eq_(values['key1'], reg.get('key1'))\n        eq_(NO_VALUE, reg.get('key2'))\n        eq_(values['key3'], reg.get('key3'))\n        eq_(NO_VALUE, reg.get('key10'))\n\n    def test_region_set_get_nothing(self):\n        reg = self._region()\n        some_key = gen_some_key()\n        reg.delete_multi([some_key])\n        eq_(reg.get(some_key), NO_VALUE)\n\n    def test_region_creator(self):\n        reg = self._region()\n\n        def creator():\n            return 'some value'\n        some_key = gen_some_key()\n        eq_(reg.get_or_create(some_key, creator), 'some value')\n\n    @pytest.mark.time_intensive\n    def test_threaded_dogpile(self):\n        reg = self._region(config_args={'expiration_time': 0.25})\n        lock = Lock()\n        canary = []\n        some_key = gen_some_key()\n\n        def creator():\n            ack = lock.acquire(False)\n            canary.append(ack)\n            time.sleep(0.25)\n            if ack:\n                lock.release()\n            return 'some value'\n\n        def f():\n            for x in range(5):\n                reg.get_or_create(some_key, creator)\n                time.sleep(0.5)\n        threads = [Thread(target=f) for i in range(10)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n        assert len(canary) > 2\n        if not reg.backend.has_lock_timeout():\n            assert False not in canary\n\n    @pytest.mark.time_intensive\n    def test_threaded_get_multi(self):\n        \"\"\"This test is testing that when we get inside the \"creator\" for\n        a certain key, there are no other \"creators\" running at all for\n        that key.\n\n        With \"distributed\" locks, this is not 100% the case.\n\n        \"\"\"\n        some_key = gen_some_key()\n        reg = self._region(config_args={'expiration_time': 0.25})\n        backend_mutex = reg.backend.get_mutex(some_key)\n        is_custom_mutex = backend_mutex is not None\n        locks = dict(((str(i), Lock()) for i in range(11)))\n        canary = collections.defaultdict(list)\n\n        def creator(*keys):\n            assert keys\n            ack = [locks[key].acquire(False) for key in keys]\n            for acq, key in zip(ack, keys):\n                canary[key].append(acq)\n            time.sleep(0.5)\n            for acq, key in zip(ack, keys):\n                if acq:\n                    locks[key].release()\n            return ['some value %s' % k for k in keys]\n\n        def f():\n            for x in range(5):\n                reg.get_or_create_multi([str(random.randint(1, 10)) for i in range(random.randint(1, 5))], creator)\n                time.sleep(0.5)\n        f()\n        threads = [Thread(target=f) for i in range(5)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n        assert sum([len(v) for v in canary.values()]) > 10\n        if not is_custom_mutex:\n            for l in canary.values():\n                assert False not in l\n\n    def test_region_delete(self):\n        reg = self._region()\n        some_key = gen_some_key()\n        reg.set(some_key, 'some value')\n        reg.delete(some_key)\n        reg.delete(some_key)\n        eq_(reg.get(some_key), NO_VALUE)\n\n    @pytest.mark.time_intensive\n    def test_region_expire(self):\n        some_key = gen_some_key()\n        expire_time = 1.0\n        reg = self._region(config_args={'expiration_time': expire_time})\n        counter = itertools.count(1)\n\n        def creator():\n            return 'some value %d' % next(counter)\n        eq_(reg.get_or_create(some_key, creator), 'some value 1')\n        time.sleep(expire_time + 0.2 * expire_time)\n        post_expiration = reg.get(some_key, ignore_expiration=True)\n        if post_expiration is not NO_VALUE:\n            eq_(post_expiration, 'some value 1')\n        eq_(reg.get_or_create(some_key, creator), 'some value 2')\n        eq_(reg.get(some_key), 'some value 2')\n\n    def test_decorated_fn_functionality(self):\n        reg = self._region()\n        counter = itertools.count(1)\n\n        @reg.cache_on_arguments()\n        def my_function(x, y):\n            return next(counter) + x + y\n        my_function.invalidate(3, 4)\n        my_function.invalidate(5, 6)\n        my_function.invalidate(4, 3)\n        eq_(my_function(3, 4), 8)\n        eq_(my_function(5, 6), 13)\n        eq_(my_function(3, 4), 8)\n        eq_(my_function(4, 3), 10)\n        my_function.invalidate(4, 3)\n        eq_(my_function(4, 3), 11)\n\n    def test_exploding_value_fn(self):\n        some_key = gen_some_key()\n        reg = self._region()\n\n        def boom():\n            raise Exception('boom')\n        assert_raises_message(Exception, 'boom', reg.get_or_create, some_key, boom)\n\ndef raise_cant_deserialize_exception(v):\n    raise CantDeserializeException()\n\nclass _GenericSerializerTestSuite:\n    region_args = {'serializer': lambda v: json.dumps(v).encode('ascii'), 'deserializer': json.loads}\n\n    def test_serializer_cant_deserialize(self):\n        region = self._region(region_args={'serializer': self.region_args['serializer'], 'deserializer': raise_cant_deserialize_exception})\n        value = {'foo': ['bar', 1, False, None]}\n        region.set('k', value)\n        asserted = region.get('k')\n        eq_(asserted, NO_VALUE)\n\n    def test_uses_serializer(self):\n        region = self._region()\n        backend = region.backend\n        value = {'foo': ['bar', 1, False, None]}\n        region.set('k', value)\n        raw = backend.get_serialized('k')\n        assert isinstance(raw, bytes)\n        pipe = raw.find(b'|')\n        payload = raw[pipe + 1:]\n        eq_(payload, self.region_args['serializer'](value))\n        eq_(region._parse_serialized_from_backend(raw).payload, value)\n\n    def test_uses_deserializer(self):\n        region = self._region()\n        value = {'foo': ['bar', 1, False, None]}\n        region.set('k', value)\n        asserted = region.get('k')\n        eq_(asserted, value)\n\nclass _GenericMutexTestSuite(_GenericBackendFixture):\n\n    def test_mutex(self):\n        backend = self._backend()\n        mutex = backend.get_mutex('foo')\n        assert not mutex.locked()\n        ac = mutex.acquire()\n        assert ac\n        ac2 = mutex.acquire(False)\n        assert mutex.locked()\n        assert not ac2\n        mutex.release()\n        assert not mutex.locked()\n        ac3 = mutex.acquire()\n        assert ac3\n        mutex.release()\n\n    def test_subclass_match(self):\n        backend = self._backend()\n        mutex = backend.get_mutex('foo')\n        assert isinstance(mutex, CacheMutex)\n\n    @pytest.mark.time_intensive\n    def test_mutex_threaded(self):\n        backend = self._backend()\n        backend.get_mutex('foo')\n        lock = Lock()\n        canary = []\n\n        def f():\n            for x in range(5):\n                mutex = backend.get_mutex('foo')\n                mutex.acquire()\n                for y in range(5):\n                    ack = lock.acquire(False)\n                    canary.append(ack)\n                    time.sleep(0.002)\n                    if ack:\n                        lock.release()\n                mutex.release()\n                time.sleep(0.02)\n        threads = [Thread(target=f) for i in range(5)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join()\n        assert False not in canary\n\n    def test_mutex_reentrant_across_keys(self):\n        backend = self._backend()\n        for x in range(3):\n            m1 = backend.get_mutex('foo')\n            m2 = backend.get_mutex('bar')\n            try:\n                m1.acquire()\n                assert m2.acquire(False)\n                assert not m2.acquire(False)\n                m2.release()\n                assert m2.acquire(False)\n                assert not m2.acquire(False)\n                m2.release()\n            finally:\n                m1.release()\n\n    def test_reentrant_dogpile(self):\n        reg = self._region()\n\n        def create_foo():\n            return 'foo' + reg.get_or_create('bar', create_bar)\n\n        def create_bar():\n            return 'bar'\n        eq_(reg.get_or_create('foo', create_foo), 'foobar')\n        eq_(reg.get_or_create('foo', create_foo), 'foobar')\n\nclass MockMutex(object):\n\n    def __init__(self, key):\n        self.key = key\n\n    def acquire(self, blocking=True):\n        return True\n\n    def release(self):\n        return\n\n    def locked(self):\n        return False\n\nclass MockBackend(CacheBackend):\n\n    def __init__(self, arguments):\n        self.arguments = arguments\n        self._cache = {}\n\n    def get_mutex(self, key):\n        return MockMutex(key)\n\n    def get(self, key):\n        try:\n            return self._cache[key]\n        except KeyError:\n            return NO_VALUE\n\n    def get_multi(self, keys):\n        return [self.get(key) for key in keys]\n\n    def set(self, key, value):\n        self._cache[key] = value\n\n    def set_multi(self, mapping):\n        for key, value in mapping.items():\n            self.set(key, value)\n\n    def delete(self, key):\n        self._cache.pop(key, None)\n\n    def delete_multi(self, keys):\n        for key in keys:\n            self.delete(key)\nregister_backend('mock', __name__, 'MockBackend')",
    "dogpile/cache/backends/null.py": "\"\"\"\nNull Backend\n-------------\n\nThe Null backend does not do any caching at all.  It can be\nused to test behavior without caching, or as a means of disabling\ncaching for a region that is otherwise used normally.\n\n.. versionadded:: 0.5.4\n\n\"\"\"\nfrom ..api import CacheBackend\nfrom ..api import NO_VALUE\n__all__ = ['NullBackend']\n\nclass NullLock(object):\n\n    def locked(self):\n        return False\n\nclass NullBackend(CacheBackend):\n    \"\"\"A \"null\" backend that effectively disables all cache operations.\n\n    Basic usage::\n\n        from dogpile.cache import make_region\n\n        region = make_region().configure(\n            'dogpile.cache.null'\n        )\n\n    \"\"\"\n\n    def __init__(self, arguments):\n        pass\n\n    def get(self, key):\n        return NO_VALUE\n\n    def get_multi(self, keys):\n        return [NO_VALUE for k in keys]\n\n    def set(self, key, value):\n        pass\n\n    def set_multi(self, mapping):\n        pass\n\n    def delete(self, key):\n        pass\n\n    def delete_multi(self, keys):\n        pass",
    "dogpile/cache/api.py": "from __future__ import annotations\nimport abc\nimport enum\nimport pickle\nimport time\nfrom typing import Any\nfrom typing import Callable\nfrom typing import cast\nfrom typing import Literal\nfrom typing import Mapping\nfrom typing import NamedTuple\nfrom typing import Optional\nfrom typing import Sequence\nfrom typing import Union\nfrom ..util.typing import Self\n\nclass NoValue(enum.Enum):\n    \"\"\"Describe a missing cache value.\n\n    The :data:`.NO_VALUE` constant should be used.\n\n    \"\"\"\n\n    @property\n    def payload(self) -> Self:\n        return self\n\n    def __repr__(self):\n        \"\"\"Ensure __repr__ is a consistent value in case NoValue is used to\n        fill another cache key.\n\n        \"\"\"\n        return '<dogpile.cache.api.NoValue object>'\n\n    def __bool__(self) -> Literal[False]:\n        return False\n    NO_VALUE = 'NoValue'\nNoValueType = Literal[NoValue.NO_VALUE]\nNO_VALUE = NoValue.NO_VALUE\n'Value returned from :meth:`.CacheRegion.get` that describes\\na  key not present.'\nMetaDataType = Mapping[str, Any]\nKeyType = str\n'A cache key.'\nValuePayload = Any\n'An object to be placed in the cache against a key.'\nKeyManglerType = Callable[[KeyType], KeyType]\nSerializer = Callable[[ValuePayload], bytes]\nDeserializer = Callable[[bytes], ValuePayload]\n\nclass CantDeserializeException(Exception):\n    \"\"\"Exception indicating deserialization failed, and that caching\n    should proceed to re-generate a value\n\n    .. versionadded:: 1.2.0\n\n    \"\"\"\n\nclass CacheMutex(abc.ABC):\n    \"\"\"Describes a mutexing object with acquire and release methods.\n\n    This is an abstract base class; any object that has acquire/release\n    methods may be used.\n\n    .. versionadded:: 1.1\n\n\n    .. seealso::\n\n        :meth:`.CacheBackend.get_mutex` - the backend method that optionally\n        returns this locking object.\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def acquire(self, wait: bool=True) -> bool:\n        \"\"\"Acquire the mutex.\n\n        :param wait: if True, block until available, else return True/False\n         immediately.\n\n        :return: True if the lock succeeded.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def release(self) -> None:\n        \"\"\"Release the mutex.\"\"\"\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def locked(self) -> bool:\n        \"\"\"Check if the mutex was acquired.\n\n        :return: true if the lock is acquired.\n\n        .. versionadded:: 1.1.2\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        return hasattr(C, 'acquire') and hasattr(C, 'release')\n\nclass CachedValue(NamedTuple):\n    \"\"\"Represent a value stored in the cache.\n\n    :class:`.CachedValue` is a two-tuple of\n    ``(payload, metadata)``, where ``metadata``\n    is dogpile.cache's tracking information (\n    currently the creation time).\n\n    \"\"\"\n    payload: ValuePayload\n    'the actual cached value.'\n    metadata: MetaDataType\n    'Metadata dictionary for the cached value.\\n\\n    Prefer using accessors such as :attr:`.CachedValue.cached_time` rather\\n    than accessing this mapping directly.\\n\\n    '\n\n    @property\n    def cached_time(self) -> float:\n        \"\"\"The epoch (floating point time value) stored when this payload was\n        cached.\n\n        .. versionadded:: 1.3\n\n        \"\"\"\n        return cast(float, self.metadata['ct'])\n\n    @property\n    def age(self) -> float:\n        \"\"\"Returns the elapsed time in seconds as a `float` since the insertion\n        of the value in the cache.\n\n        This value is computed **dynamically** by subtracting the cached\n        floating point epoch value from the value of ``time.time()``.\n\n        .. versionadded:: 1.3\n\n        \"\"\"\n        return time.time() - self.cached_time\nCacheReturnType = Union[CachedValue, NoValueType]\n'The non-serialized form of what may be returned from a backend\\nget method.\\n\\n'\nSerializedReturnType = Union[bytes, NoValueType]\n'the serialized form of what may be returned from a backend get method.'\nBackendFormatted = Union[CacheReturnType, SerializedReturnType]\n'Describes the type returned from the :meth:`.CacheBackend.get` method.'\nBackendSetType = Union[CachedValue, bytes]\n'Describes the value argument passed to the :meth:`.CacheBackend.set`\\nmethod.'\nBackendArguments = Mapping[str, Any]\n\nclass CacheBackend:\n    \"\"\"Base class for backend implementations.\n\n    Backends which set and get Python object values should subclass this\n    backend.   For backends in which the value that's stored is ultimately\n    a stream of bytes, the :class:`.BytesBackend` should be used.\n\n    \"\"\"\n    key_mangler: Optional[Callable[[KeyType], KeyType]] = None\n    'Key mangling function.\\n\\n    May be None, or otherwise declared\\n    as an ordinary instance method.\\n\\n    '\n    serializer: Union[None, Serializer] = None\n    'Serializer function that will be used by default if not overridden\\n    by the region.\\n\\n    .. versionadded:: 1.1\\n\\n    '\n    deserializer: Union[None, Deserializer] = None\n    'deserializer function that will be used by default if not overridden\\n    by the region.\\n\\n    .. versionadded:: 1.1\\n\\n    '\n\n    def __init__(self, arguments: BackendArguments):\n        \"\"\"Construct a new :class:`.CacheBackend`.\n\n        Subclasses should override this to\n        handle the given arguments.\n\n        :param arguments: The ``arguments`` parameter\n         passed to :func:`.make_registry`.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def from_config_dict(cls, config_dict: Mapping[str, Any], prefix: str) -> Self:\n        prefix_len = len(prefix)\n        return cls(dict(((key[prefix_len:], config_dict[key]) for key in config_dict if key.startswith(prefix))))\n\n    def has_lock_timeout(self) -> bool:\n        return False\n\n    def get_mutex(self, key: KeyType) -> Optional[CacheMutex]:\n        \"\"\"Return an optional mutexing object for the given key.\n\n        This object need only provide an ``acquire()``\n        and ``release()`` method.\n\n        May return ``None``, in which case the dogpile\n        lock will use a regular ``threading.Lock``\n        object to mutex concurrent threads for\n        value creation.   The default implementation\n        returns ``None``.\n\n        Different backends may want to provide various\n        kinds of \"mutex\" objects, such as those which\n        link to lock files, distributed mutexes,\n        memcached semaphores, etc.  Whatever\n        kind of system is best suited for the scope\n        and behavior of the caching backend.\n\n        A mutex that takes the key into account will\n        allow multiple regenerate operations across\n        keys to proceed simultaneously, while a mutex\n        that does not will serialize regenerate operations\n        to just one at a time across all keys in the region.\n        The latter approach, or a variant that involves\n        a modulus of the given key's hash value,\n        can be used as a means of throttling the total\n        number of value recreation operations that may\n        proceed at one time.\n\n        \"\"\"\n        return None\n\n    def get(self, key: KeyType) -> BackendFormatted:\n        \"\"\"Retrieve an optionally serialized value from the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.get`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :return: the Python object that corresponds to\n         what was established via the :meth:`.CacheBackend.set` method,\n         or the :data:`.NO_VALUE` constant if not present.\n\n        If a serializer is in use, this method will only be called if the\n        :meth:`.CacheBackend.get_serialized` method is not overridden.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_multi(self, keys: Sequence[KeyType]) -> Sequence[BackendFormatted]:\n        \"\"\"Retrieve multiple optionally serialized values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.get_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        :return a list of values as would be returned\n         individually via the :meth:`.CacheBackend.get` method, corresponding\n         to the list of keys given.\n\n        If a serializer is in use, this method will only be called if the\n        :meth:`.CacheBackend.get_serialized_multi` method is not overridden.\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_serialized(self, key: KeyType) -> SerializedReturnType:\n        \"\"\"Retrieve a serialized value from the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.get`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :return: a bytes object, or :data:`.NO_VALUE`\n         constant if not present.\n\n        The default implementation of this method for :class:`.CacheBackend`\n        returns the value of the :meth:`.CacheBackend.get` method.\n\n        .. versionadded:: 1.1\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n        \"\"\"\n        return cast(SerializedReturnType, self.get(key))\n\n    def get_serialized_multi(self, keys: Sequence[KeyType]) -> Sequence[SerializedReturnType]:\n        \"\"\"Retrieve multiple serialized values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.get_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        :return: list of bytes objects\n\n        The default implementation of this method for :class:`.CacheBackend`\n        returns the value of the :meth:`.CacheBackend.get_multi` method.\n\n        .. versionadded:: 1.1\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n        \"\"\"\n        return cast(Sequence[SerializedReturnType], self.get_multi(keys))\n\n    def set(self, key: KeyType, value: BackendSetType) -> None:\n        \"\"\"Set an optionally serialized value in the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.set`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :param value: The optionally serialized :class:`.CachedValue` object.\n         May be an instance of :class:`.CachedValue` or a bytes object\n         depending on if a serializer is in use with the region and if the\n         :meth:`.CacheBackend.set_serialized` method is not overridden.\n\n        .. seealso::\n\n            :meth:`.CacheBackend.set_serialized`\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized(self, key: KeyType, value: bytes) -> None:\n        \"\"\"Set a serialized value in the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.set`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :param value: a bytes object to be stored.\n\n        The default implementation of this method for :class:`.CacheBackend`\n        calls upon the :meth:`.CacheBackend.set` method.\n\n        .. versionadded:: 1.1\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n        \"\"\"\n        self.set(key, value)\n\n    def set_multi(self, mapping: Mapping[KeyType, BackendSetType]) -> None:\n        \"\"\"Set multiple values in the cache.\n\n        :param mapping: a dict in which the key will be whatever was passed to\n         the :meth:`.CacheRegion.set_multi` method, processed by the \"key\n         mangling\" function, if any.\n\n        When implementing a new :class:`.CacheBackend` or cutomizing via\n        :class:`.ProxyBackend`, be aware that when this method is invoked by\n        :meth:`.Region.get_or_create_multi`, the ``mapping`` values are the\n        same ones returned to the upstream caller. If the subclass alters the\n        values in any way, it must not do so 'in-place' on the ``mapping`` dict\n        -- that will have the undesirable effect of modifying the returned\n        values as well.\n\n        If a serializer is in use, this method will only be called if the\n        :meth:`.CacheBackend.set_serialized_multi` method is not overridden.\n\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized_multi(self, mapping: Mapping[KeyType, bytes]) -> None:\n        \"\"\"Set multiple serialized values in the cache.\n\n        :param mapping: a dict in which the key will be whatever was passed to\n         the :meth:`.CacheRegion.set_multi` method, processed by the \"key\n         mangling\" function, if any.\n\n        When implementing a new :class:`.CacheBackend` or cutomizing via\n        :class:`.ProxyBackend`, be aware that when this method is invoked by\n        :meth:`.Region.get_or_create_multi`, the ``mapping`` values are the\n        same ones returned to the upstream caller. If the subclass alters the\n        values in any way, it must not do so 'in-place' on the ``mapping`` dict\n        -- that will have the undesirable effect of modifying the returned\n        values as well.\n\n        .. versionadded:: 1.1\n\n        The default implementation of this method for :class:`.CacheBackend`\n        calls upon the :meth:`.CacheBackend.set_multi` method.\n\n        .. seealso::\n\n            :class:`.BytesBackend`\n\n\n        \"\"\"\n        self.set_multi(mapping)\n\n    def delete(self, key: KeyType) -> None:\n        \"\"\"Delete a value from the cache.\n\n        :param key: String key that was passed to the\n         :meth:`.CacheRegion.delete`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        The behavior here should be idempotent,\n        that is, can be called any number of times\n        regardless of whether or not the\n        key exists.\n        \"\"\"\n        raise NotImplementedError()\n\n    def delete_multi(self, keys: Sequence[KeyType]) -> None:\n        \"\"\"Delete multiple values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.delete_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        The behavior here should be idempotent,\n        that is, can be called any number of times\n        regardless of whether or not the\n        key exists.\n\n        .. versionadded:: 0.5.0\n\n        \"\"\"\n        raise NotImplementedError()\n\nclass DefaultSerialization:\n    serializer: Union[None, Serializer] = staticmethod(pickle.dumps)\n    deserializer: Union[None, Deserializer] = staticmethod(pickle.loads)\n\nclass BytesBackend(DefaultSerialization, CacheBackend):\n    \"\"\"A cache backend that receives and returns series of bytes.\n\n    This backend only supports the \"serialized\" form of values; subclasses\n    should implement :meth:`.BytesBackend.get_serialized`,\n    :meth:`.BytesBackend.get_serialized_multi`,\n    :meth:`.BytesBackend.set_serialized`,\n    :meth:`.BytesBackend.set_serialized_multi`.\n\n    .. versionadded:: 1.1\n\n    \"\"\"\n\n    def get_serialized(self, key: KeyType) -> SerializedReturnType:\n        \"\"\"Retrieve a serialized value from the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.get`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :return: a bytes object, or :data:`.NO_VALUE`\n         constant if not present.\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_serialized_multi(self, keys: Sequence[KeyType]) -> Sequence[SerializedReturnType]:\n        \"\"\"Retrieve multiple serialized values from the cache.\n\n        :param keys: sequence of string keys that was passed to the\n         :meth:`.CacheRegion.get_multi` method, which will also be processed\n         by the \"key mangling\" function if one was present.\n\n        :return: list of bytes objects\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized(self, key: KeyType, value: bytes) -> None:\n        \"\"\"Set a serialized value in the cache.\n\n        :param key: String key that was passed to the :meth:`.CacheRegion.set`\n         method, which will also be processed by the \"key mangling\" function\n         if one was present.\n\n        :param value: a bytes object to be stored.\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def set_serialized_multi(self, mapping: Mapping[KeyType, bytes]) -> None:\n        \"\"\"Set multiple serialized values in the cache.\n\n        :param mapping: a dict in which the key will be whatever was passed to\n         the :meth:`.CacheRegion.set_multi` method, processed by the \"key\n         mangling\" function, if any.\n\n        When implementing a new :class:`.CacheBackend` or cutomizing via\n        :class:`.ProxyBackend`, be aware that when this method is invoked by\n        :meth:`.Region.get_or_create_multi`, the ``mapping`` values are the\n        same ones returned to the upstream caller. If the subclass alters the\n        values in any way, it must not do so 'in-place' on the ``mapping`` dict\n        -- that will have the undesirable effect of modifying the returned\n        values as well.\n\n        .. versionadded:: 1.1\n\n        \"\"\"\n        raise NotImplementedError()",
    "dogpile/testing/assertions.py": "import re\nimport sys\nimport time\n\ndef is_(a, b, msg=None):\n    \"\"\"Assert a is b, with repr messaging on failure.\"\"\"\n    assert a is b, msg or '%r is not %r' % (a, b)\n\ndef ne_(a, b, msg=None):\n    \"\"\"Assert a != b, with repr messaging on failure.\"\"\"\n    assert a != b, msg or '%r == %r' % (a, b)\n\ndef assert_raises_message(except_cls, msg, callable_, *args, **kwargs):\n    try:\n        callable_(*args, **kwargs)\n        assert False, 'Callable did not raise an exception'\n    except except_cls as e:\n        assert re.search(msg, str(e)), '%r !~ %s' % (msg, e)\n\ndef winsleep():\n    if sys.platform.startswith('win'):\n        time.sleep(0.001)",
    "dogpile/cache/proxy.py": "\"\"\"\nProxy Backends\n------------------\n\nProvides a utility and a decorator class that allow for modifying the behavior\nof different backends without altering the class itself or having to extend the\nbase backend.\n\n.. versionadded:: 0.5.0  Added support for the :class:`.ProxyBackend` class.\n\n\"\"\"\nfrom __future__ import annotations\nfrom typing import Mapping\nfrom typing import Optional\nfrom typing import Sequence\nfrom .api import BackendFormatted\nfrom .api import BackendSetType\nfrom .api import CacheBackend\nfrom .api import CacheMutex\nfrom .api import KeyType\nfrom .api import SerializedReturnType\nfrom ..util.typing import Self\n\nclass ProxyBackend(CacheBackend):\n    \"\"\"A decorator class for altering the functionality of backends.\n\n    Basic usage::\n\n        from dogpile.cache import make_region\n        from dogpile.cache.proxy import ProxyBackend\n\n        class MyFirstProxy(ProxyBackend):\n            def get_serialized(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get_serialized(key)\n\n            def get(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get(key)\n\n            def set(self, key, value):\n                # ... custom code goes here ...\n                self.proxied.set(key)\n\n        class MySecondProxy(ProxyBackend):\n            def get_serialized(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get_serialized(key)\n\n            def get(self, key):\n                # ... custom code goes here ...\n                return self.proxied.get(key)\n\n\n        region = make_region().configure(\n            'dogpile.cache.dbm',\n            expiration_time = 3600,\n            arguments = {\n                \"filename\":\"/path/to/cachefile.dbm\"\n            },\n            wrap = [ MyFirstProxy, MySecondProxy ]\n        )\n\n    Classes that extend :class:`.ProxyBackend` can be stacked\n    together.  The ``.proxied`` property will always\n    point to either the concrete backend instance or\n    the next proxy in the chain that a method can be\n    delegated towards.\n\n    .. versionadded:: 0.5.0\n\n    \"\"\"\n\n    def __init__(self, *arg, **kw):\n        pass\n\n    def wrap(self, backend: CacheBackend) -> Self:\n        \"\"\"Take a backend as an argument and setup the self.proxied property.\n        Return an object that be used as a backend by a :class:`.CacheRegion`\n        object.\n        \"\"\"\n        assert isinstance(backend, CacheBackend) or isinstance(backend, ProxyBackend)\n        self.proxied = backend\n        return self\n\n    def get(self, key: KeyType) -> BackendFormatted:\n        return self.proxied.get(key)\n\n    def set(self, key: KeyType, value: BackendSetType) -> None:\n        self.proxied.set(key, value)\n\n    def delete(self, key: KeyType) -> None:\n        self.proxied.delete(key)\n\n    def get_multi(self, keys: Sequence[KeyType]) -> Sequence[BackendFormatted]:\n        return self.proxied.get_multi(keys)\n\n    def set_multi(self, mapping: Mapping[KeyType, BackendSetType]) -> None:\n        self.proxied.set_multi(mapping)\n\n    def delete_multi(self, keys: Sequence[KeyType]) -> None:\n        self.proxied.delete_multi(keys)\n\n    def get_mutex(self, key: KeyType) -> Optional[CacheMutex]:\n        return self.proxied.get_mutex(key)\n\n    def get_serialized(self, key: KeyType) -> SerializedReturnType:\n        return self.proxied.get_serialized(key)\n\n    def get_serialized_multi(self, keys: Sequence[KeyType]) -> Sequence[SerializedReturnType]:\n        return self.proxied.get_serialized_multi(keys)\n\n    def set_serialized(self, key: KeyType, value: bytes) -> None:\n        self.proxied.set_serialized(key, value)\n\n    def set_serialized_multi(self, mapping: Mapping[KeyType, bytes]) -> None:\n        self.proxied.set_serialized_multi(mapping)"
  }
}