{
  "dir_path": "/app/elasticsearch_curator",
  "package_name": "elasticsearch_curator",
  "sample_name": "elasticsearch_curator-test_helpers_getters",
  "src_dir": "curator/",
  "test_dir": "tests/",
  "test_file": "tests/unit/test_helpers_getters.py",
  "test_code": "\"\"\"Unit testing for helpers.creators functions\"\"\"\n\nfrom unittest import TestCase\nfrom unittest.mock import Mock\nimport pytest\nfrom elastic_transport import ApiResponseMeta\nfrom elasticsearch8 import NotFoundError, TransportError\nfrom curator.exceptions import CuratorException, FailedExecution, MissingArgument\nfrom curator.helpers import getters\n\nFAKE_FAIL = Exception('Simulated Failure')\nNAMED_INDICES = [\"index-2015.01.01\", \"index-2015.02.01\"]\nREPO_NAME = 'repo_name'\nTEST_REPO = {REPO_NAME: {}}\nSNAP_NAME = 'snap_name'\nSINGLE = {'snapshot': SNAP_NAME, 'indices': NAMED_INDICES}\nSNAPSHOT = {'snapshots': [SINGLE]}\nSNAPSHOTS = {\n    'snapshots': [SINGLE, {'snapshot': 'snapshot-2015.03.01', 'indices': NAMED_INDICES}]\n}\n\n\nclass TestByteSize(TestCase):\n    \"\"\"TestByteSize\n\n    Test helpers.getters.byte_size functionality.\n    \"\"\"\n\n    def test_byte_size(self):\n        \"\"\"test_byte_size\n\n        Output should match expected\n        \"\"\"\n        size = 3 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024\n        unit = ['Z', 'E', 'P', 'T', 'G', 'M', 'K', '']\n        for i in range(0, 7):\n            assert f'3.0{unit[i]}B' == getters.byte_size(size)\n            size /= 1024\n\n    def test_byte_size_yotta(self):\n        \"\"\"test_byte_size_yotta\n\n        Output should match expected\n        \"\"\"\n        size = 3 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024 * 1024\n        assert '3.0YB' == getters.byte_size(size)\n\n    def test_raise_invalid(self):\n        \"\"\"test_raise_invalid\n\n        Should raise a TypeError exception if an invalid value is passed\n        \"\"\"\n        with pytest.raises(TypeError):\n            getters.byte_size('invalid')\n\n\nclass TestGetIndices(TestCase):\n    \"\"\"TestGetIndices\n\n    Test helpers.getters.get_indices functionality.\n    \"\"\"\n\n    IDX1 = 'index-2016.03.03'\n    IDX2 = 'index-2016.03.04'\n    RESPONSE = [{'index': IDX1, 'state': 'open'}, {'index': IDX2, 'state': 'open'}]\n\n    def test_client_exception(self):\n        \"\"\"test_client_exception\n\n        Should raise a FailedExecution exception when an upstream exception occurs\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = self.RESPONSE\n        client.cat.indices.side_effect = FAKE_FAIL\n        with pytest.raises(FailedExecution):\n            getters.get_indices(client)\n\n    def test_positive(self):\n        \"\"\"test_positive\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = self.RESPONSE\n        self.assertEqual([self.IDX1, self.IDX2], sorted(getters.get_indices(client)))\n\n    def test_empty(self):\n        \"\"\"test_empty\n\n        Output should be an empty list\n        \"\"\"\n        client = Mock()\n        client.cat.indices.return_value = {}\n        self.assertEqual([], getters.get_indices(client))\n\n\nclass TestGetRepository(TestCase):\n    \"\"\"TestGetRepository\n\n    Test helpers.getters.get_repository functionality.\n    \"\"\"\n\n    MULTI = {'other': {}, REPO_NAME: {}}\n\n    def test_get_repository_missing_arg(self):\n        \"\"\"test_get_repository_missing_arg\n\n        Should return an empty response if no repository name provided\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = {}\n        assert not getters.get_repository(client)\n\n    def test_get_repository_positive(self):\n        \"\"\"test_get_repository_positive\n\n        Return value should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        assert TEST_REPO == getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_transporterror_negative(self):\n        \"\"\"test_get_repository_transporterror_negative\n\n        Should raise a CuratorException if a TransportError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.side_effect = TransportError(\n            503, ('exception', 'reason')\n        )\n        with pytest.raises(CuratorException, match=r'503 Check Elasticsearch logs'):\n            getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_notfounderror_negative(self):\n        \"\"\"test_get_repository_notfounderror_negative\n\n        Should raise a CuratorException if a NotFoundError is raised first\n        \"\"\"\n        client = Mock()\n        # 5 positional args for meta: status, http_version, headers, duration, node\n        meta = ApiResponseMeta(404, '1.1', {}, 0.01, None)\n        body = 'simulated error'\n        msg = 'simulated error'\n        # 3 positional args for NotFoundError: message, meta, body\n        effect = NotFoundError(msg, meta, body)\n        client.snapshot.get_repository.side_effect = effect\n        with pytest.raises(CuratorException, match=r'Error: NotFoundError'):\n            getters.get_repository(client, repository=REPO_NAME)\n\n    def test_get_repository_all_positive(self):\n        \"\"\"test_get_repository_all_positive\n\n        Return value should match expected with multiple repositories\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = self.MULTI\n        assert self.MULTI == getters.get_repository(client)\n\n\nclass TestGetSnapshot(TestCase):\n    \"\"\"TestGetSnapshot\n\n    Test helpers.getters.get_snapshot functionality.\n    \"\"\"\n\n    def test_get_snapshot_missing_repository_arg(self):\n        \"\"\"test_get_snapshot_missing_repository_arg\n\n        Should raise a MissingArgument exception when repository not passed\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'No value for \"repository\" provided'\n        ):\n            getters.get_snapshot(client, snapshot=SNAP_NAME)\n\n    def test_get_snapshot_positive(self):\n        \"\"\"test_get_snapshot_positive\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOT\n        assert SNAPSHOT == getters.get_snapshot(\n            client, repository=REPO_NAME, snapshot=SNAP_NAME\n        )\n\n    def test_get_snapshot_transporterror_negative(self):\n        \"\"\"test_get_snapshot_transporterror_negative\n\n        Should raise a FailedExecution exception if a TransportError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        client.snapshot.get.side_effect = TransportError(401, \"simulated error\")\n        with pytest.raises(FailedExecution, match=r'Error: 401'):\n            getters.get_snapshot(client, repository=REPO_NAME, snapshot=SNAP_NAME)\n\n    def test_get_snapshot_notfounderror_negative(self):\n        \"\"\"test_get_snapshot_notfounderror_negative\n\n        Should raise a FailedExecution exception if a NotFoundError is raised first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get_repository.return_value = TEST_REPO\n        # 5 positional args for meta: status, http_version, headers, duration, node\n        meta = ApiResponseMeta(404, '1.1', {}, 1.0, None)\n        client.snapshot.get.side_effect = NotFoundError(\n            'simulated error', meta, 'simulated error'\n        )\n        with pytest.raises(FailedExecution, match=r'Error: NotFoundError'):\n            getters.get_snapshot(client, repository=REPO_NAME, snapshot=SNAP_NAME)\n\n\nclass TestGetSnapshotData(TestCase):\n    \"\"\"TestGetSnapshotData\n\n    Test helpers.getters.get_snapshot_data functionality.\n    \"\"\"\n\n    def test_missing_repo_arg(self):\n        \"\"\"test_missing_repo_arg\n\n        Should raise a MissingArgument exception if the repository arg is missing\n        \"\"\"\n        client = Mock()\n        with pytest.raises(\n            MissingArgument, match=r'No value for \"repository\" provided'\n        ):\n            getters.get_snapshot_data(client)\n\n    def test_return_data(self):\n        \"\"\"test_return_data\n\n        Output should match expected\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOTS\n        client.snapshot.get_repository.return_value = TEST_REPO\n        assert SNAPSHOTS['snapshots'] == getters.get_snapshot_data(\n            client, repository=REPO_NAME\n        )\n\n    def test_raises_exception_onfail(self):\n        \"\"\"test_raises_exception_onfail\n\n        Should raise a FailedExecution exception if a TransportError is raised upstream\n        first\n        \"\"\"\n        client = Mock()\n        client.snapshot.get.return_value = SNAPSHOTS\n        client.snapshot.get.side_effect = TransportError(401, \"simulated error\")\n        client.snapshot.get_repository.return_value = TEST_REPO\n        with pytest.raises(FailedExecution, match=r'Error: 401'):\n            getters.get_snapshot_data(client, repository=REPO_NAME)\n\n\nclass TestNodeRoles(TestCase):\n    \"\"\"TestNodeRoles\n\n    Test helpers.getters.node_roles functionality.\n    \"\"\"\n\n    def test_node_roles(self):\n        \"\"\"test_node_roles\n\n        Output should match expected\n        \"\"\"\n        node_id = 'my_node'\n        expected = ['data']\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'roles': expected}}}\n        assert expected == getters.node_roles(client, node_id)\n\n\nclass TestSingleDataPath(TestCase):\n    \"\"\"TestSingleDataPath\n\n    Test helpers.getters.single_data_path functionality.\n    \"\"\"\n\n    def test_single_data_path(self):\n        \"\"\"test_single_data_path\n\n        Return value should be True with only one data path\n        \"\"\"\n        node_id = 'my_node'\n        client = Mock()\n        client.nodes.stats.return_value = {\n            'nodes': {node_id: {'fs': {'data': ['one']}}}\n        }\n        assert getters.single_data_path(client, node_id)\n\n    def test_two_data_paths(self):\n        \"\"\"test_two_data_paths\n\n        Return value should be False with two data paths\n        \"\"\"\n        node_id = 'my_node'\n        client = Mock()\n        client.nodes.stats.return_value = {\n            'nodes': {node_id: {'fs': {'data': ['one', 'two']}}}\n        }\n        assert not getters.single_data_path(client, node_id)\n\n\nclass TestNameToNodeId(TestCase):\n    \"\"\"TestNameToNodeId\n\n    Test helpers.getters.name_to_node_id functionality.\n    \"\"\"\n\n    def test_positive(self):\n        \"\"\"test_positive\n\n        Output should match expected\n        \"\"\"\n        node_id = 'node_id'\n        node_name = 'node_name'\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'name': node_name}}}\n        assert node_id == getters.name_to_node_id(client, node_name)\n\n    def test_negative(self):\n        \"\"\"test_negative\n\n        Output should be None due to mismatch\n        \"\"\"\n        node_id = 'node_id'\n        node_name = 'node_name'\n        client = Mock()\n        client.nodes.info.return_value = {'nodes': {node_id: {'name': node_name}}}\n        assert None is getters.name_to_node_id(client, 'wrong_name')\n\n\nclass TestNodeIdToName(TestCase):\n    \"\"\"TestNodeIdToName\n\n    Test helpers.getters.node_id_to_name functionality.\n    \"\"\"\n\n    def test_negative(self):\n        \"\"\"test_negative\n\n        Output should be None due to mismatch\n        \"\"\"\n        client = Mock()\n        client.nodes.info.return_value = {\n            'nodes': {'my_node_id': {'name': 'my_node_name'}}\n        }\n        assert None is getters.node_id_to_name(client, 'not_my_node_id')\n\n\nclass TestGetAliasActions(TestCase):\n    \"\"\"TestGetAliasActions\n\n    Test helpers.getters.get_alias_actions functionality.\n    \"\"\"\n\n    def test_get_alias_actions(self):\n        \"\"\"test_get_alias_actions\"\"\"\n        name = 'alias1'\n        aliases = {name: {}}\n        oldidx = 'old'\n        newidx = 'new'\n        expected = [\n            {'remove': {'index': oldidx, 'alias': name}},\n            {'add': {'index': newidx, 'alias': name}},\n        ]\n        assert getters.get_alias_actions(oldidx, newidx, aliases) == expected\n\n\nclass TestGetTierPreference(TestCase):\n    \"\"\"TestGetTierPreference\n\n    Test helpers.getters.get_tier_preference functionality.\n    \"\"\"\n\n    def test_get_tier_preference1(self):\n        \"\"\"test_get_tier_preference1\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_frozen', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_frozen'\n\n    def test_get_tier_preference2(self):\n        \"\"\"test_get_tier_preference2\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_cold,data_warm,data_hot'\n\n    def test_get_tier_preference3(self):\n        \"\"\"test_get_tier_preference3\"\"\"\n        client = Mock()\n        roles = ['data_content']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert getters.get_tier_preference(client) == 'data_content'\n\n    def test_get_tier_preference4(self):\n        \"\"\"test_get_tier_preference4\"\"\"\n        client = Mock()\n        roles = ['data_cold', 'data_frozen', 'data_hot', 'data_warm']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert (\n            getters.get_tier_preference(client, target_tier='data_cold')\n            == 'data_cold,data_warm,data_hot'\n        )\n\n    def test_get_tier_preference5(self):\n        \"\"\"test_get_tier_preference5\"\"\"\n        client = Mock()\n        roles = ['data_content']\n        client.nodes.info.return_value = {'nodes': {'nodename': {'roles': roles}}}\n        assert (\n            getters.get_tier_preference(client, target_tier='data_hot')\n            == 'data_content'\n        )\n",
  "GT_file_code": {
    "curator/helpers/getters.py": "\"\"\"Utility functions that get things\"\"\"\n\nimport logging\nfrom elasticsearch8 import exceptions as es8exc\nfrom curator.exceptions import (\n    ConfigurationError,\n    CuratorException,\n    FailedExecution,\n    MissingArgument,\n)\n\n\ndef byte_size(num, suffix='B'):\n    \"\"\"\n    :param num: The number of byte\n    :param suffix: An arbitrary suffix, like ``Bytes``\n\n    :type num: int\n    :type suffix: str\n\n    :returns: A formatted string indicating the size in bytes, with the proper unit,\n        e.g. KB, MB, GB, TB, etc.\n    :rtype: float\n    \"\"\"\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return f'{num:3.1f}{unit}{suffix}'\n        num /= 1024.0\n    return f'{num:.1f}Y{suffix}'\n\n\ndef escape_dots(stringval):\n    \"\"\"\n    Escape any dots (periods) in ``stringval``.\n\n    Primarily used for ``filter_path`` where dots are indicators of path nesting\n\n    :param stringval: A string, ostensibly an index name\n\n    :type stringval: str\n\n    :returns: ``stringval``, but with any periods escaped with a backslash\n    :retval: str\n    \"\"\"\n    return stringval.replace('.', r'\\.')\n\n\ndef get_alias_actions(oldidx, newidx, aliases):\n    \"\"\"\n    :param oldidx: The old index name\n    :param newidx: The new index name\n    :param aliases: The aliases\n\n    :type oldidx: str\n    :type newidx: str\n    :type aliases: dict\n\n    :returns: A list of actions suitable for\n        :py:meth:`~.elasticsearch.client.IndicesClient.update_aliases` ``actions``\n        kwarg.\n    :rtype: list\n    \"\"\"\n    actions = []\n    for alias in aliases.keys():\n        actions.append({'remove': {'index': oldidx, 'alias': alias}})\n        actions.append({'add': {'index': newidx, 'alias': alias}})\n    return actions\n\n\ndef get_data_tiers(client):\n    \"\"\"\n    Get all valid data tiers from the node roles of each node in the cluster by\n    polling each node\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The available data tiers in ``tier: bool`` form.\n    :rtype: dict\n    \"\"\"\n\n    def role_check(role, node_info):\n        if role in node_info['roles']:\n            return True\n        return False\n\n    info = client.nodes.info()['nodes']\n    retval = {\n        'data_hot': False,\n        'data_warm': False,\n        'data_cold': False,\n        'data_frozen': False,\n    }\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            # This guarantees we don't overwrite a True with a False.\n            # We only add True values\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval\n\n\ndef get_indices(client, search_pattern='_all'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.CatClient.indices`\n\n    :param client: A client connection object\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n    :returns: The current list of indices from the cluster\n    :rtype: list\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    indices = []\n    try:\n        # Doing this in two stages because IndexList also calls for these args,\n        # and the unit tests need to Mock this call the same exact way.\n        resp = client.cat.indices(\n            index=search_pattern,\n            expand_wildcards='open,closed',\n            h='index,status',\n            format='json',\n        )\n    except Exception as err:\n        raise FailedExecution(f'Failed to get indices. Error: {err}') from err\n    if not resp:\n        return indices\n    for entry in resp:\n        indices.append(entry['index'])\n    logger.debug('All indices: %s', indices)\n    return indices\n\n\ndef get_repository(client, repository=''):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get_repository`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n\n    :returns: Configuration information for ``repository``.\n    :rtype: dict\n    \"\"\"\n    try:\n        return client.snapshot.get_repository(name=repository)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get repository {repository}.  Error: {err} Check Elasticsearch '\n            f'logs for more information.'\n        )\n        raise CuratorException(msg) from err\n\n\ndef get_snapshot(client, repository=None, snapshot=''):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n    :param snapshot: The snapshot name, or a comma-separated list of snapshots\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n    :type snapshot: str\n\n    :returns: Information about the provided ``snapshot``, a snapshot (or a\n        comma-separated list of snapshots). If no snapshot specified, it will\n        collect info for all snapshots.  If none exist, an empty :py:class:`dict`\n        will be returned.\n    :rtype: dict\n    \"\"\"\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    snapname = '*' if snapshot == '' else snapshot\n    try:\n        return client.snapshot.get(repository=repository, snapshot=snapshot)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get information about snapshot {snapname} from repository: '\n            f'{repository}.  Error: {err}'\n        )\n        raise FailedExecution(msg) from err\n\n\ndef get_snapshot_data(client, repository=None):\n    \"\"\"\n    Get all snapshots from repository and return a list.\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\n\n    :param client: A client connection object\n    :param repository: The Elasticsearch snapshot repository to use\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type repository: str\n\n    :returns: The list of all snapshots from ``repository``\n    :rtype: list\n    \"\"\"\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    try:\n        return client.snapshot.get(repository=repository, snapshot=\"*\")['snapshots']\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = (\n            f'Unable to get snapshot information from repository: '\n            f'{repository}. Error: {err}'\n        )\n        raise FailedExecution(msg) from err\n\n\ndef get_tier_preference(client, target_tier='data_frozen'):\n    \"\"\"Do the tier preference thing in reverse order from coldest to hottest\n    Based on the value of ``target_tier``, build out the list to use.\n\n    :param client: A client connection object\n    :param target_tier: The target data tier, e.g. data_warm.\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type target_tier: str\n\n    :returns: A suitable tier preference string in csv format\n    :rtype: str\n    \"\"\"\n    tiermap = {\n        'data_content': 0,\n        'data_hot': 1,\n        'data_warm': 2,\n        'data_cold': 3,\n        'data_frozen': 4,\n    }\n    tiers = get_data_tiers(client)\n    test_list = []\n    for tier in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n        if tier in tiers and tiermap[tier] <= tiermap[target_tier]:\n            test_list.insert(0, tier)\n    if target_tier == 'data_frozen':\n        # We're migrating to frozen here. If a frozen tier exists, frozen searchable\n        # snapshot mounts should only ever go to the frozen tier.\n        if 'data_frozen' in tiers and tiers['data_frozen']:\n            return 'data_frozen'\n    # If there are no  nodes with the 'data_frozen' role...\n    preflist = []\n    for key in test_list:\n        # This ordering ensures that colder tiers are prioritized\n        if key in tiers and tiers[key]:\n            preflist.append(key)\n    # If all of these are false, then we have no data tiers and must use 'data_content'\n    if not preflist:\n        return 'data_content'\n    # This will join from coldest to hottest as csv string,\n    # e.g. 'data_cold,data_warm,data_hot'\n    return ','.join(preflist)\n\n\ndef get_write_index(client, alias):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param alias: An alias name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type alias: str\n\n    :returns: The the index name associated with the alias that is designated\n        ``is_write_index``\n    :rtype: str\n    \"\"\"\n    try:\n        response = client.indices.get_alias(index=alias)\n    except Exception as exc:\n        raise CuratorException(f'Alias {alias} not found') from exc\n    # If there are more than one in the list, one needs to be the write index\n    # otherwise the alias is a one to many, and can't do rollover.\n    retval = None\n    if len(list(response.keys())) > 1:\n        for index in list(response.keys()):\n            try:\n                if response[index]['aliases'][alias]['is_write_index']:\n                    retval = index\n            except KeyError as exc:\n                raise FailedExecution(\n                    'Invalid alias: is_write_index not found in 1 to many alias'\n                ) from exc\n    else:\n        # There's only one, so this is it\n        retval = list(response.keys())[0]\n    return retval\n\n\ndef index_size(client, idx, value='total'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.stats`\n\n    :param client: A client connection object\n    :param idx: An index name\n    :param value: One of either ``primaries`` or ``total``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type value: str\n\n    :returns: The sum of either ``primaries`` or ``total`` shards for index ``idx``\n    :rtype: integer\n    \"\"\"\n    fpath = f'indices.{escape_dots(idx)}.{value}.store.size_in_bytes'\n    return client.indices.stats(index=idx, filter_path=fpath)['indices'][idx][value][\n        'store'\n    ]['size_in_bytes']\n\n\ndef meta_getter(client, idx, get=None):\n    \"\"\"Meta Getter\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_settings` or\n    :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param idx: An Elasticsearch index\n    :param get: The kind of get to perform, e.g. settings or alias\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type get: str\n\n    :returns: The settings from the get call to the named index\n    :rtype: dict\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    acceptable = ['settings', 'alias']\n    if not get:\n        raise ConfigurationError('\"get\" can not be a NoneType')\n    if get not in acceptable:\n        raise ConfigurationError(f'\"get\" must be one of {acceptable}')\n    retval = {}\n    try:\n        if get == 'settings':\n            retval = client.indices.get_settings(index=idx)[idx]['settings']['index']\n        elif get == 'alias':\n            retval = client.indices.get_alias(index=idx)[idx]['aliases']\n    except es8exc.NotFoundError as missing:\n        logger.error('Index %s was not found!', idx)\n        raise es8exc.NotFoundError from missing\n    except KeyError as err:\n        logger.error('Key not found: %s', err)\n        raise KeyError from err\n    # pylint: disable=broad-except\n    except Exception as exc:\n        logger.error('Exception encountered: %s', exc)\n    return retval\n\n\ndef name_to_node_id(client, name):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param name: The node ``name``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type name: str\n\n    :returns: The node_id of the node identified by ``name``\n    :rtype: str\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    fpath = 'nodes'\n    info = client.nodes.info(filter_path=fpath)\n    for node in info['nodes']:\n        if info['nodes'][node]['name'] == name:\n            logger.debug('Found node_id \"%s\" for name \"%s\".', node, name)\n            return node\n    logger.error('No node_id found matching name: \"%s\"', name)\n    return None\n\n\ndef node_id_to_name(client, node_id):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: The name of the node identified by ``node_id``\n    :rtype: str\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    fpath = f'nodes.{node_id}.name'\n    info = client.nodes.info(filter_path=fpath)\n    name = None\n    if node_id in info['nodes']:\n        name = info['nodes'][node_id]['name']\n    else:\n        logger.error('No node_id found matching: \"%s\"', node_id)\n    logger.debug('Name associated with node_id \"%s\": %s', node_id, name)\n    return name\n\n\ndef node_roles(client, node_id):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: The list of roles assigned to the node identified by ``node_id``\n    :rtype: list\n    \"\"\"\n    fpath = f'nodes.{node_id}.roles'\n    return client.nodes.info(filter_path=fpath)['nodes'][node_id]['roles']\n\n\ndef single_data_path(client, node_id):\n    \"\"\"\n    In order for a shrink to work, it should be on a single filesystem, as shards\n    cannot span filesystems. Calls :py:meth:`~.elasticsearch.client.NodesClient.stats`\n\n    :param client: A client connection object\n    :param node_id: The node ``node_id``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type node_id: str\n\n    :returns: ``True`` if the node has a single filesystem, else ``False``\n    :rtype: bool\n    \"\"\"\n    fpath = f'nodes.{node_id}.fs.data'\n    response = client.nodes.stats(filter_path=fpath)\n    return len(response['nodes'][node_id]['fs']['data']) == 1\n",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\"\n"
  },
  "GT_src_dict": {
    "curator/helpers/getters.py": {
      "byte_size": {
        "code": "def byte_size(num, suffix='B'):\n    \"\"\"Converts a given number of bytes into a formatted string representation with appropriate size units (e.g., KB, MB, GB). \n\nParameters:\n- num (int): The number of bytes to convert.\n- suffix (str): An optional suffix to append to the size string (default is 'B').\n\nReturns:\n- str: A formatted string indicating the size in bytes with the appropriate unit. The function accommodates sizes up to yottabytes (Y).\n\nThis function iteratively divides the input number by 1024, switching to the next unit in the series, until the absolute value is less than 1024.\"\"\"\n    '\\n    :param num: The number of byte\\n    :param suffix: An arbitrary suffix, like ``Bytes``\\n\\n    :type num: int\\n    :type suffix: str\\n\\n    :returns: A formatted string indicating the size in bytes, with the proper unit,\\n        e.g. KB, MB, GB, TB, etc.\\n    :rtype: float\\n    '\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return f'{num:3.1f}{unit}{suffix}'\n        num /= 1024.0\n    return f'{num:.1f}Y{suffix}'",
        "docstring": "Converts a given number of bytes into a formatted string representation with appropriate size units (e.g., KB, MB, GB). \n\nParameters:\n- num (int): The number of bytes to convert.\n- suffix (str): An optional suffix to append to the size string (default is 'B').\n\nReturns:\n- str: A formatted string indicating the size in bytes with the appropriate unit. The function accommodates sizes up to yottabytes (Y).\n\nThis function iteratively divides the input number by 1024, switching to the next unit in the series, until the absolute value is less than 1024.",
        "signature": "def byte_size(num, suffix='B'):",
        "type": "Function",
        "class_signature": null
      },
      "get_alias_actions": {
        "code": "def get_alias_actions(oldidx, newidx, aliases):\n    \"\"\"Generates a list of alias update actions for transitioning from an old Elasticsearch index to a new one.\n\n:param oldidx: The name of the index from which aliases will be removed.\n:type oldidx: str\n:param newidx: The name of the index to which aliases will be added.\n:type newidx: str\n:param aliases: A dictionary of aliases that need to be updated, with alias names as keys.\n:type aliases: dict\n\n:returns: A list of actions suitable for the `update_aliases` method of the Elasticsearch IndicesClient, which includes 'remove' actions for the old index and 'add' actions for the new index.\n:rtype: list\n\nThis function constructs the required actions to update index aliases during index rollovers or renames, ensuring that all specified aliases point to the correct index. No constants are directly used within the function; it relies on the input parameters provided when called.\"\"\"\n    '\\n    :param oldidx: The old index name\\n    :param newidx: The new index name\\n    :param aliases: The aliases\\n\\n    :type oldidx: str\\n    :type newidx: str\\n    :type aliases: dict\\n\\n    :returns: A list of actions suitable for\\n        :py:meth:`~.elasticsearch.client.IndicesClient.update_aliases` ``actions``\\n        kwarg.\\n    :rtype: list\\n    '\n    actions = []\n    for alias in aliases.keys():\n        actions.append({'remove': {'index': oldidx, 'alias': alias}})\n        actions.append({'add': {'index': newidx, 'alias': alias}})\n    return actions",
        "docstring": "Generates a list of alias update actions for transitioning from an old Elasticsearch index to a new one.\n\n:param oldidx: The name of the index from which aliases will be removed.\n:type oldidx: str\n:param newidx: The name of the index to which aliases will be added.\n:type newidx: str\n:param aliases: A dictionary of aliases that need to be updated, with alias names as keys.\n:type aliases: dict\n\n:returns: A list of actions suitable for the `update_aliases` method of the Elasticsearch IndicesClient, which includes 'remove' actions for the old index and 'add' actions for the new index.\n:rtype: list\n\nThis function constructs the required actions to update index aliases during index rollovers or renames, ensuring that all specified aliases point to the correct index. No constants are directly used within the function; it relies on the input parameters provided when called.",
        "signature": "def get_alias_actions(oldidx, newidx, aliases):",
        "type": "Function",
        "class_signature": null
      },
      "get_data_tiers": {
        "code": "def get_data_tiers(client):\n    \"\"\"Get the valid data tiers based on the roles of each node in an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: A dictionary with boolean values indicating the presence of each data tier: `data_hot`, `data_warm`, `data_cold`, and `data_frozen`.\n:rtype: dict\n\nThis function polls each node in the cluster to check for specific roles related to data tiers. The function uses a helper function, `role_check`, to determine if a role exists in a node's roles. The initial return value dictionary (`retval`) lists all data tiers as `False`, ensuring that only existing tiers are marked as `True` based on the nodes' configurations. The significance of the data tiers lies in their use for data organization and retrieval in Elasticsearch, impacting how data is allocated and queried within the cluster.\"\"\"\n    '\\n    Get all valid data tiers from the node roles of each node in the cluster by\\n    polling each node\\n\\n    :param client: A client connection object\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n\\n    :returns: The available data tiers in ``tier: bool`` form.\\n    :rtype: dict\\n    '\n\n    def role_check(role, node_info):\n        \"\"\"Check if a specified role exists in the provided node information.\n\n:param role: The name of the role to check for within the node's roles.\n:type role: str\n:param node_info: A dictionary containing information about the node, including its roles.\n:type node_info: dict\n\n:returns: True if the role is present in the node's roles; otherwise, False.\n:rtype: bool\n\nThis function is used internally in the `get_data_tiers` function to determine the presence of specific data roles (e.g., 'data_hot', 'data_warm', etc.) in the Elasticsearch node configuration.\"\"\"\n        if role in node_info['roles']:\n            return True\n        return False\n    info = client.nodes.info()['nodes']\n    retval = {'data_hot': False, 'data_warm': False, 'data_cold': False, 'data_frozen': False}\n    for node in info:\n        for role in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n            if role_check(role, info[node]):\n                retval[role] = True\n    return retval",
        "docstring": "Get the valid data tiers based on the roles of each node in an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: A dictionary with boolean values indicating the presence of each data tier: `data_hot`, `data_warm`, `data_cold`, and `data_frozen`.\n:rtype: dict\n\nThis function polls each node in the cluster to check for specific roles related to data tiers. The function uses a helper function, `role_check`, to determine if a role exists in a node's roles. The initial return value dictionary (`retval`) lists all data tiers as `False`, ensuring that only existing tiers are marked as `True` based on the nodes' configurations. The significance of the data tiers lies in their use for data organization and retrieval in Elasticsearch, impacting how data is allocated and queried within the cluster.",
        "signature": "def get_data_tiers(client):",
        "type": "Function",
        "class_signature": null
      },
      "get_indices": {
        "code": "def get_indices(client, search_pattern='_all'):\n    \"\"\"Retrieve the list of indices in the Elasticsearch cluster.\n\nThis function interacts with the Elasticsearch client's `CatClient` to obtain the current list of indices based on the provided search pattern. It expands wildcards to include both open and closed indices, and retrieves relevant index details in JSON format.\n\n:param client: A client connection object for interacting with Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param search_pattern: A pattern for filtering the indices (default is '_all' to retrieve all indices).\n:type search_pattern: str\n\n:returns: A list of index names currently present in the cluster.\n:rtype: list\n\n:raises FailedExecution: If there is an error in retrieving the indices from the Elasticsearch cluster.\n\nThis function uses the `logging` module to log the list of indices. The `expand_wildcards` parameter is set to include both open and closed indices, and the response is handled to extract just the index names for return.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.CatClient.indices`\\n\\n    :param client: A client connection object\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n\\n    :returns: The current list of indices from the cluster\\n    :rtype: list\\n    '\n    logger = logging.getLogger(__name__)\n    indices = []\n    try:\n        resp = client.cat.indices(index=search_pattern, expand_wildcards='open,closed', h='index,status', format='json')\n    except Exception as err:\n        raise FailedExecution(f'Failed to get indices. Error: {err}') from err\n    if not resp:\n        return indices\n    for entry in resp:\n        indices.append(entry['index'])\n    logger.debug('All indices: %s', indices)\n    return indices",
        "docstring": "Retrieve the list of indices in the Elasticsearch cluster.\n\nThis function interacts with the Elasticsearch client's `CatClient` to obtain the current list of indices based on the provided search pattern. It expands wildcards to include both open and closed indices, and retrieves relevant index details in JSON format.\n\n:param client: A client connection object for interacting with Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param search_pattern: A pattern for filtering the indices (default is '_all' to retrieve all indices).\n:type search_pattern: str\n\n:returns: A list of index names currently present in the cluster.\n:rtype: list\n\n:raises FailedExecution: If there is an error in retrieving the indices from the Elasticsearch cluster.\n\nThis function uses the `logging` module to log the list of indices. The `expand_wildcards` parameter is set to include both open and closed indices, and the response is handled to extract just the index names for return.",
        "signature": "def get_indices(client, search_pattern='_all'):",
        "type": "Function",
        "class_signature": null
      },
      "get_repository": {
        "code": "def get_repository(client, repository=''):\n    \"\"\"Retrieve configuration information for a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository to query. If not specified, defaults to an empty string.\n:type repository: str\n\n:returns: A dictionary containing configuration details of the specified snapshot repository.\n:rtype: dict\n\n:raises CuratorException: If the repository cannot be retrieved due to a TransportError or NotFoundError, this exception is raised with a message indicating the failure and suggesting to check the Elasticsearch logs for more details.\n\nThis function utilizes the `client.snapshot.get_repository` method from the Elasticsearch Python client to fetch repository details. It handles exceptions specific to the Elasticsearch library, demonstrating dependency on the `elasticsearch8` package for access to snapshot operations.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get_repository`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n\\n    :returns: Configuration information for ``repository``.\\n    :rtype: dict\\n    '\n    try:\n        return client.snapshot.get_repository(name=repository)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get repository {repository}.  Error: {err} Check Elasticsearch logs for more information.'\n        raise CuratorException(msg) from err",
        "docstring": "Retrieve configuration information for a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository to query. If not specified, defaults to an empty string.\n:type repository: str\n\n:returns: A dictionary containing configuration details of the specified snapshot repository.\n:rtype: dict\n\n:raises CuratorException: If the repository cannot be retrieved due to a TransportError or NotFoundError, this exception is raised with a message indicating the failure and suggesting to check the Elasticsearch logs for more details.\n\nThis function utilizes the `client.snapshot.get_repository` method from the Elasticsearch Python client to fetch repository details. It handles exceptions specific to the Elasticsearch library, demonstrating dependency on the `elasticsearch8` package for access to snapshot operations.",
        "signature": "def get_repository(client, repository=''):",
        "type": "Function",
        "class_signature": null
      },
      "get_snapshot": {
        "code": "def get_snapshot(client, repository=None, snapshot=''):\n    \"\"\"Retrieve information about a specified snapshot from a given Elasticsearch repository.\n\nThis function interacts with the Elasticsearch Snapshot API to fetch details about a specific snapshot or all snapshots in a repository. If no snapshot is specified, it retrieves information for all available snapshots, returning an empty dictionary if none exist. The function raises a MissingArgument exception if the repository parameter is not provided and a FailedExecution exception if there are errors during the API call.\n\nParameters:\n- client (Elasticsearch): A connection object to the Elasticsearch cluster.\n- repository (str): The name of the Elasticsearch snapshot repository from which to retrieve snapshot information.\n- snapshot (str): The name of the snapshot or a comma-separated list of snapshots to obtain info for. If left empty, all snapshots are queried.\n\nReturns:\n- dict: A dictionary containing information about the specified snapshot(s) from the repository.\n\nExceptions:\n- Raises MissingArgument if the repository is not specified.\n- Raises FailedExecution if there is a transport error or if the specified snapshot cannot be found in the repository.\n\nDependencies:\n- Uses `es8exc.TransportError` and `es8exc.NotFoundError` from the elasticsearch8.exceptions module for error handling.\n- Relies on the Elasticsearch Snapshot Client's `get` method for interaction with the Elasticsearch cluster.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n    :param snapshot: The snapshot name, or a comma-separated list of snapshots\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n    :type snapshot: str\\n\\n    :returns: Information about the provided ``snapshot``, a snapshot (or a\\n        comma-separated list of snapshots). If no snapshot specified, it will\\n        collect info for all snapshots.  If none exist, an empty :py:class:`dict`\\n        will be returned.\\n    :rtype: dict\\n    '\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    snapname = '*' if snapshot == '' else snapshot\n    try:\n        return client.snapshot.get(repository=repository, snapshot=snapshot)\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get information about snapshot {snapname} from repository: {repository}.  Error: {err}'\n        raise FailedExecution(msg) from err",
        "docstring": "Retrieve information about a specified snapshot from a given Elasticsearch repository.\n\nThis function interacts with the Elasticsearch Snapshot API to fetch details about a specific snapshot or all snapshots in a repository. If no snapshot is specified, it retrieves information for all available snapshots, returning an empty dictionary if none exist. The function raises a MissingArgument exception if the repository parameter is not provided and a FailedExecution exception if there are errors during the API call.\n\nParameters:\n- client (Elasticsearch): A connection object to the Elasticsearch cluster.\n- repository (str): The name of the Elasticsearch snapshot repository from which to retrieve snapshot information.\n- snapshot (str): The name of the snapshot or a comma-separated list of snapshots to obtain info for. If left empty, all snapshots are queried.\n\nReturns:\n- dict: A dictionary containing information about the specified snapshot(s) from the repository.\n\nExceptions:\n- Raises MissingArgument if the repository is not specified.\n- Raises FailedExecution if there is a transport error or if the specified snapshot cannot be found in the repository.\n\nDependencies:\n- Uses `es8exc.TransportError` and `es8exc.NotFoundError` from the elasticsearch8.exceptions module for error handling.\n- Relies on the Elasticsearch Snapshot Client's `get` method for interaction with the Elasticsearch cluster.",
        "signature": "def get_snapshot(client, repository=None, snapshot=''):",
        "type": "Function",
        "class_signature": null
      },
      "get_snapshot_data": {
        "code": "def get_snapshot_data(client, repository=None):\n    \"\"\"Get all snapshots from the specified Elasticsearch snapshot repository and return them as a list.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository from which to retrieve snapshots.\n:type repository: str\n\n:raises MissingArgument: If no value for the `repository` parameter is provided.\n:raises FailedExecution: If there is an issue retrieving the snapshot information from the repository, e.g., due to network errors or a non-existent repository.\n\n:returns: A list of all snapshots found in the specified repository.\n:rtype: list\n\nThe function interacts with the Elasticsearch SnapshotClient to fetch snapshot data. It calls the `get` method with `snapshot=\"*\"` to retrieve all snapshots. The actual response is filtered to the `['snapshots']` key to obtain the desired data. This function is reliant on the `es8exc` exception classes to handle specific errors related to Elasticsearch operations.\"\"\"\n    '\\n    Get all snapshots from repository and return a list.\\n    Calls :py:meth:`~.elasticsearch.client.SnapshotClient.get`\\n\\n    :param client: A client connection object\\n    :param repository: The Elasticsearch snapshot repository to use\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type repository: str\\n\\n    :returns: The list of all snapshots from ``repository``\\n    :rtype: list\\n    '\n    if not repository:\n        raise MissingArgument('No value for \"repository\" provided')\n    try:\n        return client.snapshot.get(repository=repository, snapshot='*')['snapshots']\n    except (es8exc.TransportError, es8exc.NotFoundError) as err:\n        msg = f'Unable to get snapshot information from repository: {repository}. Error: {err}'\n        raise FailedExecution(msg) from err",
        "docstring": "Get all snapshots from the specified Elasticsearch snapshot repository and return them as a list.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository from which to retrieve snapshots.\n:type repository: str\n\n:raises MissingArgument: If no value for the `repository` parameter is provided.\n:raises FailedExecution: If there is an issue retrieving the snapshot information from the repository, e.g., due to network errors or a non-existent repository.\n\n:returns: A list of all snapshots found in the specified repository.\n:rtype: list\n\nThe function interacts with the Elasticsearch SnapshotClient to fetch snapshot data. It calls the `get` method with `snapshot=\"*\"` to retrieve all snapshots. The actual response is filtered to the `['snapshots']` key to obtain the desired data. This function is reliant on the `es8exc` exception classes to handle specific errors related to Elasticsearch operations.",
        "signature": "def get_snapshot_data(client, repository=None):",
        "type": "Function",
        "class_signature": null
      },
      "get_tier_preference": {
        "code": "def get_tier_preference(client, target_tier='data_frozen'):\n    \"\"\"Determine the appropriate tier preference string for Elasticsearch data nodes based on the specified target data tier. The function builds a preference list by first checking the available data tiers in the cluster through the `get_data_tiers` function, which returns a dictionary indicating the presence of various data roles.\n\nParameters:\n- client: An instance of the Elasticsearch client, used to interact with the Elasticsearch cluster.\n- target_tier: A string representing the desired tier (e.g., 'data_warm'). The default is 'data_frozen'.\n\nReturns:\n- A comma-separated string indicating the preferred data tiers from coldest to hottest (e.g., 'data_cold,data_warm,data_hot'). If no valid tiers are found, it defaults to returning 'data_content'.\n\nConstants:\n- tiermap: A dictionary mapping tier names to their priority levels, with 'data_content' at the lowest (0) and 'data_frozen' at the highest (4). This mapping determines the order in which tiers are considered when building the preference list.\n\nInteractions:\nThe function utilizes the `get_data_tiers` function to retrieve the statuses of available data tiers in the cluster, which directly influences the output of tier preferences.\"\"\"\n    'Do the tier preference thing in reverse order from coldest to hottest\\n    Based on the value of ``target_tier``, build out the list to use.\\n\\n    :param client: A client connection object\\n    :param target_tier: The target data tier, e.g. data_warm.\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type target_tier: str\\n\\n    :returns: A suitable tier preference string in csv format\\n    :rtype: str\\n    '\n    tiermap = {'data_content': 0, 'data_hot': 1, 'data_warm': 2, 'data_cold': 3, 'data_frozen': 4}\n    tiers = get_data_tiers(client)\n    test_list = []\n    for tier in ['data_hot', 'data_warm', 'data_cold', 'data_frozen']:\n        if tier in tiers and tiermap[tier] <= tiermap[target_tier]:\n            test_list.insert(0, tier)\n    if target_tier == 'data_frozen':\n        if 'data_frozen' in tiers and tiers['data_frozen']:\n            return 'data_frozen'\n    preflist = []\n    for key in test_list:\n        if key in tiers and tiers[key]:\n            preflist.append(key)\n    if not preflist:\n        return 'data_content'\n    return ','.join(preflist)",
        "docstring": "Determine the appropriate tier preference string for Elasticsearch data nodes based on the specified target data tier. The function builds a preference list by first checking the available data tiers in the cluster through the `get_data_tiers` function, which returns a dictionary indicating the presence of various data roles.\n\nParameters:\n- client: An instance of the Elasticsearch client, used to interact with the Elasticsearch cluster.\n- target_tier: A string representing the desired tier (e.g., 'data_warm'). The default is 'data_frozen'.\n\nReturns:\n- A comma-separated string indicating the preferred data tiers from coldest to hottest (e.g., 'data_cold,data_warm,data_hot'). If no valid tiers are found, it defaults to returning 'data_content'.\n\nConstants:\n- tiermap: A dictionary mapping tier names to their priority levels, with 'data_content' at the lowest (0) and 'data_frozen' at the highest (4). This mapping determines the order in which tiers are considered when building the preference list.\n\nInteractions:\nThe function utilizes the `get_data_tiers` function to retrieve the statuses of available data tiers in the cluster, which directly influences the output of tier preferences.",
        "signature": "def get_tier_preference(client, target_tier='data_frozen'):",
        "type": "Function",
        "class_signature": null
      },
      "name_to_node_id": {
        "code": "def name_to_node_id(client, name):\n    \"\"\"Retrieve the node ID corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object to the Elasticsearch cluster, enabling communication with the nodes.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node for which the ID is requested.\n:type name: str\n\n:returns: The node ID associated with the specified node name, or `None` if no matching node is found.\n:rtype: str\n\nThis function interacts with the Elasticsearch client to fetch node information. It uses the `info` method from `NodesClient` to retrieve details about all nodes in the cluster, filtering for node names. The function logs debug messages for successful and failed attempts to find the node ID. Constants include `fpath`, which indicates the filter path for retrieving node information. If the node name exists, it returns the associated node ID; otherwise, it returns `None`.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param name: The node ``name``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type name: str\\n\\n    :returns: The node_id of the node identified by ``name``\\n    :rtype: str\\n    '\n    logger = logging.getLogger(__name__)\n    fpath = 'nodes'\n    info = client.nodes.info(filter_path=fpath)\n    for node in info['nodes']:\n        if info['nodes'][node]['name'] == name:\n            logger.debug('Found node_id \"%s\" for name \"%s\".', node, name)\n            return node\n    logger.error('No node_id found matching name: \"%s\"', name)\n    return None",
        "docstring": "Retrieve the node ID corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object to the Elasticsearch cluster, enabling communication with the nodes.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node for which the ID is requested.\n:type name: str\n\n:returns: The node ID associated with the specified node name, or `None` if no matching node is found.\n:rtype: str\n\nThis function interacts with the Elasticsearch client to fetch node information. It uses the `info` method from `NodesClient` to retrieve details about all nodes in the cluster, filtering for node names. The function logs debug messages for successful and failed attempts to find the node ID. Constants include `fpath`, which indicates the filter path for retrieving node information. If the node name exists, it returns the associated node ID; otherwise, it returns `None`.",
        "signature": "def name_to_node_id(client, name):",
        "type": "Function",
        "class_signature": null
      },
      "node_id_to_name": {
        "code": "def node_id_to_name(client, node_id):\n    \"\"\"Retrieve the name of an Elasticsearch node based on the provided node ID.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The identifier of the node for which to retrieve the name.\n:type node_id: str\n\n:returns: The name of the node associated with the given `node_id`, or `None` if not found.\n:rtype: str\n\nThis function interacts with the Elasticsearch client's `NodesClient.info` method to obtain node information. It constructs a filter path based on the `node_id` to access the specific node's details. If the `node_id` is valid and found in the response, the corresponding node name is returned. A logger is used to record an error if no matching node ID is found, and a debug log for the associated name.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: The name of the node identified by ``node_id``\\n    :rtype: str\\n    '\n    logger = logging.getLogger(__name__)\n    fpath = f'nodes.{node_id}.name'\n    info = client.nodes.info(filter_path=fpath)\n    name = None\n    if node_id in info['nodes']:\n        name = info['nodes'][node_id]['name']\n    else:\n        logger.error('No node_id found matching: \"%s\"', node_id)\n    logger.debug('Name associated with node_id \"%s\": %s', node_id, name)\n    return name",
        "docstring": "Retrieve the name of an Elasticsearch node based on the provided node ID.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The identifier of the node for which to retrieve the name.\n:type node_id: str\n\n:returns: The name of the node associated with the given `node_id`, or `None` if not found.\n:rtype: str\n\nThis function interacts with the Elasticsearch client's `NodesClient.info` method to obtain node information. It constructs a filter path based on the `node_id` to access the specific node's details. If the `node_id` is valid and found in the response, the corresponding node name is returned. A logger is used to record an error if no matching node ID is found, and a debug log for the associated name.",
        "signature": "def node_id_to_name(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "node_roles": {
        "code": "def node_roles(client, node_id):\n    \"\"\"Retrieve the roles assigned to a specified Elasticsearch node.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node within the cluster.\n:type node_id: str\n\n:returns: A list of roles assigned to the specified node, such as ['data_hot', 'data_warm', etc.].\n:rtype: list\n\nThis function uses the Elasticsearch client to call `NodesClient.info`, filtering the response to obtain only the roles associated with the given `node_id`. It directly accesses the structure of the response where roles are stored under `['nodes'][node_id]['roles']`. The `node_id` must correspond to a valid node in the cluster for the function to return meaningful results.\"\"\"\n    '\\n    Calls :py:meth:`~.elasticsearch.client.NodesClient.info`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: The list of roles assigned to the node identified by ``node_id``\\n    :rtype: list\\n    '\n    fpath = f'nodes.{node_id}.roles'\n    return client.nodes.info(filter_path=fpath)['nodes'][node_id]['roles']",
        "docstring": "Retrieve the roles assigned to a specified Elasticsearch node.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node within the cluster.\n:type node_id: str\n\n:returns: A list of roles assigned to the specified node, such as ['data_hot', 'data_warm', etc.].\n:rtype: list\n\nThis function uses the Elasticsearch client to call `NodesClient.info`, filtering the response to obtain only the roles associated with the given `node_id`. It directly accesses the structure of the response where roles are stored under `['nodes'][node_id]['roles']`. The `node_id` must correspond to a valid node in the cluster for the function to return meaningful results.",
        "signature": "def node_roles(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "single_data_path": {
        "code": "def single_data_path(client, node_id):\n    \"\"\"Check if a specified Elasticsearch node is configured with a single filesystem.\n\nThis function retrieves the filesystem statistics of the node identified by `node_id`\nand determines whether it has a single data path. A single filesystem is essential for operations\nlike shard shrinking, as shards cannot span across multiple filesystems.\n\n:param client: A client connection object connected to the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The node identifier whose filesystem configuration is being checked.\n:type node_id: str\n\n:returns: ``True`` if the node has only one filesystem data path, otherwise ``False``.\n:rtype: bool\n\nThis function depends on the Elasticsearch client's `nodes.stats` method, using a filter path\nto retrieve data specifically about the filesystem of the specified node.\"\"\"\n    '\\n    In order for a shrink to work, it should be on a single filesystem, as shards\\n    cannot span filesystems. Calls :py:meth:`~.elasticsearch.client.NodesClient.stats`\\n\\n    :param client: A client connection object\\n    :param node_id: The node ``node_id``\\n\\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\\n    :type node_id: str\\n\\n    :returns: ``True`` if the node has a single filesystem, else ``False``\\n    :rtype: bool\\n    '\n    fpath = f'nodes.{node_id}.fs.data'\n    response = client.nodes.stats(filter_path=fpath)\n    return len(response['nodes'][node_id]['fs']['data']) == 1",
        "docstring": "Check if a specified Elasticsearch node is configured with a single filesystem.\n\nThis function retrieves the filesystem statistics of the node identified by `node_id`\nand determines whether it has a single data path. A single filesystem is essential for operations\nlike shard shrinking, as shards cannot span across multiple filesystems.\n\n:param client: A client connection object connected to the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The node identifier whose filesystem configuration is being checked.\n:type node_id: str\n\n:returns: ``True`` if the node has only one filesystem data path, otherwise ``False``.\n:rtype: bool\n\nThis function depends on the Elasticsearch client's `nodes.stats` method, using a filter path\nto retrieve data specifically about the filesystem of the specified node.",
        "signature": "def single_data_path(client, node_id):",
        "type": "Function",
        "class_signature": null
      },
      "role_check": {
        "code": "    def role_check(role, node_info):\n        \"\"\"Check if a specified role exists in the provided node information.\n\n:param role: The name of the role to check for within the node's roles.\n:type role: str\n:param node_info: A dictionary containing information about the node, including its roles.\n:type node_info: dict\n\n:returns: True if the role is present in the node's roles; otherwise, False.\n:rtype: bool\n\nThis function is used internally in the `get_data_tiers` function to determine the presence of specific data roles (e.g., 'data_hot', 'data_warm', etc.) in the Elasticsearch node configuration.\"\"\"\n        if role in node_info['roles']:\n            return True\n        return False",
        "docstring": "Check if a specified role exists in the provided node information.\n\n:param role: The name of the role to check for within the node's roles.\n:type role: str\n:param node_info: A dictionary containing information about the node, including its roles.\n:type node_info: dict\n\n:returns: True if the role is present in the node's roles; otherwise, False.\n:rtype: bool\n\nThis function is used internally in the `get_data_tiers` function to determine the presence of specific data roles (e.g., 'data_hot', 'data_warm', etc.) in the Elasticsearch node configuration.",
        "signature": "def role_check(role, node_info):",
        "type": "Function",
        "class_signature": null
      }
    },
    "curator/exceptions.py": {}
  },
  "dependency_dict": {
    "curator/helpers/getters.py:get_tier_preference": {},
    "curator/helpers/getters.py:get_data_tiers": {}
  },
  "call_tree": {
    "tests/unit/test_helpers_getters.py:TestByteSize:test_byte_size": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestByteSize:test_byte_size_yotta": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestByteSize:test_raise_invalid": {
      "curator/helpers/getters.py:byte_size": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_client_exception": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_empty": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetIndices:test_positive": {
      "curator/helpers/getters.py:get_indices": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_all_positive": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_missing_arg": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_notfounderror_negative": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_positive": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetRepository:test_get_repository_transporterror_negative": {
      "curator/helpers/getters.py:get_repository": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_missing_repository_arg": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_notfounderror_negative": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_positive": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshot:test_get_snapshot_transporterror_negative": {
      "curator/helpers/getters.py:get_snapshot": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_missing_repo_arg": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_raises_exception_onfail": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetSnapshotData:test_return_data": {
      "curator/helpers/getters.py:get_snapshot_data": {}
    },
    "tests/unit/test_helpers_getters.py:TestNodeRoles:test_node_roles": {
      "curator/helpers/getters.py:node_roles": {}
    },
    "tests/unit/test_helpers_getters.py:TestSingleDataPath:test_single_data_path": {
      "curator/helpers/getters.py:single_data_path": {}
    },
    "tests/unit/test_helpers_getters.py:TestSingleDataPath:test_two_data_paths": {
      "curator/helpers/getters.py:single_data_path": {}
    },
    "tests/unit/test_helpers_getters.py:TestNameToNodeId:test_negative": {
      "curator/helpers/getters.py:name_to_node_id": {}
    },
    "tests/unit/test_helpers_getters.py:TestNameToNodeId:test_positive": {
      "curator/helpers/getters.py:name_to_node_id": {}
    },
    "tests/unit/test_helpers_getters.py:TestNodeIdToName:test_negative": {
      "curator/helpers/getters.py:node_id_to_name": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetAliasActions:test_get_alias_actions": {
      "curator/helpers/getters.py:get_alias_actions": {}
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference1": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference2": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference3": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference4": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "tests/unit/test_helpers_getters.py:TestGetTierPreference:test_get_tier_preference5": {
      "curator/helpers/getters.py:get_tier_preference": {
        "curator/helpers/getters.py:get_data_tiers": {
          "curator/helpers/getters.py:role_check": {}
        }
      }
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_cli.py:TestCLIMethods:test_action_is_none": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_cli.py:TestCLIMethods:test_no_action": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    },
    "/mnt/sfs_turbo/yaxindu/tmp/elasticsearch_curator-image-test_helpers_getters/elasticsearch_curator-test_helpers_getters/tests/integration/test_integrations.py:TestFilters:test_filter_by_alias_bad_aliases": {
      "curator/exceptions.py:ConfigurationError:ConfigurationError": {}
    }
  },
  "PRD": "# PROJECT NAME: elasticsearch_curator-test_helpers_getters\n\n# FOLDER STRUCTURE:\n```\n..\n\u2514\u2500\u2500 curator/\n    \u251c\u2500\u2500 exceptions.py\n    \u2502   \u2514\u2500\u2500 ConfigurationError.ConfigurationError\n    \u2514\u2500\u2500 helpers/\n        \u2514\u2500\u2500 getters.py\n            \u251c\u2500\u2500 byte_size\n            \u251c\u2500\u2500 get_alias_actions\n            \u251c\u2500\u2500 get_data_tiers\n            \u251c\u2500\u2500 get_indices\n            \u251c\u2500\u2500 get_repository\n            \u251c\u2500\u2500 get_snapshot\n            \u251c\u2500\u2500 get_snapshot_data\n            \u251c\u2500\u2500 get_tier_preference\n            \u251c\u2500\u2500 name_to_node_id\n            \u251c\u2500\u2500 node_id_to_name\n            \u251c\u2500\u2500 node_roles\n            \u251c\u2500\u2500 role_check\n            \u2514\u2500\u2500 single_data_path\n```\n\n# IMPLEMENTATION REQUIREMENTS:\n## MODULE DESCRIPTION:\nThis module is designed to validate and test the functionality of helper methods within the `creators.helpers.getters` library, which interacts with Elasticsearch to retrieve and manipulate metadata, indices, snapshots, repositories, and node properties. It ensures the reliability of critical capabilities such as byte size formatting, fetching indices and repository details, snapshot management, node role identification, tier preference evaluation, and more. By rigorously testing various error scenarios and edge cases, the module provides a robust layer of assurance for developers working with Elasticsearch, streamlining debugging and optimizing interactions with the Elasticsearch API. This addresses the need for dependable utility functions, ensuring accurate data retrieval and minimizing unexpected failures during integration or execution.\n\n## FILE 1: curator/helpers/getters.py\n\n- FUNCTION NAME: get_alias_actions\n  - SIGNATURE: def get_alias_actions(oldidx, newidx, aliases):\n  - DOCSTRING: \n```python\n\"\"\"\nGenerates a list of alias update actions for transitioning from an old Elasticsearch index to a new one.\n\n:param oldidx: The name of the index from which aliases will be removed.\n:type oldidx: str\n:param newidx: The name of the index to which aliases will be added.\n:type newidx: str\n:param aliases: A dictionary of aliases that need to be updated, with alias names as keys.\n:type aliases: dict\n\n:returns: A list of actions suitable for the `update_aliases` method of the Elasticsearch IndicesClient, which includes 'remove' actions for the old index and 'add' actions for the new index.\n:rtype: list\n\nThis function constructs the required actions to update index aliases during index rollovers or renames, ensuring that all specified aliases point to the correct index. No constants are directly used within the function; it relies on the input parameters provided when called.\n\"\"\"\n```\n\n- FUNCTION NAME: name_to_node_id\n  - SIGNATURE: def name_to_node_id(client, name):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the node ID corresponding to a given node name from an Elasticsearch cluster.\n\n:param client: A client connection object to the Elasticsearch cluster, enabling communication with the nodes.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param name: The name of the node for which the ID is requested.\n:type name: str\n\n:returns: The node ID associated with the specified node name, or `None` if no matching node is found.\n:rtype: str\n\nThis function interacts with the Elasticsearch client to fetch node information. It uses the `info` method from `NodesClient` to retrieve details about all nodes in the cluster, filtering for node names. The function logs debug messages for successful and failed attempts to find the node ID. Constants include `fpath`, which indicates the filter path for retrieving node information. If the node name exists, it returns the associated node ID; otherwise, it returns `None`.\n\"\"\"\n```\n\n- FUNCTION NAME: get_data_tiers\n  - SIGNATURE: def get_data_tiers(client):\n  - DOCSTRING: \n```python\n\"\"\"\nGet the valid data tiers based on the roles of each node in an Elasticsearch cluster.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n\n:returns: A dictionary with boolean values indicating the presence of each data tier: `data_hot`, `data_warm`, `data_cold`, and `data_frozen`.\n:rtype: dict\n\nThis function polls each node in the cluster to check for specific roles related to data tiers. The function uses a helper function, `role_check`, to determine if a role exists in a node's roles. The initial return value dictionary (`retval`) lists all data tiers as `False`, ensuring that only existing tiers are marked as `True` based on the nodes' configurations. The significance of the data tiers lies in their use for data organization and retrieval in Elasticsearch, impacting how data is allocated and queried within the cluster.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/getters.py:get_tier_preference\n    - curator/helpers/getters.py:role_check\n\n- FUNCTION NAME: node_id_to_name\n  - SIGNATURE: def node_id_to_name(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the name of an Elasticsearch node based on the provided node ID.\n\n:param client: A client connection object for interacting with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The identifier of the node for which to retrieve the name.\n:type node_id: str\n\n:returns: The name of the node associated with the given `node_id`, or `None` if not found.\n:rtype: str\n\nThis function interacts with the Elasticsearch client's `NodesClient.info` method to obtain node information. It constructs a filter path based on the `node_id` to access the specific node's details. If the `node_id` is valid and found in the response, the corresponding node name is returned. A logger is used to record an error if no matching node ID is found, and a debug log for the associated name.\n\"\"\"\n```\n\n- FUNCTION NAME: role_check\n  - SIGNATURE: def role_check(role, node_info):\n  - DOCSTRING: \n```python\n\"\"\"\nCheck if a specified role exists in the provided node information.\n\n:param role: The name of the role to check for within the node's roles.\n:type role: str\n:param node_info: A dictionary containing information about the node, including its roles.\n:type node_info: dict\n\n:returns: True if the role is present in the node's roles; otherwise, False.\n:rtype: bool\n\nThis function is used internally in the `get_data_tiers` function to determine the presence of specific data roles (e.g., 'data_hot', 'data_warm', etc.) in the Elasticsearch node configuration.\n\"\"\"\n```\n\n- FUNCTION NAME: get_tier_preference\n  - SIGNATURE: def get_tier_preference(client, target_tier='data_frozen'):\n  - DOCSTRING: \n```python\n\"\"\"\nDetermine the appropriate tier preference string for Elasticsearch data nodes based on the specified target data tier. The function builds a preference list by first checking the available data tiers in the cluster through the `get_data_tiers` function, which returns a dictionary indicating the presence of various data roles.\n\nParameters:\n- client: An instance of the Elasticsearch client, used to interact with the Elasticsearch cluster.\n- target_tier: A string representing the desired tier (e.g., 'data_warm'). The default is 'data_frozen'.\n\nReturns:\n- A comma-separated string indicating the preferred data tiers from coldest to hottest (e.g., 'data_cold,data_warm,data_hot'). If no valid tiers are found, it defaults to returning 'data_content'.\n\nConstants:\n- tiermap: A dictionary mapping tier names to their priority levels, with 'data_content' at the lowest (0) and 'data_frozen' at the highest (4). This mapping determines the order in which tiers are considered when building the preference list.\n\nInteractions:\nThe function utilizes the `get_data_tiers` function to retrieve the statuses of available data tiers in the cluster, which directly influences the output of tier preferences.\n\"\"\"\n```\n  - DEPENDENCIES:\n    - curator/helpers/getters.py:get_data_tiers\n\n- FUNCTION NAME: get_snapshot_data\n  - SIGNATURE: def get_snapshot_data(client, repository=None):\n  - DOCSTRING: \n```python\n\"\"\"\nGet all snapshots from the specified Elasticsearch snapshot repository and return them as a list.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository from which to retrieve snapshots.\n:type repository: str\n\n:raises MissingArgument: If no value for the `repository` parameter is provided.\n:raises FailedExecution: If there is an issue retrieving the snapshot information from the repository, e.g., due to network errors or a non-existent repository.\n\n:returns: A list of all snapshots found in the specified repository.\n:rtype: list\n\nThe function interacts with the Elasticsearch SnapshotClient to fetch snapshot data. It calls the `get` method with `snapshot=\"*\"` to retrieve all snapshots. The actual response is filtered to the `['snapshots']` key to obtain the desired data. This function is reliant on the `es8exc` exception classes to handle specific errors related to Elasticsearch operations.\n\"\"\"\n```\n\n- FUNCTION NAME: get_indices\n  - SIGNATURE: def get_indices(client, search_pattern='_all'):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the list of indices in the Elasticsearch cluster.\n\nThis function interacts with the Elasticsearch client's `CatClient` to obtain the current list of indices based on the provided search pattern. It expands wildcards to include both open and closed indices, and retrieves relevant index details in JSON format.\n\n:param client: A client connection object for interacting with Elasticsearch.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param search_pattern: A pattern for filtering the indices (default is '_all' to retrieve all indices).\n:type search_pattern: str\n\n:returns: A list of index names currently present in the cluster.\n:rtype: list\n\n:raises FailedExecution: If there is an error in retrieving the indices from the Elasticsearch cluster.\n\nThis function uses the `logging` module to log the list of indices. The `expand_wildcards` parameter is set to include both open and closed indices, and the response is handled to extract just the index names for return.\n\"\"\"\n```\n\n- FUNCTION NAME: get_repository\n  - SIGNATURE: def get_repository(client, repository=''):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve configuration information for a specified Elasticsearch snapshot repository.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param repository: The name of the Elasticsearch snapshot repository to query. If not specified, defaults to an empty string.\n:type repository: str\n\n:returns: A dictionary containing configuration details of the specified snapshot repository.\n:rtype: dict\n\n:raises CuratorException: If the repository cannot be retrieved due to a TransportError or NotFoundError, this exception is raised with a message indicating the failure and suggesting to check the Elasticsearch logs for more details.\n\nThis function utilizes the `client.snapshot.get_repository` method from the Elasticsearch Python client to fetch repository details. It handles exceptions specific to the Elasticsearch library, demonstrating dependency on the `elasticsearch8` package for access to snapshot operations.\n\"\"\"\n```\n\n- FUNCTION NAME: get_snapshot\n  - SIGNATURE: def get_snapshot(client, repository=None, snapshot=''):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve information about a specified snapshot from a given Elasticsearch repository.\n\nThis function interacts with the Elasticsearch Snapshot API to fetch details about a specific snapshot or all snapshots in a repository. If no snapshot is specified, it retrieves information for all available snapshots, returning an empty dictionary if none exist. The function raises a MissingArgument exception if the repository parameter is not provided and a FailedExecution exception if there are errors during the API call.\n\nParameters:\n- client (Elasticsearch): A connection object to the Elasticsearch cluster.\n- repository (str): The name of the Elasticsearch snapshot repository from which to retrieve snapshot information.\n- snapshot (str): The name of the snapshot or a comma-separated list of snapshots to obtain info for. If left empty, all snapshots are queried.\n\nReturns:\n- dict: A dictionary containing information about the specified snapshot(s) from the repository.\n\nExceptions:\n- Raises MissingArgument if the repository is not specified.\n- Raises FailedExecution if there is a transport error or if the specified snapshot cannot be found in the repository.\n\nDependencies:\n- Uses `es8exc.TransportError` and `es8exc.NotFoundError` from the elasticsearch8.exceptions module for error handling.\n- Relies on the Elasticsearch Snapshot Client's `get` method for interaction with the Elasticsearch cluster.\n\"\"\"\n```\n\n- FUNCTION NAME: single_data_path\n  - SIGNATURE: def single_data_path(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nCheck if a specified Elasticsearch node is configured with a single filesystem.\n\nThis function retrieves the filesystem statistics of the node identified by `node_id`\nand determines whether it has a single data path. A single filesystem is essential for operations\nlike shard shrinking, as shards cannot span across multiple filesystems.\n\n:param client: A client connection object connected to the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The node identifier whose filesystem configuration is being checked.\n:type node_id: str\n\n:returns: ``True`` if the node has only one filesystem data path, otherwise ``False``.\n:rtype: bool\n\nThis function depends on the Elasticsearch client's `nodes.stats` method, using a filter path\nto retrieve data specifically about the filesystem of the specified node.\n\"\"\"\n```\n\n- FUNCTION NAME: byte_size\n  - SIGNATURE: def byte_size(num, suffix='B'):\n  - DOCSTRING: \n```python\n\"\"\"\nConverts a given number of bytes into a formatted string representation with appropriate size units (e.g., KB, MB, GB). \n\nParameters:\n- num (int): The number of bytes to convert.\n- suffix (str): An optional suffix to append to the size string (default is 'B').\n\nReturns:\n- str: A formatted string indicating the size in bytes with the appropriate unit. The function accommodates sizes up to yottabytes (Y).\n\nThis function iteratively divides the input number by 1024, switching to the next unit in the series, until the absolute value is less than 1024.\n\"\"\"\n```\n\n- FUNCTION NAME: node_roles\n  - SIGNATURE: def node_roles(client, node_id):\n  - DOCSTRING: \n```python\n\"\"\"\nRetrieve the roles assigned to a specified Elasticsearch node.\n\n:param client: A client connection object to interact with the Elasticsearch cluster.\n:type client: :py:class:`~.elasticsearch.Elasticsearch`\n:param node_id: The unique identifier for the node within the cluster.\n:type node_id: str\n\n:returns: A list of roles assigned to the specified node, such as ['data_hot', 'data_warm', etc.].\n:rtype: list\n\nThis function uses the Elasticsearch client to call `NodesClient.info`, filtering the response to obtain only the roles associated with the given `node_id`. It directly accesses the structure of the response where roles are stored under `['nodes'][node_id]['roles']`. The `node_id` must correspond to a valid node in the cluster for the function to return meaningful results.\n\"\"\"\n```\n\n## FILE 2: curator/exceptions.py\n\n# TASK DESCRIPTION:\nIn this project, you need to implement the functions and methods listed above. The functions have been removed from the code but their docstrings remain.\nYour task is to:\n1. Read and understand the docstrings of each function/method\n2. Understand the dependencies and how they interact with the target functions\n3. Implement the functions/methods according to their docstrings and signatures\n4. Ensure your implementations work correctly with the rest of the codebase\n",
  "file_code": {
    "curator/helpers/getters.py": "\"\"\"Utility functions that get things\"\"\"\nimport logging\nfrom elasticsearch8 import exceptions as es8exc\nfrom curator.exceptions import ConfigurationError, CuratorException, FailedExecution, MissingArgument\n\ndef escape_dots(stringval):\n    \"\"\"\n    Escape any dots (periods) in ``stringval``.\n\n    Primarily used for ``filter_path`` where dots are indicators of path nesting\n\n    :param stringval: A string, ostensibly an index name\n\n    :type stringval: str\n\n    :returns: ``stringval``, but with any periods escaped with a backslash\n    :retval: str\n    \"\"\"\n    return stringval.replace('.', '\\\\.')\n\ndef get_write_index(client, alias):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param alias: An alias name\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type alias: str\n\n    :returns: The the index name associated with the alias that is designated\n        ``is_write_index``\n    :rtype: str\n    \"\"\"\n    try:\n        response = client.indices.get_alias(index=alias)\n    except Exception as exc:\n        raise CuratorException(f'Alias {alias} not found') from exc\n    retval = None\n    if len(list(response.keys())) > 1:\n        for index in list(response.keys()):\n            try:\n                if response[index]['aliases'][alias]['is_write_index']:\n                    retval = index\n            except KeyError as exc:\n                raise FailedExecution('Invalid alias: is_write_index not found in 1 to many alias') from exc\n    else:\n        retval = list(response.keys())[0]\n    return retval\n\ndef index_size(client, idx, value='total'):\n    \"\"\"\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.stats`\n\n    :param client: A client connection object\n    :param idx: An index name\n    :param value: One of either ``primaries`` or ``total``\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type value: str\n\n    :returns: The sum of either ``primaries`` or ``total`` shards for index ``idx``\n    :rtype: integer\n    \"\"\"\n    fpath = f'indices.{escape_dots(idx)}.{value}.store.size_in_bytes'\n    return client.indices.stats(index=idx, filter_path=fpath)['indices'][idx][value]['store']['size_in_bytes']\n\ndef meta_getter(client, idx, get=None):\n    \"\"\"Meta Getter\n    Calls :py:meth:`~.elasticsearch.client.IndicesClient.get_settings` or\n    :py:meth:`~.elasticsearch.client.IndicesClient.get_alias`\n\n    :param client: A client connection object\n    :param idx: An Elasticsearch index\n    :param get: The kind of get to perform, e.g. settings or alias\n\n    :type client: :py:class:`~.elasticsearch.Elasticsearch`\n    :type idx: str\n    :type get: str\n\n    :returns: The settings from the get call to the named index\n    :rtype: dict\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    acceptable = ['settings', 'alias']\n    if not get:\n        raise ConfigurationError('\"get\" can not be a NoneType')\n    if get not in acceptable:\n        raise ConfigurationError(f'\"get\" must be one of {acceptable}')\n    retval = {}\n    try:\n        if get == 'settings':\n            retval = client.indices.get_settings(index=idx)[idx]['settings']['index']\n        elif get == 'alias':\n            retval = client.indices.get_alias(index=idx)[idx]['aliases']\n    except es8exc.NotFoundError as missing:\n        logger.error('Index %s was not found!', idx)\n        raise es8exc.NotFoundError from missing\n    except KeyError as err:\n        logger.error('Key not found: %s', err)\n        raise KeyError from err\n    except Exception as exc:\n        logger.error('Exception encountered: %s', exc)\n    return retval",
    "curator/exceptions.py": "\"\"\"Curator Exceptions\"\"\"\n\nclass CuratorException(Exception):\n    \"\"\"\n    Base class for all exceptions raised by Curator which are not Elasticsearch\n    exceptions.\n    \"\"\"\n\nclass ConfigurationError(CuratorException):\n    \"\"\"\n    Exception raised when a misconfiguration is detected\n    \"\"\"\n\nclass MissingArgument(CuratorException):\n    \"\"\"\n    Exception raised when a needed argument is not passed.\n    \"\"\"\n\nclass NoIndices(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty index_list\n    \"\"\"\n\nclass NoSnapshots(CuratorException):\n    \"\"\"\n    Exception raised when an operation is attempted against an empty snapshot_list\n    \"\"\"\n\nclass ActionError(CuratorException):\n    \"\"\"\n    Exception raised when an action (against an index_list or snapshot_list) cannot be taken.\n    \"\"\"\n\nclass FailedExecution(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to execute for some reason.\n    \"\"\"\n\nclass SnapshotInProgress(ActionError):\n    \"\"\"\n    Exception raised when a snapshot is already in progress\n    \"\"\"\n\nclass ActionTimeout(CuratorException):\n    \"\"\"\n    Exception raised when an action fails to complete in the allotted time\n    \"\"\"\n\nclass FailedSnapshot(CuratorException):\n    \"\"\"\n    Exception raised when a snapshot does not complete with state SUCCESS\n    \"\"\"\n\nclass FailedRestore(CuratorException):\n    \"\"\"\n    Exception raised when a Snapshot Restore does not restore all selected indices\n    \"\"\"\n\nclass FailedReindex(CuratorException):\n    \"\"\"\n    Exception raised when failures are found in the reindex task response\n    \"\"\"\n\nclass ClientException(CuratorException):\n    \"\"\"\n    Exception raised when the Elasticsearch client and/or connection is the source of the problem.\n    \"\"\"\n\nclass LoggingException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot either log or configure logging\n    \"\"\"\n\nclass RepositoryException(CuratorException):\n    \"\"\"\n    Exception raised when Curator cannot verify a snapshot repository\n    \"\"\"\n\nclass SearchableSnapshotException(CuratorException):\n    \"\"\"\n    Exception raised when Curator finds something out of order with a Searchable Snapshot\n    \"\"\""
  }
}